This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
ba/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          master
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        master
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    workflows/
      lint.yaml
    CODEOWNERS
    dependabot.yaml
  aws_guardduty_malware_protection_plans/
    marketplace/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    openinvoice/
      data.tf
      main.tf
      notify-teams.py
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    .terraform-version
  cdn-mineralsoft/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    variables.tf
    versions.tf
  codebuild/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    outputs.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  consul-aws/
    .terraform-version
    aws_ec2_managed_prefix_list.tf
    data.tf
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    route53.tf
    variables.tf
    versions.tf
  edge-proxy/
    templates/
      custom.sh.tpl
    .terraform-version
    aws_ec2_managed_prefix_list.tf
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  elasticache-mineralsoft/
    .terraform-version
    aws_ec2_managed_prefix_list.tf
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  elasticsearch-cluster/
    jaeger/
      .terraform-version
      aws_ec2_managed_prefix_list.tf
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      variables.tf
  elasticsearch-service/
    main.tf
  elasticsearch-service-role/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  epayables/
    secrets/
      .terraform-version
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      variables.tf
      versions.tf
  grafana/
    datasources/
      .terraform-version
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      dev-uw2.backend.tfvars
      dev-uw2.tfvars
      main.tf
      Makefile
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      prod-uw2.backend.tfvars
      prod-uw2.tfvars
      README.md
      variables.tf
      versions.tf
    firehose/
      dashboards/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        firehose-template.json.tpl
        main.tf
        prod.backend.tfvars
        prod.tfvars
        providers.tf
        variables.tf
  iam/
    backup-data/
      .terraform-version
      main.tf
      oi-backup-data.tf
      preprod.backend.tfvars
      preprod.tfvars
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    codebuild/
      .terraform-version
      dev.backend.tfvars
      main.tf
      variables.tf
      versions.tf
    dms/
      .terraform-version
      dev.backend.tfvars
      main.tf
      preprod.backend.tfvars
      prod.backend.tfvars
      variables.tf
      versions.tf
    mineralsoft/
      .terraform-version
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      mineralsoft-user.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      variables.tf
      versions.tf
    revenue-data/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      el-revenue-data.tf
      main.tf
      odx-revenue-data.tf
      pds-revenue-data.tf
      prod.backend.tfvars
      prod.tfvars
      revenue-data-reader.tf
      variables.tf
      versions.tf
    s3-batch-operations/
      minerals-migration/
        .terraform-version
        main.tf
        preprod.backend.tfvars
        preprod.tfvars
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
    s3-cross-account-access/
      minerals-migration/
        .terraform-version
        preprod.backend.tfvars
        preprod.tfvars
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
    users/
      policies/
        genai-bidout-policy.json
        sw-attachment-reader-policy.json
      .terraform-version
      bedrock.tf
      bidout.tf
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      oi-fundthrough-user.tf
      preprod-ue1.backend.tfvars
      preprod-ue1.tfvars
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      refinery-user.tf
      sw-attachment-reader.tf
      terraform-migration.tf
      variables.tf
      versions.tf
  invoiceclassifier-lambda/
    .terraform-version
    dev-ue1.backend.tfvars
    main.tf
    variables.tf
    versions.tf
  jenkins/
    terraform.yaml
  mobile-dmz/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    load_balancer.tf
    variables.tf
    versions.tf
    vpc_endpoint.tf
  mobile-dmz-ue1/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    load_balancer.tf
    variables.tf
    versions.tf
    vpc_endpoint.tf
  mongodb/
    bidout-project/
      .terraform-version
      data.tf
      dev.backend.tfvars
      dev.tfvars
      main.tf
      outputs.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      vault.tf
      versions.tf
  nomad-cluster-aws/
    client/
      .terraform-version
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      nomad-batch.tf
      nomad-service.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      prod-uw2.backend.tfvars
      prod-uw2.tfvars
      variables.tf
      versions.tf
    server/
      .terraform-version
      aws_ec2_managed_prefix_list.tf
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      prod-uw2.backend.tfvars
      prod-uw2.tfvars
      variables.tf
      versions.tf
  nomad-cluster-aws-scheduler/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    nomad-scheduler-job.tpl
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    scheduler.tf
    variables.tf
    versions.tf
  openticket-mobile-service/
    secrets/
      .terraform-version
      main.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      variables.tf
      versions.tf
  rds/
    kms/
      rds-mineralsoft/
        .terraform-version
        dev-ue1.backend.tfvars
        dev-ue1.tfvars
        main.tf
        prod-ue1.backend.tfvars
        prod-ue1.tfvars
        variables.tf
        versions.tf
    rds-lambda-snapshot/
      .gitignore
      .terraform-version
      main.tf
      Makefile
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      rds_snapshot_create_lambda.py
      rds_snapshot_share_lambda.py
      README.md
      variables.tf
      versions.tf
    rds-minerals-jpm-historical/
      versions.tf
    rds-redash/
      .terraform-version
      aws_ec2_managed_prefix_list.tf
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      variables.tf
      versions.tf
  route-53/
    regional-services/
      .terraform-version
      data.tf
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      preprod-ue1.backend.tfvars
      preprod-ue1.tfvars
      prod-ue1.backend.tfvars
      prod-ue1.tfvars
      prod-uw2.backend.tfvars
      prod-uw2.tfvars
      route53.tf
      variables.tf
      versions.tf
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
    zone.tf
  route-53-resolver/
    .terraform-version
    aws_ec2_managed_prefix_list.tf
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    dev-uw2.backend.tfvars
    dev-uw2.tfvars
    main.tf
    preprod-ue1.backend.tfvars
    preprod-ue1.tfvars
    preprod-uw2.backend.tfvars
    preprod-uw2.tfvars
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  s3/
    .terraform-version
    chef-validator.tf
    dev.backend.tfvars
    jenkins-backups.tf
    main.tf
    minerals.tf
    prod.backend.tfvars
    variables.tf
    versions.tf
  s3-buckets/
    files/
      spendanalytics.json
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  s3-enverus-ba-log-archive/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    variables.tf
    versions.tf
  s3-minerals/
    bucket_policies/
      preprod-policy.json
      prod-policy.json
    source_bucket_policies/
      minerals.json
    .terraform-version
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    variables.tf
    versions.tf
  s3-minerals-dr/
    .terraform-version
    main.tf
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  s3-openticket-mobile/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    s3.tf
    variables.tf
    versions.tf
  shouldcost-service/
    secrets/
      .terraform-version
      dev-ue1.backend.tfvars
      dev-ue1.tfvars
      main.tf
      variables.tf
      versions.tf
  ssl-certificates/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  ssl-certificates-minerals/
    .terraform-version
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  vault/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  vault_azuread_sso/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  vault_mounts/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  vault_policies_and_roles/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  vpc/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    us-east-1.tf
    us-west-2.tf
    variables.tf
    versions.tf
  waf/
    .terraform-version
    dev-ue1.backend.tfvars
    dev-ue1.tfvars
    main.tf
    preprod-ue1.backend.tfvars
    preprod-ue1.tfvars
    preprod-uw2.backend.tfvars
    preprod-uw2.tfvars
    prod-ue1.backend.tfvars
    prod-ue1.tfvars
    prod-uw2.backend.tfvars
    prod-uw2.tfvars
    variables.tf
    versions.tf
  _dependency_graph.json
  .gitignore
  .pre-commit-config.yaml
  .tflint.hcl
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  README.md
cts/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    workflows/
      update-runner-ami.yaml
    CODEOWNERS
    dependabot.yaml
  acm/
    cts_enverus_com/
      .terraform-version
      acm.tf
      dev.backend.tfvars
      prod.backend.tfvars
      variables.tf
      versions.tf
  artifactory/
    .terraform-version
    access-tokens.tf
    groups.tf
    permission-targets.tf
    prod.backend.tfvars
    prod.tfvars
    repositories.tf
    TransitionREADME.md
    variables.tf
    versions.tf
  auth/
    auth0-backup/
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  central-terraform-state-storage-bucket/
    .terraform-version
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  chef-infra-server/
    .terraform-version
    instance-role.tf
    main.tf
    prod.backend.tfvars
    prod.tfvars
    s3-buckets.tf
    variables.tf
    versions.tf
  cloudfront/
    rudderstack/
      .terraform-version
      acm.tf
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      route53.tf
      variables.tf
      versions.tf
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    outputs.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  consul-cluster/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  ecr/
    .terraform-version
    ecr.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  ecr-pull-through-cache/
    .terraform-version
    data.tf
    ecr.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  enverus-cts/
    cts.terraform.tfvars
  github/
    oidc/
      custom-roles/
        packer/
          .terraform-version
          dev.backend.tfvars
          dev.tfvars
          main.tf
          prod.backend.tfvars
          prod.tfvars
          variables.tf
          versions.tf
        .terraform-version
      idp/
        .terraform-version
        dev.backend.tfvars
        main.tf
        prod.backend.tfvars
        variables.tf
        versions.tf
      sre-roles/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        main.tf
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
    runners/
      templates/
        ba-runner-configs/
          x64-lg.yaml
          x64.yaml
        bidout-runner-configs/
          x64-lg.yaml
          x64.yaml
        cts-runner-configs/
          x64-lg.yaml
          x64.yaml
        ea-runner-configs/
          arm64-lg.yaml
          x64-lg.yaml
          x64.yaml
        nv-runner-configs/
          x64-lg.yaml
          x64.yaml
        pr-runner-configs/
          x64-lg.yaml
          x64.yaml
        rseg-runner-configs/
          x64-lg.yaml
          x64.yaml
        sandbox-runner-configs/
          arm64-lg.yaml
          x64-lg.yaml
          x64.yaml
        tr-runner-configs/
          x64-lg.yaml
          x64.yaml
      .terraform-version
      iam.tf
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      vault.tf
      versions.tf
    s3/
      .terraform-version
      buckets.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    secrets-manager/
      files/
        sre-gha-secrets-reader-role-policy.json
        trust-policy.json.tpl
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      variables.tf
      versions.tf
  github-enterprise-importer/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    README.md
    variables.tf
    versions.tf
  github-organization-secrets/
    artifactory/
      module/
        github-org-secret.tf
        inputs.tf
        versions.tf
      .terraform-version
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    redgate-sqlcompare/
      module/
        inputs.tf
        redgate-sqlcompare-database-credentials.tf
        versions.tf
      .terraform-version
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  github-sso/
    azuread-groups/
      .terraform-version
      data.tf
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    bid-out/
      .terraform-version
      azuread_application.tf
      data.tf
      members.tf
      prod.backend.tfvars
      service_principal.tf
      versions.tf
    business-analytics/
      .terraform-version
      azuread_application.tf
      data.tf
      prod.backend.tfvars
      service_principal.tf
      versions.tf
    drillinginfo/
      .terraform-version
      main.tf
      outputs.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    pearlstreettechnologies/
      .terraform-version
      azuread_application.tf
      data.tf
      members.tf
      prod.backend.tfvars
      service_principal.tf
      versions.tf
  grafana/
    access-policies/
      open-invoice/
        .terraform-version
        main.tf
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
      prism/
        .terraform-version
        main.tf
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
    dashboards/
      templates/
        accounts-service/
          failures_accounts_service_dev_panels/
            accounts_service_errors_alert_rule.json
            accounts_service_errors_panel.json
            accounts_service_salesforce_errors_alert_rule.json
            accounts_service_salesforce_errors_panel.json
          failures_accounts_service_preprod_panels/
            accounts_service_errors_alert_rule.json
            accounts_service_errors_panel.json
            accounts_service_salesforce_errors_alert_rule.json
            accounts_service_salesforce_errors_panel.json
          failures_accounts_service_prod_panels/
            accounts_service_errors_alert_rule.json
            accounts_service_errors_panel.json
            accounts_service_salesforce_errors_alert_rule.json
            accounts_service_salesforce_errors_panel.json
          failures_firehose_dev_panels/
            failures_firehose_alert_rule.json
            failures_firehose_panel.json
          failures_firehose_preprod_panels/
            failures_firehose_alert_rule.json
            failures_firehose_panel.json
          failures_firehose_prod_panels/
            failures_firehose_alert_rule.json
            failures_firehose_panel.json
          failures_load_balancer_dev_panels/
            failures_load_balancer_alert_rule.json
            failures_load_balancer_panel.json
            failures_load_balancer_targets_alert_rule.json
            failures_load_balancer_targets_panel.json
            failures_load_balancer_unhealthy_hosts_alert_rule.json
            failures_load_balancer_unhealthy_hosts_panel.json
          failures_load_balancer_preprod_panels/
            failures_load_balancer_alert_rule.json
            failures_load_balancer_panel.json
            failures_load_balancer_targets_alert_rule.json
            failures_load_balancer_targets_panel.json
            failures_load_balancer_unhealthy_hosts_alert_rule.json
            failures_load_balancer_unhealthy_hosts_panel.json
          failures_load_balancer_prod_panels/
            failures_load_balancer_alert_rule.json
            failures_load_balancer_panel.json
            failures_load_balancer_targets_alert_rule.json
            failures_load_balancer_targets_panel.json
            failures_load_balancer_unhealthy_hosts_alert_rule.json
            failures_load_balancer_unhealthy_hosts_panel.json
          failures_other_apps_dev_panels/
            failures_other_apps_admin_portal_alert_rule.json
            failures_other_apps_admin_portal_panel.json
            failures_other_apps_prism_alert_rule.json
            failures_other_apps_prism_panel.json
          failures_other_apps_preprod_panels/
            failures_other_apps_admin_portal_alert_rule.json
            failures_other_apps_admin_portal_panel.json
            failures_other_apps_prism_alert_rule.json
            failures_other_apps_prism_panel.json
          failures_other_apps_prod_panels/
            failures_other_apps_admin_portal_alert_rule.json
            failures_other_apps_admin_portal_panel.json
            failures_other_apps_prism_alert_rule.json
            failures_other_apps_prism_panel.json
          drill_in_kubernetes.json
          drill_in_nomad_2.json
          drill_in_nomad.json
          failures_accounts_service_dev.json
          failures_accounts_service_preprod.json
          failures_accounts_service_prod.json
          failures_firehose_dev.json
          failures_firehose_preprod.json
          failures_firehose_prod.json
          failures_load_balancer_dev.json
          failures_load_balancer_preprod.json
          failures_load_balancer_prod.json
          failures_other_apps_dev.json
          failures_other_apps_preprod.json
          failures_other_apps_prod.json
          nodejs_application_kubernetes.json
          nodejs_application_nomad.json
          view_kubernetes_2.json
          view_nomad_2.json
      dev.backend.tfvars
      dev.tfvars
      main.tf
      variables.tf
      versions.tf
    datasources/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    service-accounts/
      .terraform-version
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  iam/
    hci/
      .terraform-version
      data.tf
      prod.backend.tfvars
      service_principal_awx.tf
      sre-azure-stack-hci-secret.tf
      variables.tf
      versions.tf
    policies/
      github-action-runner/
        .terraform-version
        main.tf
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
    roles/
      argo-cd-sts/
        .terraform-version
        dev.backend.tfvars
        main.tf
        prod.backend.tfvars
        variables.tf
        versions.tf
      ssm-agent/
        .terraform-version
        dev.backend.tfvars
        prod.backend.tfvars
        ssmAgent.tf
        variables.tf
        versions.tf
      tf-atlantis-test/
        .terraform-version
        dev.backend.tfvars
        main.tf
        variables.tf
        versions.tf
  kubecost/
    .terraform-version
    dev.backend.tfvars
    federated-store.yaml.tftpl
    main.tf
    prod.backend.tfvars
    variables.tf
    versions.tf
  lambda/
    bottlerocket-parameter/
      EKSPortions/
        iam.tf
        lambda.tf
        nodegroup_update_iam.json
        nodegroup_update_lambda.py
        README.md
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      lambda_function.py
      main.tf
      outputs.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    github-bots/
      repo-settings-manager/
        files/
          bucket-policy.json.tpl
          lambda-cross-account-access-policy.json
          oidc_lambda_maintenance_policy.tpl
          oidc_lambda_maintenance_trust_policy.tpl
          secret-policy.json.template
        .terraform-version
        app-gateway.tf
        aws-secrets-manager.tf
        dev.backend.tfvars
        dev.tfvars
        iam.tf
        lambda-function.tf
        main.tf
        prod.backend.tfvars
        prod.tfvars
        variables.tf
        versions.tf
  packer/
    .terraform-version
    packer-iam-user.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  rds/
    awx/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  route53/
    cts/
      .terraform-version
      dev.backend.tfvars
      prod.backend.tfvars
      resolver.tf
      variables.tf
      versions.tf
      zones.tf
    enverus_com_subzones/
      .terraform-version
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
      zones.tf
  s3-buckets/
    policies/
      chef-validator.json.tpl
    .terraform-version
    buckets.tf
    dev.backend.tfvars
    dev.tfvars
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  sre-hackathon/
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  sre-windows-utility/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    README.md
    variables.tf
    versions.tf
  testing/
    atlantis/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      variables.tf
      versions.tf
    consul-aws/
      .terraform-version
      consul.tf
      dev.backend.tfvars
      dev.tfvars
      variables.tf
      versions.tf
    di_es_regulatory/
      master/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        main.tf
        README.md
        variables.tf
        versions.tf
      README.md
    nomad-cluster/
      nomad-client-service/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        main.tf
        variables.tf
        versions.tf
      nomad-scheduler/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        nomad-scheduler-job.tpl
        scheduler.tf
        variables.tf
        versions.tf
      nomad-server/
        .terraform-version
        dev.backend.tfvars
        dev.tfvars
        main.tf
        variables.tf
        versions.tf
  vault_azuread_sso_cts/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    import.tf_
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_cts/
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_mounts/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_policies_and_roles/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_secrets/
    .terraform-version
    main.tf
    prod.backend.tfvars
    variables.tf
    versions.tf
  vault_token/
    .terraform-version
    main.tf
    prod.backend.tfvars
    variables.tf
    versions.tf
  vpc/
    destroy/
      pcx-02031e7eefce8d289/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-05b06763d8a6a1eaa/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-07247a9287ae0491f/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-08ad6f18e7be5b5c5/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-0c5ec45fa78af0411/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-0d89179c6f96fcc0d/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-0fb92a6cb59559c65/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
      pcx-d0e587b9/
        .terraform-version
        0generated.tf
        accepter.tf
        dev.backend.tfvars
        dev.tfvars
        requester.tf
        variables.tf
        versions.tf
    eu-north-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    eu-west-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    us-east-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    us-west-2/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  _dependency_graph.json
  .gitignore
  .pre-commit-config.yaml
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  README.md
  temp_test_graph.py
ea/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    CODEOWNERS
    dependabot.yaml
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    outputs.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  github-webhooks/
    atlantis/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      variables.tf
      versions.tf
  iam/
    bedrock-cross-account-invocation/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  prism-alerts/
    s3-bucket/
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  vpc/
    us-east-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    us-west-2/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      moved.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  _dependency_graph.json
  .gitignore
  .pre-commit-config.yaml
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  README.md
egress/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    workflows/
      ci-release.yaml
      ci-terraform.yaml
      pr-labeler.yaml
      pr-lint.yaml
    CODEOWNERS
    dependabot.yaml
    pr-labeler.yaml
  examples/
    vpc/
      main.tf
  _dependency_graph.json
  .gitignore
  .releaserc
  .semver-output
  .terraform-version
  CHANGELOG.md
  clould-wan.tf
  dhcp_options.tf
  egress_dependency_graph.json
  elastic_ips.tf
  endpoints.tf
  internet_gateways.tf
  locals.tf
  Makefile
  nat_gateways.tf
  network_interfaces.tf
  outputs.tf
  package.json
  prefix_list.tf
  README.md
  route_tables.tf
  route53_profiles.tf
  route53_records.tf
  route53_zones.tf
  security_groups.tf
  subnets.tf
  variables.tf
  versions.tf
  vpc.tf
gen-ai/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  iam/
    bedrock_knowledge_base_role.tf
    bedrockrole_assume_role.tf
    data.tf
    dev.backend.tfvars
    prod.backend.tfvars
    variables.tf
    versions.tf
  route53/
    .terraform-version
    dev.backend.tfvars
    dns.excalidraw
    prod.backend.tfvars
    prod.tfvars
    records.tf
    resolver.tf
    variables.tf
    versions.tf
    zones.tf
  s3/
    .terraform-version
    dev.backend.tfvars
    main.tf
    prod.backend.tfvars
    variables.tf
    versions.tf
  vpc/
    eu-north-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    eu-west-1/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    us-east-1/
      .terraform-version
      data.tf
      dev.backend.tfvars
      dev.tfvars
      endpoints.tf
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
    us-west-2/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  _dependency_graph.json
  .gitignore
  .pre-commit-config.yaml
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  README.md
networking/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    workflows/
      teams-notification.yaml
    CODEOWNERS
    dependabot.yaml
  acm/
    .terraform-version
    cert.tf
    dev.backend.tfvars
    main.tf
    variables.tf
  atlantis-github-webhook-infra/
    github-org-webhooks/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      variables.tf
      versions.tf
    .gitignore
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    outputs.tf
    README.md
    terraform.tfvars.sample
    variables.tf
    versions.tf
  cloud-wan/
    .terraform-version
    cloudwan-policy.tf
    data.tf
    design.excalidraw
    dev.backend.tfvars
    dev.tfvars
    flowlogs.tf
    locals.tf
    main.tf
    outputs.tf
    prod.backend.tfvars
    prod.tfvars
    resource-sharing.tf
    variables.tf
    versions.tf
    vpc.tf
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    outputs.tf
    README.md
    variables.tf
    versions.tf
  consul-cluster/
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  direct-connect/
    _off_dev.backend.tfvars_off
    _off_dev.tfvars_off
    .terraform-version
    connection.tf
    dev.backend.tfvars
    dev.tfvars
    gateway.tf
    outputs.tf
    variables.tf
    versions.tf
    virtual-interfaces.tf
  eks/
    lbc-crd/
      crds.yaml
      kustomization.yaml
    manifests/
      dashboard/
        dashboard-admin.yaml
        dashboard-ingress.yaml
        deployment.yaml
    policies/
      external-dns.json
      iam-policy.json
    .terraform-version
    dashboard.tf
    dev.backend.tfvars
    dev.tfvars
    eks-cluster.tf
    external-dns.tf
    general-purpose-alb.tf
    helm_packages.tf
    helm.tf
    kubernetes.tf
    launchtemplate.tf
    lb-controller.tf
    outputs.tf
    security-groups.tf
    userdata.sh.tpl
    variables.tf
    versions.tf
  github-actions-for-ghe/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  github-oidc/
    policies/
      github_oidc_resource_policy.json
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    README.md
    variables.tf
    versions.tf
  grafana/
    datasources/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      Makefile
      README.md
      variables.tf
      versions.tf
  iam/
    users/
      .terraform-version
      atlantis_assume_role_cross_account.tf
      dev.backend.tfvars
      variables.tf
      versions.tf
  route-53/
    .terraform-version
    dev.backend.tfvars
    resolver.tf
    variables.tf
    versions.tf
    zones.tf
  s3/
    .terraform-version
    aviatrix.tf
    chef-validator.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
  shared-managed-prefix-lists/
    module/
      managed-prefix-list/
        main.tf
        README.md
        versions.tf
    .terraform-version
    main.tf
    prod.backend.tfvars
    README.md
    variables.tf
    versions.tf
  vault/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  vault_azuread_sso/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  vault_mounts/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  vault_policies_and_roles/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    variables.tf
    versions.tf
  vpc/
    vpc-dev/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      variables.tf
      versions.tf
  _dependency_graph.json
  .gitattributes
  .gitignore
  .pre-commit-config.yaml
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  networking_dependency_graph.json
pr/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    CODEOWNERS
    dependabot.yaml
  acm/
    .terraform-version
    acm.tf
    dev.backend.tfvars
    prod.backend.tfvars
    variables.tf
    versions.tf
  config/
    remediation/
      documents/
        automation/
          ec2-ebs-encryption-by-default-remediation.yaml
          kms-cmk-not-scheduled-for-deletion-remediation.yaml
      data.tf
      document_kms_cmk_not_scheduled_for_deletion.tf
      documents_ec2_ebs_encryption_by_default.tf
      iam.tf
      parameters.tf
      remediation_ec2_ebs_encryption_by_default.tf
      remediation_kms_cmk_not_scheduled_for_deletion.tf
      variables.tf
      versions.tf
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  consul/
    .terraform-version
    aws_ec2_managed_prefix_list.tf
    data.tf
    dev.backend.tfvars
    dev.tfvars
    load-balancer.tf
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  grafana/
    datasources/
      .terraform-version
      dev.backend.tfvars
      dev.tfvars
      main.tf
      prod.backend.tfvars
      prod.tfvars
      variables.tf
      versions.tf
  route-53/
    .terraform-version
    dev.backend.tfvars
    prod.backend.tfvars
    resolver.tf
    variables.tf
    versions.tf
    zones.tf
  s3-buckets/
    policies/
      chef-validator.json.tpl
    .terraform-version
    buckets.tf
    dev.backend.tfvars
    dev.tfvars
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault/
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_azuread_sso/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vault_policies_and_roles/
    .terraform-version
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  vpc/
    .terraform-version
    data.tf
    dev.backend.tfvars
    dev.tfvars
    main.tf
    prod.backend.tfvars
    prod.tfvars
    variables.tf
    versions.tf
  _dependency_graph.json
  .gitattributes
  .gitignore
  .pre-commit-config.yaml
  atlantis.yaml
  global-dev-backend.tfvars
  global-dev.tfvars
  global-prod-backend.tfvars
  global-prod.tfvars
  README.md
vpc/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      update.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            HEAD
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    HEAD
    packed-refs
  .github/
    workflows/
      ci-release.yaml
      ci-terraform.yaml
      pr-labeler.yaml
      pr-lint.yaml
    dependabot.yaml
    pr-labeler.yaml
  examples/
    vpc/
      main.tf
  jenkins/
    aws-vpc.yaml
  _dependency_graph.json
  .gitignore
  .pre-commit-config.yaml
  .releaserc
  .semver-output
  .terraform-version
  CHANGELOG.md
  clould-wan.tf
  data_sources.tf
  dhcp_options.tf
  eks_cgnat.tf
  elastic_ips.tf
  endpoints.tf
  flowlogs.tf
  internet_gateways.tf
  locals.tf
  Makefile
  nacl.tf
  nat_gateways.tf
  network_interfaces.tf
  outputs.tf
  package.json
  prefix_list.tf
  README.md
  route_tables.tf
  route53_profile_associations.tf
  security_groups.tf
  subnets.tf
  variables.tf
  versions.tf
  vpc_dependency_graph.json
  vpc.tf

================================================================
Files
================================================================

================
File: ba/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: ba/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: ba/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: ba/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: ba/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: ba/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: ba/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: ba/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: ba/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: ba/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: ba/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: ba/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: ba/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: ba/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: ba/.git/logs/refs/heads/master
================
0000000000000000000000000000000000000000 f33df6cff20b49b08158f85b83bb7b0e5fcb90ae Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406145 -0600	clone: from github.com:enverus-cts/sre.ba.terraform.git

================
File: ba/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 f33df6cff20b49b08158f85b83bb7b0e5fcb90ae Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406145 -0600	clone: from github.com:enverus-cts/sre.ba.terraform.git

================
File: ba/.git/logs/HEAD
================
0000000000000000000000000000000000000000 f33df6cff20b49b08158f85b83bb7b0e5fcb90ae Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406145 -0600	clone: from github.com:enverus-cts/sre.ba.terraform.git

================
File: ba/.git/refs/heads/master
================
f33df6cff20b49b08158f85b83bb7b0e5fcb90ae

================
File: ba/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/master

================
File: ba/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.ba.terraform.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master
	vscode-merge-base = origin/master

================
File: ba/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: ba/.git/HEAD
================
ref: refs/heads/master

================
File: ba/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
c63435dde60fa1569a3537b8e832f18c9fe1c70d refs/remotes/origin/ENL-6859-ms-codebuild-secrets-manager
d3ec89058c929d336dfed318c6c92551c4b737a9 refs/remotes/origin/ODXBMA-15723
aa48fc966e2baa371534a228ffa57fe036352c20 refs/remotes/origin/SRE-14129-replace-jaeger-prod
ac0446f3d763cff5e1e13f0b82ab967b03bf41b7 refs/remotes/origin/SRE-14188_deploy_mondoo_integration_cf_stack
6d71c498b54c8a54fae9795b14a7a4bee6dc0d09 refs/remotes/origin/SRE-14820-add-PR-checks
452b9f1dba3b43670143e77d54b9defea0df7d1c refs/remotes/origin/SRE-15398-edge-proxy-count
b4d99a883b6889c969093175f7e5936cc53320da refs/remotes/origin/SRE-9511
a15c12b47d19ed6c45e4fe2084cefcca80fd1965 refs/remotes/origin/SRE-9980_Apply_template_to_propogate_new_ami
70633731a0b1bf84d4e09ac1dac6640382b6882a refs/remotes/origin/delete-s3-buckets-trigger-only
4919863b01c273771245931f42352f2c5ea8e0f4 refs/remotes/origin/feat/SRE-12315_Update_Trust_policy_for_new_atlantis_irsa
3f86468aadc8d962b9653564cabc1cf313ba2a5c refs/remotes/origin/feat/sre-12427-add-vault-mount
d202a4b95e77492d2fbef21509a9b63ca072d2d4 refs/remotes/origin/feat/sre-15060-use-alloy
f33df6cff20b49b08158f85b83bb7b0e5fcb90ae refs/remotes/origin/master
ae507c7e821f4596724dc1f7ab6db800a3c4a417 refs/remotes/origin/ms/DEV-elasticsearch-instance-upgrade
61125511d6edbea69b911d1d0d7f82932a1ce734 refs/remotes/origin/ms/PREPROD-remove-redash-RDS-1-31-2023
4271c98ef44541af5229495f3a67219c40e13938 refs/remotes/origin/ms/elasticsearch-upgrade-20230112
87fae10aaea9fe779f7ddd3d8f9014ea7f6057d7 refs/remotes/origin/nexus-477
283c69bd6c814d5b15c9a1fd5776dc79ffac55fe refs/remotes/origin/remove-nomad-preprod
70bc46b1f5befca2669b92650ab358f770a041ba refs/remotes/origin/update-launchconfig
b8713b313f4291e59b783270444a090971f5c6fb refs/remotes/origin/update-ms-node-type

================
File: ba/.github/workflows/lint.yaml
================
name: Terraform Lint

on:
  pull_request:
    paths:
      - '**/*.tf'
      - '**/*.tfvars'
      - '.github/workflows/lint.yaml'

jobs:
  detect-changes:
    runs-on: enverus-ubuntu
    outputs:
      tf_dirs: ${{ steps.find-changed-tf-dirs.outputs.dirs }}
    steps:
      - uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@ed68ef82c095e0d48ec87eccea555d944a631a4c # v46
        with:
          dir_names: true

      - name: Find changed Terraform directories
        id: find-changed-tf-dirs
        run: |
          echo "Changed directories:"
          echo "${{ steps.changed-files.outputs.all_changed_files }}"

          # Filter directories containing .tf or .tfvars files
          DIRS=$(
            for dir in ${{ steps.changed-files.outputs.all_changed_files }}; do
              if [ -n "$(find "$dir" -maxdepth 1 -name '*.tf' -o -name '*.tfvars' 2>/dev/null)" ]; then
                echo "$dir"
              fi
            done | sort -u | jq -R -s -c 'split("\n")[:-1]'
          )

          echo "Found Terraform directories: $DIRS"
          echo "dirs=$DIRS" >> $GITHUB_OUTPUT

  lint:
    needs: detect-changes
    if: needs.detect-changes.outputs.tf_dirs != '[]' && needs.detect-changes.outputs.tf_dirs != ''
    runs-on: enverus-ubuntu
    strategy:
      matrix:
        dir: ${{ fromJson(needs.detect-changes.outputs.tf_dirs) }}
    steps:
      - uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0

      - name: Get github app pem key base64
        id: github-app-creds
        uses: enverus-cts/action-sre-vault-retrieve-secret@v1.0.1
        with:
          secret-path: "enverus-cts/github/enverus-cts/gh-app-action-workflow-rw"
          vault-server: "https://vault.prod.cts.enverus.com/"

      - name: Decode the GitHub App Private Key
        id: decode
        shell: bash
        run: |
          private_key=$(echo "${{ steps.github-app-creds.outputs.githubAppPrivateKeyB64 }}" | base64 -d | awk 'BEGIN {ORS="\\n"} {print}' | head -c -2) &> /dev/null
          echo "::add-mask::$private_key"
          echo "private-key=$private_key" >> "$GITHUB_OUTPUT"

      - name: Get token
        uses: actions/create-github-app-token@0f859bf9e69e887678d5bbfbee594437cb440ffe # v2.1.0
        id: app-token
        with:
          app-id: ${{ steps.github-app-creds.outputs.githubAppID }}
          private-key: ${{ steps.decode.outputs.private-key }}
          owner: "enverus-cts"

      - name: git insteadOf
        run: |
          git config --global url."https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/".insteadOf ssh://git@github.com/
          git config --global user.name "Enverus CI"
          git config --global user.email 'ci@enverus.com'
        shell: bash

      - name: Setup TFLint
        uses: terraform-linters/setup-tflint@90f302c255ef959cbfb4bd10581afecdb7ece3e6 # v4.1.1
 
      - name: Run TFLint with reviewdog
        uses: reviewdog/action-tflint@41b4770c9d9e50741c20e431986b33124a07ca52 # v1.24.2
        with:
          github_token: ${{ steps.app-token.outputs.token }}
          working_directory: ${{ matrix.dir }}
          reporter: github-pr-review
          fail_level: "any"
          filter_mode: "nofilter"
          tflint_version: "v0.24.0"
          tflint_rulesets: "aws"
          flags: "--call-module-type=all"

      - name: Run TFSec with PR commenter
        uses: aquasecurity/tfsec-pr-commenter-action@7a44c5dcde5dfab737363e391800629e27b6376b # v1.3.1
        with:
          github_token: ${{ steps.app-token.outputs.token }}
          working_directory: ${{ matrix.dir }}
          tfsec_args: ''

      # Disabled
      # Can't do this without access to terraform aws role which is not needed at this time.
      # - name: Terraform validate
      #   shell: bash
      #   run: |
      #     echo "Running terraform validate in ${{ matrix.dir }}"
      #     cd ${{ matrix.dir }}
      #     # Extract all unique environments from tfvars files
      #     ENVS=$(find . -name "*tfvars" -exec basename {} \; | \
      #           grep -v "backend" | \
      #           cut -d'-' -f1 | \
      #           sort -u)
      #     echo "Found environments: $ENVS"
      #     # Process each environment
      #     for ENV in $ENVS; do
      #       echo "Processing environment: $ENV"
      #       # Find the global backend config
      #       GLOBAL_BACKEND=$(find $(git rev-parse --show-toplevel) -name "global-${ENV}-backend.tfvars")
      #       # Find all environment specific backend configs for this env
      #       ENV_BACKENDS=$(find . -name "*${ENV}*.backend.tfvars")
      #       for ENV_BACKEND in $ENV_BACKENDS; do
      #         echo "Validating with backend config: $ENV_BACKEND"
      #         # Initialize Terraform with backend configs
      #         terraform init -input=false \
      #           -backend-config="$GLOBAL_BACKEND" \
      #           -backend-config="$ENV_BACKEND"
      #         # Run validate and capture output
      #         terraform validate -json | jq -r '.valid' > validation_result.txt
      #         if [ "$(cat validation_result.txt)" != "true" ]; then
      #           echo "Terraform validation failed for $ENV with backend $ENV_BACKEND"
      #           terraform validate  # Run again without -json for readable error
      #           exit 1
      #         else
      #           echo "Terraform validation succeeded for $ENV with backend $ENV_BACKEND"
      #         fi
      #       done
      #     done

================
File: ba/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: ba/.github/dependabot.yaml
================
version: 2
updates:

  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/.terraform-version
================
latest

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/dev.backend.tfvars
================
key            = "603547102569/dev/aws_guardduty_malware_protection_plans/marketplace/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/dev.tfvars
================
bucket_names = [
  "marketplace-attachments-dev.ba.enverus.com",
  "marketplace-message-attachments-dev.ba.enverus.com",
  "marketplace-attachments-uat.ba.enverus.com",
  "marketplace-message-attachments-uat.ba.enverus.com"
]
ec2-region             = "us-east-1"
product                = "marketplace"
vault_path_webhook_url = "enverus-ba/marketplace/marketplace-guardduty-malware-protection-teams-webhook-subprod"

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/main.tf
================
module "aws_guardduty_malware_protection_plans" {
  source                 = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-s3-guardduty-malware-protection?ref=v1.0.1"
  env                    = var.env
  bu                     = var.bu
  bucket_names           = var.bucket_names
  vault_path_webhook_url = var.vault_path_webhook_url
  product                = var.product
}

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/prod.backend.tfvars
================
key            = "512870776320/prod/aws_guardduty_malware_protection_plans/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/prod.tfvars
================
bucket_names = [
  "marketplace-attachments-prod.ba.enverus.com",
  "marketplace-message-attachments-prod.ba.enverus.com"
]
ec2-region             = "us-east-1"
product                = "marketplace"
vault_path_webhook_url = "enverus-ba/marketplace/marketplace-guardduty-malware-protection-teams-webhook"

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "environment, eg. dev"
  type        = string
}

variable "ec2-region" {
  description = "full name of region ex: us-east-1"
  type        = string
}

variable "bu" {
  description = "business unit, eg ba"
  type        = string
}

variable "bucket_names" {
  description = "List of S3 bucket names"
  type        = list(string)
}

variable "product" {
  description = "Product name, eg. marketplace"
  type        = string
}

variable "vault_path_webhook_url" {
  description = "Vault path for the webhook URL"
  type        = string
}

================
File: ba/aws_guardduty_malware_protection_plans/marketplace/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.43"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "s3"
      Team         = "marketplace-dev@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/aws_guardduty_malware_protection_plans/marketplace"
      Environment  = var.env
      Product      = "marketplace"
    }
  }
}

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/data.tf
================
data "aws_kms_alias" "s3" {
  name = "alias/aws/s3"
}

data "aws_caller_identity" "current" {}

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/main.tf
================
resource "aws_guardduty_malware_protection_plan" "main" {
  for_each = toset(var.bucket_names)

  role = aws_iam_role.guardduty_malware_protection_role.arn

  protected_resource {
    s3_bucket {
      bucket_name = each.key
    }
  }

  actions {
    tagging {
      status = "ENABLED"
    }
  }
}

resource "aws_iam_role" "guardduty_malware_protection_role" {
  name = "GuardDutyMalwareProtectionRole"

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Principal = {
          Service = "malware-protection-plan.guardduty.amazonaws.com"
        },
        Action = "sts:AssumeRole"
      }
    ]
  })
}

data "aws_iam_policy_document" "guardduty_malware_protection" {
  statement {
    sid    = "AllowManagedRuleToSendS3EventsToGuardDuty"
    effect = "Allow"
    actions = [
      "events:PutRule",
      "events:DeleteRule",
      "events:PutTargets",
      "events:RemoveTargets"
    ]
    resources = [
      "arn:aws:events:us-east-1:${data.aws_caller_identity.current.account_id}:rule/DO-NOT-DELETE-AmazonGuardDutyMalwareProtectionS3*"
    ]
    condition {
      test     = "StringLike"
      variable = "events:ManagedBy"
      values   = ["malware-protection-plan.guardduty.amazonaws.com"]
    }
  }

  statement {
    sid    = "AllowGuardDutyToMonitorEventBridgeManagedRule"
    effect = "Allow"
    actions = [
      "events:DescribeRule",
      "events:ListTargetsByRule"
    ]
    resources = [
      "arn:aws:events:us-east-1:${data.aws_caller_identity.current.account_id}:rule/DO-NOT-DELETE-AmazonGuardDutyMalwareProtectionS3*"
    ]
  }

  statement {
    sid    = "AllowPostScanTag"
    effect = "Allow"
    actions = [
      "s3:PutObjectTagging",
      "s3:GetObjectTagging",
      "s3:PutObjectVersionTagging",
      "s3:GetObjectVersionTagging"
    ]
    resources = [
      for bucket in var.bucket_names : "arn:aws:s3:::${bucket}/*"
    ]
  }

  statement {
    sid    = "AllowEnableS3EventBridgeEvents"
    effect = "Allow"
    actions = [
      "s3:PutBucketNotification",
      "s3:GetBucketNotification"
    ]
    resources = [
      for bucket in var.bucket_names : "arn:aws:s3:::${bucket}"
    ]
  }

  statement {
    sid     = "AllowPutValidationObject"
    effect  = "Allow"
    actions = ["s3:PutObject"]
    resources = [
      for bucket in var.bucket_names : "arn:aws:s3:::${bucket}/malware-protection-resource-validation-object"
    ]
  }

  statement {
    sid     = "AllowCheckBucketOwnership"
    effect  = "Allow"
    actions = ["s3:ListBucket"]
    resources = [
      for bucket in var.bucket_names : "arn:aws:s3:::${bucket}"
    ]
  }

  statement {
    sid    = "AllowMalwareScan"
    effect = "Allow"
    actions = [
      "s3:GetObject",
      "s3:GetObjectVersion"
    ]
    resources = [
      for bucket in var.bucket_names : "arn:aws:s3:::${bucket}/*"
    ]
  }

  statement {
    sid    = "AllowDecryptForMalwareScan"
    effect = "Allow"
    actions = [
      "kms:GenerateDataKey",
      "kms:Decrypt"
    ]
    resources = [data.aws_kms_alias.s3.target_key_arn]
  }
}

resource "aws_iam_policy" "guardduty_malware_protection_policy" {
  name        = "GuardDutyMalwareProtectionPolicy"
  description = "Policy for GuardDuty Malware Protection with S3 and EventBridge permissions"
  policy      = data.aws_iam_policy_document.guardduty_malware_protection.json
}

resource "aws_iam_role_policy_attachment" "main" {
  role       = aws_iam_role.guardduty_malware_protection_role.name
  policy_arn = aws_iam_policy.guardduty_malware_protection_policy.arn
}

##################
## notifications ##
##################
resource "aws_cloudwatch_event_rule" "guardduty_malware_scan" {
  name        = "guardduty-malware-scan-rule"
  description = "Triggers on GuardDuty Malware Protection Object Scan Result"
  event_pattern = jsonencode({
    "source" : ["aws.guardduty"],
    "detail-type" : ["GuardDuty Malware Protection Object Scan Result"],
    "detail" : {
      "scanStatus" : ["COMPLETED"],
      "resourceType" : ["S3_OBJECT"],
      "scanResultDetails" : {
        "scanResultStatus" : ["THREATS_FOUND"]
      }
    },

  })
}

resource "aws_cloudwatch_event_target" "send_to_lambda" {
  rule      = aws_cloudwatch_event_rule.guardduty_malware_scan.name
  target_id = "SendToLambda"
  arn       = aws_lambda_function.guardduty_notify_teams.arn
}

resource "aws_lambda_permission" "allow_eventbridge" {
  statement_id  = "AllowExecutionFromEventBridge"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.guardduty_notify_teams.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.guardduty_malware_scan.arn
}

resource "aws_iam_role" "lambda_exec" {
  name = "lambda_guardduty_notify_teams_role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [{
      Action = "sts:AssumeRole",
      Effect = "Allow",
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_logs" {
  role       = aws_iam_role.lambda_exec.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

resource "aws_lambda_function" "guardduty_notify_teams" {
  filename         = data.archive_file.lambda_zip.output_path
  function_name    = "guardduty_notify_teams"
  role             = aws_iam_role.lambda_exec.arn
  handler          = "notify-teams.handler"
  runtime          = "python3.13"
  source_code_hash = filebase64sha256(data.archive_file.lambda_zip.output_path)

  environment {
    variables = {
      TEAMS_WEBHOOK_URL = data.vault_generic_secret.teams_webhook.data["webhook_url"]
    }
  }
}

data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/notify-teams.py"
  output_path = "${path.module}/notify-teams.zip"
}

data vault_generic_secret "teams_webhook" {
  path = "enverus-ba/payables/openinvoice-guardduty-malware-protection-teams-webhook"
}

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/notify-teams.py
================
import json
import urllib.request
import os

TEAMS_WEBHOOK_URL = os.environ.get("TEAMS_WEBHOOK_URL")

def handler(event, context):
    print("Received event:", json.dumps(event, indent=2))

    detail = event.get("detail", {})
    scan_status = detail.get("scanStatus")
    result_status = detail.get("scanResultDetails", {}).get("scanResultStatus")
    threats = detail.get("scanResultDetails", {}).get("threats", [])
    bucket = detail.get("s3ObjectDetails", {}).get("bucketName")
    object_key = detail.get("s3ObjectDetails", {}).get("objectKey")

    if scan_status == "COMPLETED" and result_status == "THREATS_FOUND":
        threat_names = [t.get("name") for t in threats]
        message = (
            f"**GuardDuty Malware Threat Detected**\n\n"
            f"**Bucket**: `{bucket}`\n"
            f"**Object Key**: `{object_key}`\n"
            f"**Threats**: {', '.join(threat_names)}"
        )
        send_to_teams(message)
    else:
        print("No threats found or scan not completed.")

    return {
        "statusCode": 200,
        "body": json.dumps("Scan processed.")
    }

def send_to_teams(message):
    if not TEAMS_WEBHOOK_URL:
        print("No Teams webhook URL configured.")
        return

    payload = json.dumps({
        "text": message
    }).encode("utf-8")

    req = urllib.request.Request(
        TEAMS_WEBHOOK_URL,
        data=payload,
        headers={"Content-Type": "application/json"}
    )

    try:
        with urllib.request.urlopen(req) as response:
            print(f"Message sent to Teams: {response.status}")
    except Exception as e:
        print(f"Failed to send message to Teams: {e}")

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/prod.backend.tfvars
================
key            = "512870776320/prod/aws_guardduty_malware_protection_plans/openinvoice/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true
bucket         = "enverus-centralized-terraform-state"

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/prod.tfvars
================
bucket_names = [
  "openinvoice-onboard.ba.enverus.com",
  "openinvoice-uat.ba.enverus.com",
  "openinvoice-prod.ba.enverus.com"
]
ec2-region = "us-east-1"

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/variables.tf
================
## SRE-14536 update edge-proxy AMIs
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "environment, eg. dev"
  type        = string
}

variable "ec2-region" {
  description = "full name of region ex: us-east-1"
  type        = string
}

variable "bu" {
  description = "business unit, eg ba"
  type        = string
}

variable "bucket_names" {
  description = "List of S3 bucket names"
  type        = list(string)
}

================
File: ba/aws_guardduty_malware_protection_plans/openinvoice/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.43"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "s3"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/aws_guardduty_malware_protection_plans"
      Environment  = var.env
      Product      = "openinvoice"
    }
  }
}

================
File: ba/aws_guardduty_malware_protection_plans/.terraform-version
================
latest

================
File: ba/cdn-mineralsoft/.terraform-version
================
latest:^1.4

================
File: ba/cdn-mineralsoft/dev-ue1.backend.tfvars
================
key = "dev/east/cdn/terraform.tfstate"

================
File: ba/cdn-mineralsoft/dev-ue1.tfvars
================
comment        = "dev cdn"
alias          = "cdn-mineralsoft.dev.ba.drillinginfo.com"
vpc_name_tag   = "ba-vpc-dev"
inside_sg_name = "ba-vpc-dev-inside-sg"
region         = "us-east-1"
#keys
app_server_domain_name = "mineralsoft.dev.ba.drillinginfo.com"

================
File: ba/cdn-mineralsoft/main.tf
================
data "aws_acm_certificate" "star" {
  domain      = "*.${var.env}.${var.bu}.drillinginfo.com"
  most_recent = true
}

data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_lb" "edge_lb" {
  name = "${var.bu}-${var.env}-edge-lb"
}

data "aws_route53_zone" "selected" {
  name = "${var.env}.ba.drillinginfo.com"
}

#------------------------------------------------------------------------------------
#Create CDN
#------------------------------------------------------------------------------------
resource "aws_cloudfront_distribution" "cdn" {
  aliases = [var.alias]
  comment = var.comment

  default_cache_behavior {
    allowed_methods = ["HEAD", "GET"]
    cached_methods  = ["GET", "HEAD"]
    compress        = "false"
    default_ttl     = "86400"

    forwarded_values {
      cookies {
        forward = "none"
      }

      headers      = ["Host"]
      query_string = "false"
    }

    max_ttl                = "31536000"
    min_ttl                = "0"
    smooth_streaming       = "false"
    target_origin_id       = "app-server"
    trusted_signers        = ["self"]
    viewer_protocol_policy = "redirect-to-https"
  }

  enabled         = "true"
  http_version    = "http2"
  is_ipv6_enabled = "true"

  ordered_cache_behavior {
    allowed_methods = ["HEAD", "GET"]
    cached_methods  = ["HEAD", "GET"]
    compress        = "false"
    default_ttl     = "86400"

    forwarded_values {
      cookies {
        forward = "none"
      }

      headers      = ["Host"]
      query_string = "false"
    }

    max_ttl                = "31536000"
    min_ttl                = "600"
    path_pattern           = "static/*"
    smooth_streaming       = "false"
    target_origin_id       = "app-server"
    viewer_protocol_policy = "redirect-to-https"
  }

  origin {
    custom_origin_config {
      http_port                = "80"
      https_port               = "443"
      origin_keepalive_timeout = "5"
      origin_protocol_policy   = "match-viewer"
      origin_read_timeout      = "30"
      origin_ssl_protocols     = ["TLSv1.2", "TLSv1.1", "TLSv1"]
    }

    domain_name = var.app_server_domain_name
    origin_id   = "app-server"
  }

  price_class = "PriceClass_All"

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  retain_on_delete = "false"

  viewer_certificate {
    acm_certificate_arn            = data.aws_acm_certificate.star.arn
    cloudfront_default_certificate = "false"
    minimum_protocol_version       = "TLSv1.2_2018"
    ssl_support_method             = "sni-only"
  }
}

#------------------------------------------------------------------------------------
#Create CDN DNS entry
#------------------------------------------------------------------------------------

# create this record only for dev and preprod - the cdns in those environments cannot be used because the
# origin domain names resolve to private elbs
resource "aws_route53_record" "mineralsoft-non-prod" {
  count   = var.env == "prod" ? 0 : 1
  zone_id = data.aws_route53_zone.selected.zone_id
  name    = "cdn-mineralsoft.${var.env}.ba.drillinginfo.com"
  type    = "A"

  alias {
    name                   = data.aws_lb.edge_lb.dns_name
    zone_id                = data.aws_lb.edge_lb.zone_id
    evaluate_target_health = false
  }
}

# create this record only for prod
resource "aws_route53_record" "mineralsoft-prod" {
  count   = var.env == "prod" ? 1 : 0
  zone_id = data.aws_route53_zone.selected.zone_id
  name    = "cdn-mineralsoft"
  type    = "CNAME"
  ttl     = 30

  records = [aws_cloudfront_distribution.cdn.domain_name]
}

================
File: ba/cdn-mineralsoft/prod-ue1.backend.tfvars
================
key = "prod/east/cdn/terraform.tfstate"

================
File: ba/cdn-mineralsoft/prod-ue1.tfvars
================
comment        = "Mineralsoft production cdn"
alias          = "cdn-mineralsoft.prod.ba.drillinginfo.com"
vpc_name_tag   = "ba-vpc-prod"
inside_sg_name = "ba-vpc-prod-inside-sg"
region         = "us-east-1"
#keys
app_server_domain_name = "mineralsoft.prod.ba.drillinginfo.com"

================
File: ba/cdn-mineralsoft/variables.tf
================
variable "region" {}

variable "comment" {
  description = "describe additional comments for the cdn"
}
variable "alias" {
  description = " alias of the cdn"
}

variable "bu" {
  description = "the business unit"
  default     = "ba"
  type        = string
}
variable "env" {
  description = "Which environment is the instance in"
  type        = string
}
variable "vpc_name_tag" {
  description = "Value of Name tag applied to target VPC, eg 'dev-VPC'"
  type        = string
}
variable "inside_sg_name" {
  description = "string pattern to search for 'inside' sg"
  type        = string
}

variable "app_server_domain_name" {
  description = "used as source for CDN"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/cdn-mineralsoft/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/codebuild/.terraform-version
================
latest

================
File: ba/codebuild/dev.backend.tfvars
================
key            = "603547102569/codebuild/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/codebuild/dev.tfvars
================
codebuild_service_role = "codebuild-service-role20250812172545336800000001"
source_version         = "ENL-6859-codebuild-unittest-poc"

================
File: ba/codebuild/main.tf
================
data "aws_iam_role" "codebuild_service_role" {
  name = var.codebuild_service_role
}

resource "aws_codebuild_project" "mineralsoft_unittest_poc" {
  name          = "mineralsoft_unittest_poc"
  description   = "A basic CodeBuild project that will run unittests for Mineralsoft"
  build_timeout = var.build_timeout_minutes

  service_role = data.aws_iam_role.codebuild_service_role.arn

  artifacts {
    type = "NO_ARTIFACTS"
  }

  environment {
    compute_type                = var.environment_compute_type
    image                       = var.environment_image
    type                        = var.environment_image_type
    image_pull_credentials_type = var.environment_image_creds
    privileged_mode             = true
  }

  source {
    type      = var.source_type
    location  = var.source_location
    buildspec = var.source_buildspec
  }

  source_version = var.source_version
}

================
File: ba/codebuild/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "codebuild_service_role" {
  description = "The name of the codebuild service role"
}

variable "source_type" {
  description = "Type of source code repo"
  default     = "GITHUB"
}

variable "source_version" {
  description = "Branch, tag, or commit to pull from source code"
  default     = "main"
}

variable "source_location" {
  description = "URL of the source repo"
  default     = "https://github.com/enverus-ba/ba-ms-minerals"
}

variable "source_buildspec" {
  description = "Path to the buildspec.yaml file in the source_location"
  default     = "buildspec.yaml"
}

variable "environment_image_creds" {
  default = "CODEBUILD"
}

variable "environment_image_type" {
  default = "LINUX_CONTAINER"
}

variable "environment_image" {
  default = "aws/codebuild/standard:7.0"
}

variable "environment_compute_type" {
  default = "BUILD_GENERAL1_SMALL"
}

variable "build_timeout_minutes" {
  description = "Number of minutes before a build timeout occurs"
  default     = 5
}

================
File: ba/codebuild/versions.tf
================
terraform {
  required_version = ">= 1.12"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 6"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = "dev"
      BusinessUnit     = "ba"
      Product          = "mineralsoft"
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/codebuild"
      Team             = "mineralsoft-devops@enverus.com"
    }
  }
}

================
File: ba/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)
                 
        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: ba/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response) 
            return { "parameter": response,"errorMessage":"none" } 
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'
          
          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}
        
        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled' 
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added' 
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'    
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'  
          
          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter'] 
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']
                 
          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)   
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'    
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)           
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.' 

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')
          
          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id) 
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: ba/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: ba/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: ba/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
#trigger atlantis

module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: ba/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: ba/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: ba/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: ba/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: ba/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: ba/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: ba/config/.terraform-version
================
latest:^1.8

================
File: ba/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: ba/config/dev.backend.tfvars
================
key = "dev/aws_config/terraform.tfstate"

================
File: ba/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: ba/config/main.tf
================
##AWS Config
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: ba/config/outputs.tf
================


================
File: ba/config/prod.backend.tfvars
================
key = "prod/aws_config/terraform.tfstate"

================
File: ba/config/prod.tfvars
================
environment             = "prod"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: ba/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}

variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: ba/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: ba/consul-aws/.terraform-version
================
latest:^1.7

================
File: ba/consul-aws/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/consul-aws/data.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg", "*-INSIDE-SG"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

================
File: ba/consul-aws/dev-ue1.backend.tfvars
================
key = "dev/east/consul/terraform.tfstate"

================
File: ba/consul-aws/dev-ue1.tfvars
================
env            = "dev"
encryption_key = "XuqDDt/iorsgaP0q2uIt1Q=="
vpc_name_tag   = "ba-vpc-dev"
datacenter     = "aws-ue1"

vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_dev"
ec2-region          = "us-east-1"
abv-region          = "ue1"

# aws-clusters-to-join = "aws-uw2@us-west-2"
# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/consul-aws/main.tf
================
# SRE-12198: comment to trigger atlantis plan

#consul server module
module "consul_servers_aws" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.consul-cluster-aws.git?ref=v0.18.0"

  vpc_name_tag         = var.vpc_name_tag
  env                  = var.env
  bu                   = var.bu
  tagLocation          = var.ec2-region
  tagTeam              = "sre@enverus.com"
  tagSourceCode        = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/consul-aws"
  encryption_key       = var.encryption_key
  datacenter           = var.datacenter
  recursors            = "8.8.8.8"
  aws_clusters_to_join = var.aws-clusters-to-join
  instance_type        = var.instance_type
  #ansible pull
  vo_routing_key                           = var.vo_routing_key
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}
# output "consul_servers_aws" { value = module.consul_servers_aws.consul_servers_aws }
# output "consul_servers_aws_subnet_private_subnets" { value = module.consul_servers_aws.aws_subnet_private_subnets }

resource "aws_security_group" "consul_lb_sg" {
  name        = "${var.abv-region}-${var.bu}-${var.env}-consul-ui-sg"
  description = "Allow acces to consul UI load balancer"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside_sg.id]
  }

  egress {
    from_port   = 8500
    to_port     = 8500
    protocol    = "tcp"
    cidr_blocks = [data.aws_vpc.vpc.cidr_block]
  }
}

resource "aws_lb" "consul_lb" {
  name     = "${var.abv-region}-${var.bu}-${var.env}-consul-lb"
  internal = true
  security_groups = [
    aws_security_group.consul_lb_sg.id,
    data.aws_security_group.inside_sg.id,
  ]
  subnets = data.aws_subnets.private_subnets.ids

  tags = {
    Component = "consul"
    Name      = "${var.bu}-${var.env}-consul-lb"
  }
}

data "vault_generic_secret" "grafana" {
  path = "di-secrets/terraform/grafana-provider"
}

data "grafana_folder" "sre_lb_alert_folder" {
  title = "SRE-LoadBalancer-${title(var.env)} Alerts"
}

module "unhealthy_host_alert" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.load-balancer-unhealthy-host-alert?ref=v1.0.4"

  grafana_API_key              = data.vault_generic_secret.grafana.data["api_key"]
  loadbalancer_type            = "ALB"
  cloudwatch_data_source_name  = "Cloudwatch-${var.bu}-${var.env}-${var.ec2-region}"
  loadbalancer_name            = aws_lb.consul_lb.arn_suffix
  grafana_notification_channel = "VictorOps Alert - key-${var.env}Uptime"
  environment                  = var.env
  grafana_dashboard_folder_id  = data.grafana_folder.sre_lb_alert_folder.uid
  load_balancer_region         = var.ec2-region
}

resource "aws_lb_target_group" "consul_tg" {
  name     = "${var.abv-region}-${var.bu}-${var.env}-consul-tg"
  port     = 8500
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.vpc.id

  health_check {
    path = "/v1/status/leader"
  }
}

resource "aws_lb_listener" "consul_listener" {
  load_balancer_arn = aws_lb.consul_lb.arn
  port              = 80

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.consul_tg.arn
  }
}

resource "aws_autoscaling_attachment" "asg_attachment_bar" {
  autoscaling_group_name = module.consul_servers_aws.asg_name
  lb_target_group_arn    = aws_lb_target_group.consul_tg.arn
}

================
File: ba/consul-aws/prod-ue1.backend.tfvars
================
key = "prod/east/consul/terraform.tfstate"

================
File: ba/consul-aws/prod-ue1.tfvars
================
env            = "prod"
encryption_key = "H7yMJC/pXy255qYxj6nwfQ=="
vpc_name_tag   = "ba-vpc-prod"
datacenter     = "aws-ue1"

ec2-region          = "us-east-1"
abv-region          = "ue1"

aws-clusters-to-join = "aws-uw2@us-west-2"

# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/consul-aws/prod-uw2.backend.tfvars
================
key = "prod/west/consul/terraform.tfstate"

================
File: ba/consul-aws/prod-uw2.tfvars
================
env            = "prod"
encryption_key = "H7yMJC/pXy255qYxj6nwfQ=="
vpc_name_tag   = "ba-vpc-prod"
datacenter     = "aws-uw2"

ec2-region = "us-west-2"
abv-region = "uw2"

aws-clusters-to-join = "aws-ue1@us-east-1"

# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/consul-aws/route53.tf
================
data "aws_route53_zone" "main" {
  name         = "${var.env}.${var.bu}.drillinginfo.com"
  private_zone = false
}

resource "aws_route53_record" "consul_ui" {
  zone_id = data.aws_route53_zone.main.zone_id
  name    = "consul-${var.abv-region}.${var.env}.${var.bu}.drillinginfo.com"
  type    = "A"

  alias {
    name                   = aws_lb.consul_lb.dns_name
    zone_id                = aws_lb.consul_lb.zone_id
    evaluate_target_health = true
  }
}
output "aws_route53_record_consul_ui" { value = aws_route53_record.consul_ui }

================
File: ba/consul-aws/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "env" {}

variable "encryption_key" {}

variable "vpc_name_tag" {}

variable "ec2-region" {}

variable "abv-region" {}

variable "bu" {
  description = "business unit abbreviation"
}

variable "datacenter" {
  description = "name of datacenter for consul cluster"
}

variable "aws-clusters-to-join" {
  description = "space sep. strings indication clusters to join, format: dc@region"
  default     = ""
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
  default     = "c5a.large"
}

variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "vo_routing_key" {
  description = "Provide a Victor Ops Routing Key"
  type        = string
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
}

================
File: ba/consul-aws/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4" # this is blocked by hashicorp module using an old version of the ASG resource.
    }
    grafana = {
      source  = "grafana/grafana"
      version = ">= 1.22"
    }
    vault = {
      source = "hashicorp/vault"
    }
    consul = {
      source  = "hashicorp/consul"
      version = "~> 2.12.0"
      # v2.13 is only compatible with consul 1.10 or newer
    }
  }
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      Component        = "consul"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/consul-aws"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "consul" {
  address    = aws_route53_record.consul_ui.fqdn
  datacenter = var.datacenter
}

================
File: ba/edge-proxy/templates/custom.sh.tpl
================
#!/bin/bash

# Verify that nginx is listening on 80 - if not, stop and start a few times
# to resolve: [error] 5771#0: open() "/var/run/nginx.pid" failed (2: No such file or directory)
LIMIT=5
SLEEP_TIME=5

count=0
nc -zv localhost 80
if [ $? -ne 0 ]; then
  echo "NGINX is not running!"
  while true
  do
    if [ $count -gt $LIMIT ]; then
      echo "Max tries exceeded :("
      exit 1
    fi
    sudo systemctl stop nginx && sudo systemctl start nginx
    nc -zv localhost 80
    if [ $? -ne 0 ]; then
      echo "NGINX is not running! Stop start again."
    else
      echo "NGINX is listening on 80"
      break
    fi
    ((count++))
    sleep $SLEEP_TIME
  done
else
  echo "NGINX is listening on 80"
fi

================
File: ba/edge-proxy/.terraform-version
================
latest:^1.10

================
File: ba/edge-proxy/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/edge-proxy/dev-ue1.backend.tfvars
================
key            = "dev/us-east-1/edge-proxy/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/edge-proxy/dev-ue1.tfvars
================
elb-name           = "ue1-dev-ba-frontend-lb"
domain_name        = "edge-ue1.dev.ba.drillinginfo.com"
vpc_name_tag       = "ba-vpc-dev"
dmz_sg_name_tag    = "ba-vpc-dev-dmz-sg"
consul_sg_name_tag = "ba-dev-aws-ue1-consul"
ec2-region         = "us-east-1"
abv-region         = "ue1"
internal           = true
env                = "dev"
asg_environment    = "ba_dev_ue1"
chef_environment   = "ba-dev-docker"
lb_idle_timeout    = 300
bu                 = "ba"
chef-run-list      = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_consul::client_aws_ue1]\", \"recipe[nginx_reverse_proxy::edge_proxy_ba_aws_ue1]\", \"recipe[di_environment]\""
ami-name-filter    = "drillinginfo/ubuntu2404/edge-proxy-aws-ubuntu-24.04-amd64-*"

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/edge-proxy/main.tf
================
# update SRE/tf_module_aws_autoscaling_group
data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg"]
  }
}

data "aws_acm_certificate" "star" {
  domain      = "*.${var.env}.${var.bu}.drillinginfo.com"
  types       = ["AMAZON_ISSUED"]
  most_recent = true
}

resource "aws_security_group" "front_sg" {
  name_prefix = "${var.env}-front-80"
  description = "Security group for inbound 80"
  vpc_id      = data.aws_vpc.vpc_id.id

  tags = {
    Name        = "${var.env}-front-80"
    Component   = "frontend-sg"
    Environment = var.env
  }
}

resource "aws_security_group_rule" "inbound_http" {
  type        = "ingress"
  from_port   = "80"
  to_port     = "80"
  protocol    = "tcp"
  cidr_blocks = ["0.0.0.0/0"]

  security_group_id = aws_security_group.front_sg.id
}

data "aws_security_group" "ba_dmz" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = [var.dmz_sg_name_tag]
  }
}

resource "aws_security_group" "websockets_sg" {
  name_prefix = "${var.env}-websockets-81"
  description = "Security group for websockets"
  vpc_id      = data.aws_vpc.vpc_id.id

  tags = {
    Name        = "${var.env}-websockets-81"
    Component   = "websockets-sg"
    Environment = var.env
  }
}

resource "aws_security_group_rule" "websockets" {
  type            = "ingress"
  from_port       = "81"
  to_port         = "81"
  protocol        = "tcp"
  prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
  cidr_blocks = [
    "10.0.0.0/8",
  ]
  security_group_id = aws_security_group.websockets_sg.id
}

resource "aws_security_group_rule" "websockets-01" {
  type                     = "ingress"
  from_port                = "81"
  to_port                  = "81"
  protocol                 = "tcp"
  source_security_group_id = data.aws_security_group.ba_dmz.id
  security_group_id        = aws_security_group.websockets_sg.id
}

data "aws_security_group" "consul_sg" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = [var.consul_sg_name_tag]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc_id.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

data "aws_subnets" "dmz" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc_id.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*DMZ | Public*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

##############################################
######## ALB and DNS ########
##############################################

# ---------------------------------------------------------------------------------------------------------------------
# CREATE THE ELB
# ---------------------------------------------------------------------------------------------------------------------
resource "aws_lb" "edge_lb" {
  name            = "${var.bu}-${var.env}-edge-lb"
  internal        = var.internal
  security_groups = [aws_security_group.front-elb.id, data.aws_security_group.inside_sg.id]
  subnets         = var.internal == true ? data.aws_subnets.private_subnets.ids : data.aws_subnets.dmz.ids
  idle_timeout    = var.lb_idle_timeout

  tags = {
    Component = "edge-proxy"
    Name      = "${var.bu}-${var.env}-edge-lb"
  }
}

resource "aws_lb_listener_certificate" "ssl_cert" {
  for_each        = toset(var.additional_acm_cert_arns)
  listener_arn    = aws_lb_listener.edge_listener.arn
  certificate_arn = each.key
}

resource "aws_lb_target_group" "edge_tg" {
  name     = "${var.bu}-${var.env}-edge-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.vpc_id.id

  health_check {
    path = "/elb-health"
  }
}

resource "aws_lb_listener" "edge_listener" {
  load_balancer_arn = aws_lb.edge_lb.arn
  port              = 443
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-FS-1-2-Res-2020-10"
  certificate_arn   = data.aws_acm_certificate.star.arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.edge_tg.arn
  }
}

resource "aws_lb_listener" "https_redirect" {
  load_balancer_arn = aws_lb.edge_lb.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type = "redirect"

    redirect {
      port        = "443"
      protocol    = "HTTPS"
      status_code = "HTTP_301"
    }
  }
}

# ---------------------------------------------------------------------------------------------------------------------
# CREATE THE GRAFANA ALERT FOR UNHEALTHY HOSTS IN THE LB
# ---------------------------------------------------------------------------------------------------------------------

data "vault_generic_secret" "grafana" {
  path = "di-secrets/terraform/grafana-provider"
}

data "grafana_folder" "sre_lb_alert_folder" {
  title = "SRE-LoadBalancer-${title(var.env)} Alerts"
}

module "unhealthy_host_alert" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.load-balancer-unhealthy-host-alert?ref=v1.0.4"

  grafana_API_key              = data.vault_generic_secret.grafana.data["api_key"]
  loadbalancer_type            = "ALB"
  cloudwatch_data_source_name  = "Cloudwatch-${var.bu}-${var.env}-${var.ec2-region}"
  loadbalancer_name            = aws_lb.edge_lb.arn_suffix
  grafana_notification_channel = "VictorOps Alert - key-${var.env}Uptime"
  environment                  = var.env
  grafana_dashboard_folder_id  = data.grafana_folder.sre_lb_alert_folder.uid
  load_balancer_region         = var.ec2-region
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONALLY CREATE A ROUTE 53 ENTRY FOR THE ELB
# ---------------------------------------------------------------------------------------------------------------------

data "aws_route53_zone" "selected" {
  name = "${var.env}.ba.drillinginfo.com"
}

resource "aws_route53_record" "front_elb" {
  zone_id = data.aws_route53_zone.selected.zone_id
  name    = var.domain_name
  type    = "A"

  alias {
    name                   = aws_lb.edge_lb.dns_name
    zone_id                = aws_lb.edge_lb.zone_id
    evaluate_target_health = false
  }
}

# ---------------------------------------------------------------------------------------------------------------------
# CREATE THE SECURITY GROUP THAT CONTROLS WHAT TRAFFIC CAN GO IN AND OUT OF THE ELB
# ---------------------------------------------------------------------------------------------------------------------

resource "aws_security_group" "front-elb" {
  name        = "${var.elb-name}-elb"
  description = "Security group for the edge proxy"
  vpc_id      = data.aws_vpc.vpc_id.id

  tags = {
    Component   = "front-edge-proxy"
    Environment = var.env
  }
}

resource "aws_security_group_rule" "allow_inbound_http" {
  type        = "ingress"
  from_port   = "80"
  to_port     = "80"
  protocol    = "tcp"
  cidr_blocks = ["0.0.0.0/0"]

  security_group_id = aws_security_group.front-elb.id
}

resource "aws_security_group_rule" "allow_inbound_https" {
  type        = "ingress"
  from_port   = "443"
  to_port     = "443"
  protocol    = "tcp"
  cidr_blocks = ["0.0.0.0/0"]

  security_group_id = aws_security_group.front-elb.id
}

resource "aws_security_group_rule" "allow_all_outbound-elb" {
  type        = "egress"
  from_port   = 0
  to_port     = 0
  protocol    = "-1"
  cidr_blocks = ["0.0.0.0/0"]

  security_group_id = aws_security_group.front-elb.id
}

# create instances
data "template_file" "restart_nginx" {
  template = file("${path.module}/templates/custom.sh.tpl")
}

module "aws-asg-edge-proxy-ba" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-autoscaling-group.git?ref=v10.4.1"

  providers = {
    aws = aws.custom
  }

  # ami search filters
  ami-filters = {
    name           = var.ami-name-filter
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lt params and userdata
  environment        = var.asg_environment
  os                 = "ubuntu20"
  ec2-name           = "aws-${var.abv-region}-${var.env}-${var.bu}-web"
  instance-type      = var.instance-type
  subnet-ids         = data.aws_subnets.private_subnets.ids
  security-group-ids = "${data.aws_security_group.inside_sg.id},${aws_security_group.front_sg.id},${aws_security_group.websockets_sg.id},${data.aws_security_group.consul_sg.id}"
  keypair-name       = "cm@drillinginfo.com"
  iam-profile        = "service-instance-profile"
  ebs-optimized      = "true"

  # asg params
  asg-name                  = "${var.env}-${var.bu}-web-asg"
  desired-capacity          = "2"
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "2"
  suspended-processes       = []
  target-group-arns         = [aws_lb_target_group.edge_tg.arn]
  vo_routing_key            = var.vo_routing_key
  # Chef
  chef-version     = "12.22.5"
  chef-environment = var.chef_environment
  chef-run-list    = var.chef-run-list

  # Tagging
  tagComponent                             = "web"
  tagProduct                               = "nexus"
  tagStack                                 = var.env
  tagAutospot                              = "true"
  tagLocation                              = var.ec2-region
  tagBusinessUnit                          = var.bu
  tagTeam                                  = "sre@enverus.com"
  tagSourceCode                            = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/edge-proxy"
  tagEnv                                   = var.env
  custom-script                            = data.template_file.restart_nginx.rendered
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

resource "aws_autoscaling_lifecycle_hook" "initialization_timer" {
  name                   = "initialization_timer"
  autoscaling_group_name = module.aws-asg-edge-proxy-ba.asg_name
  default_result         = "CONTINUE"
  heartbeat_timeout      = 60
  lifecycle_transition   = "autoscaling:EC2_INSTANCE_LAUNCHING"
}

================
File: ba/edge-proxy/prod-ue1.backend.tfvars
================
key            = "prod/us-east-1/edge-proxy/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/edge-proxy/prod-ue1.tfvars
================
elb-name           = "ue1-prod-ba-frontend-lb"
domain_name        = "edge-ue1.prod.ba.drillinginfo.com"
vpc_name_tag       = "ba-vpc-prod"
dmz_sg_name_tag    = "ba-vpc-prod-dmz-sg"
consul_sg_name_tag = "ba-prod-aws-ue1-consul"
ec2-region         = "us-east-1"
abv-region         = "ue1"
internal           = false
env                = "prod"
asg_environment    = "ba_prod_ue1"
chef_environment   = "ba-prod-docker"
lb_idle_timeout    = 300
bu                 = "ba"
chef-run-list      = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_consul::client_aws_ue1]\", \"recipe[nginx_reverse_proxy::edge_proxy_ba_aws_ue1]\", \"recipe[di_environment]\""
ami-name-filter    = "drillinginfo/ubuntu2404/edge-proxy-aws-ubuntu-24.04-amd64-*"

additional_acm_cert_arns = [
  "arn:aws:acm:us-east-1:512870776320:certificate/3b217938-3c0d-4962-823d-4f17c6f8b571"
]

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/edge-proxy/prod-uw2.backend.tfvars
================
key            = "512870776320/prod/us-west-2/edge-proxy/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/edge-proxy/prod-uw2.tfvars
================
elb-name           = "uw2-prod-ba-frontend-lb"
domain_name        = "edge-uw2.prod.ba.drillinginfo.com"
vpc_name_tag       = "ba-vpc-prod"
dmz_sg_name_tag    = "ba-vpc-prod-dmz-sg"
consul_sg_name_tag = "ba-prod-aws-uw2-consul"
ec2-region         = "us-west-2"
abv-region         = "uw2"
internal           = false
env                = "prod"
asg_environment    = "ba_prod_uw2"
chef_environment   = "ba-prod-docker"
lb_idle_timeout    = 300
bu                 = "ba"
chef-run-list      = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_consul::client_aws_uw2]\", \"recipe[nginx_reverse_proxy::edge_proxy_ba_aws_uw2]\", \"recipe[di_environment]\""
ami-name-filter    = "drillinginfo/ubuntu2404/edge-proxy-aws-ubuntu-24.04-amd64-*"

additional_acm_cert_arns = [
  "arn:aws:acm:us-west-2:512870776320:certificate/8d259c6e-5a8b-4933-8e06-c24a38427080"
]

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

================
File: ba/edge-proxy/variables.tf
================
## SRE-14536 update edge-proxy AMIs
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "env" {
  description = "environment, eg. dev"
}

variable "ec2-region" {
  description = "full name of region ex: us-east-1"
}

variable "abv-region" {
  description = "abreviated name of region ex: ue1"
}

variable "bu" {
  description = "business unit, eg ba"
}

variable "vpc_name_tag" {
  description = "Value of vpc Name tag"
}

variable "chef_environment" {
  default = "ba-dev-docker"
}

variable "chef-run-list" {}

variable "elb-name" {
  description = "The name to use for the ELB and all other resources in this module."
}

variable "domain_name" {
  description = "The domain name to use in the DNS A record for the ELB"
}

variable "internal" {
  description = "If set to true, this will be an internal ELB, accessible only within the VPC."
  default     = false
}

variable "dmz_sg_name_tag" {
  description = "value of Name tag of DMZ sg"
}

variable "consul_sg_name_tag" {
  description = "value of Name tag of consul sg"
}

variable "lb_idle_timeout" {
  description = "idle timeout for load balancer"
}

variable "instance-type" {
  description = "type, eg t2.micro"
  default     = "m6i.large"
}

variable "asg_environment" {
  description = "This is the environment string used by the ASG module to select s3 buckets for chef key and chef org name"
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "additional_acm_cert_arns" {
  type        = list(string)
  description = "Optional ACM certs to apply to the LB other than the bu-specific one"
  default     = []
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
}

variable "ami-name-filter" {
  description = "name filter string used to select DI ami"
}

================
File: ba/edge-proxy/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.43"
    }
    grafana = {
      source  = "grafana/grafana"
      version = ">= 1.22"
    }
  }
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

# need an aliased provider to pass in
provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "custom"
}

# need a default provider for local resources
provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "web"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/edge-proxy"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

================
File: ba/elasticache-mineralsoft/.terraform-version
================
latest:^1.4

================
File: ba/elasticache-mineralsoft/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/elasticache-mineralsoft/dev-ue1.backend.tfvars
================
key = "dev/us-east-1/elasticache/terraform.tfstate"

================
File: ba/elasticache-mineralsoft/dev-ue1.tfvars
================
vpc_name_tag         = "ba-vpc-dev"
inside_sg_name       = "ba-vpc-dev-inside-sg"
ec2-region           = "us-east-1"
engine               = "redis"
cluster_id           = "minerals-redis-cache"
node_type            = "cache.m4.large"
num_cache_nodes      = 1
parameter_group_name = "default.redis6.x"
engine_version       = "6.2"
port                 = 6379

================
File: ba/elasticache-mineralsoft/main.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = [var.inside_sg_name]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*INSIDE*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

resource "aws_elasticache_subnet_group" "private" {
  name       = "${var.bu}-${var.env}-private-redis-cache"
  subnet_ids = data.aws_subnets.private_subnets.ids
}

resource "aws_security_group" "elasticache" {
  name        = "${var.bu}-${var.env}-private-redis-cache-sg"
  description = "Managed by Terraform"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 6379
    to_port         = 6379
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside.id]
  }
}

resource "aws_elasticache_cluster" "minerals" {
  cluster_id           = var.cluster_id
  engine               = var.engine
  node_type            = var.node_type
  num_cache_nodes      = var.num_cache_nodes
  parameter_group_name = var.parameter_group_name
  engine_version       = var.engine_version
  port                 = var.port
  subnet_group_name    = aws_elasticache_subnet_group.private.name
  security_group_ids   = [aws_security_group.elasticache.id]

  tags = {
    Name = "mineralsoft-${var.env}"
  }
}
output "aws_elasticache_cluster_minerals" { value = aws_elasticache_cluster.minerals }

================
File: ba/elasticache-mineralsoft/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/elasticache/terraform.tfstate"

================
File: ba/elasticache-mineralsoft/prod-ue1.tfvars
================
vpc_name_tag         = "ba-vpc-prod"
inside_sg_name       = "ba-vpc-prod-inside-sg"
ec2-region           = "us-east-1"
engine               = "redis"
cluster_id           = "minerals-redis-cache"
node_type            = "cache.m4.large"
num_cache_nodes      = 1
parameter_group_name = "default.redis6.x"
engine_version       = "6.2"

================
File: ba/elasticache-mineralsoft/prod-uw2.backend.tfvars
================
key = "prod/us-west-2/elasticache-mineralsoft/terraform.tfstate"

================
File: ba/elasticache-mineralsoft/prod-uw2.tfvars
================
vpc_name_tag         = "ba-vpc-prod"
inside_sg_name       = "ba-vpc-prod-inside-sg"
ec2-region           = "us-west-2"
engine               = "redis"
cluster_id           = "minerals-redis-cache-dr"
node_type            = "cache.m4.large"
num_cache_nodes      = 1
parameter_group_name = "default.redis3.2"
engine_version       = "3.2.10"

================
File: ba/elasticache-mineralsoft/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "bu" {
  description = "the business unit"
  default     = "ba"
}

variable "ec2-region" {
  description = "region in which to create instance"
}

variable "env" {
  description = "Environment, eg dev"
}

variable "vpc_name_tag" {
}

variable "inside_sg_name" {
  description = "string pattern to search for 'inside' sg"
}

variable "engine" {
  description = "engine type eg redis"
}

variable "cluster_id" {
  description = "name of the cluster"
}

variable "node_type" {
  description = "instance type"
}

variable "num_cache_nodes" {
  description = "number of nodes"
}

variable "parameter_group_name" {
  description = " parameter group name"
}

variable "engine_version" {
  description = "db engine version, eg 10.6"
}

variable "port" {
  description = "port to reach node"
  default     = 6379
}

================
File: ba/elasticache-mineralsoft/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "mineralsoft"
      Team             = "sre@enverus.com"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
      Sourcecode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/elasticache-mineralsoft"
    }
  }
}

================
File: ba/elasticsearch-cluster/jaeger/.terraform-version
================
latest:^1.4

================
File: ba/elasticsearch-cluster/jaeger/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}

================
File: ba/elasticsearch-cluster/jaeger/dev-ue1.backend.tfvars
================
key = "dev/elasticsearch-service-us-east-1/jaeger/terraform.tfstate"

================
File: ba/elasticsearch-cluster/jaeger/dev-ue1.tfvars
================
vpc-name                       = "ba-vpc-dev"
inside_sg_name                 = "ba-vpc-dev-inside-sg"
env                            = "dev"
aws_region                     = "us-east-1"
cluster_instance_type          = "t3.medium.elasticsearch"
cluster_instance_count         = 4
master_instance_type           = "t3.medium.elasticsearch"
master_instance_count          = 3
ebs_volume_size                = 150
create_iam_service_linked_role = false
vpc_options_subnet_ids = [ "subnet-0f4bac0a7ac27db63","subnet-08ec74a3da4206380" ]
#Tags
tagStack            = "dev"
tagComponent        = "jaeger"
tagLocation         = "us-east-1"
tagBusinessUnit     = "ba"
tagTeam             = "sre"
tagTerraformCreated = "true"

================
File: ba/elasticsearch-cluster/jaeger/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc-name]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = [var.inside_sg_name]
  }
}

resource "aws_security_group" "es" {
  name        = "elasticsearch-jaeger-traces-${var.env}"
  description = "Managed by Terraform"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside_sg.id]
  }
}

data "aws_region" "current" {}

data "aws_caller_identity" "current" {}

resource "aws_iam_service_linked_role" "es" {
  count            = var.create_iam_service_linked_role ? 1 : 0
  aws_service_name = "es.amazonaws.com"
}

resource "aws_elasticsearch_domain" "es" {
  depends_on            = [aws_iam_service_linked_role.es]
  domain_name           = "jaeger-traces-${var.env}"
  elasticsearch_version = var.elasticsearch_version

  ebs_options {
    ebs_enabled = true
    volume_type = "gp2"
    volume_size = var.ebs_volume_size
  }

  cluster_config {
    instance_type            = var.cluster_instance_type
    instance_count           = var.cluster_instance_count
    dedicated_master_enabled = true
    dedicated_master_type    = var.master_instance_type
    dedicated_master_count   = var.master_instance_count
    zone_awareness_enabled   = true
  }


  vpc_options {
    subnet_ids = var.vpc_options_subnet_ids

    security_group_ids = ["${data.aws_security_group.inside_sg.id}", "${aws_security_group.es.id}"]
  }

  advanced_options = {
    "rest.action.multi.allow_explicit_index" = "true"
  }

  access_policies = <<CONFIG
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "es:*",
            "Principal": {
              "AWS": "*"
            },
            "Effect": "Allow",
            "Resource": "arn:aws:es:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:domain/jaeger-traces-${var.env}/*"
        }
    ]
}
CONFIG

  snapshot_options {
    automated_snapshot_start_hour = 0
  }

  tags = {
    Component        = var.tagComponent
    Stack            = var.tagStack
    Team             = var.tagTeam
    Location         = var.tagLocation
    BusinessUnit     = var.tagBusinessUnit
    TerraformCreated = var.tagTerraformCreated
    SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/elasticsearch-cluster/jaeger"
  }

}

================
File: ba/elasticsearch-cluster/jaeger/prod-ue1.backend.tfvars
================
key = "prod/elasticsearch-service-us-east-1/jaeger/terraform.tfstate"

================
File: ba/elasticsearch-cluster/jaeger/prod-ue1.tfvars
================
vpc-name                       = "ba-vpc-prod"
inside_sg_name                 = "ba-vpc-prod-inside-sg"
env                            = "prod"
aws_region                     = "us-east-1"
cluster_instance_type          = "m5.large.elasticsearch"
cluster_instance_count         = 4
master_instance_type           = "m5.large.elasticsearch"
master_instance_count          = 3
ebs_volume_size                = 150
create_iam_service_linked_role = false
vpc_options_subnet_ids = [ "subnet-0ff04ec1a4b43e25c","subnet-09f7a7512b2722e23" ]
#Tags
tagStack            = "prod"
tagComponent        = "jaeger"
tagLocation         = "us-east-1"
tagBusinessUnit     = "ba"
tagTeam             = "sre"
tagTerraformCreated = "true"

================
File: ba/elasticsearch-cluster/jaeger/variables.tf
================
# variable definitions

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "aws_region" {
  description = "eg eu-west-1"
}

variable "env" {
}

variable "vpc-name" {
}

variable "elasticsearch_version" {
  description = "version of elasticsearch to run in the domain"
  default     = "6.2"
}

variable "cluster_instance_type" {
  description = "ESS instance type to use for data nodes"
}

variable "master_instance_type" {
  description = "ESS instance type to use for master nodes"
}

variable "cluster_instance_count" {
  description = "number of data instances"
}

variable "master_instance_count" {
  description = "number of master instances"
}

variable "ebs_volume_size" {
  description = "Size of ebs volumes attached to data nodes (gb)"
}

variable "create_iam_service_linked_role" {
  description = "Whether to create IAM service linked role for AWS ElasticSearch service. Can be only one per AWS account."
  type        = bool
  default     = true
}

variable "tagBusinessUnit" {
  description = "Name of business unit, eg. 'upstream' or 'cds'"
}

variable "tagStack" {
  description = "Tag resources with name of stack - generally matches environment"
}

variable "tagLocation" {
  description = "Tag resources with location of datacenter"
}

variable "tagComponent" {
  description = "Tag resources with component name, eg. 'direct-access', or 'curve-builder'"
}

variable "tagTeam" {
  description = "Tag resources with team, eg. 'sre'"
}

variable "tagTerraformCreated" {
  description = "Tag resources if they are created by terraform, eg. 'true' or 'false'"
}

variable "inside_sg_name" {
  description = "string pattern to search for 'inside' sg"
}

variable "vpc_options_subnet_ids" {
  type = list(string)
  description = "values for subnet_ids in vpc_options"
}

================
File: ba/elasticsearch-service/main.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = [var.inside_sg_name]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }
# output "private_subnets" { value = slice(data.aws_subnets.private_subnets.ids, 0, length(var.instance_count) + 1) }

data "aws_region" "region" {}
data "aws_caller_identity" "current" {}

resource "aws_security_group" "es" {
  name        = "${var.bu}-elasticsearch-${var.elasticsearch_domain_name}-${var.env}"
  description = "Managed by Terraform"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside.id]
  }
}

resource "aws_cloudwatch_log_group" "es" {
  name              = "ES_APPLICATION_LOGS"
  retention_in_days = 30
}

resource "aws_cloudwatch_log_resource_policy" "es" {
  policy_name     = "allow_es_service"
  policy_document = <<CONFIG
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "es.amazonaws.com"
      },
      "Action": [
        "logs:PutLogEvents",
        "logs:PutLogEventsBatch",
        "logs:CreateLogStream"
      ],
      "Resource": "arn:aws:logs:*"
    }
  ]
}
CONFIG
}

resource "aws_iam_service_linked_role" "es" {
  aws_service_name = "es.amazonaws.com"
}

resource "aws_elasticsearch_domain" "es" {
  domain_name           = var.elasticsearch_domain_name
  elasticsearch_version = var.elasticsearch_version

  cluster_config {
    instance_type          = var.instance_type
    instance_count         = var.instance_count
    zone_awareness_enabled = var.zone_awareness_enabled
  }

  ebs_options {
    ebs_enabled = var.ebs_enabled
    volume_size = var.ebs_volume_size
  }

  vpc_options {
    subnet_ids         = slice(data.aws_subnets.private_subnets.ids, 0, length(var.instance_count) + 1)
    security_group_ids = [aws_security_group.es.id]
  }

  log_publishing_options {
    log_type                 = "ES_APPLICATION_LOGS"
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.es.arn
  }

  advanced_options = {
    "rest.action.multi.allow_explicit_index" = true
  }

  access_policies = <<CONFIG
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "es:*",
            "Principal": "*",
            "Effect": "Allow",
            "Resource": "arn:aws:es:${data.aws_region.region.name}:${data.aws_caller_identity.current.account_id}:domain/${var.elasticsearch_domain_name}/*"
        }
    ]
}
CONFIG

  snapshot_options {
    automated_snapshot_start_hour = var.automated_snapshot_start_hour
  }

  tags = {
    Name = "mineralsoft-${var.env}"
  }

  depends_on = [
    aws_iam_service_linked_role.es,
  ]
}
output "aws_elasticsearch_domain_es" { value = aws_elasticsearch_domain.es }
#decom

================
File: ba/elasticsearch-service-role/.terraform-version
================
latest:^1.7

================
File: ba/elasticsearch-service-role/dev.backend.tfvars
================
key = "dev/es-service/terraform.tfstate"

================
File: ba/elasticsearch-service-role/dev.tfvars
================
ec2-region = "us-east-1"

================
File: ba/elasticsearch-service-role/main.tf
================
resource "aws_iam_service_linked_role" "es" {
  aws_service_name = "es.amazonaws.com"
}

================
File: ba/elasticsearch-service-role/prod.backend.tfvars
================
key = "prod/es-service/terraform.tfstate"

================
File: ba/elasticsearch-service-role/prod.tfvars
================
ec2-region = "us-east-1"

================
File: ba/elasticsearch-service-role/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "bu" {}

variable "ec2-region" {
  description = "region in which to create instance"
}

variable "env" {
  description = "Environment, eg dev"
}

================
File: ba/elasticsearch-service-role/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/elasticsearch-service-role"
      TerraformCreated = "true"
      Team             = "sre@enverus.com"
      Stack            = var.env
      Component        = "mineralsoft"
      Environment      = var.env
    }
  }
}

================
File: ba/epayables/secrets/.terraform-version
================
latest:^1.8

================
File: ba/epayables/secrets/dev-ue1.backend.tfvars
================
key = "603547102569/dev/us-east-1/epayables-secrets/terraform.tfstate"

================
File: ba/epayables/secrets/dev-ue1.tfvars
================
mountpoint = "di-secrets"
secret_paths = [
  # dev
  "terraform/application/epayables/dev/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/dev/db/ep-core/docusign_app",
  "terraform/application/epayables/dev/db/ep-core/msa_app",
  "terraform/application/epayables/dev/db/ep-core/oauth2_app",
  "terraform/application/epayables/dev/db/ep-core/requisition_app",
  "terraform/application/epayables/dev/db/ep-core/ticket_app",
  # staging
  "terraform/application/epayables/staging/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/staging/db/ep-core/oauth2_app",
  "terraform/application/epayables/staging/db/ep-core/requisition_app",
  "terraform/application/epayables/staging/db/ep-core/buyer_mobile_app",
  "terraform/application/epayables/staging/db/ep-core/ticket_app",
  "terraform/application/epayables/staging/db/ep-core/fundthrough_app",
  "terraform/application/epayables/staging/db/ep-core/msa_app",
  "terraform/application/epayables/staging/db/ep-core/docusign_app",
  # rc
  "terraform/application/epayables/rc/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/rc/db/ep-core/docusign_app",
  "terraform/application/epayables/rc/db/ep-core/msa_app",
  "terraform/application/epayables/rc/db/ep-core/oauth2_app",
  "terraform/application/epayables/rc/db/ep-core/requisition_app",
  "terraform/application/epayables/rc/db/ep-core/ticket_app",
]
VAULT_ADDR = "https://vault-ue1.dev.ba.drillinginfo.com"

================
File: ba/epayables/secrets/main.tf
================
module "vault_secrets" {
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/vault-secrets.git?ref=main"

  mountpoint   = var.mountpoint
  secret_paths = var.secret_paths
}

output "vault_secrets" {
  value = module.vault_secrets
}

================
File: ba/epayables/secrets/prod-ue1.backend.tfvars
================
key = "512870776320/prod/us-east-1/epayables-secrets/terraform.tfstate"

================
File: ba/epayables/secrets/prod-ue1.tfvars
================
mountpoint = "di-secrets"
secret_paths = [
  # onboard
  "terraform/application/epayables/onboard/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/onboard/db/ep-core/oauth2_app",
  "terraform/application/epayables/onboard/db/ep-core/requisition_app",
  "terraform/application/epayables/onboard/db/ep-core/buyer_mobile_app",
  "terraform/application/epayables/onboard/db/ep-core/ticket_app",
  "terraform/application/epayables/onboard/db/ep-core/fundthrough_app",
  "terraform/application/epayables/onboard/db/ep-core/msa_app",
  "terraform/application/epayables/onboard/db/ep-core/docusign_app",
  # uat
  "terraform/application/epayables/uat/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/uat/db/ep-core/docusign_app",
  "terraform/application/epayables/uat/db/ep-core/msa_app",
  "terraform/application/epayables/uat/db/ep-core/oauth2_app",
  "terraform/application/epayables/uat/db/ep-core/requisition_app",
  "terraform/application/epayables/uat/db/ep-core/ticket_app",
  # prod
  "terraform/application/epayables/prod/iam-fundtrhough-user-access-key",
  "terraform/application/epayables/prod/db/ep-core/oauth2_app",
  "terraform/application/epayables/prod/db/ep-core/requisition_app",
  "terraform/application/epayables/prod/db/ep-core/buyer_mobile_app",
  "terraform/application/epayables/prod/db/ep-core/ticket_app",
  "terraform/application/epayables/prod/db/ep-core/fundthrough_app",
  "terraform/application/epayables/prod/db/ep-core/msa_app",
  "terraform/application/epayables/prod/db/ep-core/docusign_app",
  # RFX/Bidout application
  "terraform/application/epayables/prod/rfx/github",
]
VAULT_ADDR = "https://vault-ue1.prod.ba.drillinginfo.com"

================
File: ba/epayables/secrets/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "mountpoint" {
  description = "Vault secret mountpoint"
  type        = string
}

variable "secret_paths" {
  description = "The full logical path at which to write the given data. To write data into the generic secret backend mounted in Vault by default. Writing to other backends with this resource is possible; consult each backend's documentation to see which endpoints support the PUT and DELETE methods."
  type        = list(string)
  default     = []
}

================
File: ba/epayables/secrets/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/grafana/datasources/.terraform-version
================
latest:^1.4

================
File: ba/grafana/datasources/dev-ue1.backend.tfvars
================
key = "dev/us-east-1/grafana-datasources/terraform.tfstate"

================
File: ba/grafana/datasources/dev-ue1.tfvars
================
region = "us-east-1"

================
File: ba/grafana/datasources/dev-uw2.backend.tfvars
================
key = "dev/us-west-2/grafana-datasources/terraform.tfstate"

================
File: ba/grafana/datasources/dev-uw2.tfvars
================
region = "us-west-2"

================
File: ba/grafana/datasources/main.tf
================
# Data sources

data "vault_generic_secret" "grafana_api" {
  path = "di-secrets/terraform/grafana-provider"
}

# Create IAM policy
resource "aws_iam_policy" "iam_policy" {
  name        = "grafana-cloudwatch-access-${var.env}-${var.region}"
  path        = "/"
  description = "IAM policy for enverus.grafana.net IAM user to access cloudwatch metrics"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        "Sid" : "AllowReadingMetricsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "cloudwatch:DescribeAlarmsForMetric",
          "cloudwatch:DescribeAlarmHistory",
          "cloudwatch:DescribeAlarms",
          "cloudwatch:ListMetrics",
          "cloudwatch:GetMetricStatistics",
          "cloudwatch:GetMetricData"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingLogsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "logs:DescribeLogGroups",
          "logs:GetLogGroupFields",
          "logs:StartQuery",
          "logs:StopQuery",
          "logs:GetQueryResults",
          "logs:GetLogEvents"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingTagsInstancesRegionsFromEC2",
        "Effect" : "Allow",
        "Action" : [
          "ec2:DescribeTags",
          "ec2:DescribeInstances",
          "ec2:DescribeRegions"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingResourcesForTags",
        "Effect" : "Allow",
        "Action" : "tag:GetResources",
        "Resource" : "*"
      },
    ]
  })
}

# Create IAM User
resource "aws_iam_user" "iam_user" {
  name = "grafana-cloudwatch-metrics-${var.env}-${var.region}"
  path = "/"
}

resource "aws_iam_access_key" "iam_access_key" {
  user = aws_iam_user.iam_user.name
}

# Attach IAM policy to IAM User
resource "aws_iam_user_policy_attachment" "iam_user_policy_attachment" {
  user       = aws_iam_user.iam_user.name
  policy_arn = aws_iam_policy.iam_policy.arn
}

# Stash IAM user in Vault
resource "vault_generic_secret" "generic_secret" {
  path      = "di-secrets/terraform/aws/grafana/${var.bu}/${var.env}/${var.region}"
  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.iam_access_key.id}",
  "secret_key": "${aws_iam_access_key.iam_access_key.secret}"
}
EOF
}

# Create Grafana Datasource
module "datasource" {
  source          = "git@github.com:enverus-cts/sre.tf-modules.hosted-grafana.git//datasources"
  datasource_name = "Cloudwatch-${var.bu}-${var.env}-${var.region}"
  grafana_API_key = data.vault_generic_secret.grafana_api.data["api_key"]
  region          = var.region
  env             = var.env
  datasource_type = "cloudwatch"
  access_key      = aws_iam_access_key.iam_access_key.id
  secret_key      = aws_iam_access_key.iam_access_key.secret
}

================
File: ba/grafana/datasources/Makefile
================
.PHONY: gen _gen-main _gen-examples _gen-modules

CURRENT_DIR     = $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
TF_EXAMPLES     = $(sort $(dir $(wildcard $(CURRENT_DIR)examples/*/)))
TF_MODULES      = $(sort $(dir $(wildcard $(CURRENT_DIR)modules/*/)))
TF_DOCS_VERSION = 0.16.0

# Adjust your delimiter here or overwrite via make arguments
DELIM_START = <!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
DELIM_CLOSE = <!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

gen:
	@echo "################################################################################"
	@echo "# Terraform-docs generate"
	@echo "################################################################################"
	@$(MAKE) _gen-main

_gen-main:
	@echo "------------------------------------------------------------"
	@echo "# Main module"
	@echo "------------------------------------------------------------"
	@if docker run --rm \
		-v $(CURRENT_DIR):/data \
		-e DELIM_START='$(DELIM_START)' \
		-e DELIM_CLOSE='$(DELIM_CLOSE)' \
		cytopia/terraform-docs:${TF_DOCS_VERSION} \
		terraform-docs-replace-012 md README.md; then \
		echo "OK"; \
	else \
		echo "Failed"; \
		exit 1; \
	fi

================
File: ba/grafana/datasources/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/grafana-datasources/terraform.tfstate"

================
File: ba/grafana/datasources/prod-ue1.tfvars
================
region = "us-east-1"

================
File: ba/grafana/datasources/prod-uw2.backend.tfvars
================
key = "prod/us-west-2/grafana-datasources/terraform.tfstate"

================
File: ba/grafana/datasources/prod-uw2.tfvars
================
region = "us-west-2"

================
File: ba/grafana/datasources/README.md
================
<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.3 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | >= 4.32 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_aws"></a> [aws](#provider\_aws) | >= 4.32 |
| <a name="provider_vault"></a> [vault](#provider\_vault) | n/a |

## Modules

| Name | Source | Version |
|------|--------|---------|
| <a name="module_datasource"></a> [datasource](#module\_datasource) | git@github.com:enverus-cts/sre.tf-modules.hosted-grafana.git//datasources | n/a |

## Resources

| Name | Type |
|------|------|
| [aws_iam_access_key.iam_access_key](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_access_key) | resource |
| [aws_iam_policy.iam_policy](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy) | resource |
| [aws_iam_user.iam_user](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user) | resource |
| [aws_iam_user_policy_attachment.iam_user_policy_attachment](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_policy_attachment) | resource |
| [vault_generic_secret.generic_secret](https://registry.terraform.io/providers/hashicorp/vault/latest/docs/resources/generic_secret) | resource |
| [vault_generic_secret.grafana_api](https://registry.terraform.io/providers/hashicorp/vault/latest/docs/data-sources/generic_secret) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_VAULT_ADDR"></a> [VAULT\_ADDR](#input\_VAULT\_ADDR) | n/a | `any` | n/a | yes |
| <a name="input_assume_role_arn"></a> [assume\_role\_arn](#input\_assume\_role\_arn) | The arn of the role to assume. specific to the account being deployed to | `any` | n/a | yes |
| <a name="input_bu"></a> [bu](#input\_bu) | Business Unit | `string` | n/a | yes |
| <a name="input_env"></a> [env](#input\_env) | Environment level (dev/preprod/prod) | `string` | n/a | yes |
| <a name="input_region"></a> [region](#input\_region) | Region | `string` | n/a | yes |

## Outputs

No outputs.
<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

================
File: ba/grafana/datasources/variables.tf
================
variable "VAULT_ADDR" {}

variable "region" {
  type        = string
  description = "Region"
}

variable "bu" {
  type        = string
  description = "Business Unit"
}

variable "env" {
  type        = string
  description = "Environment level (dev/preprod/prod)"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/grafana/datasources/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

#Providers
provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "grafana-datasources"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/grafana/datasources"
      TerraformCreated = "true"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/grafana/firehose/dashboards/.terraform-version
================
latest:^0.12

================
File: ba/grafana/firehose/dashboards/dev.backend.tfvars
================
key = "dev/grafana/nomad-firehose/dashboards/terraform.tfstate"

================
File: ba/grafana/firehose/dashboards/dev.tfvars
================
env                     = "dev"
region                  = "us-east-1"
bu                      = "ba"
consul_address          = "consul-ue1.dev.ba.drillinginfo.com"
consul_token            = "XuqDDt/iorsgaP0q2uIt1Q=="
vault_path_aws_keys     = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_dev"
vault_path_grafana_keys = "di-secrets/terraform/grafana-provider"

================
File: ba/grafana/firehose/dashboards/firehose-template.json.tpl
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 0,
  "id": 128,
  "links": [],
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "last"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "5m",
        "frequency": "1m",
        "handler": 1,
        "message": "Failed allocation(s) for ${name}",
        "name": "${bu}-${env} - Failed allocation - Service: ${name}",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "${notification_uid}"
          }
        ]
      },
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": "grafanacloud-enverus-logs (prometheus)",
      "fieldConfig": {
        "defaults": {
          "custom": {
            "align": null,
            "filterable": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 4,
      "legend": {
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "7.3.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "count_over_time(({environment=\"${env}\", business_unit=\"${bu}\", service=\"di-nomad-firehose\"} | json | JobID=\"${name}\" | ClientStatus=\"failed\" | line_format \"{{.JobID}}\")[1m])",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "fill": true,
          "line": true,
          "op": "gt",
          "value": 0
        }
      ],
      "timeFrom": null,
      "timeRegions": [],
      "timeShift": null,
      "title": "Panel Title",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "transparent": true,
      "type": "graph",
      "xaxis": {
        "buckets": null,
        "mode": "time",
        "name": null,
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        },
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        }
      ],
      "yaxis": {
        "align": false,
        "alignLevel": null
      }
    }
  ],
  "refresh": false,
  "schemaVersion": 26,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "${bu} - ${env} - Nomad Firehose - ${name}",
  "uid": "${db_id}",
  "version": 3
}

================
File: ba/grafana/firehose/dashboards/main.tf
================
terraform {
  backend "s3" {}
  required_version = "~> 0.12.31"
}

data "vault_generic_secret" "aws" {
  path = var.vault_path_aws_keys
}

data "vault_generic_secret" "grafana" {
  path = var.vault_path_grafana_keys
}

data "consul_services" "aws-ue1" {
  query_options {
    datacenter = "aws-ue1"
  }
}

locals {
  aws_ue1_services = [
    for name in data.consul_services.aws-ue1.names : name
    if length(regexall(".-proxy.*", name)) == 0
  ]
  svc_all = local.aws_ue1_services
  rk_all  = data.consul_keys.aws_ue1_vo_routing_key.*.var.vo_routing_key
  svc_rk  = zipmap(local.svc_all, local.rk_all)
  cs_temp = sort(compact(distinct(local.svc_all)))
}

data "consul_keys" "aws_ue1_vo_routing_key" {
  datacenter = "aws-ue1"
  count      = length(local.aws_ue1_services)
  key {
    name = "vo_routing_key"
    path = "services/${local.aws_ue1_services[count.index]}/nomad/VO_ROUTING_KEY"
  }
}

output "cs_temp" {
  value = local.cs_temp
}

output "svc_rk" {
  value = local.svc_rk
}

resource "random_string" "db_id" {
  count   = length(local.cs_temp)
  length  = 10
  special = false
  number  = false
}

data "http" "nc_json" {
  url = "https://enverus.grafana.net/api/alert-notifications/lookup"

  request_headers = {
    Authorization = "Bearer ${data.vault_generic_secret.grafana.data["api_key"]}"
  }
}

locals {
  ### vars to build notificaiton channel name - nc uid after new ncs have been created
  raw_data     = jsondecode(data.http.nc_json.body)
  nc_uid       = local.raw_data[*].uid
  nc_name      = local.raw_data[*].name
  name_uid_map = zipmap(local.nc_name, local.nc_uid)
}

output "nc_json_uids_filtered" {
  value = local.nc_uid
}

output "nc_json_names_filtered" {
  value = local.nc_name
}

output "name_uid" {
  value = local.name_uid_map
}

data "template_file" "import" {
  template = file("${path.module}/firehose-template.json.tpl")
  count    = length(local.svc_rk)

  vars = {
    name             = keys(local.svc_rk)[count.index]
    notification_uid = lookup(local.name_uid_map, "VictorOps Alert - ${values(local.svc_rk)[count.index]}", "9PAg4JhMz")
    env              = var.env
    bu               = var.bu
    db_id            = random_string.db_id[count.index].result
  }
}

resource "grafana_folder" "firehose" {
  title = "Nomad Firehose - ${var.env} - ${var.bu}"
}

resource "grafana_dashboard" "firehose" {
  count       = length(local.cs_temp)
  config_json = data.template_file.import[count.index].rendered
  folder      = grafana_folder.firehose.id
}

================
File: ba/grafana/firehose/dashboards/prod.backend.tfvars
================
key = "prod/grafana/nomad-firehose/dashboards/terraform.tfstate"

================
File: ba/grafana/firehose/dashboards/prod.tfvars
================
env                     = "prod"
region                  = "us-east-1"
bu                      = "ba"
consul_address          = "consul-ue1.prod.ba.drillinginfo.com"
consul_token            = "H7yMJC/pXy255qYxj6nwfQ=="
vault_path_aws_keys     = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_prod"
vault_path_grafana_keys = "di-secrets/terraform/grafana-provider"

================
File: ba/grafana/firehose/dashboards/providers.tf
================
provider "vault" {
  address = "https://vault.dev.drillinginfo.com"
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "consul" {
  address = var.consul_address
  token   = var.consul_token
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

================
File: ba/grafana/firehose/dashboards/variables.tf
================
variable "env" {
  description = "Environment - used for tagging, naming, backend config"
}

variable "region" {
  description = "AWS ec2 region"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {}

variable "consul_address" {}

variable "consul_token" {}

variable "vault_path_grafana_keys" {}

variable "vault_path_aws_keys" {}

================
File: ba/iam/backup-data/.terraform-version
================
latest:^1.4

================
File: ba/iam/backup-data/main.tf
================
# Setup backend and state data and provider for IAM users

terraform {
  backend "s3" {}
}

# aws resources
provider "aws" {
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/iam/backup-data/oi-backup-data.tf
================
# resource "aws_iam_user" "oi-backup-data" {
#   name          = "oi-bkp-ba-${var.env}"
#   force_destroy = true

#   tags = {
#     BU        = "ba"
#     Component = "oi"
#     Contact   = "sre@drillinginfo.com"
#   }
# }

# data "aws_iam_policy_document" "oi-backup-data-policy" {
#   statement {
#     actions = [
#       "s3:*"
#     ]
#     resources = var.backup_policy_resources
#     effect    = "Allow"
#   }
# }

# resource "aws_iam_user_policy" "oi-backup-data-policy" {
#   name   = "oi-backup-data-policy"
#   user   = aws_iam_user.oi-backup-data.name
#   policy = data.aws_iam_policy_document.oi-backup-data-policy.json
# }

================
File: ba/iam/backup-data/preprod.backend.tfvars
================
key = "preprod/iam/oi/backup/terraform.tfstate"

================
File: ba/iam/backup-data/preprod.tfvars
================
env                 = "preprod"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_preprod"
backup_policy_resources = [
  "arn:aws:s3:::oi-db-backup-rc.enverus.com/*",
  "arn:aws:s3:::oi-db-backup-rc.enverus.com"
]

================
File: ba/iam/backup-data/prod.backend.tfvars
================
key = "prod/iam/oi/backup/terraform.tfstate"

================
File: ba/iam/backup-data/prod.tfvars
================
env                 = "prod"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_prod"
backup_policy_resources = [
  "arn:aws:s3:::oi-db-backup-uat.enverus.com/*",
  "arn:aws:s3:::oi-db-backup-uat.enverus.com",
  "arn:aws:s3:::oi-db-backup-onboard.enverus.com/*",
  "arn:aws:s3:::oi-db-backup-onboard.enverus.com"
]

================
File: ba/iam/backup-data/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}
variable "env" {}
variable "vault_path_aws_keys" {}
variable "backup_policy_resources" {
  description = "resources used by the oi backup data user"
}

================
File: ba/iam/backup-data/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/iam/codebuild/.terraform-version
================
latest

================
File: ba/iam/codebuild/dev.backend.tfvars
================
key            = "603547102569/iam/codebuild/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ba/iam/codebuild/main.tf
================
resource "aws_iam_role" "codebuild_service_role" {
  name_prefix = "codebuild-service-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Principal = {
          Service = "codebuild.amazonaws.com"
        },
        Action = "sts:AssumeRole"
      }
    ]
  })
}

resource "aws_iam_policy" "logs_policy" {
  name        = "allow-cloudwatch-logs"
  description = "Policy to allow logging actions for CodeBuild"

  policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents"
        ],
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "attach_logs_policy" {
  role       = aws_iam_role.codebuild_service_role.name
  policy_arn = aws_iam_policy.logs_policy.arn
}

================
File: ba/iam/codebuild/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/iam/codebuild/versions.tf
================
terraform {
  required_version = ">= 1.12"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 6"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = "dev"
      BusinessUnit     = "ba"
      Product          = "mineralsoft"
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/iam/codebuild"
      Team             = "mineralsoft-devops@enverus.com"
    }
  }
}

================
File: ba/iam/dms/.terraform-version
================
latest:^1.4

================
File: ba/iam/dms/dev.backend.tfvars
================
key = "dev/iam/dms/terraform.tfstate"

================
File: ba/iam/dms/main.tf
================
data "aws_iam_policy_document" "dms_assume_role" {
  statement {
    actions = ["sts:AssumeRole"]

    principals {
      identifiers = ["dms.amazonaws.com"]
      type        = "Service"
    }
  }
}

resource "aws_iam_role" "dms-access-for-endpoint" {
  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json
  name               = "dms-access-for-endpoint"
}

resource "aws_iam_role_policy_attachment" "dms-access-for-endpoint-AmazonDMSRedshiftS3Role" {
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonDMSRedshiftS3Role"
  role       = aws_iam_role.dms-access-for-endpoint.name
}

resource "aws_iam_role" "dms-cloudwatch-logs-role" {
  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json
  name               = "dms-cloudwatch-logs-role"
}

resource "aws_iam_role_policy_attachment" "dms-cloudwatch-logs-role-AmazonDMSCloudWatchLogsRole" {
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonDMSCloudWatchLogsRole"
  role       = aws_iam_role.dms-cloudwatch-logs-role.name
}

resource "aws_iam_role" "dms-vpc-role" {
  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json
  name               = "dms-vpc-role"
}

resource "aws_iam_role_policy_attachment" "dms-vpc-role-AmazonDMSVPCManagementRole" {
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonDMSVPCManagementRole"
  role       = aws_iam_role.dms-vpc-role.name
}

================
File: ba/iam/dms/preprod.backend.tfvars
================
key = "preprod/iam/dms/terraform.tfstate"

================
File: ba/iam/dms/prod.backend.tfvars
================
key = "prod/iam/dms/terraform.tfstate"

================
File: ba/iam/dms/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/iam/dms/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Product          = "nexus"
      Component        = "iam-dms"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/iam/dms"
      TerraformCreated = "true"
    }
  }
}

================
File: ba/iam/mineralsoft/.terraform-version
================
latest:^1.4

================
File: ba/iam/mineralsoft/dev-ue1.backend.tfvars
================
key = "dev/iam/users/mineralsoft/terraform.tfstate"

================
File: ba/iam/mineralsoft/dev-ue1.tfvars
================
env           = "dev"
region        = "us-east-1"
vault_address = "https://vault-ue1.dev.ba.drillinginfo.com"
dynamodb_resources = [
  "arn:aws:dynamodb:us-east-1:603547102569:table/pii-*-staging"
]
s3_resources = [
  "arn:aws:s3:::ms-app-files-staging.ba.enverus.com",
  "arn:aws:s3:::ms-app-files-staging.ba.enverus.com/*",
  "arn:aws:s3:::ms-sftp-staging.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-staging.ba.enverus.com/*"
]
secretmanager_resources = [
  "arn:aws:secretsmanager:us-east-1:603547102569:secret:ba-ms-nt-staging*"
]

================
File: ba/iam/mineralsoft/mineralsoft-user.tf
================
resource "aws_iam_user" "mineralsoft-user" {
  name          = "mineralsoft-${var.env}-user"
  force_destroy = true
}

data "aws_iam_policy_document" "mineralsoft-user-policies" {
  statement {
    sid = "s3"
    actions = [
      "s3:*",
      "s3-object-lambda:*"
    ]
    resources = var.s3_resources
    effect    = "Allow"
  }
  statement {
    sid = "dynamodb"
    actions = [
      "dynamodb:*"
    ]
    resources = var.dynamodb_resources
    effect    = "Allow"
  }
  statement {
    sid = "secretmanager"
    actions = [
      "secretsmanager:GetResourcePolicy",
      "secretsmanager:GetSecretValue",
      "secretsmanager:DescribeSecret",
      "secretsmanager:ListSecretVersionIds",
      "secretsmanager:GetRandomPassword",
      "secretsmanager:ListSecrets"
    ]
    resources = var.secretmanager_resources
    effect    = "Allow"
  }
}

resource "aws_iam_user_policy" "mineralsoft-policy" {
  name   = "mineralsoft-policy"
  user   = aws_iam_user.mineralsoft-user.name
  policy = data.aws_iam_policy_document.mineralsoft-user-policies.json
}

resource "aws_iam_access_key" "mineralsoft-data-connector" {
  user = aws_iam_user.mineralsoft-user.name
}

resource "vault_generic_secret" "vault_secret_iam_mineralsoft_data_connector" {
  path = "di-secrets/terraform/aws-api-keys/mineralsoft-user"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.mineralsoft-data-connector.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.mineralsoft-data-connector.id
    }
  )
}

================
File: ba/iam/mineralsoft/prod-ue1.backend.tfvars
================
key = "prod/iam/users/mineralsoft/terraform.tfstate"

================
File: ba/iam/mineralsoft/prod-ue1.tfvars
================
env           = "prod"
region        = "us-east-1"
vault_address = "https://vault-ue1.prod.ba.drillinginfo.com"
dynamodb_resources = [
  "arn:aws:dynamodb:us-east-1:512870776320:table/pii-*-prod",
  "arn:aws:dynamodb:us-east-1:512870776320:table/pii-*-uat"
]
s3_resources = [
  "arn:aws:s3:::ms-app-files-prod.ba.enverus.com",
  "arn:aws:s3:::ms-app-files-prod.ba.enverus.com/*",
  "arn:aws:s3:::ms-app-files-uat.ba.enverus.com",
  "arn:aws:s3:::ms-app-files-uat.ba.enverus.com/*",
  "arn:aws:s3:::ms-sftp-prod.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-prod.ba.enverus.com/*",
  "arn:aws:s3:::ms-sftp-uat.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-uat.ba.enverus.com/*"
]
secretmanager_resources = [
  "arn:aws:secretsmanager:us-east-1:512870776320:secret:ba-ms-nt-prod*",
  "arn:aws:secretsmanager:us-east-1:512870776320:secret:ba-ms-nt-uat*",
]

================
File: ba/iam/mineralsoft/variables.tf
================
variable "bu" {}
variable "env" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}
variable "vault_address" {}
variable "region" {}
variable "s3_resources" {
  description = "s3 resources for mineralsoft policy"
}
variable "dynamodb_resources" {
  description = "dynamodb resources for mineralsoft policy"
}
variable "secretmanager_resources" {
  description = "secretmanager resources for mineralsoft policy"
}

================
File: ba/iam/mineralsoft/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.vault_address
}

# aws resources
provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Product      = "mineralsoft"
      BusinessUnit = var.bu
      Component    = "iam"
      Team         = "sre@enverus.com"
      SourceCode   = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/iam/mineralsoft"
      Environment  = var.env
    }
  }
}

================
File: ba/iam/revenue-data/.terraform-version
================
latest:^1.4

================
File: ba/iam/revenue-data/dev.backend.tfvars
================
key = "dev/iam/oi/terraform.tfstate"

================
File: ba/iam/revenue-data/dev.tfvars
================
env                 = "dev"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_dev"
el_policy_resources = [
  "arn:aws:s3:::energylink-data-dev.ba.enverus.com",
  "arn:aws:s3:::energylink-data-dev.ba.enverus.com/*",
  "arn:aws:s3:::energylink-data-uat.ba.enverus.com",
  "arn:aws:s3:::energylink-data-uat.ba.enverus.com/*",
  "arn:aws:s3:::mineraliq-pdf-dev.ba.enverus.com",
  "arn:aws:s3:::mineraliq-pdf-dev.ba.enverus.com/*",
  "arn:aws:s3:::mineraliq-pdf-uat.ba.enverus.com",
  "arn:aws:s3:::mineraliq-pdf-uat.ba.enverus.com/*",
]
wm_el_policy_resources = [
  "arn:aws:s3:::wm-data-staging.ba.enverus.com",
  "arn:aws:s3:::wm-data-staging.ba.enverus.com/*"
]
ea_policy_resources = [
  "arn:aws:s3:::ea-data-prod.ba.enverus.com",
  "arn:aws:s3:::ea-data-prod.ba.enverus.com/*"
]
reader_policy_resources = [
  "arn:aws:s3:::energylink-data-dev.ba.enverus.com",
  "arn:aws:s3:::energylink-data-dev.ba.enverus.com/*",
  "arn:aws:s3:::energylink-data-uat.ba.enverus.com",
  "arn:aws:s3:::energylink-data-uat.ba.enverus.com/*",
]
mineralsoft_el_policy_resources = [
  "arn:aws:s3:::ms-sftp-staging.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-staging.ba.enverus.com/*"
]

================
File: ba/iam/revenue-data/el-revenue-data.tf
================
resource "aws_iam_user" "el-revenue-data" {
  name          = "el-revenue-data"
  force_destroy = true

  tags = {
    BU        = "ba"
    Component = "el"
    Contact   = "sre@drillinginfo.com"
  }
}

data "aws_iam_policy_document" "el-revenue-data-policy" {
  statement {
    sid = "1"
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:ListBucket"
    ]
    resources = var.el_policy_resources
    effect    = "Allow"
  }

  statement {
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:ListBucket"
    ]

    resources = var.wm_el_policy_resources

    condition {
      test     = "StringLike"
      variable = "s3:prefix"

      values = [
        "EnergyLink/*",
      ]
    }
  }

  statement {
    actions = [
      "s3:ListBucket",
      "s3:GetObjectAcl",
      "s3:GetObject",
      "s3:GetObjectVersion",
      "s3:GetBucketLocation"
    ]

    resources = var.ea_policy_resources
    effect    = "Allow"
  }

  statement {
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:ListBucket"
    ]

    resources = var.mineralsoft_el_policy_resources

    condition {
      test     = "StringLike"
      variable = "s3:prefix"

      values = [
        "energylink/*",
      ]
    }
  }

  statement {
    actions = [
      "s3:GetObject",
      "s3:ListBucket"
    ]

    resources = var.wm_el_policy_resources

    condition {
      test     = "StringLike"
      variable = "s3:prefix"

      values = [
        "PropertyMap/*",
      ]
    }
  }
}

resource "aws_iam_user_policy" "el-revenue-data-policy" {
  name   = "el-revenue-data-policy"
  user   = aws_iam_user.el-revenue-data.name
  policy = data.aws_iam_policy_document.el-revenue-data-policy.json
}

================
File: ba/iam/revenue-data/main.tf
================
# Setup backend and state data and provider for IAM users
terraform {
  backend "s3" {}
}

# aws resources
provider "aws" {
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/iam/revenue-data/odx-revenue-data.tf
================
# resource "aws_iam_user" "odx-revenue-data" {
#   count         = (var.env == "prod" ? 1 : 0)
#   name          = "odx-revenue-data"
#   force_destroy = true

#   tags = {
#     BU        = "ba"
#     Component = "odx"
#     Contact   = "sre@drillinginfo.com"
#   }
# }

# data "aws_iam_policy_document" "odx-revenue-data-policy" {
#   statement {
#     actions = [
#       "s3:PutObject",
#       "s3:GetObject",
#       "s3:ListBucket"
#     ]
#     resources = [
#       "arn:aws:s3:::odx-data-prod.ba.enverus.com",
#       "arn:aws:s3:::odx-data-prod.ba.enverus.com/*"
#     ]
#     effect = "Allow"
#   }
# }

# resource "aws_iam_user_policy" "odx-revenue-data-policy" {
#   count  = (var.env == "prod" ? 1 : 0)
#   name   = "odx-revenue-data-policy"
#   user   = aws_iam_user.odx-revenue-data[count.index].name
#   policy = data.aws_iam_policy_document.odx-revenue-data-policy.json
# }

================
File: ba/iam/revenue-data/pds-revenue-data.tf
================
# resource "aws_iam_user" "pds-revenue-data" {
#   count         = (var.env == "prod" ? 1 : 0)
#   name          = "pds-revenue-data"
#   force_destroy = true

#   tags = {
#     BU        = "ba"
#     Component = "pds"
#     Contact   = "sre@drillinginfo.com"
#   }
# }

# data "aws_iam_policy_document" "pds-revenue-data-policy" {
#   statement {
#     actions = [
#       "s3:PutObject",
#       "s3:GetObject",
#       "s3:ListBucket"
#     ]
#     resources = [
#       "arn:aws:s3:::pds-data-prod.ba.enverus.com",
#       "arn:aws:s3:::pds-data-prod.ba.enverus.com/*",
#       "arn:aws:s3:::pds-legacy-data-prod.ba.enverus.com/*",
#       "arn:aws:s3:::pds-legacy-data-prod.ba.enverus.com"
#     ]
#     effect = "Allow"
#   }
# }

# resource "aws_iam_user_policy" "pds-revenue-data-policy" {
#   count  = (var.env == "prod" ? 1 : 0)
#   name   = "pds-revenue-data-policy"
#   user   = aws_iam_user.pds-revenue-data[count.index].name
#   policy = data.aws_iam_policy_document.pds-revenue-data-policy.json
# }

================
File: ba/iam/revenue-data/prod.backend.tfvars
================
key = "prod/iam/oi/terraform.tfstate"

================
File: ba/iam/revenue-data/prod.tfvars
================
env                 = "prod"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_prod"
el_policy_resources = [
  "arn:aws:s3:::energylink-data-prod.ba.enverus.com",
  "arn:aws:s3:::energylink-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::mineraliq-pdf-prod.ba.enverus.com",
  "arn:aws:s3:::mineraliq-pdf-prod.ba.enverus.com/*"
]
wm_el_policy_resources = [
  "arn:aws:s3:::wm-data-prod.ba.enverus.com",
  "arn:aws:s3:::wm-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::ea-data-prod.ba.enverus.com",
  "arn:aws:s3:::ea-data-prod.ba.enverus.com/*"
]
ea_policy_resources = [
  "arn:aws:s3:::ea-data-prod.ba.enverus.com",
  "arn:aws:s3:::ea-data-prod.ba.enverus.com/*"
]
reader_policy_resources = [
  "arn:aws:s3:::energylink-data-prod.ba.enverus.com",
  "arn:aws:s3:::energylink-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::odx-data-prod.ba.enverus.com",
  "arn:aws:s3:::odx-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::pds-data-prod.ba.enverus.com",
  "arn:aws:s3:::pds-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::pds-legacy-data-prod.ba.enverus.com/*",
  "arn:aws:s3:::pds-legacy-data-prod.ba.enverus.com"
]
mineralsoft_el_policy_resources = [
  "arn:aws:s3:::ms-sftp-prod.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-prod.ba.enverus.com/*",
  "arn:aws:s3:::ms-sftp-uat.ba.enverus.com",
  "arn:aws:s3:::ms-sftp-uat.ba.enverus.com/*"
]

================
File: ba/iam/revenue-data/revenue-data-reader.tf
================
# resource "aws_iam_user" "revenue-data-reader" {
#   name          = "revenue-data-reader"
#   force_destroy = true

#   tags = {
#     BU        = "ba"
#     Component = "openinvoice"
#     Contact   = "sre@drillinginfo.com"
#   }
# }

# data "aws_iam_policy_document" "revenue-data-reader-policy" {
#   statement {
#     actions = [
#       "s3:GetObject",
#       "s3:ListBucket"
#     ]
#     resources = var.reader_policy_resources
#     effect    = "Allow"
#   }
# }

# resource "aws_iam_user_policy" "revenue-data-reader-policy" {
#   name   = "revenue-data-reader-policy"
#   user   = aws_iam_user.revenue-data-reader.name
#   policy = data.aws_iam_policy_document.revenue-data-reader-policy.json
# }

================
File: ba/iam/revenue-data/variables.tf
================
variable "env" {}
variable "el_policy_resources" {
  description = "resources used by the el revenue data user"
}
variable "wm_el_policy_resources" {
  description = "well matching resources used by the el revenue data user"
}
variable "ea_policy_resources" {
  description = "EA resources used by the el revenue data user"
}
variable "mineralsoft_el_policy_resources" {
  description = "MineralSoft resources used by the el data user"
}
variable "reader_policy_resources" {
  description = "resources used by the revenue data reader user"
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/iam/revenue-data/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/iam/s3-batch-operations/minerals-migration/.terraform-version
================
latest:^1.4

================
File: ba/iam/s3-batch-operations/minerals-migration/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

# create a role to use for cross account s3 batch copy from minerals source to destination in ba-prod
resource "aws_iam_role" "s3-cross-account-batch-copy" {
  name = "s3-cross-account-batch-copy-minerals-migration"

  # Terraform's "jsonencode" function converts a
  # Terraform expression result to valid JSON syntax.
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Sid    = ""
        Principal = {
          Service = "batchoperations.s3.amazonaws.com"
        }
      },
    ]
  })

  inline_policy {
    name = "s3-cross-account-batch-copy-minerals-migration-policy"

    policy = jsonencode({
      "Version" : "2012-10-17",
      "Statement" : [
        {
          "Sid" : "AllowBatchOperationsDestinationObjectCOPY",
          "Effect" : "Allow",
          "Action" : [
            "s3:PutObject",
            "s3:PutObjectVersionAcl",
            "s3:PutObjectAcl",
            "s3:PutObjectVersionTagging",
            "s3:PutObjectTagging",
            "s3:GetObject",
            "s3:GetObjectVersion",
            "s3:GetObjectAcl",
            "s3:GetObjectTagging",
            "s3:GetObjectVersionAcl",
            "s3:GetObjectVersionTagging"
          ],
          "Resource" : [
            "arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*",
            "arn:aws:s3:::enverus-minerals-prod-dr-0b4d3e5148cd/*",
            "arn:aws:s3:::enverus-minerals-preprod-8e3a124ee403/*",
            "arn:aws:s3:::minerals/*"
          ]
        }
      ]
    })
  }

  tags = {
    Environment      = var.env
    Team             = "sre@enverus.com"
    stack            = var.env
    component        = "mineralsoft"
    terraformcreated = "true"
    bu               = "ba"
    tagSourceCode    = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/iam/s3-batch-operations/minerals-migration"
  }
}

================
File: ba/iam/s3-batch-operations/minerals-migration/preprod.backend.tfvars
================
key = "preprod/iam/s3-batch-operations/minerals-migration/terraform.tfstate"

================
File: ba/iam/s3-batch-operations/minerals-migration/preprod.tfvars
================
# Put prod-specific values here
region = "us-east-1"

================
File: ba/iam/s3-batch-operations/minerals-migration/prod.backend.tfvars
================
key = "prod/iam/s3-batch-operations/minerals-migration/terraform.tfstate"

================
File: ba/iam/s3-batch-operations/minerals-migration/prod.tfvars
================
# Put prod-specific values here
region             = "us-east-1"
bucket_policy_file = "prod-policy.json"

================
File: ba/iam/s3-batch-operations/minerals-migration/variables.tf
================
variable "region" {
  description = "aws region"
}

variable "env" {
  description = "environment, eg dev"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/iam/s3-batch-operations/minerals-migration/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/iam/s3-cross-account-access/minerals-migration/.terraform-version
================
latest:^1.4

================
File: ba/iam/s3-cross-account-access/minerals-migration/preprod.backend.tfvars
================
key = "preprod/iam/s3-cross-account-access/minerals-migration/terraform.tfstate"

================
File: ba/iam/s3-cross-account-access/minerals-migration/preprod.tfvars
================
# Put prod-specific values here
vault_path_aws_keys_minerals = "di-secrets/terraform/aws_api_keys/terraform_keys_mineralsoft_prod"
region                       = "us-east-1"

================
File: ba/iam/s3-cross-account-access/minerals-migration/prod.backend.tfvars
================
key = "prod/iam/s3-cross-account-access/minerals-migration/terraform.tfstate"

================
File: ba/iam/s3-cross-account-access/minerals-migration/prod.tfvars
================
# Put prod-specific values here
vault_path_aws_keys_minerals = "di-secrets/terraform/aws_api_keys/terraform_keys_mineralsoft_prod"
region                       = "us-east-1"

================
File: ba/iam/s3-cross-account-access/minerals-migration/variables.tf
================
variable "vault_path_aws_keys_minerals" {
  description = "path in Vault to aws api keys"
}

variable "region" {
  description = "aws region"
}

variable "env" {
  description = "environment, eg dev"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/iam/s3-cross-account-access/minerals-migration/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

================
File: ba/iam/users/policies/genai-bidout-policy.json
================
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "bedrock:ListTagsForResource",
                "bedrock:ListProvisionedModelThroughputs",
                "bedrock:ListModelCustomizationJobs",
                "bedrock:ListFoundationModels",
                "bedrock:ListCustomModels",
                "bedrock:InvokeModelWithResponseStream",
                "bedrock:InvokeModel",
                "bedrock:GetProvisionedModelThroughput",
                "bedrock:GetModelInvocationLoggingConfiguration",
                "bedrock:GetModelCustomizationJob",
                "bedrock:GetFoundationModelAvailability",
                "bedrock:GetFoundationModel",
                "bedrock:GetCustomModel"
            ],
            "Effect": "Allow",
            "Resource": "*"
        }
    ]
}

================
File: ba/iam/users/policies/sw-attachment-reader-policy.json
================
{
  "Version": "2012-10-17",
  "Statement": [
      {
          "Sid": "Statement1",
          "Effect": "Allow",
          "Action": [
              "s3:GetObject*",
              "s3:ListBucket"
          ],
          "Resource": [
              "arn:aws:s3:::odx-tree-prod.ba.enverus.com",
              "arn:aws:s3:::odx-tree-prod.ba.enverus.com/*"
          ],
          "Condition": {
              "ForAnyValue:StringLike": {
                  "s3:prefix": [
                      "SpendWorksAttachments/*"
                  ]
              }
          }
      }
  ]
}

================
File: ba/iam/users/.terraform-version
================
latest:^1.10

================
File: ba/iam/users/bedrock.tf
================
resource "aws_iam_user" "genai-oi-bedrock" {
  name          = "genai-oi-bedrock-${var.env}"
  force_destroy = true

  tags = {
    BU        = "ba"
    Component = "openinvoice"
    Contact   = "mayank.patel@enverus.com"
  }
}

resource "aws_iam_policy" "genai-oi-bedrock-policy" {
  name        = "genai-oi-bedrock-policy-${var.env}"
  description = "read only policy"
  policy      = file("${path.module}/policies/genai-bidout-policy.json")
}

resource "aws_iam_user_policy_attachment" "genai-oi-bedrock-policy" {
  user       = aws_iam_user.genai-oi-bedrock.name
  policy_arn = aws_iam_policy.genai-oi-bedrock-policy.arn
}

resource "aws_iam_access_key" "genai-oi-bedrock-policy-key" {
  user = aws_iam_user.genai-oi-bedrock.name
}

resource "vault_generic_secret" "vault-secret-iam-genai-oi-bedrock-policy-key" {
  path = "di-secrets/terraform/aws-api-keys/${aws_iam_user.genai-oi-bedrock.name}"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.genai-oi-bedrock-policy-key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.genai-oi-bedrock-policy-key.id
    }
  )
}

================
File: ba/iam/users/bidout.tf
================
resource "aws_iam_user" "genai-bidout" {
  name          = "genai-bidout-${var.env}"
  force_destroy = true

  tags = {
    BU        = "ba"
    Component = "bidout"
    Contact   = "mayank.patel@enverus.com"
  }
}

resource "aws_iam_policy" "genai-bidout-policy" {
  name        = "genai-bidout-policy-${var.env}"
  description = "read only policy"
  policy      = file("${path.module}/policies/genai-bidout-policy.json")
}

resource "aws_iam_user_policy_attachment" "genai-bidout-policy" {
  user       = aws_iam_user.genai-bidout.name
  policy_arn = aws_iam_policy.genai-bidout-policy.arn
}

resource "aws_iam_access_key" "genai-bidout-policy-key" {
  user = aws_iam_user.genai-bidout.name
}

resource "vault_generic_secret" "vault-secret-iam-genai-bidout-policy-key" {
  path = "di-secrets/terraform/aws-api-keys/${aws_iam_user.genai-bidout.name}"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.genai-bidout-policy-key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.genai-bidout-policy-key.id
    }
  )
}

================
File: ba/iam/users/dev-ue1.backend.tfvars
================
key = "dev/iam/users/terraform.tfstate"

================
File: ba/iam/users/dev-ue1.tfvars
================
env           = "dev"
resource_env  = "staging"
region        = "us-east-1"
vault_address = "https://vault-ue1.dev.ba.drillinginfo.com"

================
File: ba/iam/users/main.tf
================
# Setup backend and state data and provider for IAM users

================
File: ba/iam/users/oi-fundthrough-user.tf
================
# this creates "dev" (in ba-dev account) and "prod" (in ba-prod account) users
resource "aws_iam_user" "fundthrough-user1" {
  name          = "fundthrough-${var.env}-user"
  force_destroy = true

  tags = {
    BU      = "ba"
    Contact = "sre@drillinginfo.com"
  }
}

resource "aws_iam_access_key" "fundthrough_user1_api_key" {
  user = aws_iam_user.fundthrough-user1.name
}

resource "vault_generic_secret" "fundthrough_user1_api_key" {
  path = "di-secrets/terraform/application/epayables/${var.env == "prod" ? "prod" : "dev"}/iam-fundtrhough-user-access-key"

  data_json = jsonencode(
    {
      "USER_NAME"             = aws_iam_user.fundthrough-user1.name
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.fundthrough_user1_api_key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.fundthrough_user1_api_key.id
    }
  )
}

# this creates "staging" (in ba-dev account) and "onboard" (in ba-prod account) users
resource "aws_iam_user" "fundthrough-user2" {
  name          = var.env == "prod" ? "fundthrough-onboard-user" : "fundthrough-staging-user"
  force_destroy = true

  tags = {
    BU      = "ba"
    Contact = "sre@drillinginfo.com"
  }
}

resource "aws_iam_access_key" "fundthrough_user2_api_key" {
  user = aws_iam_user.fundthrough-user2.name
}

resource "vault_generic_secret" "fundthrough_user2_api_key" {
  path = "di-secrets/terraform/application/epayables/${var.env == "prod" ? "onboard" : "staging"}/iam-fundtrhough-user-access-key"

  data_json = jsonencode(
    {
      "USER_NAME"             = aws_iam_user.fundthrough-user2.name
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.fundthrough_user2_api_key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.fundthrough_user2_api_key.id
    }
  )
}

# this creates "rc" (in ba-dev account) and "uat" (in ba-prod account) users
resource "aws_iam_user" "fundthrough-user3" {
  name          = var.env == "prod" ? "fundthrough-uat-user" : "fundthrough-rc-user"
  force_destroy = true

  tags = {
    BU      = "ba"
    Contact = "sre@drillinginfo.com"
  }
}

resource "aws_iam_access_key" "fundthrough_user3_api_key" {
  user = aws_iam_user.fundthrough-user3.name
}

resource "vault_generic_secret" "fundthrough_user3_api_key" {
  path = "di-secrets/terraform/application/epayables/${var.env == "prod" ? "uat" : "rc"}/iam-fundtrhough-user-access-key"

  data_json = jsonencode(
    {
      "USER_NAME"             = aws_iam_user.fundthrough-user3.name
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.fundthrough_user3_api_key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.fundthrough_user3_api_key.id
    }
  )
}

================
File: ba/iam/users/preprod-ue1.backend.tfvars
================
key = "preprod/iam/users/terraform.tfstate"

================
File: ba/iam/users/preprod-ue1.tfvars
================
env           = "preprod"
resource_env  = "preprod"
region        = "us-east-1"
vault_address = "https://vault-ue1.preprod.ba.drillinginfo.com"

================
File: ba/iam/users/prod-ue1.backend.tfvars
================
key = "prod/iam/users/terraform.tfstate"

================
File: ba/iam/users/prod-ue1.tfvars
================
env           = "prod"
resource_env  = "prod"
region        = "us-east-1"
vault_address = "https://vault-ue1.prod.ba.drillinginfo.com"

================
File: ba/iam/users/refinery-user.tf
================
resource "aws_iam_user" "iam-refinery-data-user" {
  name          = "refinery-${var.env}"
  force_destroy = true

  tags = {
    BU      = "ba"
    Contact = "sre@drillinginfo.com"
  }
}

data "aws_iam_policy_document" "trap-data-policies" {
  statement {
    sid = "AllowList"
    actions = [
      "s3:ListBucket"
    ]
    resources = [
      "arn:aws:s3:::trap-data-${var.resource_env}.ba.enverus.com",
      "arn:aws:s3:::trap-data-${var.resource_env}.ba.enverus.com/*",
      "arn:aws:s3:::trapdata-${var.resource_env}.ba.enverus.com",
      "arn:aws:s3:::trapdata-${var.resource_env}.ba.enverus.com/*"
    ]
    effect = "Allow"
  }

  statement {
    sid = "AllowPut"
    actions = [
      "s3:GetObject",
      "s3:PutObject"
    ]
    resources = [
      "arn:aws:s3:::trap-data-${var.resource_env}.ba.enverus.com/refinery/out/*",
      "arn:aws:s3:::trapdata-${var.resource_env}.ba.enverus.com/refinery/out/*"
    ]
    effect = "Allow"
  }

  statement {
    sid = "GetAndListRefinery"
    actions = [
      "s3:ListBucket",
      "s3:Get*"
    ]
    resources = [
      "arn:aws:s3:::trap-data-${var.resource_env}.ba.enverus.com/refinery/*",
      "arn:aws:s3:::trapdata-${var.resource_env}.ba.enverus.com/refinery/*"
    ]
    effect = "Allow"

    condition {
      test     = "StringNotEquals"
      variable = "s3:prefix"

      values = [
        "*.json"
      ]
    }
  }

  statement {
    sid = "GetAndListAll"
    actions = [
      "s3:ListBucket",
      "s3:Get*"
    ]
    resources = [
      "arn:aws:s3:::trap-data-${var.resource_env}.ba.enverus.com/*",
      "arn:aws:s3:::trapdata-${var.resource_env}.ba.enverus.com/*"
    ]
    effect = "Allow"

    condition {
      test     = "StringNotEquals"
      variable = "s3:prefix"

      values = [
        "*.png"
      ]
    }
  }
}

resource "aws_iam_user_policy" "trap-data-policy" {
  name   = "trap-data-policy"
  user   = aws_iam_user.iam-refinery-data-user.name
  policy = data.aws_iam_policy_document.trap-data-policies.json
}

resource "aws_iam_access_key" "refinery-data-connector" {
  user = aws_iam_user.iam-refinery-data-user.name
}

resource "vault_generic_secret" "vault_secret_iam_refinery_data_connector" {
  path = "di-secrets/terraform/aws-api-keys/iam-refinery-data-user"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.refinery-data-connector.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.refinery-data-connector.id
    }
  )
}

================
File: ba/iam/users/sw-attachment-reader.tf
================
resource "aws_iam_user" "sw-attachment-reader" {
  count         = (var.env == "prod" ? 1 : 0)
  name          = "sw-attachment-reader"
  force_destroy = true

  tags = {
    BU        = "ba"
    Component = "odx"
    Contact   = "mayank.patel@enverus.com"
  }
}

resource "aws_iam_policy" "sw-attachment-reader-policy" {
  count       = (var.env == "prod" ? 1 : 0)
  name        = "sw-attachment-reader-policy"
  description = "read only policy"
  policy      = file("${path.module}/policies/sw-attachment-reader-policy.json")
}

resource "aws_iam_user_policy_attachment" "sw-attachment-reader-policy" {
  count      = (var.env == "prod" ? 1 : 0)
  user       = aws_iam_user.sw-attachment-reader[count.index].name
  policy_arn = aws_iam_policy.sw-attachment-reader-policy[count.index].arn
}

resource "aws_iam_access_key" "sw-attachment-reader-policy-key" {
  count = (var.env == "prod" ? 1 : 0)
  user  = aws_iam_user.sw-attachment-reader[count.index].name
}

resource "vault_generic_secret" "vault-secret-iam-sw-attachment-reader-policy-key" {
  count = (var.env == "prod" ? 1 : 0)
  path  = "di-secrets/terraform/aws-api-keys/${aws_iam_user.sw-attachment-reader[count.index].name}"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.sw-attachment-reader-policy-key[count.index].secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.sw-attachment-reader-policy-key[count.index].id
    }
  )
}

================
File: ba/iam/users/terraform-migration.tf
================
resource "aws_iam_user" "iam-terraform-user" {
  name          = "terraform-${var.env}"
  force_destroy = true

  tags = {
    BU      = "ba"
    Contact = "sre@drillinginfo.com"
  }
}

data "aws_iam_policy_document" "ba-access-oi-policies" {
  statement {
    sid = "AllowList"
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:GetObjectTagging",
      "s3:ListBucket",
      "s3:PutObjectTagging",
    "s3:DeleteObject"]
    resources = [
      "arn:aws:s3:::ctx.transzap.com",
      "arn:aws:s3:::clusters.prometheus.ba-tools.transzap.com",
      "arn:aws:s3:::grafana-provisioning.ba-tools.transzap.com"
    ]
    effect = "Allow"
  }
  statement {
    sid = "BucketMigrationProd"
    actions = [
      "s3:PutObjectTagging",
      "s3:PutObjectAcl",
      "s3:PutObject",
      "s3:ListBucket",
      "s3:GetObjectTagging",
      "s3:GetObjectAcl",
      "s3:GetObject",
      "s3:GetBucketLocation",
      "s3:DeleteObject"
    ]
    resources = [
      "arn:aws:s3:::web-methods-wm910:*",
      "arn:aws:s3:::terraform-state.ba.enverus.com:*",
      "arn:aws:s3:::serverless-artifact.ba.enverus.com:*",
      "arn:aws:s3:::resource-placeholder-dev:*",
      "arn:aws:s3:::oi-dev-dbf-cdn:*",
      "arn:aws:s3:::oi-dev-dbf-cdn/*:*",
      "arn:aws:s3:::msa-attachments-uat.transzap.com:*",
      "arn:aws:s3:::msa-attachments-prod.transzap.com:*",
      "arn:aws:s3:::msa-attachments-onboard.transzap.com:*",
      "arn:aws:s3:::ep-attachments-uat.transzap.com:*",
      "arn:aws:s3:::ep-attachments-prod.transzap.com:*",
      "arn:aws:s3:::ep-attachments-onboard.transzap.com:*",
      "arn:aws:s3:::case-mgmt-attachments-uat.transzap.com:*",
      "arn:aws:s3:::case-mgmt-attachments-prod.transzap.com:*",
      "arn:aws:s3:::case-mgmt-attachments-onboard.transzap.com:*"
    ]
  }
}

resource "aws_iam_user_policy" "terraform-iam-user-policy" {
  name   = "terraform_ba_access_oi_buckets"
  user   = aws_iam_user.iam-terraform-user.name
  policy = data.aws_iam_policy_document.ba-access-oi-policies.json
}

resource "aws_iam_user_policy_attachment" "iam_user_admin_policy_attachment" {
  user       = aws_iam_user.iam-terraform-user.name
  policy_arn = "arn:aws:iam::aws:policy/AdministratorAccess"
}

resource "aws_iam_access_key" "terraform_data_connector" {
  user = aws_iam_user.iam-terraform-user.name
}

resource "vault_generic_secret" "vault_secret_iam_terraform_data_connector" {
  path = "di-secrets/terraform/aws-api-keys/iam-terraform-user"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.terraform_data_connector.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.terraform_data_connector.id
    }
  )
}

================
File: ba/iam/users/variables.tf
================
variable "env" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "resource_env" {
  description = "environment of the resource reason for this in dev the s3 bucket has staging in the name"
}

variable "vault_address" {}
variable "region" {}

================
File: ba/iam/users/versions.tf
================
terraform {
  backend "s3" {}
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.vault_address
}

# aws resources
provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/iam/users"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: ba/invoiceclassifier-lambda/.terraform-version
================
latest:^1.4

================
File: ba/invoiceclassifier-lambda/dev-ue1.backend.tfvars
================
key = "dev/us-west-2/invoiceclassifier-lambda/terraform.tfstate"

================
File: ba/invoiceclassifier-lambda/main.tf
================
#Datasources
data "aws_caller_identity" "caller_identity" {}

# ECRs to store the images
resource "aws_ecr_repository" "invoiceclassifier-lambda-repo" {
  name = "invoiceclassifier-lambda"
}
resource "aws_ecr_repository" "invoiceclassifierbuilder-lambda-repo" {
  name = "invoiceclassifierbuilder-lambda"
}
resource "aws_ecr_repository" "invoiceclassifierfourier-lambda-repo" {
  name = "invoiceclassifierfourier-lambda"
}

# Permit replication
# Need to add the replication on 070551638384 side.
resource "aws_ecr_registry_policy" "example" {
  policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Sid    = "ReplicationAccessCrossAccount",
        Effect = "Allow",
        Principal = {
          "AWS" : "arn:aws:iam::070551638384:root"
        },
        Action = [
          "ecr:ReplicateImage"
        ],
        Resource = [
          "arn:aws:ecr:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:repository/*"
        ]
      }
    ]
  })
}


#IAM policy for Lambda

## IAM permissions


### Roles
resource "aws_iam_role" "invoiceclassifier-lambda-role" {
  name               = "invoiceclassifier-lambda-role"
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": [
            "lambda.amazonaws.com",
            "batchoperations.s3.amazonaws.com"
          ]
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}

resource "aws_iam_role" "invoiceclassifierbuilder-lambda-role" {
  name               = "invoiceclassifierbuilder-lambda-role"
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": [
            "lambda.amazonaws.com",
            "batchoperations.s3.amazonaws.com"
          ]
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}

resource "aws_iam_role" "invoiceclassifierfourier-lambda-role" {
  name               = "invoiceclassifierfourier-lambda-role"
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": [
            "lambda.amazonaws.com",
            "batchoperations.s3.amazonaws.com"
          ]
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}


### Policy
data "aws_iam_policy" "AmazonS3FullAccess" {
  arn = "arn:aws:iam::aws:policy/AmazonS3FullAccess"
}

data "aws_iam_policy" "AWSLambdaFullAccess" {
  arn = "arn:aws:iam::aws:policy/AWSLambda_FullAccess"
}

data "aws_iam_policy" "CloudWatchFullAccess" {
  arn = "arn:aws:iam::aws:policy/CloudWatchFullAccess"
}

data "aws_iam_policy" "AWSLambdaVPCAccessExecutionRole" {
  arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
}

####  Policy for db access
resource "aws_iam_policy" "invoiceclassifier-lambda-dbaccess" {
  name        = "invoiceclassifier-lambda-dbaccess-policy"
  description = "Lambda Function DB Access Policy"

  policy = <<EOF
{
  "Version":"2012-10-17",
  "Statement":[
    {
      "Effect": "Allow",
      "Action": [
        "rds-db:connect"
      ],
      "Resource": "arn:aws:rds-db:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:dbuser:cluster-KF5FKFWAORJTDBIRNM6GEK7ZEQ/jemanuel"
    }
  ]
}
EOF
}

### Attach policies to the roles

#### invoiceclassifier-lambda

resource "aws_iam_role_policy_attachment" "AmazonS3FullAccess" {
  role       = aws_iam_role.invoiceclassifier-lambda-role.name
  policy_arn = data.aws_iam_policy.AmazonS3FullAccess.arn
}

resource "aws_iam_role_policy_attachment" "AWSLambdaFullAccess" {
  role       = aws_iam_role.invoiceclassifier-lambda-role.name
  policy_arn = data.aws_iam_policy.AWSLambdaFullAccess.arn
}

resource "aws_iam_role_policy_attachment" "CloudWatchFullAccess" {
  role       = aws_iam_role.invoiceclassifier-lambda-role.name
  policy_arn = data.aws_iam_policy.CloudWatchFullAccess.arn
}

resource "aws_iam_role_policy_attachment" "AWSLambdaVPCAccessExecutionRole" {
  role       = aws_iam_role.invoiceclassifier-lambda-role.name
  policy_arn = data.aws_iam_policy.AWSLambdaVPCAccessExecutionRole.arn
}

resource "aws_iam_role_policy_attachment" "invoiceclassifier-lambda-dbaccess" {
  role       = aws_iam_role.invoiceclassifier-lambda-role.name
  policy_arn = aws_iam_policy.invoiceclassifier-lambda-dbaccess.arn
}

#### invoiceclassifierbuilder-lambda

resource "aws_iam_role_policy_attachment" "AmazonS3FullAccess_for_builder" {
  role       = aws_iam_role.invoiceclassifierbuilder-lambda-role.name
  policy_arn = data.aws_iam_policy.AmazonS3FullAccess.arn
}

resource "aws_iam_role_policy_attachment" "AWSLambdaFullAccess_for_builder" {
  role       = aws_iam_role.invoiceclassifierbuilder-lambda-role.name
  policy_arn = data.aws_iam_policy.AWSLambdaFullAccess.arn
}

resource "aws_iam_role_policy_attachment" "CloudWatchFullAccess_for_builder" {
  role       = aws_iam_role.invoiceclassifierbuilder-lambda-role.name
  policy_arn = data.aws_iam_policy.CloudWatchFullAccess.arn
}

resource "aws_iam_role_policy_attachment" "AWSLambdaVPCAccessExecutionRole_for_builder" {
  role       = aws_iam_role.invoiceclassifierbuilder-lambda-role.name
  policy_arn = data.aws_iam_policy.AWSLambdaVPCAccessExecutionRole.arn
}

resource "aws_iam_role_policy_attachment" "invoiceclassifier-lambda-dbaccess_for_builder" {
  role       = aws_iam_role.invoiceclassifierbuilder-lambda-role.name
  policy_arn = aws_iam_policy.invoiceclassifier-lambda-dbaccess.arn
}

#### invoiceclassifierbuilder-lambda

resource "aws_iam_role_policy_attachment" "AmazonS3FullAccess_for_fourier" {
  role       = aws_iam_role.invoiceclassifierfourier-lambda-role.name
  policy_arn = data.aws_iam_policy.AmazonS3FullAccess.arn
}

resource "aws_iam_role_policy_attachment" "AWSLambdaFullAccess_for_fourier" {
  role       = aws_iam_role.invoiceclassifierfourier-lambda-role.name
  policy_arn = data.aws_iam_policy.AWSLambdaFullAccess.arn
}

resource "aws_iam_role_policy_attachment" "CloudWatchFullAccess_for_fourier" {
  role       = aws_iam_role.invoiceclassifierfourier-lambda-role.name
  policy_arn = data.aws_iam_policy.CloudWatchFullAccess.arn
}

### VPC

data "aws_vpc" "selected" {
  filter {
    name   = "tag:Name"
    values = ["ba-vpc-*"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "selected" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.selected.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*Private Subnet"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

data "aws_security_groups" "selected" {
  filter {
    name   = "tag:Name"
    values = ["ep-modules-db-*"]
  }
}


## Create Lambdas
resource "aws_lambda_function" "lambda_function_create" {
  function_name = "invoiceclassifier-lambda"
  role          = aws_iam_role.invoiceclassifier-lambda-role.arn
  package_type  = "Image"
  image_uri     = "${data.aws_caller_identity.caller_identity.account_id}.dkr.ecr.${var.region}.amazonaws.com/invoiceclassifier-lambda:latest"
  memory_size   = 4096
  timeout       = 180
  # runtime       = "provided.al2" # specifying runtime after the lambda function is actually created fails:

  vpc_config {
    subnet_ids         = data.aws_subnets.selected.ids
    security_group_ids = data.aws_security_groups.selected.ids
  }
}

resource "aws_lambda_function" "lambda_function_create_builder" {
  function_name = "invoiceclassifierbuilder-lambda"
  role          = aws_iam_role.invoiceclassifierbuilder-lambda-role.arn
  package_type  = "Image"
  image_uri     = "${data.aws_caller_identity.caller_identity.account_id}.dkr.ecr.${var.region}.amazonaws.com/invoiceclassifierbuilder-lambda:latest"
  memory_size   = 2048
  timeout       = 180
  # runtime       = "provided.al2" # specifying runtime after the lambda function is actually created fails:

  vpc_config {
    subnet_ids         = data.aws_subnets.selected.ids
    security_group_ids = data.aws_security_groups.selected.ids
  }
}

resource "aws_lambda_function" "lambda_function_create_fourier" {
  function_name = "invoiceclassifierfourier-lambda"
  role          = aws_iam_role.invoiceclassifierfourier-lambda-role.arn
  package_type  = "Image"
  image_uri     = "${data.aws_caller_identity.caller_identity.account_id}.dkr.ecr.${var.region}.amazonaws.com/invoiceclassifierfourier-lambda:latest"
  memory_size   = 4096
  timeout       = 180
  # runtime       = "provided.al2" # specifying runtime after the lambda function is actually created fails:
}

================
File: ba/invoiceclassifier-lambda/variables.tf
================
variable "region" {
  type        = string
  description = "AWS Region to execute in"
  default     = "us-east-1"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/invoiceclassifier-lambda/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/jenkins/terraform.yaml
================
# yaml to define Jenkins builds for this repo
- project:
    name: deploy-grafana-dashboard-terraform
    organization: SRE
    repo: ba-terraform
    business_unit: "ba"
    env:
      - dev
      - preprod
      - prod
    jobs:
      - "{business_unit}-{env}-terraform-grafana-dashboards"

================
File: ba/mobile-dmz/.terraform-version
================
1.2.3

================
File: ba/mobile-dmz/dev.backend.tfvars
================
key = "603547102569/mobile-dmz/terraform.tfstate"

================
File: ba/mobile-dmz/dev.tfvars
================
vpc_name             = "ba-vpc-dev"
otm_edge_lb          = "ba-dev-edge-lb"
region               = "us-west-2"
availability-zone-id = ["usw2-az1"]

================
File: ba/mobile-dmz/load_balancer.tf
================
data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name]
  }
}

data "aws_subnets" "private" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*Private*"]
  }

  filter {
    name   = "availability-zone-id"
    values = var.availability-zone-id
  }
}

data "aws_subnets" "public" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*DMZ*"]
  }

  filter {
    name   = "availability-zone-id"
    values = var.availability-zone-id
  }
}

data "aws_lb" "otm_edge" {
  name = var.otm_edge_lb
}

================
File: ba/mobile-dmz/variables.tf
================
variable "region" {}

variable "bu" {
  description = "the business unit"
  default     = "ba"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "vpc_name" {
  description = "Name of the vpc"
}

variable "otm_edge_lb" {
  description = "Name of the sso proxy ALB"
}

variable "availability-zone-id" {
  description = "List of availabilty zones this code can run in."
  type        = list(string)
}

================
File: ba/mobile-dmz/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.env
      SourceCode  = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/mobile-dmz/"
      Team        = "sre@enverus.com"
      Product     = "mobile"
    }
  }
}

================
File: ba/mobile-dmz/vpc_endpoint.tf
================
data "aws_route53_zone" "drillinginfo" {
  name         = "${(var.env == "dev" ? "dev.ba." : "")}drillinginfo.com"
  private_zone = false
}

================
File: ba/mobile-dmz-ue1/.terraform-version
================
latest

================
File: ba/mobile-dmz-ue1/dev.backend.tfvars
================
key = "603547102569/mobile-dmz-ue1/terraform.tfstate"

================
File: ba/mobile-dmz-ue1/dev.tfvars
================
vpc_name             = "ba-vpc-dev"
oi_staging_alb       = "ba-oi-staging-ext"
oi_staging_zone-ids  = ["use1-az1", "use1-az2", "use1-az4", "use1-az6"]
otm_edge_lb          = "ba-dev-edge-lb"
region               = "us-east-1"
availability-zone-id = ["use1-az1", "use1-az2", "use1-az4", "use1-az5", "use1-az6"]
ea_assume_role_arn   = "arn:aws:iam::155171951664:role/terraform"

================
File: ba/mobile-dmz-ue1/load_balancer.tf
================
data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name]
  }
}

data "aws_subnets" "private" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*Private*"]
  }

  filter {
    name   = "availability-zone-id"
    values = var.availability-zone-id
  }
}

data "aws_subnets" "oi_alb_public" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*Public Subnet"]
  }

  filter {
    name   = "availability-zone-id"
    values = var.oi_staging_zone-ids
  }
}

data "aws_lb" "oi_staging_alb" {
  name = var.oi_staging_alb
}

data "aws_lb" "otm_edge" {
  name = var.otm_edge_lb
}

resource "aws_lb_target_group" "otm_edge_target_group" {
  name        = "mobile-dmz-otm-tg"
  target_type = "alb"
  port        = 443
  protocol    = "TCP"
  vpc_id      = data.aws_vpc.main.id

  health_check {
    port = 80
    path = "/"
  }
}

resource "aws_lb" "otm_edge_lb" {
  name               = "mobile-dmz-otm-nlb"
  load_balancer_type = "network"
  subnets            = data.aws_subnets.private.ids
  internal           = true
}

resource "aws_lb_listener" "otm_edge_lb_listener" {
  load_balancer_arn = aws_lb.otm_edge_lb.arn
  port              = "443"
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.otm_edge_target_group.arn
  }
}

resource "aws_lb_target_group_attachment" "otm_edge_tg_attachment" {
  target_group_arn = aws_lb_target_group.otm_edge_target_group.arn
  target_id        = data.aws_lb.otm_edge.arn
}

resource "aws_lb" "oi_stagingappalb_nlb" {
  name               = "mobile-dmz-oi-forwarder-nlb"
  load_balancer_type = "network"
  subnets            = data.aws_subnets.oi_alb_public.ids
  internal           = true
}

resource "aws_lb_listener" "oi_staging_listener" {
  load_balancer_arn = aws_lb.oi_stagingappalb_nlb.arn
  port              = "443"
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.oi_staging_target_group.arn
  }
}

resource "aws_lb_target_group" "oi_staging_target_group" {
  name        = "mobile-dmz-oi-forwarder"
  target_type = "alb"
  port        = 443
  protocol    = "TCP"
  vpc_id      = data.aws_vpc.main.id

  health_check {
    path = "/"
    protocol = "HTTPS"
    matcher = "200-399,404"
  }
}

resource "aws_lb_target_group_attachment" "oi_staging_target_group" {
  target_group_arn = aws_lb_target_group.oi_staging_target_group.arn
  target_id        = data.aws_lb.oi_staging_alb.arn
}

================
File: ba/mobile-dmz-ue1/variables.tf
================
variable "region" {}

variable "bu" {
  description = "the business unit"
  default     = "ea"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "ea_assume_role_arn" {
  description = "The arn of the role to assume in the EA Prod account. specific to the account being deployed to"
}

variable "vpc_name" {
  description = "Name of the vpc"
}

variable "oi_staging_alb" {
  description = "Name of the OpenInvoice staging ALB"
}

variable "availability-zone-id" {
  description = "List of availabilty zones this code can run in."
  type        = list(string)
}

variable "oi_staging_zone-ids" {
  description = "List of availabilty zones for staging-app ALB."
  type        = list(string)
}

variable "otm_edge_lb" {
  description = "Name of the OTM ALB"
}

================
File: ba/mobile-dmz-ue1/versions.tf
================
terraform {
  required_version = ">= 1.2.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.19"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.env
      SourceCode  = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/mobile-dmz-ue1"
      Team        = "sre@enverus.com"
      Product     = "mobile"
    }
  }
}

provider "aws" {
  region = var.region
  alias  = "ea_prod"
  assume_role {
    role_arn = var.ea_assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.env
      SourceCode  = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/mobile-dmz-ue1"
      Team        = "sre@enverus.com"
      Product     = "mobile"
    }
  }
}

================
File: ba/mobile-dmz-ue1/vpc_endpoint.tf
================
data "aws_route53_zone" "openinvoice" {
  name         = "openinvoice.com"
  private_zone = false
  provider     = aws.ea_prod
}

resource "aws_vpc_endpoint_service" "oi_staging_endpoint_service" {
  acceptance_required        = false
  network_load_balancer_arns = [aws_lb.oi_stagingappalb_nlb.arn]
  allowed_principals         = ["arn:aws:iam::812779367494:root"]
  private_dns_name           = "staging-app.openinvoice.com"

  tags = {
    Name   = "oi-staging-endpoint-service"
    Target = "oi-staging"
  }
}

resource "aws_route53_record" "oi_staging_edge_txt" {
  provider = aws.ea_prod
  zone_id  = data.aws_route53_zone.openinvoice.zone_id
  name     = aws_vpc_endpoint_service.oi_staging_endpoint_service.private_dns_name_configuration[0].name
  type     = "TXT"
  ttl      = "300"
  records  = [aws_vpc_endpoint_service.oi_staging_endpoint_service.private_dns_name_configuration[0].value]
}

data "aws_route53_zone" "drillinginfo" {
  name         = "${(var.env == "dev" ? "dev.ba." : "")}drillinginfo.com"
  private_zone = false
}

resource "aws_vpc_endpoint_service" "otm_edge_endpoint_service" {
  acceptance_required        = false
  network_load_balancer_arns = [aws_lb.otm_edge_lb.arn]
  allowed_principals         = ["arn:aws:iam::812779367494:root"]
  private_dns_name           = "otm.dev.ba.drillinginfo.com"

  tags = {
    Name   = "otm-edge-endpoint-service"
    Target = "otm-edge"
  }
}

resource "aws_route53_record" "otm_edge_txt" {
  zone_id = data.aws_route53_zone.drillinginfo.zone_id
  name    = aws_vpc_endpoint_service.otm_edge_endpoint_service.private_dns_name_configuration[0].name
  type    = "TXT"
  ttl     = "300"
  records = [aws_vpc_endpoint_service.otm_edge_endpoint_service.private_dns_name_configuration[0].value]
}

================
File: ba/mongodb/bidout-project/.terraform-version
================
latest:^1.9

================
File: ba/mongodb/bidout-project/data.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

================
File: ba/mongodb/bidout-project/dev.backend.tfvars
================
key = "603547102569/dev/mongodb-bidout-project/terraform.tfstate"

================
File: ba/mongodb/bidout-project/dev.tfvars
================
# project and container
bu           = "ba"
env          = "dev"
region       = "us-east-1"
vpc_name_tag = "ba-vpc-dev"
whitelists = []
team_member_email = ["martin.kotala@drillinginfo.com", "tomas.saghy@drillinginfo.com", "michal.satina@drillinginfo.com", "patrik.cigas@drillinginfo.com", "petr.suchanek@drillinginfo.com"]

# cluster
clusters = [
  {
    name_suffix                            = "rfx-staging"
    bu                                     = "ba"
    region                                 = "us-east-1"
    num_shards                             = 1
    replication_factor                     = 3
    auto_scaling_disk_gb_enabled           = true
    auto_scaling_compute_enabled           = false
    auto_scaling_compute_max_instance_size = "M10"
    major_version                          = 8.0
    disk_size_gb                           = 10
    provider_disk_iops                     = 3000
    provider_volume_type                   = "STANDARD"
    provider_instance_size_name            = "M10"
    cluster_type                           = "REPLICASET"
    provider_name                          = "AWS"
    cloud_backup                           = true
    pit_enabled                            = true
    replication_specs                      = []
    advanced_configuration = {
      default_read_concern                                           = null
      default_write_concern                                          = null
      fail_index_key_too_long                                        = "false"
      javascript_enabled                                             = "true"
      minimum_enabled_tls_protocol                                   = "TLS1_2"
      no_table_scan                                                  = "false"
      oplog_size_mb                                                  = null
      sample_refresh_interval_bi_connector                           = "0"
      sample_size_bi_connector                                       = "0"
      transaction_lifetime_limit_seconds                             = 60
      change_stream_options_pre_and_post_images_expire_after_seconds = -1
    }
  }
]

================
File: ba/mongodb/bidout-project/main.tf
================
# readonly user
# resource "mongodbatlas_database_user" "test" {
#   username           = data.vault_generic_secret.di_secrets_readonly_user.data["dbusername"]
#   password           = data.vault_generic_secret.di_secrets_readonly_user.data["dbpassword"]
#   project_id         = module.project.mongodbatlas_project.id
#   auth_database_name = "admin"

#   roles {
#     role_name     = "read"
#     database_name = "bidout"
#   }
# }

module "project" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.mongodb-atlas.git//project?ref=v1.0.4"

  project_name      = "bidout-${var.env}"
  whitelists        = var.whitelists
  team_member_email = var.team_member_email
}

module "cluster" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.mongodb-atlas.git//cluster?ref=v1.0.4"

  env          = var.env
  project_name = module.project.mongodbatlas_project.name
  project_id   = module.project.mongodbatlas_project.id
  clusters     = var.clusters
}


module "privatelink" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.mongodb-atlas.git//privatelink?ref=v1.0.4"

  atlas_region    = var.region
  project_id      = module.project.mongodbatlas_project.id
  project_name    = module.project.mongodbatlas_project.name
  vpc_name_tag    = var.vpc_name_tag
  security_groups = [aws_security_group.allow_mongo.id]
}

resource "aws_security_group" "allow_mongo" {
  name        = "allow_mongo"
  description = "Allow Mongo inbound traffic and all outbound traffic"
  vpc_id      = data.aws_vpc.vpc.id

  tags = {
    Name = "allow_mongo"
  }
}

resource "aws_vpc_security_group_ingress_rule" "allow_mongo_ipv4" {
  description       = "VPC"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = data.aws_vpc.vpc.cidr_block
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

resource "aws_vpc_security_group_ingress_rule" "allow_vpn_virginia" {
  description       = "PaloAltoVPN_Virginia"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.54.248.0/21"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

resource "aws_vpc_security_group_ingress_rule" "allow_vpn_chicago" {
  description       = "PaloAltoVPN_Chicago"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.50.248.0/21"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Atlantis, GH runners
resource "aws_vpc_security_group_ingress_rule" "allow_cts_vpc_prod" {
  description       = "CTS_vpc_prod"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.25.232.0/21"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Azure VMs used by contractors
resource "aws_vpc_security_group_ingress_rule" "allow_azure_vm" {
  count             = var.env=="dev" ? 1 : 0
  description       = "Contractor_Azure_VMs"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.77.61.0/24"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Azure VMs used by contractors (2 - Mariano)
resource "aws_vpc_security_group_ingress_rule" "allow_azure_vm2" {
  count             = var.env=="dev" ? 1 : 0
  description       = "Contractor_Azure_VMs_2"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.77.38.0/24"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Databrics-dev #1
resource "aws_vpc_security_group_ingress_rule" "allow_databrics_dev1" {
  description       = "Databrics-dev1"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.25.192.0/22"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Databrics-dev #2
resource "aws_vpc_security_group_ingress_rule" "allow_databrics_dev2" {
  description       = "Databrics-dev2"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.25.196.0/23"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Databrics-prod #1
resource "aws_vpc_security_group_ingress_rule" "allow_databrics_prod1" {
  description       = "Databrics-prod1"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.25.208.0/22"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

# Databrics-prod #2
resource "aws_vpc_security_group_ingress_rule" "allow_databrics_prod2" {
  description       = "Databrics-prod2"
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "10.25.212.0/23"
  from_port         = 1024
  to_port           = 65535
  ip_protocol       = "tcp"
}

resource "aws_vpc_security_group_egress_rule" "allow_all_traffic_ipv4" {
  security_group_id = aws_security_group.allow_mongo.id
  cidr_ipv4         = "0.0.0.0/0"
  ip_protocol       = "-1" # semantically equivalent to all ports
}

================
File: ba/mongodb/bidout-project/outputs.tf
================
output "cluster" {
  value = module.cluster
}

output "project" {
  value = module.project
}

================
File: ba/mongodb/bidout-project/prod.backend.tfvars
================
key = "512870776320/prod/mongodb-bidout-project/terraform.tfstate"

================
File: ba/mongodb/bidout-project/prod.tfvars
================
# project and container for PROD
bu           = "ba"
env          = "prod"
region       = "us-east-1"
vpc_name_tag = "ba-vpc-prod"
whitelists = []
team_member_email = ["martin.kotala@drillinginfo.com", "tomas.saghy@drillinginfo.com", "michal.satina@drillinginfo.com"]

# cluster
clusters = [
  {
    name_suffix                            = "rfx-onboard"
    bu                                     = "ba"
    region                                 = "us-east-1"
    num_shards                             = 1
    replication_factor                     = 3
    auto_scaling_disk_gb_enabled           = true
    auto_scaling_compute_enabled           = false
    auto_scaling_compute_max_instance_size = "M10"
    major_version                          = 8.0
    disk_size_gb                           = 10
    provider_disk_iops                     = 3000
    provider_volume_type                   = "STANDARD"
    provider_instance_size_name            = "M10"
    cluster_type                           = "REPLICASET"
    provider_name                          = "AWS"
    cloud_backup                           = true
    pit_enabled                            = true
    replication_specs                      = []
    advanced_configuration = {
      default_read_concern                                           = null
      default_write_concern                                          = null
      fail_index_key_too_long                                        = "false"
      javascript_enabled                                             = "true"
      minimum_enabled_tls_protocol                                   = "TLS1_2"
      no_table_scan                                                  = "false"
      oplog_size_mb                                                  = null
      sample_refresh_interval_bi_connector                           = "0"
      sample_size_bi_connector                                       = "0"
      transaction_lifetime_limit_seconds                             = 60
      change_stream_options_pre_and_post_images_expire_after_seconds = -1
    }
  },
  {
    name_suffix                            = "rfx-prod"
    bu                                     = "ba"
    region                                 = "us-east-1"
    num_shards                             = 1
    replication_factor                     = 3
    auto_scaling_disk_gb_enabled           = true
    auto_scaling_compute_enabled           = false
    auto_scaling_compute_max_instance_size = "M10"
    major_version                          = 8.0
    disk_size_gb                           = 10
    provider_disk_iops                     = 3000
    provider_volume_type                   = "STANDARD"
    provider_instance_size_name            = "M10"
    cluster_type                           = "REPLICASET"
    provider_name                          = "AWS"
    cloud_backup                           = true
    pit_enabled                            = true
    replication_specs                      = []
    advanced_configuration = {
      default_read_concern                                           = null
      default_write_concern                                          = null
      fail_index_key_too_long                                        = "false"
      javascript_enabled                                             = "true"
      minimum_enabled_tls_protocol                                   = "TLS1_2"
      no_table_scan                                                  = "false"
      oplog_size_mb                                                  = null
      sample_refresh_interval_bi_connector                           = "0"
      sample_size_bi_connector                                       = "0"
      transaction_lifetime_limit_seconds                             = 60
      change_stream_options_pre_and_post_images_expire_after_seconds = -1
    }
  }
]

================
File: ba/mongodb/bidout-project/variables.tf
================
variable "bu" {
  type = string
}
variable "env" {
  description = "environment, eg. dev"
}

variable "region" {
  description = "cluster region, eg us-east-1"
  type        = string
}

variable "org_id" {
  default     = "5b5ed6074e6581400d5cbaee"
  description = "The MongoDB Atlas organization ID"
  type        = string
}

variable "whitelists" {
  type = list(
    object(
      {
        ip_address = string
        cidr_block = string
        comment    = string
      }
    )
  )
  default = [
    {
      ip_address = "4.14.200.126"
      comment    = "Enverus Via Fortuna (Austin) External IP"
      cidr_block = null
    }
  ]
}

variable "team_member_email" {
  description = "Email address of team member to add to project"
  type        = list(string)

}

# variable "route_table_name_tag" {
#   description = "Name tag value used to find route tables to modify"
#   type        = list(string)
# }

variable "vpc_name_tag" {
  description = "Name tag value used to find VPC in which to create perring connection"
  type        = string
}

variable "clusters" {
  description = "The MongoDB Atlas cluster configuration"
  type = list(
    object(
      {
        name_suffix                            = string
        bu                                     = string
        region                                 = string
        num_shards                             = number
        replication_factor                     = number
        auto_scaling_disk_gb_enabled           = bool
        auto_scaling_compute_enabled           = bool
        auto_scaling_compute_max_instance_size = string
        major_version                          = number
        disk_size_gb                           = number
        provider_disk_iops                     = number
        provider_volume_type                   = string
        provider_instance_size_name            = string
        cluster_type                           = string
        provider_name                          = string
        cloud_backup                           = bool
        pit_enabled                            = bool
        replication_specs = list(
          object(
            {
              zone_name  = string
              num_shards = number
              regions_config = object(
                {
                  region_name     = string
                  electable_nodes = number
                  priority        = number
                  read_only_nodes = number
                }
              )
            }
          )
        )
        advanced_configuration = object(
          {
            default_read_concern                                           = string
            default_write_concern                                          = string
            fail_index_key_too_long                                        = string
            javascript_enabled                                             = string
            minimum_enabled_tls_protocol                                   = string
            no_table_scan                                                  = string
            oplog_size_mb                                                  = string
            sample_refresh_interval_bi_connector                           = string
            sample_size_bi_connector                                       = string
            transaction_lifetime_limit_seconds                             = number
            change_stream_options_pre_and_post_images_expire_after_seconds = number
          }
        )
      }
    )
  )
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "VAULT_ADDR" {
  description = "address of hashicorp vault"
  type        = string
}

================
File: ba/mongodb/bidout-project/vault.tf
================
data "vault_generic_secret" "di_secrets_terraform" {
  path = "di-secrets/terraform/mongodb-atlas-sre"
}

data "vault_generic_secret" "di_secrets_readonly_user" {
  path = "di-secrets/terraform/mongodb-atlas-sre/courthouse"
}

================
File: ba/mongodb/bidout-project/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {
  }

  required_providers {
    mongodbatlas = {
      source  = "mongodb/mongodbatlas"
      version = "~> 1.19.0"
    }
    aws = {
      source = "hashicorp/aws"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Product          = "bidout"
      Component        = "mongodb"
      Team             = "martin.kotala@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/mongodb/bidout-project"
      TerraformCreated = "true"
    }
  }
}

provider "mongodbatlas" {
  public_key  = data.vault_generic_secret.di_secrets_terraform.data["atlas_public_key"]
  private_key = data.vault_generic_secret.di_secrets_terraform.data["atlas_private_key"]
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/nomad-cluster-aws/client/.terraform-version
================
latest:^1.8

================
File: ba/nomad-cluster-aws/client/dev-ue1.backend.tfvars
================
key = "dev/east/nomad-cluster/nomad-clients/terraform.tfstate"

================
File: ba/nomad-cluster-aws/client/dev-ue1.tfvars
================
asg_environment        = "ba_dev_ue1"
consul_token           = "XuqDDt/iorsgaP0q2uIt1Q=="
vault_address          = "https://vault-ue1.dev.ba.drillinginfo.com"
datacenter             = "aws-ue1"
aws_region             = "us-east-1"
ec2-short-region       = "ue1"
os                     = "ubuntu20"
vpc_name_tag           = "ba-vpc-dev"
iam-profile            = "service-instance-profile"
ebs-optimized          = "true"
instance_type          = "r6i.xlarge"
desired-capacity       = "4"
instance_type_batch    = "m6i.xlarge"
desired-capacity-batch = "1"
ami                    = "drillinginfo/ubuntu2004/nomad-client-aws-ubuntu-20.04-amd64-*"
#chef
chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment = "ba-dev-docker"
# Tagging
tagComponent = "nomad-client-service"
tagTeam      = "sre@enverus.com"

================
File: ba/nomad-cluster-aws/client/nomad-batch.tf
================
module "nomad_client_batch" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.nomad-cluster.git?ref=v4.9.0"

  nomad_type       = "batch"
  environment      = var.asg_environment
  aws_region       = var.aws_region
  instance-type    = var.instance_type_batch
  os               = var.os
  iam-profile      = var.iam-profile
  ebs-optimized    = var.ebs-optimized
  ec2-name         = "aws-${var.ec2-short-region}-${var.env}-dock-nomad-clt-batch"
  asg-name         = "${var.bu}-${var.env}-dock-nomad-clt-batch-asg"
  instance_refresh = var.instance_refresh

  desired-capacity = var.desired-capacity-batch
  datacenter       = var.datacenter
  bu               = var.bu
  vault_address    = var.vault_address
  chef-environment = var.chef-environment
  chef-run-list    = var.chef-run-list
  consul_token     = var.consul_token
  vpc_name_tag     = var.vpc_name_tag
  vo_routing_key   = var.vo_routing_key

  ami-filters = {
    name           = var.ami
    virtualization = "hvm"
    owner          = "070551638384"
  }

  tagBusinessUnit = var.bu
  tagLocation     = var.aws_region
  tagTeam         = var.tagTeam
  tagProduct      = "nexus"
  tagComponent    = "nomad-client-batch"
  tagStack        = var.env
  tagEnv          = var.env
  tagSourceCode   = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/nomad-cluster-aws/client"

  # Ansible
  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "enverus-cts/sre.ansible.grafana-alloy-check",
      playbook_file = "check-grafana-alloy.yml",
      git_host      = "cloud",
      additional_args = [
        "--extra-vars \"environment_name=${var.env} business_unit=${var.bu}\"",
        "-C main"
      ],
    },
  ]
}

================
File: ba/nomad-cluster-aws/client/nomad-service.tf
================
module "nomad_client_service" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.nomad-cluster.git?ref=v4.9.0"

  nomad_type       = "service"
  environment      = var.asg_environment
  instance-type    = var.instance_type
  os               = var.os
  iam-profile      = var.iam-profile
  ebs-optimized    = var.ebs-optimized
  ec2-name         = "aws-${var.ec2-short-region}-${var.env}-dock-nomad-clt-svc"
  asg-name         = "${var.bu}-${var.env}-nomad-client-service-asg"
  aws_region       = var.aws_region
  instance_refresh = var.instance_refresh

  desired-capacity = var.desired-capacity
  datacenter       = var.datacenter
  bu               = var.bu
  vault_address    = var.vault_address
  chef-environment = var.chef-environment
  chef-run-list    = var.chef-run-list
  consul_token     = var.consul_token
  vpc_name_tag     = var.vpc_name_tag
  vo_routing_key   = var.vo_routing_key

  ami-filters = {
    name           = var.ami
    virtualization = "hvm"
    owner          = "070551638384"
  }

  tagBusinessUnit = var.bu
  tagLocation     = var.aws_region
  tagTeam         = var.tagTeam
  tagProduct      = "nexus"
  tagComponent    = var.tagComponent
  tagStack        = var.env
  tagEnv          = var.env
  tagSourceCode   = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/nomad-cluster-aws/client"

  # Ansible
  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "enverus-cts/sre.ansible.grafana-alloy-check",
      playbook_file = "check-grafana-alloy.yml",
      git_host      = "cloud",
      additional_args = [
        "--extra-vars \"environment_name=${var.env} business_unit=${var.bu}\"",
        "-C main"
      ],
    },
  ]
}

================
File: ba/nomad-cluster-aws/client/prod-ue1.backend.tfvars
================
key = "prod/east/nomad-cluster/nomad-clients/terraform.tfstate"

================
File: ba/nomad-cluster-aws/client/prod-ue1.tfvars
================
asg_environment        = "ba_prod_ue1"
consul_token           = "H7yMJC/pXy255qYxj6nwfQ=="
vault_address          = "https://vault-ue1.prod.ba.drillinginfo.com"
datacenter             = "aws-ue1"
aws_region             = "us-east-1"
ec2-short-region       = "ue1"
os                     = "ubuntu20"
vpc_name_tag           = "ba-vpc-prod"
iam-profile            = "service-instance-profile"
ebs-optimized          = "true"
instance_type          = "m6i.2xlarge"
desired-capacity       = "3"
instance_type_batch    = "m6i.xlarge"
desired-capacity-batch = "2"
ami                    = "drillinginfo/ubuntu2004/nomad-client-aws-ubuntu-20.04-amd64-9113203f622c"
#chef
chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment = "ba-prod-docker"
# Tagging
tagComponent = "nomad-client-service"
tagTeam      = "sre@enverus.com"

================
File: ba/nomad-cluster-aws/client/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/nomad-cluster/nomad-clients/terraform.tfstate"

================
File: ba/nomad-cluster-aws/client/prod-uw2.tfvars
================
asg_environment        = "ba_prod_uw2"
consul_token           = "H7yMJC/pXy255qYxj6nwfQ=="
vault_address          = "https://vault-uw2.prod.ba.drillinginfo.com"
datacenter             = "aws-uw2"
aws_region             = "us-west-2"
ec2-short-region       = "uw2"
os                     = "ubuntu20"
vpc_name_tag           = "ba-vpc-prod"
iam-profile            = "service-instance-profile"
ebs-optimized          = "true"
instance_type          = "m6i.2xlarge"
desired-capacity       = "3"
instance_type_batch    = "m6i.xlarge"
desired-capacity-batch = "2"
ami                    = "drillinginfo/ubuntu2004/nomad-client-aws-ubuntu-20.04-amd64-9113203f622c"
#chef
chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment = "ba-prod-docker"
# Tagging
tagComponent = "nomad-client-service"
tagTeam      = "sre@enverus.com"

================
File: ba/nomad-cluster-aws/client/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}
variable "consul_token" {}
variable "vpc_name_tag" {}
variable "env" {}
variable "aws_region" {}
variable "os" {}
variable "iam-profile" {}
variable "ebs-optimized" {}
variable "desired-capacity" {}
variable "desired-capacity-batch" {}
variable "vault_address" {}
variable "chef-run-list" {}
variable "chef-environment" {}
variable "tagComponent" {}
variable "tagTeam" {}
variable "bu" {
  description = "business unit abbreviation, eg ba"
}

variable "instance_type" {
  description = "AWS instance type, eg. m5.xlarge"
}

variable "instance_type_batch" {
  description = "AWS instance type, eg. m5.xlarge"
}

variable "datacenter" {
  description = "Nomad datacenter, eg aws-uw2"
}

variable "ec2-short-region" {
  description = "ec2 region abbreviation, eg. ew1"
}

variable "ami" {
  default     = "drillinginfo/ubuntu2004/nomad-client-ubuntu-20.04-amd64-*"
  description = "ami filter name"
}

variable "asg_environment" {
  description = "This is the environment string used by the ASG module to select s3 buckets for chef key and chef org name"
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "instance_refresh" {
  description = "Instance refresh configuration"
  type        = any
  default = {
    strategy = "Rolling"
    preferences = {
      instance_warmup        = 900
      min_healthy_percentage = 100
    }
  }
}

================
File: ba/nomad-cluster-aws/client/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.8"
    }
  }
}


provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Product      = "nexus"
      BusinessUnit = var.bu
      Component    = "nomad-client"
      Team         = "sre@enverus.com"
      SourceCode   = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/nomad-cluster-aws/client"
      Environment  = var.env
    }
  }
}

================
File: ba/nomad-cluster-aws/server/.terraform-version
================
latest:^1.7

================
File: ba/nomad-cluster-aws/server/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/nomad-cluster-aws/server/dev-ue1.backend.tfvars
================
key = "dev/east/nomad-cluster/nomad-server/terraform.tfstate"

================
File: ba/nomad-cluster-aws/server/dev-ue1.tfvars
================
asg_environment         = "ba_dev_ue1"
consul_token            = "XuqDDt/iorsgaP0q2uIt1Q=="
vault_address           = "https://vault-ue1.dev.ba.drillinginfo.com"
nomad_type              = "server"
datacenter              = "aws-ue1"
aws_region              = "us-east-1"
abv-region              = "ue1"
os                      = "ubuntu20"
ec2-name                = "aws-ue1-dev-nomad-server"
instance_type           = "m6i.large"
vpc_name_tag            = "ba-vpc-dev"
iam-profile             = "service-instance-profile"
ebs-optimized           = "true"
asg-name                = "ba-dev-nomad-server-service-asg"
desired-capacity        = "3"
min-size                = "3"
ami                     = "drillinginfo/ubuntu2004/nomad-server-aws-ubuntu-20.04-amd64-*"
chef-run-list           = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment        = "ba-dev-docker"
tagComponent            = "nomad-server"
tagTeam                 = "sre@enverus.com"
datadog-additional-tags = "bu:ba,component:nomad-client-service,location:us-east-1,team:sre,terraformcreated:true"
environment             = "ba_dev_ue1"

# Ansible
user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

lb_tags = {
  Name = "ba-dev-nomad-lb"
  }

================
File: ba/nomad-cluster-aws/server/main.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg", "*-INSIDE-SG"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

data "aws_route53_zone" "main" {
  name         = "${var.env}.${var.bu}.drillinginfo.com"
  private_zone = false
}

module "nomad_servers_aws" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.nomad-cluster.git?ref=v4.10.1"

  nomad_type    = var.nomad_type
  environment   = var.asg_environment
  ec2-name      = var.ec2-name
  aws_region    = var.aws_region
  instance-type = var.instance_type
  os            = var.os
  iam-profile   = var.iam-profile
  ebs-optimized = var.ebs-optimized
  asg-name      = var.asg-name

  desired-capacity  = var.desired-capacity
  min-size          = var.min-size
  datacenter        = var.datacenter
  bu                = var.bu
  vault_address     = var.vault_address
  chef-environment  = var.chef-environment
  chef-run-list     = var.chef-run-list
  consul_token      = var.consul_token
  vpc_name_tag      = var.vpc_name_tag
  target-group-arns = [aws_lb_target_group.nomad_tg.arn]
  vo_routing_key    = var.vo_routing_key

  ami-filters = {
    name           = var.ami
    virtualization = "hvm"
    owner          = "070551638384"
  }

  tagBusinessUnit = var.bu
  tagLocation     = var.aws_region
  tagTeam         = var.tagTeam
  tagComponent    = var.tagComponent
  tagProduct      = "nexus"
  tagStack        = var.env
  tagEnv          = var.env
  tagSourceCode   = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/nomad-cluster-aws/server"

  # Ansible
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

resource "aws_security_group" "nomad_lb_sg" {
  name        = "${var.abv-region}-${var.bu}-${var.env}-nomad-ui-sg"
  description = "Allow acces to nomad UI load balancer"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside_sg.id]
  }

  egress {
    from_port   = 4646
    to_port     = 4646
    protocol    = "tcp"
    cidr_blocks = [data.aws_vpc.vpc.cidr_block]
  }
}

resource "aws_lb" "nomad_lb" {
  name            = "${var.abv-region}-${var.bu}-${var.env}-nomad-lb"
  internal        = true
  security_groups = [aws_security_group.nomad_lb_sg.id, data.aws_security_group.inside_sg.id]
  subnets         = data.aws_subnets.private_subnets.ids

  tags = var.lb_tags
}

data "vault_generic_secret" "grafana" {
  path = "di-secrets/terraform/grafana-provider"
}

data "grafana_folder" "sre_lb_alert_folder" {
  title = "SRE-LoadBalancer-${title(var.env)} Alerts"
}

module "unhealthy_host_alert" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.load-balancer-unhealthy-host-alert?ref=v1.0.4"

  grafana_API_key              = data.vault_generic_secret.grafana.data["api_key"]
  loadbalancer_type            = "ALB"
  cloudwatch_data_source_name  = "Cloudwatch-${var.bu}-${var.env}-${var.aws_region}"
  loadbalancer_name            = aws_lb.nomad_lb.arn_suffix
  grafana_notification_channel = "VictorOps Alert - key-${var.env}Uptime"
  environment                  = var.env
  grafana_dashboard_folder_id  = data.grafana_folder.sre_lb_alert_folder.uid
  load_balancer_region         = var.aws_region
}

resource "aws_lb_target_group" "nomad_tg" {
  name     = "${var.abv-region}-${var.bu}-${var.env}-nomad-tg"
  port     = 4646
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.vpc.id

  health_check {
    path = "/v1/status/leader"
  }

}

resource "aws_lb_listener" "nomad_listener" {
  load_balancer_arn = aws_lb.nomad_lb.arn
  port              = 80

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.nomad_tg.arn
  }

}

resource "aws_route53_record" "nomad_ui" {
  zone_id = data.aws_route53_zone.main.zone_id
  name    = "nomad-${var.abv-region}.${var.env}.${var.bu}.drillinginfo.com"
  type    = "A"

  alias {
    name                   = aws_lb.nomad_lb.dns_name
    zone_id                = aws_lb.nomad_lb.zone_id
    evaluate_target_health = true
  }
}

================
File: ba/nomad-cluster-aws/server/prod-ue1.backend.tfvars
================
key = "prod/east/nomad-cluster/nomad-server/terraform.tfstate"

================
File: ba/nomad-cluster-aws/server/prod-ue1.tfvars
================
asg_environment  = "ba_prod_ue1"
consul_token     = "H7yMJC/pXy255qYxj6nwfQ=="
vault_address    = "https://vault-ue1.prod.ba.drillinginfo.com"
nomad_type       = "server"
datacenter       = "aws-ue1"
aws_region       = "us-east-1"
abv-region       = "ue1"
os               = "ubuntu20"
ec2-name         = "aws-ue1-prod-nomad-server"
instance_type    = "m6i.large"
vpc_name_tag     = "ba-vpc-prod"
iam-profile      = "service-instance-profile"
ebs-optimized    = "true"
asg-name         = "ba-prod-nomad-server-service-asg"
desired-capacity = "3"
min-size         = "3"
ami              = "drillinginfo/ubuntu2004/nomad-server-aws-ubuntu-20.04-amd64-*"
#chef
chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment = "ba-prod-docker"
# Tagging
tagComponent = "nomad-server"
tagTeam      = "sre@enverus.com"

# Ansible
user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

lb_tags = {
  Name           = "ba-prod-nomad-lb"
  }

================
File: ba/nomad-cluster-aws/server/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/nomad-cluster/nomad-server/terraform.tfstate"

================
File: ba/nomad-cluster-aws/server/prod-uw2.tfvars
================
asg_environment  = "ba_prod_uw2"
consul_token     = "H7yMJC/pXy255qYxj6nwfQ=="
vault_address    = "https://vault-uw2.prod.ba.drillinginfo.com"
nomad_type       = "server"
datacenter       = "aws-uw2"
aws_region       = "us-west-2"
abv-region       = "uw2"
os               = "ubuntu20"
ec2-name         = "aws-uw2-prod-nomad-server"
instance_type    = "m6i.large"
vpc_name_tag     = "ba-vpc-prod"
iam-profile      = "service-instance-profile"
ebs-optimized    = "true"
asg-name         = "ba-prod-nomad-server-service-asg"
desired-capacity = "3"
min-size         = "3"
ami              = "drillinginfo/ubuntu2004/nomad-server-aws-ubuntu-20.04-amd64-*"
#chef
chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\", \"recipe[di_environment]\""
chef-environment = "ba-prod-docker"
# Tagging
tagComponent = "nomad-server"
tagTeam      = "sre@enverus.com"

# Ansible
user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=ba\"",
      "-C main"
    ],
  }
]

lb_tags = {
  Name = "ba-prod-nomad-lb"
}

================
File: ba/nomad-cluster-aws/server/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}
variable "consul_token" {}
variable "vpc_name_tag" {}
variable "env" {}
variable "aws_region" {}
variable "abv-region" {}
variable "os" {}
variable "ec2-name" {}
variable "iam-profile" {}
variable "ebs-optimized" {}
variable "asg-name" {}
variable "desired-capacity" {}
variable "nomad_type" {}
variable "min-size" {}
variable "chef-run-list" {}
variable "chef-environment" {}
variable "tagComponent" {}
variable "tagTeam" {}
variable "datacenter" {}
variable "vault_address" {}
variable "vo_routing_key" {}
variable "bu" {
  description = "business unit abbreviation, eg ba"
}

variable "instance_type" {
  description = "AWS instance type, eg. m5.xlarge"
}

variable "ami" {
  default     = "drillinginfo/ubuntu2004/nomad-server-aws-ubuntu-20.04-amd64-*"
  description = "ami filter name"
}

variable "asg_environment" {
  description = "This is the environment string used by the ASG module to select s3 buckets for chef key and chef org name"
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
  default = []
}

variable "lb_tags" {
  description = "Tags to apply to the load balancer"
  type = map(string)
}

================
File: ba/nomad-cluster-aws/server/versions.tf
================
terraform {
  required_version = ">= 1.12"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "< 6.0.0"
    }
    grafana = {
      source  = "grafana/grafana"
      version = ">= 1.22"
    }
  }
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Product      = "nexus"
      BusinessUnit = var.bu
      Component    = var.tagComponent
      Team         = var.tagTeam
      SourceCode   = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/nomad-cluster-aws/server"
      Environment  = var.env
    }
  }
}

================
File: ba/nomad-cluster-aws-scheduler/.terraform-version
================
latest:^1.4

================
File: ba/nomad-cluster-aws-scheduler/dev-ue1.backend.tfvars
================
key = "dev/east/nomad-cluster/nomad-scheduler/terraform.tfstate"

================
File: ba/nomad-cluster-aws-scheduler/dev-ue1.tfvars
================
datacenter = "aws-ue1"
ec2-region = "us-east-1"

================
File: ba/nomad-cluster-aws-scheduler/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/nomad-cluster-aws-scheduler/nomad-scheduler-job.tpl
================
job "nomad-scheduler" {

  datacenters = "${datacenter}"

  type = "service"

  priority = "90"

  update {
    stagger      = "30s"
    max_parallel = 1
  }

  constraint {
    attribute = "$${node.class}"
    value = "service"
  }

  group "nomad-scheduler" {

    restart {
      # The number of attempts to run the job within the specified interval.
      attempts = 5
      interval = "5m"

      # The "delay" parameter specifies the duration to wait before restarting
      # a task after it has failed.
      delay = "15s"

      # The "mode" parameter controls what happens when a task has restarted
      # "attempts" times within the interval. "delay" mode delays the next
      # restart until the next interval. "fail" mode does not restart the task
      # if "attempts" has been hit within the interval.
      mode = "fail"
    }

    count = 1

    ephemeral_disk {
      size = "50"
    }

    task "nomad-scheduler" {

      driver = "docker"

      config {
        image = "070551638384.dkr.ecr.us-east-1.amazonaws.com/nomad-scheduler"
        force_pull = true
      }

      logs {
        max_files = 3
        max_file_size = 10
      }

      resources {
        cpu    = "100"
        memory = "150"

        network {
          mbits = 10
          port "http" {}
        }
      }
    }
  }
}

================
File: ba/nomad-cluster-aws-scheduler/prod-ue1.backend.tfvars
================
key = "prod/east/nomad-cluster/nomad-scheduler/terraform.tfstate"

================
File: ba/nomad-cluster-aws-scheduler/prod-ue1.tfvars
================
datacenter = "aws-ue1"
ec2-region = "us-east-1"

================
File: ba/nomad-cluster-aws-scheduler/scheduler.tf
================
provider "nomad" {
  address = "http://nomad-ue1.${var.env}.ba.drillinginfo.com"
  region  = var.datacenter
}

data "template_file" "scheduler-job" {
  template = file("${path.module}/nomad-scheduler-job.tpl")

  vars = {
    datacenter = var.datacenter
  }
}

resource "nomad_job" "scheduler" {
  jobspec = data.template_file.scheduler-job.rendered
}

================
File: ba/nomad-cluster-aws-scheduler/variables.tf
================
variable "ec2-region" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}
variable "datacenter" {}
variable "env" {}

================
File: ba/nomad-cluster-aws-scheduler/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    nomad = {
      source = "hashicorp/nomad"
    }
    template = {
      source = "hashicorp/template"
    }
  }
}

================
File: ba/openticket-mobile-service/secrets/.terraform-version
================
latest:^1.3

================
File: ba/openticket-mobile-service/secrets/main.tf
================
provider "vault" {
  address = var.VAULT_ADDR
}

module "vault_secrets" {
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/vault-secrets.git?ref=main"

  mountpoint   = var.mountpoint
  secret_paths = var.secret_paths
}

output "vault_secrets" {
  value = module.vault_secrets
}

================
File: ba/openticket-mobile-service/secrets/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/openticket-mobile-service-secrets/terraform.tfstate"

================
File: ba/openticket-mobile-service/secrets/prod-ue1.tfvars
================
mountpoint = "di-secrets"
secret_paths = [
  "terraform/application/openticket-mobile-service/prod/database",
  "terraform/application/openticket-mobile-service/prod/jwt",
  "terraform/application/openticket-mobile-service/prod/locations",
  "terraform/application/openticket-mobile-service/onboard/database",
  "terraform/application/openticket-mobile-service/onboard/jwt",
  "terraform/application/openticket-mobile-service/onboard/locations",
]
VAULT_ADDR = "https://vault-ue1.prod.ba.drillinginfo.com"

================
File: ba/openticket-mobile-service/secrets/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "mountpoint" {
  description = "Vault secret mountpoint"
  type        = string
}

variable "secret_paths" {
  description = "The full logical path at which to write the given data. To write data into the generic secret backend mounted in Vault by default. Writing to other backends with this resource is possible; consult each backend's documentation to see which endpoints support the PUT and DELETE methods."
  type        = list(string)
  default     = []
}

================
File: ba/openticket-mobile-service/secrets/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
  }
}

================
File: ba/rds/kms/rds-mineralsoft/.terraform-version
================
latest:^1.4

================
File: ba/rds/kms/rds-mineralsoft/dev-ue1.backend.tfvars
================
key = "dev/us-east-1/kms/rds-mineralsoft/terraform.tfstate"

================
File: ba/rds/kms/rds-mineralsoft/dev-ue1.tfvars
================
# dev-specific variable values:
owner_principal = "arn:aws:iam::603547102569:root"
shared_principals = [
  "arn:aws:iam::512870776320:root",
  "arn:aws:iam::816432189621:root",
]
vault_path_terraform_admin_user_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_dev"
region                               = "us-east-1"
#Removed as role doesn't exist anymore. But retaining as the policy has the translated arn in it.
#admin_role_arn                       = "arn:aws:iam::603547102569:role/ba-dev-admin-user"
admin_role_arn                       = "arn:aws:iam::603547102569:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_AdministratorAccess_7ad1014beab53cb0"

================
File: ba/rds/kms/rds-mineralsoft/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

resource "aws_kms_key" "a" {
  description             = "KMS key for mineralsoft rds"
  deletion_window_in_days = 30
  policy                  = data.aws_iam_policy_document.kms.json

  tags = {
    "Name"      = "KMS key for mineralsoft rds"
    "env"       = var.env
    "team"      = "sre@enverus.com"
    "bu"        = var.bu
    "component" = "mineralsoft"
  }
}

data "aws_iam_policy_document" "kms" {
  statement {
    sid = "enable iam user perms"

    actions = [
      "kms:*"
    ]

    principals {
      type        = "AWS"
      identifiers = [var.owner_principal]
    }

    resources = [
      "*"
    ]
  }

  statement {
    sid = "allow use of the key"

    actions = [
      "kms:Encrypt",
      "kms:Decrypt",
      "kms:ReEncrypt*",
      "kms:GenerateDataKey*",
      "kms:DescribeKey"
    ]

    principals {
      type        = "AWS"
      identifiers = var.shared_principals
    }

    resources = [
      "*"
    ]
  }

  statement {
    sid = "Allow attachment of persistent resources"

    actions = [
      "kms:CreateGrant",
      "kms:ListGrants",
      "kms:RevokeGrant"
    ]

    principals {
      type        = "AWS"
      identifiers = var.shared_principals
    }

    condition {
      test     = "Bool"
      variable = "kms:GrantIsForAWSResource"

      values = [
        true
      ]
    }

    resources = [
      "*"
    ]
  }

  statement {
    sid = "Allow access for key admins"

    actions = [
      "kms:Create*",
      "kms:Describe*",
      "kms:Enable*",
      "kms:List*",
      "kms:Put*",
      "kms:Update*",
      "kms:Revoke*",
      "kms:Disable*",
      "kms:Get*",
      "kms:Delete*",
      "kms:TagResource",
      "kms:UntagResource",
      "kms:ScheduleKeyDeletion",
      "kms:CancelKeyDeletion"
    ]

    principals {
      type        = "AWS"
      identifiers = [var.admin_role_arn]
    }

    resources = [
      "*"
    ]
  }
}

resource "aws_kms_alias" "a" {
  name          = "alias/rds-mineralsoft"
  target_key_id = aws_kms_key.a.key_id
}

================
File: ba/rds/kms/rds-mineralsoft/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/kms/rds-mineralsoft/terraform.tfstate"

================
File: ba/rds/kms/rds-mineralsoft/prod-ue1.tfvars
================
# prod-specific variable values:
owner_principal = "arn:aws:iam::512870776320:root"
shared_principals = [
  "arn:aws:iam::603547102569:root",
  "arn:aws:iam::816432189621:root",
]
vault_path_terraform_admin_user_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_prod"
region                               = "us-east-1"
#Removed as role doesn't exist anymore. But retaining as the policy has the translated arn in it.
#admin_role_arn                       = "arn:aws:iam::512870776320:role/ba-prod-admin-user"
admin_role_arn                       = "arn:aws:iam::512870776320:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_AdministratorAccess_473f1b97b8b26bfc"

================
File: ba/rds/kms/rds-mineralsoft/variables.tf
================
variable "region" {
  description = "aws region"
}

variable "bu" {
  description = "the business unit"
  default     = "ba"
}

variable "env" {
  description = "environment for resources, eg dev"
}

variable "owner_principal" {
  description = "AWS principal for owner account"
}

variable "shared_principals" {
  description = "list of AWS principals to share key with"
  type        = list(string)
}

variable "admin_role_arn" {
  description = "arn of admin role"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/rds/kms/rds-mineralsoft/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/rds/rds-lambda-snapshot/.gitignore
================
#VSCode directories
.vscode/
# Local .terraform directories
**/.terraform/*
.terraform.lock.hcl

# .tfstate files
*.tfstate
*.tfstate.*

# Crash log files
crash.log
logs.txt
# Ignore any .tfvars files that are generated automatically for each Terraform run. Most
# .tfvars files are managed as part of configuration and so should be included in
# version control.
#
# example.tfvars

# Ignore override files as they are usually used to override resources locally and so
# are not checked in
override.tf
override.tf.json
*_override.tf
*_override.tf.json

# Include override files you do wish to add to version control using negated pattern
#
# !example_override.tf

# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan
# example: *tfplan*

================
File: ba/rds/rds-lambda-snapshot/.terraform-version
================
latest:^1.4

================
File: ba/rds/rds-lambda-snapshot/main.tf
================
#backend
terraform {
  backend "s3" {}
}

#Providers
provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

#Datasources
data "aws_caller_identity" "caller_identity" {}

#Zip the python code up
data "archive_file" "archive_file_create_snapshot" {
  type             = "zip"
  source_file      = "${path.module}/rds_snapshot_create_lambda.py"
  output_path      = "${path.module}/rds_snapshot_create_lambda.zip"
  output_file_mode = "0444"
}

data "archive_file" "archive_file_share_snapshot" {
  type             = "zip"
  source_file      = "${path.module}/rds_snapshot_share_lambda.py"
  output_path      = "${path.module}/rds_snapshot_share_lambda.zip"
  output_file_mode = "0666"
}


#IAM policy for Lambda

#Lambdas
## IAM permissions
### Policy
resource "aws_iam_policy" "iam_policy_create" {
  name        = "rds-create-snapshot-lambda-policy"
  path        = "/"
  description = "IAM policy to allow lambda to create an RDS snapshot"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogGroup",
        ]
        Resource = "arn:aws:logs:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:*"
      },
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogStream",
          "logs:PutLogEvents",
        ]
        Resource = "arn:aws:logs:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:log-group:/aws/lambda/*"
      },
      {
        Effect = "Allow"
        Action = [
          "rds:Describe*",
          "rds:CreateDBSnapshot",
          "rds:AddTagsToResource"
        ]
        Resource = "*"
      },
    ]
  })
}

resource "aws_iam_policy" "iam_policy_share" {
  name        = "rds-share-snapshot-lambda-policy"
  path        = "/"
  description = "IAM policy to allow lambda to share an RDS snapshot"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogGroup",
        ]
        Resource = "arn:aws:logs:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:*"
      },
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogStream",
          "logs:PutLogEvents",
        ]
        Resource = "arn:aws:logs:${var.region}:${data.aws_caller_identity.caller_identity.account_id}:log-group:/aws/lambda/*"
      },
      {
        Effect = "Allow"
        Action = [
          "rds:ModifyDBSnapshot",
          "rds:ModifyDBSnapshotAttribute"
        ]
        Resource = "*"
      },
    ]
  })
}

### Role
resource "aws_iam_role" "iam_role_create" {
  name               = "rds-create-snapshot-lambda-role"
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}

resource "aws_iam_role" "iam_role_share" {
  name               = "rds-share-snapshot-lambda-role"
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}

### Attach policies to the roles
resource "aws_iam_role_policy_attachment" "iam_role_policy_attachment_create1" {
  role       = aws_iam_role.iam_role_create.name
  policy_arn = aws_iam_policy.iam_policy_create.arn
}

resource "aws_iam_role_policy_attachment" "iam_role_policy_attachment_create2" {
  role       = aws_iam_role.iam_role_create.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

resource "aws_iam_role_policy_attachment" "iam_role_policy_attachment_share2" {
  role       = aws_iam_role.iam_role_share.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

resource "aws_iam_role_policy_attachment" "iam_role_policy_attachment_share1" {
  role       = aws_iam_role.iam_role_share.name
  policy_arn = aws_iam_policy.iam_policy_share.arn
}

## Create snapshot Lambda
resource "aws_lambda_function" "lambda_function_create" {
  filename         = "${path.module}/rds_snapshot_create_lambda.zip"
  function_name    = "rds_snapshot_create_lambda"
  role             = aws_iam_role.iam_role_create.arn
  runtime          = "python3.8"
  handler          = "rds_snapshot_create_lambda.lambda_handler"
  source_code_hash = data.archive_file.archive_file_create_snapshot.output_base64sha256
}

## Share snapshot Lambda
resource "aws_lambda_function" "lambda_function_share" {
  filename         = "rds_snapshot_share_lambda.zip"
  function_name    = "rds_snapshot_share_lambda"
  role             = aws_iam_role.iam_role_share.arn
  runtime          = "python3.8"
  handler          = "rds_snapshot_share_lambda.lambda_handler"
  source_code_hash = data.archive_file.archive_file_share_snapshot.output_base64sha256
}

#Cloudwatch trigger for the last day of the month for the create lambda to run.
resource "aws_cloudwatch_event_rule" "cloudwatch_event_rule_create" {
  name                = "rds-snapshot-create"
  description         = "Take a snapshot of an RDS instance on the last day of the month"
  schedule_expression = "cron(0 22 1 * ? *)"
}

resource "aws_cloudwatch_event_target" "cloudwatch_event_target_create" {
  target_id = "rds_snapshot_create_lambda"
  rule      = aws_cloudwatch_event_rule.cloudwatch_event_rule_create.name
  arn       = aws_lambda_function.lambda_function_create.arn
  input     = <<ENI
{
  "rds": "${var.rds_name}",
  "region": "${var.region}"
}
ENI

}

#Cloudwatch trigger for the first day of the month for the share lambda to run.
#These are on different days as create can take quite a bit of time, and there is no point in having a lambda sit there costing $$.
resource "aws_cloudwatch_event_rule" "cloudwatch_event_rule_share" {
  name                = "rds-snapshot-share"
  description         = "Share a snapshot of an RDS instance on the first day of the month"
  schedule_expression = "cron(0 6 2 * ? *)"
  event_bus_name      = "default"
}

resource "aws_cloudwatch_event_target" "cloudwatch_event_target_share" {
  target_id = "rds_snapshot_share_lambda"
  rule      = aws_cloudwatch_event_rule.cloudwatch_event_rule_share.name
  arn       = aws_lambda_function.lambda_function_share.arn
  input     = <<ENI
{
  "rds": "${var.rds_name}",
  "region": "${var.region}",
  "receiving_account": "${var.receiving_account}"
}
ENI

}


resource "aws_lambda_permission" "lambda_permission_create" {
  statement_id  = "AllowExecutionFromCloudWatchCreate"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.lambda_function_create.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.cloudwatch_event_rule_create.arn
}

resource "aws_lambda_permission" "lambda_permission_share" {
  statement_id  = "AllowExecutionFromCloudWatchShare"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.lambda_function_share.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.cloudwatch_event_rule_share.arn
}

================
File: ba/rds/rds-lambda-snapshot/Makefile
================
.PHONY: gen _gen-main _gen-examples _gen-modules

CURRENT_DIR     = $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
TF_EXAMPLES     = $(sort $(dir $(wildcard $(CURRENT_DIR)examples/*/)))
TF_MODULES      = $(sort $(dir $(wildcard $(CURRENT_DIR)modules/*/)))
TF_DOCS_VERSION = 0.16.0

# Adjust your delimiter here or overwrite via make arguments
DELIM_START = <!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
DELIM_CLOSE = <!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

gen:
	@echo "################################################################################"
	@echo "# Terraform-docs generate"
	@echo "################################################################################"
	@$(MAKE) _gen-main

_gen-main:
	@echo "------------------------------------------------------------"
	@echo "# Main module"
	@echo "------------------------------------------------------------"
	@if docker run --rm \
		-v $(CURRENT_DIR):/data \
		-e DELIM_START='$(DELIM_START)' \
		-e DELIM_CLOSE='$(DELIM_CLOSE)' \
		cytopia/terraform-docs:${TF_DOCS_VERSION} \
		terraform-docs-replace-012 md README.md; then \
		echo "OK"; \
	else \
		echo "Failed"; \
		exit 1; \
	fi

================
File: ba/rds/rds-lambda-snapshot/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/rds-lambda-snapshot/terraform.tfstate"

================
File: ba/rds/rds-lambda-snapshot/prod-ue1.tfvars
================
rds_name          = "mineralsoft-prod"
region            = "us-east-1"
receiving_account = 816432189621

================
File: ba/rds/rds-lambda-snapshot/rds_snapshot_create_lambda.py
================
import json
import boto3
import logging
from datetime import datetime

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    client = boto3.client('rds', event['region'])
    dateTimeObj = datetime.now()
    timestampStr = dateTimeObj.strftime("%d-%b-%Y")
    DBSnapshotIdentifier = event['rds']+timestampStr
    logger.info(DBSnapshotIdentifier)
    try:
        response = client.create_db_snapshot(
            DBSnapshotIdentifier=DBSnapshotIdentifier,
            DBInstanceIdentifier=event['rds'],
            Tags=[
                {'Key': 'CreatedBy', 'Value': 'Snapshot Tool for RDS'},
                {'Key': 'CreatedOn', 'Value': timestampStr},
                {'Key': 'shareAndCopy', 'Value': 'YES'}
            ]
        )
    except Exception as e:
        logger.info("Could not create snapshot '{0}, '{1}".format(DBSnapshotIdentifier, e))

    return {
        'statusCode': 200,
        'body': "Done"
    }

================
File: ba/rds/rds-lambda-snapshot/rds_snapshot_share_lambda.py
================
import json
import boto3
import logging
from datetime import datetime
from dateutil.relativedelta import relativedelta

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    client = boto3.client('rds', event['region'])
    dateTimeObj = datetime.now() - relativedelta(days=1)
    timestampStr = dateTimeObj.strftime("%d-%b-%Y")
    DBSnapshotIdentifier = event['rds']+timestampStr
    try:
        logger.info(f"Share snapshot from {timestampStr} snapshot of {event['rds']}")
        client.modify_db_snapshot_attribute(
            DBSnapshotIdentifier=event['rds']+timestampStr,
            AttributeName="restore",
            ValuesToAdd=[event['receiving_account']]
        )

    except Exception as e:
        logger.info("Could not share snapshot '{0}, '{1}".format(DBSnapshotIdentifier, e))

    return {
        'statusCode': 200,
        'body': "Done"
    }

================
File: ba/rds/rds-lambda-snapshot/README.md
================
# rds-lambda-snapshot
lamdba to snapshot an RDS instance based on a cloudwatch trigger

# Overview
This system is a 2 lambda system, with corresponding cloudwatch events.
On the last day of the month at 2200 hrs, a snapshot is taken of specified rds instance.
On the frist day of the month at 0600 hrs, the snapshot from the day before is shared to another account.
It was setup this way because an RDS snapshot can take a while to take, and there was no point in having a lambda sit there waiting for it to finish the snapshot.  Therefore, the process was broken up onto 2 different days.

** Warning **
There is currently no error checking on the RDS instance name, and this will run regardless of the RDS name being correct.
<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.2.9 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | >= 4.32 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_archive"></a> [archive](#provider\_archive) | n/a |
| <a name="provider_aws"></a> [aws](#provider\_aws) | >= 4.32 |

## Modules

No modules.

## Resources

| Name | Type |
|------|------|
| [aws_cloudwatch_event_rule.cloudwatch_event_rule_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_rule) | resource |
| [aws_cloudwatch_event_rule.cloudwatch_event_rule_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_rule) | resource |
| [aws_cloudwatch_event_target.cloudwatch_event_target_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_target) | resource |
| [aws_cloudwatch_event_target.cloudwatch_event_target_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_target) | resource |
| [aws_iam_policy.iam_policy_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy) | resource |
| [aws_iam_policy.iam_policy_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy) | resource |
| [aws_iam_role.iam_role_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role) | resource |
| [aws_iam_role.iam_role_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role) | resource |
| [aws_iam_role_policy_attachment.iam_role_policy_attachment_create1](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment) | resource |
| [aws_iam_role_policy_attachment.iam_role_policy_attachment_create2](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment) | resource |
| [aws_iam_role_policy_attachment.iam_role_policy_attachment_share1](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment) | resource |
| [aws_iam_role_policy_attachment.iam_role_policy_attachment_share2](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment) | resource |
| [aws_lambda_function.lambda_function_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function) | resource |
| [aws_lambda_function.lambda_function_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function) | resource |
| [aws_lambda_permission.lambda_permission_create](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_permission) | resource |
| [aws_lambda_permission.lambda_permission_share](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_permission) | resource |
| [archive_file.archive_file_create_snapshot](https://registry.terraform.io/providers/hashicorp/archive/latest/docs/data-sources/file) | data source |
| [archive_file.archive_file_share_snapshot](https://registry.terraform.io/providers/hashicorp/archive/latest/docs/data-sources/file) | data source |
| [aws_caller_identity.caller_identity](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/caller_identity) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_VAULT_ADDR"></a> [VAULT\_ADDR](#input\_VAULT\_ADDR) | n/a | `any` | n/a | yes |
| <a name="input_assume_role_arn"></a> [assume\_role\_arn](#input\_assume\_role\_arn) | The arn of the role to assume. specific to the account being deployed to | `any` | n/a | yes |
| <a name="input_rds_name"></a> [rds\_name](#input\_rds\_name) | RDS instance name to be snapshotted | `string` | n/a | yes |
| <a name="input_receiving_account"></a> [receiving\_account](#input\_receiving\_account) | Account ID of the account to share the RDS snapshot with. | `number` | n/a | yes |
| <a name="input_region"></a> [region](#input\_region) | AWS Region to execute in | `string` | `"us-east-1"` | no |
| <a name="input_vault_path_aws_keys"></a> [vault\_path\_aws\_keys](#input\_vault\_path\_aws\_keys) | n/a | `any` | n/a | yes |

## Outputs

No outputs.

<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

================
File: ba/rds/rds-lambda-snapshot/variables.tf
================
variable "rds_name" {
  type        = string
  description = "RDS instance name to be snapshotted"
}

variable "region" {
  type        = string
  description = "AWS Region to execute in"
  default     = "us-east-1"
}

variable "receiving_account" {
  type        = number
  description = "Account ID of the account to share the RDS snapshot with."
}

variable "VAULT_ADDR" {}
variable "vault_path_aws_keys" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/rds/rds-lambda-snapshot/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/rds/rds-minerals-jpm-historical/versions.tf
================
terraform {
  required_version = ">= 1.2.2"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "mineralsoft"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/rds/rds-minerals-jpm-historical"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

================
File: ba/rds/rds-redash/.terraform-version
================
latest:^1.4

================
File: ba/rds/rds-redash/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/rds/rds-redash/dev-ue1.backend.tfvars
================
key = "dev/us-east-1/rds-redash/terraform.tfstate"

================
File: ba/rds/rds-redash/dev-ue1.tfvars
================
# dev-specific variable values:
vpc_name_tag                         = "ba-vpc-dev"
inside_sg_name                       = "ba-vpc-dev-inside-sg"
ec2-region                           = "us-east-1"
engine_version                       = "12.17"
instance_class                       = "db.t3.medium"
allocated_storage                    = "100"
db_parameter_group_family            = "postgres12"
multi_az                             = false
snapshot_identifier                  = ""
backup_retention_period              = 1
vault_path_terraform_admin_user_keys = "di-secrets/terraform/aws_api_keys/terraform_admin_user_keys_ba_dev"

================
File: ba/rds/rds-redash/main.tf
================
data "vault_generic_secret" "master_db_creds" {
  path = "di-secrets/terraform/database/mineralsoft-redash"
}

data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside" {
  vpc_id = data.aws_vpc.vpc.id

  filter {
    name   = "tag:Name"
    values = [var.inside_sg_name]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "inside" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*| INSIDE | Private Subnet"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

resource "aws_security_group" "db" {
  name        = "redash-${var.env}-db-sg"
  description = "Allow default port Postgres"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# create database
module "db" {
  source  = "terraform-aws-modules/rds/aws"
  version = "~> 5.0.0"

  identifier = "redash-${var.env}"

  engine            = "postgres"
  engine_version    = var.engine_version
  instance_class    = var.instance_class
  allocated_storage = var.allocated_storage
  storage_encrypted = true

  db_name = "redash"

  # NOTE: Do NOT use 'user' as the value for 'username' as it throws:
  # "Error creating DB Instance: InvalidParameterValue: MasterUsername
  # user cannot be used as it is a reserved word used by the engine"
  username = data.vault_generic_secret.master_db_creds.data["master_username"]
  password = data.vault_generic_secret.master_db_creds.data["master_password"]

  port = "5432"

  vpc_security_group_ids = [aws_security_group.db.id]

  maintenance_window = "Mon:00:00-Mon:03:00"
  backup_window      = "03:00-06:00"

  # disable backups to create DB faster
  backup_retention_period = var.backup_retention_period

  tags = {
    Name        = "redash-${var.env}"
    Team        = "sre@enverus.com"
    Stack       = var.env
    Component   = "mineralsoft"
    Environment = var.env
  }

  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]

  # DB subnet group
  subnet_ids             = data.aws_subnets.inside.ids
  create_db_subnet_group = true
  create_db_option_group = false
  create_random_password = false

  # DB parameter group
  create_db_parameter_group = false
  family                      = var.db_parameter_group_family
  #parameter_group_description = "parameter group for redash ${var.env} database"

  # Snapshot name upon DB deletion
  final_snapshot_identifier_prefix = "redash-${var.env}-FINAL"

  # Database Deletion Protection
  deletion_protection = true

  multi_az = var.multi_az

  allow_major_version_upgrade = true

  snapshot_identifier = var.snapshot_identifier

  iam_database_authentication_enabled = true
}
output "db_instance_address" { value = module.db.db_instance_address }
output "db_instance_endpoint" { value = module.db.db_instance_endpoint }
output "db_instance_name" { value = module.db.db_instance_name }

================
File: ba/rds/rds-redash/prod-ue1.backend.tfvars
================
key = "prod/us-east-1/rds-redash/terraform.tfstate"

================
File: ba/rds/rds-redash/prod-ue1.tfvars
================
# prod-specific variable values :
vpc_name_tag                         = "ba-vpc-prod"
inside_sg_name                       = "ba-vpc-prod-inside-sg"
ec2-region                           = "us-east-1"
engine_version                       = "12.17"
instance_class                       = "db.t3.medium"
allocated_storage                    = "100"
db_parameter_group_family            = "postgres12"
multi_az                             = true
snapshot_identifier                  = ""
backup_retention_period              = 15
vault_path_terraform_admin_user_keys = "di-secrets/terraform/aws_api_keys/terraform_admin_user_keys_ba_prod"

================
File: ba/rds/rds-redash/variables.tf
================
variable "bu" {
  description = "the business unit"
}

variable "ec2-region" {
  description = "region in which to create instance"
}

variable "env" {
  description = "Environment, eg dev"
}

variable "vpc_name_tag" {
}

variable "inside_sg_name" {
  description = "string pattern to search for 'inside' sg"
}

variable "engine_version" {
  description = "db engine version, eg 10.6"
}

variable "instance_class" {
  description = "db instance class, eg db.r3.2xlarge"
}

variable "allocated_storage" {
  description = "db allocated storage in GiB"
}

variable "db_parameter_group_family" {
  description = "db param group family, eg. postgres10 "
}

variable "multi_az" {
  description = "multi-az, true or false"
  type        = bool
}

variable "snapshot_identifier" {
  description = "DB Snapshot from which to create DB"
}

variable "backup_retention_period" {
  description = "days to retain backups - set to 0 to speed up db creation"
}

variable "VAULT_ADDR" {}
variable "vault_path_aws_keys" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/rds/rds-redash/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/route-53/regional-services/.terraform-version
================
latest:^1.4

================
File: ba/route-53/regional-services/data.tf
================
data "aws_route53_zone" "zone" {
  name         = "${var.env}.${var.domain_name}"
  private_zone = false
}

output "r53_zone" {
  value = data.aws_route53_zone.zone
}

data "aws_lb" "edge-lb" {
  name = "${var.business-unit}-${var.env}-edge-lb"
}

output "edge-lb" {
  value = data.aws_lb.edge-lb
}

================
File: ba/route-53/regional-services/dev-ue1.backend.tfvars
================
key = "dev-ue1/route53/regional-services/terraform.tfstate"

================
File: ba/route-53/regional-services/dev-ue1.tfvars
================
aws_region    = "us-east-1"
business-unit = "ba"
service_names_edge_lb = [
  "mineralsoft",
  "blackbox",
  "minerals-redash",
  "mineralsoft-redash-exim",
  "shouldcost",
  "otm"
]

================
File: ba/route-53/regional-services/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/route-53/regional-services/preprod-ue1.backend.tfvars
================
key = "preprod-ue1/route53/regional-services/terraform.tfstate"

================
File: ba/route-53/regional-services/preprod-ue1.tfvars
================
aws_region    = "us-east-1"
business-unit = "ba"
service_names_edge_lb = [
  "mineralsoft",
  "blackbox",
  "minerals-redash",
  "mineralsoft-redash-exim",
]

================
File: ba/route-53/regional-services/prod-ue1.backend.tfvars
================
key = "prod-ue1/route53/regional-services/terraform.tfstate"

================
File: ba/route-53/regional-services/prod-ue1.tfvars
================
aws_region    = "us-east-1"
business-unit = "ba"
service_names_edge_lb = [
  "mineralsoft",
  "minerals-redash",
  "mineralsoft-redash-exim",
  "otm-onboard",
  "otm",
]

================
File: ba/route-53/regional-services/prod-uw2.backend.tfvars
================
key = "prod-uw2/route53/regional-services/terraform.tfstate"

================
File: ba/route-53/regional-services/prod-uw2.tfvars
================
aws_region    = "us-west-2"
business-unit = "ba"
service_names_edge_lb = [
  "mineralsoft-uw2",
]

================
File: ba/route-53/regional-services/route53.tf
================
resource "aws_route53_record" "dns-edge-lb" {
  for_each = toset(var.service_names_edge_lb)

  zone_id = data.aws_route53_zone.zone.zone_id
  name    = "${each.key}.${var.env}.${var.domain_name}"
  type    = "A"

  alias {
    name                   = data.aws_lb.edge-lb.dns_name
    zone_id                = data.aws_lb.edge-lb.zone_id
    evaluate_target_health = false
  }
}

output "dns-edge-lb" {
  value = aws_route53_record.dns-edge-lb
}

================
File: ba/route-53/regional-services/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "vault_path_aws_keys" {
  description = "vault path for aws creds"
  type        = string
}

variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "business-unit" {
  description = "business unit, eg. cds"
}

variable "env" {
  description = "environment, eg dev"
}

variable "domain_name" {
  description = "Domain Name used on ACM certs and Route53 DNS"
  default     = "ba.drillinginfo.com"
}

variable "service_names_edge_lb" {
  type    = list(any)
  default = []
}

================
File: ba/route-53/regional-services/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/route-53/.terraform-version
================
latest:^1.4

================
File: ba/route-53/dev.backend.tfvars
================
key = "dev/route53/terraform.tfstate"

================
File: ba/route-53/dev.tfvars
================
region = "us-west-2"

================
File: ba/route-53/prod.backend.tfvars
================
key = "prod/route53/terraform.tfstate"

================
File: ba/route-53/prod.tfvars
================
region = "us-west-2"

================
File: ba/route-53/variables.tf
================
variable "region" {}
variable "env" {}

variable "bu" {
  description = "business unit abbreviation, eg. ba"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/route-53/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/route-53/zone.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

# create an environment-specific zone
resource "aws_route53_zone" "main" {
  name = "${var.env}.${var.bu}.drillinginfo.com"
}

================
File: ba/route-53-resolver/.terraform-version
================
latest:^1.7

================
File: ba/route-53-resolver/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}
# output "aws_ec2_managed_prefix_list_vpn_prefix_list" { value = data.aws_ec2_managed_prefix_list.vpn_prefix_list }

================
File: ba/route-53-resolver/dev-ue1.backend.tfvars
================
key = "dev/route-53-resolver-ue1/terraform.tfstate"

================
File: ba/route-53-resolver/dev-ue1.tfvars
================
vpc_name_tag      = "ba-vpc-dev"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-east-1"

================
File: ba/route-53-resolver/dev-uw2.backend.tfvars
================
key = "dev/route-53-resolver/terraform.tfstate"

================
File: ba/route-53-resolver/dev-uw2.tfvars
================
vpc_name_tag      = "ba-vpc-dev"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-west-2"
transzap_dns_ip   = "10.52.8.26"

================
File: ba/route-53-resolver/main.tf
================
data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc_id.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

resource "aws_security_group" "route53_resolver_tcp_udp" {
  name        = "route53_resolver_tcp_udp"
  description = "Port 53 for DNS"
  vpc_id      = data.aws_vpc.vpc_id.id

  ingress {
    description     = "DNS from Route53 resolver - tcp"
    from_port       = 53
    to_port         = 53
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
  }

  ingress {
    description     = "DNS from Route53 resolver - udp"
    from_port       = 53
    to_port         = 53
    protocol        = "udp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name          = "route-53-${var.env}"
    Team          = "sre@enverus.com"
    Stack         = var.env
    Component     = "route-53-resolver"
    Environment   = var.env
    Business_unit = var.bu
  }
}
output "aws_sg_route53_resolver" { value = aws_security_group.route53_resolver_tcp_udp }

resource "aws_route53_resolver_endpoint" "outbound" {
  name      = "DNS Outbound Resolver"
  direction = "OUTBOUND"

  security_group_ids = [
    aws_security_group.route53_resolver_tcp_udp.id
  ]
  dynamic "ip_address" {
    for_each = data.aws_subnets.private_subnets.ids
    content {
      subnet_id = ip_address.value
    }
  }

  tags = {
    Name          = "route-53-${var.env}"
    Team          = var.aws_tag_team
    Stack         = var.env
    Component     = var.aws_tag_component
    Environment   = var.env
    Business_unit = var.bu
  }
}
output "aws_route53_resolver_endpoint" { value = aws_route53_resolver_endpoint.outbound }

resource "aws_route53_resolver_rule" "enverus" {
  for_each             = var.enverus_domain_rules
  domain_name          = each.value.domain
  name                 = each.value.name
  rule_type            = "FORWARD"
  resolver_endpoint_id = aws_route53_resolver_endpoint.outbound.id

  target_ip {
    ip = var.transzap_dns_ip
  }

  tags = {
    Name          = "route-53-${var.env}"
    Team          = var.aws_tag_team
    Stack         = var.env
    Component     = var.aws_tag_component
    Environment   = var.env
    Business_unit = var.bu
  }
}

resource "aws_route53_resolver_rule" "drillinginfo" {
  domain_name          = var.drillinginfo_domain_rules.domain
  name                 = var.drillinginfo_domain_rules.name
  rule_type            = "FORWARD"
  resolver_endpoint_id = aws_route53_resolver_endpoint.outbound.id

  target_ip {
    ip = var.drillinginfo_target_ip
  }
}
output "aws_route53_resolver_rule" { value = aws_route53_resolver_rule.enverus }

resource "aws_route53_resolver_rule_association" "drillinginfo" {
  resolver_rule_id = aws_route53_resolver_rule.drillinginfo.id
  vpc_id           = data.aws_vpc.vpc_id.id
}

resource "aws_route53_resolver_rule_association" "enverus" {
  for_each         = var.enverus_domain_rules
  resolver_rule_id = aws_route53_resolver_rule.enverus[each.key].id
  vpc_id           = data.aws_vpc.vpc_id.id
}

output "aws_route53_resolver_rule_association" { value = aws_route53_resolver_rule_association.enverus }

================
File: ba/route-53-resolver/preprod-ue1.backend.tfvars
================
key = "preprod/route-53-resolver-ue1/terraform.tfstate"

================
File: ba/route-53-resolver/preprod-ue1.tfvars
================
vpc_name_tag      = "ba-vpc-preprod"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-east-1"
transzap_dns_ip   = "10.52.8.26"

================
File: ba/route-53-resolver/preprod-uw2.backend.tfvars
================
key = "preprod/route-53-resolver/terraform.tfstate"

================
File: ba/route-53-resolver/preprod-uw2.tfvars
================
vpc_name_tag      = "ba-vpc-preprod"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-west-2"
transzap_dns_ip   = "10.52.8.26"

================
File: ba/route-53-resolver/prod-ue1.backend.tfvars
================
key = "prod/route-53-resolver-ue1/terraform.tfstate"

================
File: ba/route-53-resolver/prod-ue1.tfvars
================
vpc_name_tag      = "ba-vpc-prod"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-east-1"

================
File: ba/route-53-resolver/prod-uw2.backend.tfvars
================
key = "prod/route-53-resolver/terraform.tfstate"

================
File: ba/route-53-resolver/prod-uw2.tfvars
================
vpc_name_tag      = "ba-vpc-prod"
aws_tag_team      = "SRE"
aws_tag_component = "epayables"
ec2-region        = "us-west-2"
transzap_dns_ip   = "10.52.8.26"

================
File: ba/route-53-resolver/variables.tf
================
variable "env" {
  description = "environment, eg. dev"
  type        = string
}

variable "ec2-region" {
  description = "provider region, eg us-east-1"
  type        = string
}

variable "bu" {
  description = "business unit, eg ba"
  type        = string
}

variable "vpc_name_tag" {
  description = "Value of vpc Name tag"
  type        = string
}

variable "aws_tag_team" {
  description = "The team that owns the resource"
  type        = string
}

variable "aws_tag_component" {
  description = "This is the AWS region"
  type        = string
}

variable "enverus_domain_rules" {
  description = "domains and resolver rule names"
  type = map(object({
    domain = string
    name   = string

  }))
  default = {
    "openinvoice" = {
      "domain" = "transzap.com"
      "name"   = "OI-DNS"
    },
    "azure-drillinginfo" = {
      "domain" = "azure.drillinginfo.com"
      "name"   = "Azure-Drillinginfo"
    },
    "oraclevcn" = {
      "domain" = "oraclevcn.com"
      "name"   = "Oraclevcn-Drillinginfo"
    }
    "energylink" = {
      "domain" = "energylink.com"
      "name"   = "energylink-Drillinginfo"
    }
  }
}

variable "drillinginfo_domain_rules" {
  description = "domain and resolver rule name"
  type        = map(string)
  default = {
    "domain" = "drillinginfo.com"
    "name"   = "di-dns"
  }
}

variable "transzap_dns_ip" {
  description = "transzap DC"
  type        = string
  default     = "10.52.8.26"
}

variable "drillinginfo_target_ip" {
  description = "DrillingInfo DNS IP"
  type        = string
  default     = "10.52.8.26"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: ba/route-53-resolver/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.8.0"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/route-53-resolver"
      TerraformCreated = "true"
    }
  }

}

================
File: ba/s3/.terraform-version
================
latest:^1.4

================
File: ba/s3/chef-validator.tf
================
data "aws_caller_identity" "current" {
  provider = aws.us-east-1
}

locals {
  bucket_name = "di-ba-${var.env}-chef-validator"
}

module "chef_validator_bucket" {
  source = "terraform-aws-modules/s3-bucket/aws"
  providers = {
    aws = aws.us-east-1
  }

  attach_policy = true
  policy        = data.aws_iam_policy_document.chef_bucket_policy.json
  bucket        = local.bucket_name
  acl           = "private"

  versioning = {
    enabled = true
  }

  tags = {
    Team      = "sre@enverus.com"
    bu        = "ba"
    component = "chef"
    env       = var.env
  }
}

data "aws_iam_policy_document" "chef_bucket_policy" {
  provider = aws.us-east-1
  statement {
    principals {
      type = "AWS"
      identifiers = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:user/iam-base-chef-user",
        "arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"
      ]
    }

    actions = [
      "s3:GetObject",
    ]

    resources = [
      "arn:aws:s3:::${local.bucket_name}/*",
    ]
  }
}

================
File: ba/s3/dev.backend.tfvars
================
key = "dev/s3/terraform.tfstate"

================
File: ba/s3/jenkins-backups.tf
================
module "jenkins_backup" {
  source = "terraform-aws-modules/s3-bucket/aws"
  providers = {
    aws = aws.us-east-1
  }

  create_bucket = var.env == "dev" ? true : false # only create a dev bucket

  bucket = "enverus-ba-jenkins-backup-${var.env}"
  acl    = "private"

  versioning = {
    enabled = true
  }

  tags = {
    Team      = "sre@enverus.com"
    bu        = "ba"
    component = "jenkins"
    env       = var.env
  }

  // S3 bucket-level Public Access Block configuration
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# bucket user and keys
resource "aws_iam_user" "jenkins_backup_bucket_user" {
  count    = var.env == "dev" ? 1 : 0 # only create a dev bucket
  provider = aws.us-east-1
  name     = "enverus-ba-jenkins-backup-s3-bucket-user-${var.env}"
}

resource "aws_iam_access_key" "jenkins_backup_bucket_user" {
  count    = var.env == "dev" ? 1 : 0 # only create a dev bucket
  provider = aws.us-east-1
  user     = aws_iam_user.jenkins_backup_bucket_user[count.index].name
}

resource "aws_iam_user_policy" "jenkins_backup_bucket_user" {
  count    = var.env == "dev" ? 1 : 0 # only create a dev bucket
  provider = aws.us-east-1
  name     = "enverus-ba-jenkins-backup-s3-bucket-user-policy-${var.env}"
  user     = aws_iam_user.jenkins_backup_bucket_user[count.index].name

  policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:ListBucket"],
      "Resource": ["arn:aws:s3:::enverus-ba-jenkins-backup-${var.env}"]
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": ["arn:aws:s3:::enverus-ba-jenkins-backup-${var.env}/*"]
    }
  ]
}
EOF
}

resource "vault_generic_secret" "terraform_secrets" {
  count = var.env == "dev" ? 1 : 0 # only create a dev bucket
  path  = "di-secrets/terraform/aws_api_keys/enverus-ba-jenkins-backup-bucket_user_keys_${var.bu}_${var.env}"

  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.jenkins_backup_bucket_user[count.index].id}",
  "secret_key": "${aws_iam_access_key.jenkins_backup_bucket_user[count.index].secret}"
}
EOF
}

================
File: ba/s3/main.tf
================
terraform {
  backend "s3" {}
}

provider "aws" {
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "us-west-2"
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "us-east-1"
}

provider "aws" {
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "ca-central-1"
}

================
File: ba/s3/minerals.tf
================
resource "aws_s3_bucket" "minerals" {
  provider = aws.us-east-1
  bucket   = "en-${var.env}-minerals"

  tags = {
    Name         = "en-${var.env}-minerals"
    Environment  = var.env
    BusinessUnit = var.bu
    Team         = "MineralSoft"
  }
}

================
File: ba/s3/prod.backend.tfvars
================
key = "prod/s3/terraform.tfstate"

================
File: ba/s3/variables.tf
================
variable "env" {}

variable "bu" {}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/s3/versions.tf
================
terraform {
  required_version = ">= 0.13"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/s3-buckets/files/spendanalytics.json
================
{
  "Id": "Policy1555530987151",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1555530985752",
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::di-${bu}-${env}-${name}",
        "arn:aws:s3:::di-${bu}-${env}-${name}/*"
      ],
      "Condition": {
        "StringNotLike": {
          "aws:userid": ["AROAJTP5B6RX75URVGCBI:david.heath@drillinginfo.com",
                         "AROAJTP5B6RX75URVGCBI:david.turner@drillinginfo.com",
                         "AROAJTP5B6RX75URVGCBI:Mark.Kudryk@drillinginfo.com",
                         "AROAJTP5B6RX75URVGCBI:petr.nemec@drillinginfo.com",
                         "AROAJTP5B6RX75URVGCBI:King.Huang@drillinginfo.com",
                         "AIDATYJ6XXJ555LWHBEZC"]
        }
      }
    }
  ]
}

================
File: ba/s3-buckets/.terraform-version
================
latest:^1.4

================
File: ba/s3-buckets/dev.backend.tfvars
================
bucket         = "di-ba-dev-terraform"
key            = "dev/s3-buckets/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "ba-dev-terraform-state-locking"

================
File: ba/s3-buckets/dev.tfvars
================
bu  = "ba"
env = "dev"

================
File: ba/s3-buckets/main.tf
================
# ---------------------------------------------------------------------------------------------------------------------
# Create all s3 buckets
# ---------------------------------------------------------------------------------------------------------------------
terraform {
  backend "s3" {}
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
}

module "test_bucket" {
  source           = "git::ssh://git@git.drillinginfo.com/tf-modules/s3-simple-bucket.git?ref=v0.2.0"
  name             = "di-${var.bu}-${var.env}-test"
  env              = var.env
  env_to_create_in = "dev"
}

module "test_all_envs_bucket" {
  source = "git::ssh://git@git.drillinginfo.com/tf-modules/s3-simple-bucket.git?ref=v0.2.0"
  name   = "di-${var.bu}-${var.env}-test-all"
  env    = var.env
}

module "spendanalytics_training" {
  source      = "git::ssh://git@git.drillinginfo.com/tf-modules/s3-simple-bucket-with-policy.git?ref=v0.1.0"
  name        = "sa-trainings"
  env         = var.env
  bu          = var.bu
  policy_file = file("files/spendanalytics.json")
}

module "spendanalytics_validation" {
  source      = "git::ssh://git@git.drillinginfo.com/tf-modules/s3-simple-bucket-with-policy.git?ref=v0.1.0"
  name        = "sa-validations"
  env         = var.env
  bu          = var.bu
  policy_file = file("files/spendanalytics.json")
}

module "spendanalytics_attribution" {
  source      = "git::ssh://git@git.drillinginfo.com/tf-modules/s3-simple-bucket-with-policy.git?ref=v0.1.0"
  name        = "sa-attributions"
  env         = var.env
  bu          = var.bu
  policy_file = file("files/spendanalytics.json")
}

================
File: ba/s3-buckets/variables.tf
================
variable "bu" {}
variable "env" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/s3-buckets/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/s3-enverus-ba-log-archive/.terraform-version
================
latest:^1.4

================
File: ba/s3-enverus-ba-log-archive/dev-ue1.backend.tfvars
================
key = "dev/s3-enverus-ba-log-archive/terraform.tfstate"

================
File: ba/s3-enverus-ba-log-archive/dev-ue1.tfvars
================
# Put dev-specific values here
bucket_name = "enverus-ba-log-archive"
region      = "us-east-1"

================
File: ba/s3-enverus-ba-log-archive/main.tf
================
data "aws_caller_identity" "current" {}

# append a random id to make bucket recreation easier
resource "random_id" "random" {
  byte_length = 6
}

resource "aws_s3_bucket" "s3-bucket" {
  bucket = "${var.bucket_name}-${var.env}-${random_id.random.hex}"
  acl    = "private"

  lifecycle_rule {
    id                                     = "whole-bucket"
    enabled                                = true
    abort_incomplete_multipart_upload_days = 0

    transition {
      days          = 30
      storage_class = "GLACIER"
    }

    expiration {
      days = 365
    }

    noncurrent_version_expiration {
      days = 365
    }
  }

  tags = {
    Name = "${var.bucket_name}-${var.env}-${random_id.random.hex}"
  }
}
output "aws_s3_bucket" { value = aws_s3_bucket.s3-bucket }

================
File: ba/s3-enverus-ba-log-archive/prod-ue1.backend.tfvars
================
key = "prod/s3-enverus-ba-log-archive/terraform.tfstate"

================
File: ba/s3-enverus-ba-log-archive/prod-ue1.tfvars
================
# Put prod-specific values here
bucket_name = "enverus-ba-log-archive"
region      = "us-east-1"

================
File: ba/s3-enverus-ba-log-archive/variables.tf
================
variable "bucket_name" {
  description = "base name of s3 bucket"
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "region" {
  description = "aws region"
}

variable "env" {
  description = "environment, eg dev"
}

================
File: ba/s3-enverus-ba-log-archive/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    random = {
      source = "hashicorp/random"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "s3"
      Product          = "nexus"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/s3-enverus-ba-log-archive"
      TerraformCreated = "true"
      Environment      = var.env
      location         = var.region
    }
  }
}

================
File: ba/s3-minerals/bucket_policies/preprod-policy.json
================
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid":"replication- permissions for objects",
      "Effect":"Allow",
      "Principal":{
         "AWS":"arn:aws:iam::512870776320:role/s3crr_role_minerals"
      },
      "Action":[
        "s3:ReplicateObject",
        "s3:ReplicateDelete"
      ],
      "Resource":"arn:aws:s3:::enverus-minerals-preprod-8e3a124ee403/*"
    },
    {
        "Sid":"replication- permissions for bucket",
        "Effect":"Allow",
        "Principal":{
          "AWS":"arn:aws:iam::512870776320:role/s3crr_role_minerals"
        },
        "Action":[
          "s3:GetBucketVersioning",
          "s3:PutBucketVersioning"
        ],
        "Resource":"arn:aws:s3:::enverus-minerals-preprod-8e3a124ee403"
    },
    {
      "Sid":"replication- allow destination account to own objects",
      "Effect":"Allow",
      "Principal":{"AWS":"arn:aws:iam::512870776320:root"},
      "Action":[
        "s3:ObjectOwnerOverrideToBucketOwner"
      ],
      "Resource":"arn:aws:s3:::enverus-minerals-preprod-8e3a124ee403/*"
    }
  ]
}

================
File: ba/s3-minerals/bucket_policies/prod-policy.json
================
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "InventoryAndAnalyticsPolicy",
      "Effect": "Allow",
      "Principal": {
          "Service": "s3.amazonaws.com"
      },
      "Action": [
          "s3:PutObject"
      ],
      "Resource": [
          "arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*"
      ],
      "Condition": {
          "ArnLike": {
              "aws:SourceArn": "arn:aws:s3:::minerals"
          },
          "StringEquals": {
              "aws:SourceAccount": "816432189621",
              "s3:x-amz-acl": "bucket-owner-full-control"
          }
      }
    },
    {
      "Sid": "CrossAccountAccess",
      "Effect": "Allow",
      "Principal": {
        "AWS": [
            "arn:aws:iam::277940912254:role/s3-cross-account-batch-copy-minerals-migration",
            "arn:aws:iam::512870776320:role/s3-cross-account-batch-copy-minerals-migration"
        ]
      },
      "Action": [
          "s3:GetObject"
      ],
      "Resource": [
          "arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*"
      ]
    },
    {
      "Sid":"replication- permissions for objects",
      "Effect":"Allow",
      "Principal":{
         "AWS":"arn:aws:iam::816432189621:role/s3crr_role_for_minerals_migration"
      },
      "Action":[
        "s3:ReplicateObject",
        "s3:ReplicateDelete"
      ],
      "Resource":"arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*"
    },
    {
        "Sid":"replication- permissions for objects",
        "Effect":"Allow",
        "Principal":{
          "AWS":"arn:aws:iam::816432189621:role/s3crr_role_for_minerals_migration"
        },
        "Action":[
          "s3:GetBucketVersioning",
          "s3:PutBucketVersioning"
        ],
        "Resource":"arn:aws:s3:::enverus-minerals-prod-17d89cf32e50"
    },
    {
      "Sid":"replication- allow destination account to own objects",
      "Effect":"Allow",
      "Principal":{"AWS":"arn:aws:iam::816432189621:root"},
      "Action":[
        "s3:ObjectOwnerOverrideToBucketOwner"
      ],
      "Resource":"arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*"
    },
    {
      "Sid": "Allow list from ba-preprod",
      "Effect": "Allow",
      "Principal": {
          "AWS": "arn:aws:iam::277940912254:root"
      },
      "Action": "s3:ListBucket",
      "Resource": "arn:aws:s3:::enverus-minerals-prod-17d89cf32e50"
    },
    {
      "Sid": "Allow get from ba-preprod",
      "Effect": "Allow",
      "Principal": {
          "AWS": "arn:aws:iam::277940912254:root"
      },
      "Action": [
          "s3:GetObject",
          "s3:GetObjectTagging",
          "s3:PutObject",
          "s3:PutObjectTagging",
          "s3:DeleteObjectTagging"
      ],
      "Resource": "arn:aws:s3:::enverus-minerals-prod-17d89cf32e50/*"
    }
  ]
}

================
File: ba/s3-minerals/source_bucket_policies/minerals.json
================
{
  "Version": "2012-10-17",
  "Statement": [
      {
          "Sid": "AllowBatchOperationsSourceObjectCOPY",
          "Effect": "Allow",
          "Principal": {
              "AWS": [
                  "arn:aws:iam::512870776320:role/s3-cross-account-batch-copy-minerals-migration",
                  "arn:aws:iam::277940912254:role/s3-cross-account-batch-copy-minerals-migration"
              ]
          },
          "Action": [
              "s3:GetObject",
              "s3:GetObjectVersion",
              "s3:GetObjectAcl",
              "s3:GetObjectTagging",
              "s3:GetObjectVersionAcl",
              "s3:GetObjectVersionTagging"
          ],
          "Resource": "arn:aws:s3:::minerals/*"
      },
      {
          "Sid": "Allow list from ba-prod",
          "Effect": "Allow",
          "Principal": {
              "AWS": "arn:aws:iam::512870776320:root"
          },
          "Action": "s3:ListBucket",
          "Resource": "arn:aws:s3:::minerals"
      },
      {
          "Sid": "Allow get from ba-prod",
          "Effect": "Allow",
          "Principal": {
              "AWS": "arn:aws:iam::512870776320:root"
          },
          "Action": [
              "s3:GetObject",
              "s3:GetObjectTagging",
              "s3:PutObject",
              "s3:PutObjectTagging",
              "s3:DeleteObjectTagging"
          ],
          "Resource": "arn:aws:s3:::minerals/*"
      }
  ]
}

================
File: ba/s3-minerals/.terraform-version
================
latest:^1.4

================
File: ba/s3-minerals/main.tf
================
data "aws_caller_identity" "current" {}

# append a random id to make bucket re-creation easier
resource "random_id" "random" {
  byte_length = 6
}

resource "aws_s3_bucket" "s3-bucket" {
  bucket = "enverus-minerals-${var.env}-${random_id.random.hex}"
  acl    = "private"

  versioning {
    enabled = var.enable_versioning
  }

  dynamic "replication_configuration" {
    for_each = var.enable_replication ? [1] : []
    content {
      role = var.replication_role_arn

      rules {
        id       = "disaster-recovery"
        status   = "Enabled"
        priority = 1

        filter {}

        destination {
          bucket        = "arn:aws:s3:::${var.replication_destination_disaster_recovery_bucket_name}"
          storage_class = "STANDARD"
          account_id    = data.aws_caller_identity.current.account_id
          access_control_translation {
            owner = "Destination"
          }
        }
      }

      rules {
        id       = "preprod"
        status   = "Enabled"
        priority = 2

        filter {}

        destination {
          bucket        = "arn:aws:s3:::${var.replication_destination_preprod_bucket_name}"
          storage_class = "STANDARD"
          account_id    = var.replication_destination_preprod_account_id
          access_control_translation {
            owner = "Destination"
          }
        }
      }
    }
  }

  policy = var.bucket_policy_file != null ? file("${path.module}/bucket_policies/${var.bucket_policy_file}") : null

  tags = {
    Name = "enverus-minerals-${var.env}-${random_id.random.hex}"
  }
}
output "aws_s3_bucket" { value = aws_s3_bucket.s3-bucket }

================
File: ba/s3-minerals/prod-ue1.backend.tfvars
================
key = "prod/s3-minerals/terraform.tfstate"

================
File: ba/s3-minerals/prod-ue1.tfvars
================
# Put prod-specific values here
region                                                = "us-east-1"
bucket_policy_file                                    = "prod-policy.json"
enable_versioning                                     = true
enable_replication                                    = true
replication_destination_preprod_account_id            = "277940912254"
replication_destination_preprod_bucket_name           = "enverus-minerals-preprod-8e3a124ee403"
replication_destination_disaster_recovery_bucket_name = "enverus-minerals-prod-dr-0b4d3e5148cd"
replication_role_arn                                  = "arn:aws:iam::512870776320:role/s3crr_role_minerals"

================
File: ba/s3-minerals/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "region" {
  description = "aws region"
}

variable "env" {
  description = "environment, eg dev"
}

variable "enable_replication" {
  description = "enable replication to dr and preprod buckets"
  type        = bool
  default     = false
}

variable "enable_versioning" {
  description = "enable versioning of bucket objects"
  type        = bool
  default     = false
}

variable "bucket_policy_file" {
  description = "File in module with bucket policy to apply"
  type        = string
  default     = null
}

variable "replication_destination_disaster_recovery_bucket_name" {
  description = "Name of the DR bucket"
  type        = string
  default     = null
}

variable "replication_destination_preprod_account_id" {
  description = "Account ID of the preprod bucket - only used for prod"
  type        = string
  default     = null
}

variable "replication_destination_preprod_bucket_name" {
  description = "Name of the preprod bucket"
  type        = string
  default     = null
}

variable "replication_role_arn" {
  description = "arn of role used by s3 for replication"
  type        = string
  default     = null
}

================
File: ba/s3-minerals/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    random = {
      source = "hashicorp/random"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "mineralsoft"
      Product          = "nexus"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/s3-minerals"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: ba/s3-minerals-dr/.terraform-version
================
latest:^1.4

================
File: ba/s3-minerals-dr/main.tf
================
data "aws_caller_identity" "current" {}

# append a random id to make bucket recreation easier
resource "random_id" "random" {
  byte_length = 6
}

resource "aws_s3_bucket" "s3-bucket" {
  bucket = "enverus-minerals-${var.env}-dr-${random_id.random.hex}"
  acl    = "private"

  versioning {
    enabled = var.enable_versioning
  }

  tags = {
    Name             = "enverus-minerals-${var.env}-dr-${random_id.random.hex}"
    Environment      = var.env
    Team             = "sre@enverus.com"
    location         = var.region
    stack            = var.env
    component        = "mineralsoft"
    terraformcreated = "true"
    bu               = "ba"
    tagSourceCode    = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/s3-minerals"
  }
}

output "aws_s3_bucket" { value = aws_s3_bucket.s3-bucket }

================
File: ba/s3-minerals-dr/prod-uw2.backend.tfvars
================
key = "prod/us-west-2/s3-minerals-dr/terraform.tfstate"

================
File: ba/s3-minerals-dr/prod-uw2.tfvars
================
# Put prod-specific values here
region            = "us-west-2"
enable_versioning = true

================
File: ba/s3-minerals-dr/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "region" {
  description = "aws region"
}

variable "env" {
  description = "environment, eg dev"
}

variable "enable_versioning" {
  description = "controls versioning"
  type        = bool
  default     = null
}

================
File: ba/s3-minerals-dr/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    random = {
      source = "hashicorp/random"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/s3-openticket-mobile/.terraform-version
================
latest:^1.4

================
File: ba/s3-openticket-mobile/dev-ue1.backend.tfvars
================
key = "dev-ue1/s3-openticket-mobile/terraform.tfstate"

================
File: ba/s3-openticket-mobile/dev-ue1.tfvars
================
# Put dev-specific values here
vault_path_aws_keys = "di-secrets/ba_terraform/aws_api_keys/terraform_keys_ba_dev"
s3-bucket-name = [
  "enverus-dev-openticket-mobile-cache",
]
ec2-region         = "us-east-1"
enable_replication = false

================
File: ba/s3-openticket-mobile/main.tf
================
data "aws_caller_identity" "current" {}

================
File: ba/s3-openticket-mobile/prod-ue1.backend.tfvars
================
key = "prod-ue1/s3-openticket-mobile/terraform.tfstate"

================
File: ba/s3-openticket-mobile/prod-ue1.tfvars
================
# Put prod-specific values here
vault_path_aws_keys = "di-secrets/ba_terraform/aws_api_keys/terraform_keys_ba_prod"
s3-bucket-name = [
  "enverus-onboard-openticket-mobile-cache",
  "enverus-prod-openticket-mobile-cache",
]
ec2-region         = "us-east-1"
enable_replication = false

================
File: ba/s3-openticket-mobile/s3.tf
================
resource "aws_s3_bucket" "s3-bucket" {
  for_each = toset(var.s3-bucket-name)

  bucket = each.key
  acl    = "private"

  versioning {
    enabled = var.enable_replication
  }

  dynamic "replication_configuration" {
    for_each = var.enable_replication ? [1] : []
    content {
      role = var.replication_role_arn

      rules {
        id       = "backup"
        status   = "Enabled"
        priority = 10

        destination {
          bucket        = "arn:aws:s3:::${var.bucket_name}-disaster-recovery"
          storage_class = "STANDARD"
          account_id    = data.aws_caller_identity.current.account_id
          access_control_translation {
            owner = "Destination"
          }
        }
      }
    }
  }
  lifecycle_rule {
    id                                     = "whole-bucket"
    enabled                                = false
    abort_incomplete_multipart_upload_days = 0

    expiration {
      days = 60
    }

    noncurrent_version_expiration {
      days = 300
    }
  }

  tags = {
    Name        = "${each.key}"
    Environment = var.env
  }
}

================
File: ba/s3-openticket-mobile/variables.tf
================
variable "s3-bucket-name" {
  description = "list of names of s3 buckets"
}

variable "vault_path_aws_keys" {
  description = "path in Vault to aws api keys"
}

variable "ec2-region" {
  description = "aws region"
}

variable "replication_role_arn" {
  description = "arn of replication role"
  default     = ""
}

variable "enable_replication" {
  description = "disaster recovery region"
  type        = bool
}

variable "env" {
  description = "environment, eg dev"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/s3-openticket-mobile/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: ba/shouldcost-service/secrets/.terraform-version
================
latest:^1.4

================
File: ba/shouldcost-service/secrets/dev-ue1.backend.tfvars
================
key = "dev/us-east-1/shouldcost-service-secrets/terraform.tfstate"

================
File: ba/shouldcost-service/secrets/dev-ue1.tfvars
================
mountpoint = "di-secrets"
secret_paths = [
  "terraform/application/shouldcost-service",
]
VAULT_ADDR = "https://vault-ue1.dev.ba.drillinginfo.com"

================
File: ba/shouldcost-service/secrets/main.tf
================
module "vault_secrets" {
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/vault-secrets.git?ref=main"

  mountpoint   = var.mountpoint
  secret_paths = var.secret_paths
}
output "vault_secrets" { value = module.vault_secrets }

resource "vault_generic_secret" "vault_secret_shouldcost" {
  path = module.vault_secrets.local_secret_paths[0]
  data_json = jsonencode(
    {
      "DB_HOST"     = "placeholder"
      "DB_PORT"     = "placeholder"
      "DB_USER"     = "placeholder"
      "DB_NAME"     = "placeholder"
      "DB_PASSWORD" = "placeholder"
    }
  )
}

output "vault_secret_shouldcost" {
  value     = vault_generic_secret.vault_secret_shouldcost
  sensitive = true
}

================
File: ba/shouldcost-service/secrets/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "mountpoint" {
  description = "Vault secret mountpoint"
  type        = string
}

variable "secret_paths" {
  description = "The full logical path at which to write the given data. To write data into the generic secret backend mounted in Vault by default. Writing to other backends with this resource is possible; consult each backend's documentation to see which endpoints support the PUT and DELETE methods."
  type        = list(string)
  default     = []
}

================
File: ba/shouldcost-service/secrets/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/ssl-certificates/.terraform-version
================
latest:^1.4

================
File: ba/ssl-certificates/dev-ue1.backend.tfvars
================
key = "dev/ssl-certificates/terraform.tfstate"

================
File: ba/ssl-certificates/dev-ue1.tfvars
================
# Put values different between dev/preprod/prod here
zone_name                 = "dev.ba.drillinginfo.com"
domain_name               = "*.dev.ba.drillinginfo.com"
subject_alternative_names = ["dev.ba.drillinginfo.com"]
region                    = "us-east-1"

================
File: ba/ssl-certificates/main.tf
================
# Create star cert for zone:

terraform {
  backend "s3" {}
}

# provider for BA vpc
provider "aws" {
  assume_role {
    role_arn = var.assume_role_arn
  }
  region = var.region
}

resource "aws_acm_certificate" "cert" {
  domain_name               = var.domain_name
  validation_method         = var.validation_method
  subject_alternative_names = var.subject_alternative_names
}

data "aws_route53_zone" "zone" {
  name         = var.zone_name
  private_zone = false
}

resource "aws_route53_record" "cert-validation" {
  for_each = {
    for dvo in aws_acm_certificate.cert.domain_validation_options : dvo.domain_name => {
      name   = dvo.resource_record_name
      record = dvo.resource_record_value
      type   = dvo.resource_record_type
    }
  }

  allow_overwrite = true
  name            = each.value.name
  records         = [each.value.record]
  ttl             = 60
  type            = each.value.type
  zone_id         = data.aws_route53_zone.zone.zone_id
}

resource "aws_acm_certificate_validation" "main" {
  certificate_arn         = aws_acm_certificate.cert.arn
  validation_record_fqdns = [for record in aws_route53_record.cert-validation : record.fqdn]
}

================
File: ba/ssl-certificates/prod-ue1.backend.tfvars
================
key = "prod/ssl-certificates/terraform.tfstate"

================
File: ba/ssl-certificates/prod-ue1.tfvars
================
# Put values different between dev/prod/prod here
zone_name                 = "ba.drillinginfo.com"
domain_name               = "*.ba.drillinginfo.com"
subject_alternative_names = ["ba.drillinginfo.com"]
region                    = "us-east-1"

================
File: ba/ssl-certificates/prod-uw2.backend.tfvars
================
key = "512870776320/prod/uw2/ssl-certificates/terraform.tfstate"

================
File: ba/ssl-certificates/prod-uw2.tfvars
================
# Put values different between dev/prod/prod here
zone_name                 = "prod.ba.drillinginfo.com"
domain_name               = "*.prod.ba.drillinginfo.com"
subject_alternative_names = ["prod.ba.drillinginfo.com"]
region                    = "us-west-2"

================
File: ba/ssl-certificates/variables.tf
================
variable "bu" {
  description = "business unit"
}
variable "env" {
  description = "environment"
}

variable "region" {
  description = "aws region"
}

variable "zone_name" {
  description = "name of route53 zone in which to create validation records"
}

variable "domain_name" {
  description = "certificate domain name, eg. *.drillinginfo.com"
}

variable "subject_alternative_names" {
  description = "list of SAN for the cert"
  type        = list(string)
}

variable "validation_method" {
  description = "validation method for cert issue"
  default     = "DNS"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/ssl-certificates/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/ssl-certificates-minerals/.terraform-version
================
latest:^1.4

================
File: ba/ssl-certificates-minerals/main.tf
================
# Create star cert for zone:

terraform {
  backend "s3" {}
}

# provider for BA vpc
provider "aws" {
  assume_role {
    role_arn = var.assume_role_arn
  }
  region = var.ec2-region
}

resource "aws_acm_certificate" "cert" {
  domain_name               = var.domain_name
  validation_method         = var.validation_method
  subject_alternative_names = var.subject_alternative_names
}

================
File: ba/ssl-certificates-minerals/prod-ue1.backend.tfvars
================
key = "prod/ssl-certificates-minerals/terraform.tfstate"

================
File: ba/ssl-certificates-minerals/prod-ue1.tfvars
================
# Put values different between dev/prod/prod here
domain_name               = "*.mineralsoft.com"
subject_alternative_names = ["mineralsoft.com"]
ec2-region                = "us-east-1"

================
File: ba/ssl-certificates-minerals/prod-uw2.backend.tfvars
================
key = "prod/us-west-2/ssl-certificates-minerals/terraform.tfstate"

================
File: ba/ssl-certificates-minerals/prod-uw2.tfvars
================
# Put values different between dev/prod/prod here
domain_name               = "*.mineralsoft.com"
subject_alternative_names = ["mineralsoft.com"]
ec2-region                = "us-west-2"

================
File: ba/ssl-certificates-minerals/variables.tf
================
variable "bu" {
  description = "business unit"
}
variable "env" {
  description = "environment"
}

variable "ec2-region" {
  description = "aws region"
}

variable "domain_name" {
  description = "certificate domain name, eg. *.drillinginfo.com"
}

variable "subject_alternative_names" {
  description = "list of SAN for the cert"
  type        = list(string)
}

variable "validation_method" {
  description = "validation method for cert issue"
  default     = "DNS"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: ba/ssl-certificates-minerals/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: ba/vault/.terraform-version
================
latest:^1.7

================
File: ba/vault/dev-ue1.backend.tfvars
================
key = "dev/east/vault/terraform.tfstate"

================
File: ba/vault/dev-ue1.tfvars
================
#keys
consul_token = "XuqDDt/iorsgaP0q2uIt1Q=="
#module componements
datacenter    = "aws-ue1"
ec2-region    = "us-east-1"
os            = "ubuntu20"
vpc_name_tag  = "ba-vpc-dev"
instance_type = "c5d.large"
ec2-name      = "aws-ue1-ba-dev-vault"
asg-name      = "ue1-dev-ba-vault-asg"
elb-name      = "ue1-dev-ba-vault-lb"
dns-name      = "vault-ue1.dev.ba.drillinginfo.com"
#Chef
chef-environment = "ba-dev-docker"
#Tagging
tagTeam                 = "sre"
tagComponent            = "vault"
env                     = "dev"
bu                      = "ba"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "ba_dev_ue1"

================
File: ba/vault/main.tf
================
data "aws_route53_zone" "selected" {
  name     = "${var.env}.ba.drillinginfo.com"
  provider = aws.custom
}

module "aws-asg-ba-vault-server" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault.git?ref=v1.6.1"

  providers = {
    aws = aws.custom
  }

  generate_certs = 1
  cert_type      = "AMAZON_ISSUED"
  cert_domain    = "*.${var.env}.ba.drillinginfo.com"
  datacenter     = var.datacenter
  consul_token   = var.consul_token
  bu             = var.bu

  organization_name     = "Drillinginfo"
  ca_common_name        = var.dns-name
  common_name           = var.dns-name
  dns_names             = ["vault.service.consul, ${var.dns-name}, localhost"]
  ip_addresses          = ["127.0.0.1"]
  validity_period_hours = "87658"
  vpc_name_tag          = var.vpc_name_tag
  inside_subnet_filter  = var.inside_subnet_filter
  vo_routing_key        = var.vo_routing_key
  # ami search filters
  ami-filters = {
    name           = var.image
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lc params and userdata
  environment             = var.env
  bucket_hook_environment = var.bucket_hook_environment
  os                      = var.os
  ec2-name                = var.ec2-name
  instance-type           = var.instance_type
  keypair-name            = var.keypair-name
  iam-profile             = "service-instance-profile"
  ebs-optimized           = "true"

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = "2"
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "2"
  suspended-processes       = ["AZRebalance"]

  # Chef
  chef-version     = "12.21.14"
  chef-environment = var.chef-environment
  chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\""

  # Tagging
  tagComponent  = var.tagComponent
  tagProduct    = "nexus"
  tagStack      = var.env
  tagAutospot   = "false"
  tagLocation   = var.ec2-region
  tagTeam       = var.tagTeam
  tagSourceCode = "https://git.drillinginfo.com/SRE/ba-terraform/tree/master/vault"

  #elb dns stuff

  elb-name                  = var.elb-name
  internal                  = true
  cross_zone_load_balancing = true
  idle_timeout              = "60"
  lb_port                   = "443"
  vault_api_port            = "8200"
  create_dns_entry          = 1
  hosted_zone_id            = data.aws_route53_zone.selected.zone_id
  domain_name               = var.dns-name
  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "SRE/ansible_grafana_agent",
      playbook_file = "install-grafana.yml",
      git_host      = "enterprise",
      additional_args = [
        "--extra-vars \"alloy_environment_name=${var.env} business_unit=ba\"",
        "-C main"
      ],
    }
  ]
}

================
File: ba/vault/prod-ue1.backend.tfvars
================
key = "prod/east/vault/terraform.tfstate"

================
File: ba/vault/prod-ue1.tfvars
================
#keys
consul_token = "H7yMJC/pXy255qYxj6nwfQ=="
#module componements
datacenter    = "aws-ue1"
ec2-region    = "us-east-1"
os            = "ubuntu20"
vpc_name_tag  = "ba-vpc-prod"
instance_type = "c5d.large"
ec2-name      = "aws-ue1-ba-prod-vault"
asg-name      = "ue1-prod-ba-vault-asg"
elb-name      = "ue1-prod-ba-vault-lb"
dns-name      = "vault-ue1.prod.ba.drillinginfo.com"
#Chef
chef-environment = "ba-prod-docker"
#Tagging
tagTeam                 = "sre"
tagComponent            = "vault"
env                     = "prod"
bu                      = "ba"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "ba_prod_ue1"

================
File: ba/vault/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/vault/terraform.tfstate"

================
File: ba/vault/prod-uw2.tfvars
================
#keys
consul_token = "H7yMJC/pXy255qYxj6nwfQ=="
#module componements
datacenter    = "aws-uw2"
ec2-region    = "us-west-2"
os            = "ubuntu20"
vpc_name_tag  = "ba-vpc-prod"
instance_type = "c5d.large"
ec2-name      = "aws-uw2-ba-prod-vault"
asg-name      = "uw2-prod-ba-vault-asg"
elb-name      = "uw2-prod-ba-vault-lb"
dns-name      = "vault-uw2.prod.ba.drillinginfo.com"
#Chef
chef-environment = "ba-prod-docker"
#Tagging
tagTeam                 = "sre"
tagComponent            = "vault"
env                     = "prod"
bu                      = "ba"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "ba_prod_uw2"

================
File: ba/vault/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "ec2-region" {
  description = "region in which to create instance"
  type        = string
}

variable "datacenter" {
  description = "the name of the dc, in our case could be 'aws-ue1'"
  type        = string
}

variable "os" {
  description = "used to configure scripts"
  type        = string
}

variable "bu" {
  description = "the business unit"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "consul_token" {
  description = "key to connect to consul"
  type        = string
}

variable "vpc_name_tag" {
  description = "Value of Name tag applied to target VPC, eg 'dev-VPC'"
  type        = string
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "ec2-name" {
  description = "used for naming the instances"
  type        = string
}

variable "asg-name" {
  description = "used for naming autoscaling group"
  type        = string
}

variable "elb-name" {
  description = "used for naming load balancer"
  type        = string
}

variable "dns-name" {
  description = "used for naming domain name"
  type        = string
}

variable "chef-environment" {
  description = "chef environment into which the node should bootstrap"
  type        = string
}

variable "tagTeam" {
  description = "used to set team tag"
  type        = string
}

variable "tagComponent" {
  description = "used to set component tag"
  type        = string
}

variable "keypair-name" {
  default     = "cm@drillinginfo.com"
  description = "keypair for ssh"
}

variable "inside_subnet_filter" {}

variable "image" {}

variable "bucket_hook_environment" {}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

================
File: ba/vault/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.8"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "custom"
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = var.tagComponent
      Team             = var.tagTeam
      SourceCode       = "https://git.drillinginfo.com/ba-terraform/vault"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: ba/vault_azuread_sso/.terraform-version
================
latest:^1.8

================
File: ba/vault_azuread_sso/dev-ue1.backend.tfvars
================
key = "dev/east/vault_azuread_sso/terraform.tfstate"

================
File: ba/vault_azuread_sso/dev-ue1.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault-ue1.dev.ba.drillinginfo.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_BA_DEV_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_DEVS_RO = {
    policies = [
      "ba-dev-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_OPENTICKET_MOBILE_SERVICE_RO = {
    policies = [
      "openticket-mobile-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_OPENTICKET_MOBILE_SERVICE_RW = {
    policies = [
      "openticket-mobile-service-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_EPAYABLES_RO = {
    policies = [
      "oepayables-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_EPAYABLES_RW = {
    policies = [
      "epayables-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_SHOULDCOST_SERVICE_RO = {
    policies = [
      "shouldcost-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_DEV_BA_SHOULDCOST_SERVICE_RW = {
    policies = [
      "shouldcost-service-write",
    ]
  },
}
vault_path_oidc_client_secret               = "di-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "di-secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault-ue1.dev.ba.drillinginfo.com"

================
File: ba/vault_azuread_sso/main.tf
================
data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

module "vault_azuread_sso" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-azuread-sso.git?ref=v0.1.0"

  oidc_client_id                 = var.oidc_client_id
  oidc_discovery_url             = var.oidc_discovery_url
  allowed_redirect_uris_prefix   = var.allowed_redirect_uris_prefix
  vault_identity_group_alias_sre = var.vault_identity_group_alias_sre
  vault_identity_group_alias_dev = var.vault_identity_group_alias_dev
  vault_path_oidc_client_secret  = var.vault_path_oidc_client_secret
}
output "vault_azuread_sso" { value = module.vault_azuread_sso }

================
File: ba/vault_azuread_sso/prod-ue1.backend.tfvars
================
key = "prod/east/vault_azuread_sso/terraform.tfstate"

================
File: ba/vault_azuread_sso/prod-ue1.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault-ue1.prod.ba.drillinginfo.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_BA_PROD_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_DEVS_RO = {
    policies = [
      "ba-prod-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_OPENTICKET_MOBILE_SERVICE_RO = {
    policies = [
      "openticket-mobile-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_OPENTICKET_MOBILE_SERVICE_RW = {
    policies = [
      "openticket-mobile-service-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_EPAYABLES_RO = {
    policies = [
      "oepayables-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_EPAYABLES_RW = {
    policies = [
      "epayables-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_SHOULDCOST_SERVICE_RO = {
    policies = [
      "shouldcost-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_SHOULDCOST_SERVICE_RW = {
    policies = [
      "shouldcost-service-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_BA_MINERALSOFT_RW = {
    policies = [
      "mineralsoft-write",
    ]
  },
}
vault_path_oidc_client_secret               = "di-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "di-secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault-ue1.prod.ba.drillinginfo.com"

================
File: ba/vault_azuread_sso/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/vault_azuread_sso/terraform.tfstate"

================
File: ba/vault_azuread_sso/prod-uw2.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault-uw2.prod.ba.drillinginfo.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_BA_PROD_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_DEVS_RO = {
    policies = [
      "ba-prod-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_OPENTICKET_MOBILE_SERVICE_RO = {
    policies = [
      "openticket-mobile-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_OPENTICKET_MOBILE_SERVICE_RW = {
    policies = [
      "openticket-mobile-service-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_EPAYABLES_RO = {
    policies = [
      "oepayables-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_EPAYABLES_RW = {
    policies = [
      "epayables-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_SHOULDCOST_SERVICE_RO = {
    policies = [
      "shouldcost-service-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_UE1_PROD_BA_SHOULDCOST_SERVICE_RW = {
    policies = [
      "shouldcost-service-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_BA_MINERALSOFT_RW = {
    policies = [
      "mineralsoft-write",
    ]
  },
}
vault_path_oidc_client_secret               = "di-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "di-secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault-uw2.prod.ba.drillinginfo.com"

================
File: ba/vault_azuread_sso/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "vault_path_azure_service_principal_atlantis" {
  description = "The vault path to AzureAD Service Principal secret"
  type        = string
}

variable "vault_path_oidc_client_secret" {
  description = "The vault path to AzureAD OIDC secret"
  type        = string
}

variable "oidc_client_id" {
  description = "The client id for credentials to query the Azure APIs. Currently read permissions to query compute resources are required."
  type        = string
}

variable "oidc_discovery_url" {
  description = "The OIDC Discovery URL, without any .well-known component (base"
  type        = string
}

variable "allowed_redirect_uris_prefix" {
  description = "The list of allowed values for redirect_uri during OIDC logins. Required for OIDC roles"
  type        = list(string)
}

variable "vault_identity_group_alias_sre" {
  description = "Azure ID of the group alias to create."
  type        = string
  default     = null
}

variable "vault_identity_group_alias_dev" {
  description = "list of Azure IDs of the group alias to create."
  type        = any
  default     = {}
}

================
File: ba/vault_azuread_sso/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: ba/vault_mounts/.terraform-version
================
latest:^1.8

================
File: ba/vault_mounts/dev-ue1.backend.tfvars
================
key = "603547102569/dev/vault_mounts/terraform.tfstate"

================
File: ba/vault_mounts/dev-ue1.tfvars
================
VAULT_ADDR        = "https://vault-ue1.dev.ba.drillinginfo.com"
list_vault_mounts = ["enverus-cts"]

================
File: ba/vault_mounts/main.tf
================
resource "vault_mount" "mounts" {
  for_each = var.list_vault_mounts

  path = each.key
  type = "kv-v2"
}

================
File: ba/vault_mounts/prod-ue1.backend.tfvars
================
key = "512870776320/prod/vault_mounts/terraform.tfstate"

================
File: ba/vault_mounts/prod-ue1.tfvars
================
VAULT_ADDR        = "https://vault-ue1.prod.ba.drillinginfo.com"
list_vault_mounts = ["enverus-cts"]

================
File: ba/vault_mounts/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/vault_mounts/terraform.tfstate"

================
File: ba/vault_mounts/prod-uw2.tfvars
================
VAULT_ADDR        = "https://vault-uw2.prod.ba.drillinginfo.com"
list_vault_mounts = ["enverus-cts"]

================
File: ba/vault_mounts/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_mounts" {
  description = "a list of vault mounts"
  type        = set(any)
}

================
File: ba/vault_mounts/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/vault_policies_and_roles/.terraform-version
================
latest:^1.8

================
File: ba/vault_policies_and_roles/dev-ue1.backend.tfvars
================
key = "dev/east/vault_policies_and_roles/terraform.tfstate"

================
File: ba/vault_policies_and_roles/dev-ue1.tfvars
================
env                = "dev"
bu                 = "ba"
secrets_mountpoint = "di-secrets"
VAULT_ADDR         = "https://vault-ue1.dev.ba.drillinginfo.com"
list_vault_policies = {
  terraform-read-policy = [
    {
      path         = "di-secrets/*"
      capabilities = ["read"]
      description  = "Allow reading di-secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "require update access to destroy a token"
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "di-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis"
    },
    {
      path         = "di-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "di-secrets/data/prometheus"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "enverus-cts/data/github-enterprise*"
      capabilities = ["read"]
      description  = "access github enterprise credentials"
    },
    {
      path         = "enverus-cts/data/github*"
      capabilities = ["read"]
      description  = "access github app credentials"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACL policies from UI"
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  ba-dev-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/application/mineralsoft/*"
      capabilities = ["read", "list"]
      description  = "access to mineralsoft"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service*"
      capabilities = ["read", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: ba/vault_policies_and_roles/main.tf
================
module "vault_policies_and_roles" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-policies-and-roles.git?ref=main"

  list_vault_policies = var.list_vault_policies
  secrets_mountpoint  = var.secrets_mountpoint
  bu                  = var.bu
  env                 = var.env

  ## workaround for manually created approle backend
  approle_path = var.approle_path
}
output "vault_policies_and_roles" { value = module.vault_policies_and_roles }

================
File: ba/vault_policies_and_roles/prod-ue1.backend.tfvars
================
key = "prod/east/vault_policies_and_roles/terraform.tfstate"

================
File: ba/vault_policies_and_roles/prod-ue1.tfvars
================
env                = "prod"
bu                 = "ba"
secrets_mountpoint = "di-secrets"
VAULT_ADDR         = "https://vault-ue1.prod.ba.drillinginfo.com"
list_vault_policies = {
  terraform-read-policy = [
    {
      path         = "di-secrets/*"
      capabilities = ["read"]
      description  = "Allow reading di-secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "require update access to destroy a token"
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "di-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis"
    },
    {
      path         = "di-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/prometheus"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-cts/data/github-enterprise*"
      capabilities = ["read"]
      description  = "access github enterprise credentials"
    },
    {
      path         = "enverus-cts/data/github*"
      capabilities = ["read"]
      description  = "access github app credentials"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACL policies from UI"
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  ba-prod-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/application/mineralsoft/*"
      capabilities = ["read", "list"]
      description  = "access to mineralsoft"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service/*"
      capabilities = ["read", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/prefect/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  mineralsoft-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/application/mineralsoft*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to mineralsoft"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: ba/vault_policies_and_roles/prod-uw2.backend.tfvars
================
key = "512870776320/prod/west/vault_policies_and_roles/terraform.tfstate"

================
File: ba/vault_policies_and_roles/prod-uw2.tfvars
================
env                = "prod"
bu                 = "ba"
secrets_mountpoint = "di-secrets"
VAULT_ADDR         = "https://vault-uw2.prod.ba.drillinginfo.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  di-secrets-admin = [
    {
      path         = "di-secrets/data/*"
      capabilities = ["create", "update", "read"]
      description  = "Full access to all secrets"
    },
    {
      path         = "di-secrets/delete/*"
      capabilities = ["update"]
      description  = "Delete secrets"
    },
    {
      path         = "di-secrets/undelete/*"
      capabilities = ["update"]
      description  = "Undelete secrets"
    },
    {
      path         = "di-secrets/destroy/*"
      capabilities = ["update"]
      description  = "Destroy secrets"
    },
    {
      path         = "di-secrets/metadata/*"
      capabilities = ["list"]
      description  = "List metadata"
    },
    {
      path         = "di-secrets/metadata/*"
      capabilities = ["read"]
      description  = "Read metadata"
    },
    {
      path         = "di-secrets/metadata/*"
      capabilities = ["delete"]
      description  = "Delete metadata"
    }
  ]
  di-secrets-read = [
    {
      path         = "di-secrets/*"
      capabilities = ["read"]
      description  = "Read secrets"
    }
  ]
  terraform-read-policy = [
    {
      path         = "di-secrets/*"
      capabilities = ["read"]
      description  = "Allow reading di-secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "require update access to destroy a token"
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "di-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis"
    },
    {
      path         = "di-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "di-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/prometheus"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "di-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-cts/data/github-enterprise*"
      capabilities = ["read"]
      description  = "access github enterprise credentials"
    },
    {
      path         = "enverus-cts/data/github*"
      capabilities = ["read"]
      description  = "access github app credentials"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACL policies from UI"
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  ba-prod-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/application/mineralsoft/*"
      capabilities = ["read", "list"]
      description  = "access to mineralsoft"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service/*"
      capabilities = ["read", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  openticket-mobile-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/openticket-mobile-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to openticket-mobile-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  epayables-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/epayables*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to epayables"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  shouldcost-service-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/application/shouldcost-service*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to shouldcost-service"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/prefect/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "di-secrets/data/elm/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  mineralsoft-write = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/application/mineralsoft*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to mineralsoft"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: ba/vault_policies_and_roles/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_policies" {
  description = "a list of vault policies"
  type = map(list(object(
    {
      path         = string
      capabilities = list(string)
      description  = string
  })))
}

variable "secrets_mountpoint" {
  description = "Mountpoint of Secret path"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Env"
  type        = string
}

variable "approle_path" {
  description = "The unique name of the auth backend to configure. Defaults to approle."
  type        = string
  default     = null
}

================
File: ba/vault_policies_and_roles/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: ba/vpc/.terraform-version
================
latest:^1.7

================
File: ba/vpc/dev.backend.tfvars
================
bucket         = "di-ba-dev-terraform"
key            = "dev/vpc/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"

================
File: ba/vpc/dev.tfvars
================
tag_name                        = "ba-vpc-dev"
west_cidr_block                 = "10.25.88.0/21"
east_cidr_block                 = "10.25.192.0/21"
enable_cgnat_subnet             = true
enable_ecs_subnet               = true
cloud_wan_core_network_id       = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment           = "nonprod"
enable_cloud_wan_vpc_attachment = true
enable_ue1_az3                  = true

================
File: ba/vpc/main.tf
================
# Providers are in versions.tf
# Regions are in their own file.

================
File: ba/vpc/prod.backend.tfvars
================
bucket         = "di-ba-prod-terraform"
key            = "prod/vpc/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"

================
File: ba/vpc/prod.tfvars
================
tag_name                        = "ba-vpc-prod"
west_cidr_block                 = "10.25.176.0/21"
east_cidr_block                 = "10.25.208.0/21"
f5_cidr_block                   = "10.24.16.0/28"
enable_cgnat_subnet             = true
enable_ecs_subnet               = true
cloud_wan_core_network_id       = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment           = "prod"
enable_cloud_wan_vpc_attachment = true
enable_ue1_az3                  = true

================
File: ba/vpc/us-east-1.tf
================
# Create a vpc using the vpc module
module "ba-vpc-east" {
  providers = {
    aws = aws.east
  }
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = "us-east-1"
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  vpc_cidr_block                       = var.east_cidr_block
  enable_ecs_subnet                    = var.enable_cgnat_subnet
  enable_cgnat_subnet                  = var.enable_ecs_subnet
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = false
  cloudwatch_logs_endpoint_type        = false
  enable_centralized_endpoints_profile = true
  enable_ue1_az3                       = var.enable_ue1_az3
}

================
File: ba/vpc/us-west-2.tf
================
#Change this to Name
data "aws_route_table" "public_route_table" {
  filter {
    name   = "tag:Name"
    values = ["* - Public Table"]
  }
}

module "ba-vpc" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = "us-west-2"
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  vpc_cidr_block                       = var.west_cidr_block
  enable_ecs_subnet                    = var.enable_cgnat_subnet
  enable_cgnat_subnet                  = var.enable_ecs_subnet
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = false
  cloudwatch_logs_endpoint_type        = false
  enable_centralized_endpoints_profile = true
}

resource "aws_vpc_ipv4_cidr_block_association" "f5_cidr" {
  count      = var.f5_cidr_block != "" ? 1 : 0
  vpc_id     = module.ba-vpc.vpc_id
  cidr_block = var.f5_cidr_block
}

resource "aws_subnet" "f5_subnet" {
  count             = var.f5_cidr_block != "" ? 1 : 0
  vpc_id            = aws_vpc_ipv4_cidr_block_association.f5_cidr[0].vpc_id
  cidr_block        = var.f5_cidr_block
  availability_zone = "us-west-2a"

  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ1 | DMZ | F5 Subnet"
    Stack     = var.env
  }
}

resource "aws_route_table_association" "f5_route_table" {
  count          = var.f5_cidr_block != "" ? 1 : 0
  route_table_id = data.aws_route_table.public_route_table.route_table_id
  subnet_id      = aws_subnet.f5_subnet[0].id
}

================
File: ba/vpc/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "west_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "east_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "f5_cidr_block" {
  description = "CIDR block for public f5 subnet"
  type        = string
  default     = ""
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Enable use of Carrier Grade subnets"
  type        = bool
}

variable "enable_ecs_subnet" {
  description = "Enable use of ecs subnets."
  type        = bool
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to."
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to."
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Enable vpc attachment to Cloud-WAN core network."
  type        = bool
}

# If you have resources in AZ3 currently, you can enable this variable to use us-east-1-az3.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

================
File: ba/vpc/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/vpc"
      TerraformCreated = "true"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  alias  = "east"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ba"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/sre.ba.terraform/tree/master/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: ba/waf/.terraform-version
================
latest:^1.4

================
File: ba/waf/dev-ue1.backend.tfvars
================
key = "dev/waf/ue-1/terraform.tfstate"

================
File: ba/waf/dev-ue1.tfvars
================
region = "us-east-1"
public_lb_names = [
  "ms-dev-new",
  "ms-staging-new",
  "ba-oi-dev-ext",
  "ba-oi-staging-ext",
  "ba-oi-rc-ext",
  "wm-staging-ext",
  "ba-miq-dev-ext",
  "ba-miq-uat-ext",
  "ba-core-tools-ext"
]

================
File: ba/waf/main.tf
================
data "aws_lb" "lb" {
  for_each = var.public_lb_names
  name     = each.value
}

resource "aws_wafv2_web_acl" "wafv2_web_acl" {
  name        = "enverus-public-waf"
  description = "Default WAF rules for Enverus. Used on all public endpoints."
  scope       = "REGIONAL"

  default_action {
    allow {}
  }

  rule {
    name     = "enverus-public-waf"
    priority = 0

    override_action {
      none {}
    }

    statement {
      managed_rule_group_statement {
        name        = "AWSManagedRulesKnownBadInputsRuleSet"
        vendor_name = "AWS"
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "known-bad-inputs"
      sampled_requests_enabled   = true
    }
  }

  rule {
    name     = "enverus-block-ru"
    priority = 1

    action {
      block {}
    }

    statement {
      geo_match_statement {
        country_codes = ["RU", "UA"]
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "block-ru"
      sampled_requests_enabled   = true
    }
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = "enverus-public-waf"
    sampled_requests_enabled   = true
  }
}

resource "aws_wafv2_web_acl_association" "wafv2_web_acl_association" {
  for_each     = var.public_lb_names
  resource_arn = data.aws_lb.lb[each.key].arn
  web_acl_arn  = aws_wafv2_web_acl.wafv2_web_acl.arn
}

================
File: ba/waf/preprod-ue1.backend.tfvars
================
key = "preprod/waf/ue-1/terraform.tfstate"

================
File: ba/waf/preprod-ue1.tfvars
================
region = "us-east-1"
public_lb_names = [
]

================
File: ba/waf/preprod-uw2.backend.tfvars
================
key = "preprod/waf/uw-2/terraform.tfstate"

================
File: ba/waf/preprod-uw2.tfvars
================
region = "us-west-2"
public_lb_names = [
]

================
File: ba/waf/prod-ue1.backend.tfvars
================
key = "prod/waf/ue-1/terraform.tfstate"

================
File: ba/waf/prod-ue1.tfvars
================
region = "us-east-1"
public_lb_names = [
  "ba-miq-prod-ext",
  "ba-oi-onboard-ext",
  "ba-oi-prod-ext",
  "ba-oi-uat-ext",
  "ba-prod-edge-lb",
  "ms-uat-new"
]

================
File: ba/waf/prod-uw2.backend.tfvars
================
key = "prod/waf/uw-2/terraform.tfstate"

================
File: ba/waf/prod-uw2.tfvars
================
region = "us-west-2"
public_lb_names = [
]

================
File: ba/waf/variables.tf
================
variable "env" {
  type        = string
  description = "The environment to deploy in"
}
variable "bu" {
  type        = string
  description = "The business unit the objects belong to"
}
variable "region" {
  type        = string
  description = "The region to deploy in"
}
variable "assume_role_arn" {
  type        = string
  description = "The terraform role arn used to access AWS"
}
variable "public_lb_names" {
  type        = set(string)
  description = "The load balancers that will added to the WAF"
}

================
File: ba/waf/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      environment   = var.env
      business_unit = var.bu
      component     = "waf"
      team          = "tech-sre@enverus.com"
      source_code   = "https://git.drillinginfo.com/SRE/terraform/tree/master/waf"
      product       = "enterprise"
    }
  }
}

================
File: ba/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_codebuild_project.mineralsoft_unittest_poc": [
      "aws_iam_role.codebuild_service_role"
    ],
    "aws_iam_role_policy_attachment.AmazonS3FullAccess": [
      "aws_iam_role.invoiceclassifier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.AWSLambdaFullAccess": [
      "aws_iam_role.invoiceclassifier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.CloudWatchFullAccess": [
      "aws_iam_role.invoiceclassifier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.AWSLambdaVPCAccessExecutionRole": [
      "aws_iam_role.invoiceclassifier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess": [
      "aws_iam_role.invoiceclassifier-lambda-role",
      "aws_iam_policy.invoiceclassifier-lambda-dbaccess"
    ],
    "aws_iam_role_policy_attachment.AmazonS3FullAccess_for_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role"
    ],
    "aws_iam_role_policy_attachment.AWSLambdaFullAccess_for_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role"
    ],
    "aws_iam_role_policy_attachment.CloudWatchFullAccess_for_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role"
    ],
    "aws_iam_role_policy_attachment.AWSLambdaVPCAccessExecutionRole_for_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role"
    ],
    "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess_for_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role",
      "aws_iam_policy.invoiceclassifier-lambda-dbaccess"
    ],
    "aws_iam_role_policy_attachment.AmazonS3FullAccess_for_fourier": [
      "aws_iam_role.invoiceclassifierfourier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.AWSLambdaFullAccess_for_fourier": [
      "aws_iam_role.invoiceclassifierfourier-lambda-role"
    ],
    "aws_iam_role_policy_attachment.CloudWatchFullAccess_for_fourier": [
      "aws_iam_role.invoiceclassifierfourier-lambda-role"
    ],
    "aws_lambda_function.lambda_function_create": [
      "aws_iam_role.invoiceclassifier-lambda-role"
    ],
    "aws_lambda_function.lambda_function_create_builder": [
      "aws_iam_role.invoiceclassifierbuilder-lambda-role"
    ],
    "aws_lambda_function.lambda_function_create_fourier": [
      "aws_iam_role.invoiceclassifierfourier-lambda-role"
    ],
    "aws_vpc_endpoint_service.oi_staging_endpoint_service": [
      "aws_lb.oi_stagingappalb_nlb"
    ],
    "aws_route53_record.oi_staging_edge_txt": [
      "aws_vpc_endpoint_service.oi_staging_endpoint_service"
    ],
    "aws_vpc_endpoint_service.otm_edge_endpoint_service": [
      "aws_lb.otm_edge_lb"
    ],
    "aws_route53_record.otm_edge_txt": [
      "aws_vpc_endpoint_service.otm_edge_endpoint_service"
    ],
    "aws_lb_listener.otm_edge_lb_listener": [
      "aws_lb_target_group.otm_edge_target_group",
      "aws_lb.otm_edge_lb"
    ],
    "aws_lb_target_group_attachment.otm_edge_tg_attachment": [
      "aws_lb_target_group.otm_edge_target_group"
    ],
    "aws_lb_listener.oi_staging_listener": [
      "aws_lb.oi_stagingappalb_nlb",
      "aws_lb_target_group.oi_staging_target_group"
    ],
    "aws_lb_target_group_attachment.oi_staging_target_group": [
      "aws_lb_target_group.oi_staging_target_group"
    ],
    "aws_iam_access_key.jenkins_backup_bucket_user": [
      "aws_iam_user.jenkins_backup_bucket_user"
    ],
    "aws_security_group_rule.inbound_http": [
      "aws_security_group.front_sg"
    ],
    "aws_security_group_rule.websockets": [
      "aws_security_group.websockets_sg"
    ],
    "aws_security_group_rule.websockets-01": [
      "aws_security_group.websockets_sg"
    ],
    "aws_lb_listener_certificate.ssl_cert": [
      "aws_lb_listener.edge_listener"
    ],
    "aws_lb_listener.edge_listener": [
      "aws_lb.edge_lb",
      "aws_lb_target_group.edge_tg"
    ],
    "aws_route53_record.front_elb": [
      "aws_lb.edge_lb"
    ],
    "aws_security_group_rule.allow_inbound_http": [
      "aws_security_group.front-elb"
    ],
    "aws_security_group_rule.allow_inbound_https": [
      "aws_security_group.front-elb"
    ],
    "aws_security_group_rule.allow_all_outbound-elb": [
      "aws_security_group.front-elb"
    ],
    "aws_route53_record.mineralsoft-non-prod": [
      "aws_lb.edge_lb"
    ],
    "aws_route53_record.mineralsoft-prod": [
      "aws_cloudfront_distribution.cdn"
    ],
    "aws_acm_certificate_validation.main": [
      "aws_acm_certificate.cert"
    ],
    "aws_lb_listener.consul_listener": [
      "aws_lb_target_group.consul_tg",
      "aws_lb.consul_lb"
    ],
    "aws_autoscaling_attachment.asg_attachment_bar": [
      "aws_lb_target_group.consul_tg"
    ],
    "aws_route53_record.consul_ui": [
      "aws_lb.consul_lb",
      "aws_route53_zone.main"
    ],
    "aws_wafv2_web_acl_association.wafv2_web_acl_association": [
      "aws_wafv2_web_acl.wafv2_web_acl"
    ],
    "aws_route_table_association.f5_route_table": [
      "aws_subnet.f5_subnet"
    ],
    "aws_route53_resolver_rule.drillinginfo": [
      "aws_route53_resolver_endpoint.outbound"
    ],
    "aws_route53_resolver_rule_association.drillinginfo": [
      "aws_route53_resolver_rule.drillinginfo"
    ],
    "aws_route53_resolver_rule_association.enverus": [
      "aws_route53_resolver_rule.enverus"
    ],
    "aws_iam_role_policy_attachment.iam_role_policy_attachment_create1": [
      "aws_iam_role.iam_role_create",
      "aws_iam_policy.iam_policy_create"
    ],
    "aws_iam_role_policy_attachment.iam_role_policy_attachment_create2": [
      "aws_iam_role.iam_role_create"
    ],
    "aws_iam_role_policy_attachment.iam_role_policy_attachment_share2": [
      "aws_iam_role.iam_role_share"
    ],
    "aws_iam_role_policy_attachment.iam_role_policy_attachment_share1": [
      "aws_iam_policy.iam_policy_share",
      "aws_iam_role.iam_role_share"
    ],
    "aws_lambda_function.lambda_function_share": [
      "aws_iam_role.iam_role_share"
    ],
    "aws_lambda_permission.lambda_permission_create": [
      "aws_lambda_function.lambda_function_create",
      "aws_cloudwatch_event_rule.cloudwatch_event_rule_create"
    ],
    "aws_lambda_permission.lambda_permission_share": [
      "aws_cloudwatch_event_rule.cloudwatch_event_rule_share",
      "aws_lambda_function.lambda_function_share"
    ],
    "aws_kms_alias.a": [
      "aws_kms_key.a"
    ],
    "aws_iam_role_policy_attachment.attach_logs_policy": [
      "aws_iam_role.codebuild_service_role",
      "aws_iam_policy.logs_policy"
    ],
    "aws_iam_user_policy.mineralsoft-policy": [
      "aws_iam_user.mineralsoft-user"
    ],
    "aws_iam_access_key.mineralsoft-data-connector": [
      "aws_iam_user.mineralsoft-user"
    ],
    "vault_generic_secret.vault_secret_iam_mineralsoft_data_connector": [
      "aws_iam_access_key.mineralsoft-data-connector"
    ],
    "aws_iam_user_policy.oi-backup-data-policy": [
      "aws_iam_user.oi-backup-data"
    ],
    "aws_iam_user_policy.trap-data-policy": [
      "aws_iam_user.iam-refinery-data-user"
    ],
    "aws_iam_access_key.refinery-data-connector": [
      "aws_iam_user.iam-refinery-data-user"
    ],
    "vault_generic_secret.vault_secret_iam_refinery_data_connector": [
      "aws_iam_access_key.refinery-data-connector"
    ],
    "aws_iam_user_policy.terraform-iam-user-policy": [
      "aws_iam_user.iam-terraform-user"
    ],
    "aws_iam_user_policy_attachment.iam_user_admin_policy_attachment": [
      "aws_iam_user.iam-terraform-user"
    ],
    "aws_iam_access_key.terraform_data_connector": [
      "aws_iam_user.iam-terraform-user"
    ],
    "vault_generic_secret.vault_secret_iam_terraform_data_connector": [
      "aws_iam_access_key.terraform_data_connector"
    ],
    "aws_iam_user_policy_attachment.genai-oi-bedrock-policy": [
      "aws_iam_user.genai-oi-bedrock",
      "aws_iam_policy.genai-oi-bedrock-policy"
    ],
    "aws_iam_access_key.genai-oi-bedrock-policy-key": [
      "aws_iam_user.genai-oi-bedrock"
    ],
    "vault_generic_secret.vault-secret-iam-genai-oi-bedrock-policy-key": [
      "aws_iam_user.genai-oi-bedrock",
      "aws_iam_access_key.genai-oi-bedrock-policy-key"
    ],
    "aws_iam_access_key.fundthrough_user1_api_key": [
      "aws_iam_user.fundthrough-user1"
    ],
    "vault_generic_secret.fundthrough_user1_api_key": [
      "aws_iam_user.fundthrough-user1",
      "aws_iam_access_key.fundthrough_user1_api_key"
    ],
    "aws_iam_access_key.fundthrough_user2_api_key": [
      "aws_iam_user.fundthrough-user2"
    ],
    "vault_generic_secret.fundthrough_user2_api_key": [
      "aws_iam_access_key.fundthrough_user2_api_key",
      "aws_iam_user.fundthrough-user2"
    ],
    "aws_iam_access_key.fundthrough_user3_api_key": [
      "aws_iam_user.fundthrough-user3"
    ],
    "vault_generic_secret.fundthrough_user3_api_key": [
      "aws_iam_access_key.fundthrough_user3_api_key",
      "aws_iam_user.fundthrough-user3"
    ],
    "aws_iam_user_policy_attachment.sw-attachment-reader-policy": [
      "aws_iam_user.sw-attachment-reader",
      "aws_iam_policy.sw-attachment-reader-policy"
    ],
    "aws_iam_access_key.sw-attachment-reader-policy-key": [
      "aws_iam_user.sw-attachment-reader"
    ],
    "vault_generic_secret.vault-secret-iam-sw-attachment-reader-policy-key": [
      "aws_iam_user.sw-attachment-reader",
      "aws_iam_access_key.sw-attachment-reader-policy-key"
    ],
    "aws_iam_user_policy_attachment.genai-bidout-policy": [
      "aws_iam_policy.genai-bidout-policy",
      "aws_iam_user.genai-bidout"
    ],
    "aws_iam_access_key.genai-bidout-policy-key": [
      "aws_iam_user.genai-bidout"
    ],
    "vault_generic_secret.vault-secret-iam-genai-bidout-policy-key": [
      "aws_iam_access_key.genai-bidout-policy-key",
      "aws_iam_user.genai-bidout"
    ],
    "aws_iam_user_policy.revenue-data-reader-policy": [
      "aws_iam_user.revenue-data-reader"
    ],
    "aws_iam_user_policy.pds-revenue-data-policy": [
      "aws_iam_user.pds-revenue-data"
    ],
    "aws_iam_user_policy.el-revenue-data-policy": [
      "aws_iam_user.el-revenue-data"
    ],
    "aws_iam_user_policy.odx-revenue-data-policy": [
      "aws_iam_user.odx-revenue-data"
    ],
    "aws_iam_role_policy_attachment.dms-access-for-endpoint-AmazonDMSRedshiftS3Role": [
      "aws_iam_role.dms-access-for-endpoint"
    ],
    "aws_iam_role_policy_attachment.dms-cloudwatch-logs-role-AmazonDMSCloudWatchLogsRole": [
      "aws_iam_role.dms-cloudwatch-logs-role"
    ],
    "aws_iam_role_policy_attachment.dms-vpc-role-AmazonDMSVPCManagementRole": [
      "aws_iam_role.dms-vpc-role"
    ],
    "aws_lb.nomad_lb": [
      "aws_security_group.nomad_lb_sg"
    ],
    "aws_lb_listener.nomad_listener": [
      "aws_lb.nomad_lb",
      "aws_lb_target_group.nomad_tg"
    ],
    "aws_route53_record.nomad_ui": [
      "aws_lb.nomad_lb",
      "aws_route53_zone.main"
    ],
    "aws_vpc_security_group_ingress_rule.allow_mongo_ipv4": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_vpn_virginia": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_vpn_chicago": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_cts_vpc_prod": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_azure_vm": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_azure_vm2": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_databrics_dev1": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_databrics_dev2": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_databrics_prod1": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_ingress_rule.allow_databrics_prod2": [
      "aws_security_group.allow_mongo"
    ],
    "aws_vpc_security_group_egress_rule.allow_all_traffic_ipv4": [
      "aws_security_group.allow_mongo"
    ],
    "aws_iam_access_key.iam_access_key": [
      "aws_iam_user.iam_user"
    ],
    "aws_iam_user_policy_attachment.iam_user_policy_attachment": [
      "aws_iam_policy.iam_policy",
      "aws_iam_user.iam_user"
    ],
    "grafana_dashboard.firehose": [
      "grafana_folder.firehose"
    ],
    "aws_iam_role_policy_attachment.main": [
      "aws_iam_policy.guardduty_malware_protection_policy",
      "aws_iam_role.guardduty_malware_protection_role"
    ],
    "aws_cloudwatch_event_target.send_to_lambda": [
      "aws_cloudwatch_event_rule.guardduty_malware_scan",
      "aws_lambda_function.guardduty_notify_teams"
    ],
    "aws_lambda_permission.allow_eventbridge": [
      "aws_cloudwatch_event_rule.guardduty_malware_scan",
      "aws_lambda_function.guardduty_notify_teams"
    ],
    "aws_iam_role_policy_attachment.lambda_logs": [
      "aws_iam_role.lambda_exec"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role",
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ]
  },
  "dependents": {
    "aws_iam_role.codebuild_service_role": [
      "aws_codebuild_project.mineralsoft_unittest_poc",
      "aws_iam_role_policy_attachment.attach_logs_policy"
    ],
    "aws_iam_role.invoiceclassifier-lambda-role": [
      "aws_iam_role_policy_attachment.AmazonS3FullAccess",
      "aws_iam_role_policy_attachment.AWSLambdaFullAccess",
      "aws_iam_role_policy_attachment.CloudWatchFullAccess",
      "aws_iam_role_policy_attachment.AWSLambdaVPCAccessExecutionRole",
      "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess",
      "aws_lambda_function.lambda_function_create"
    ],
    "aws_iam_policy.invoiceclassifier-lambda-dbaccess": [
      "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess",
      "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess_for_builder"
    ],
    "aws_iam_role.invoiceclassifierbuilder-lambda-role": [
      "aws_iam_role_policy_attachment.AmazonS3FullAccess_for_builder",
      "aws_iam_role_policy_attachment.AWSLambdaFullAccess_for_builder",
      "aws_iam_role_policy_attachment.CloudWatchFullAccess_for_builder",
      "aws_iam_role_policy_attachment.AWSLambdaVPCAccessExecutionRole_for_builder",
      "aws_iam_role_policy_attachment.invoiceclassifier-lambda-dbaccess_for_builder",
      "aws_lambda_function.lambda_function_create_builder"
    ],
    "aws_iam_role.invoiceclassifierfourier-lambda-role": [
      "aws_iam_role_policy_attachment.AmazonS3FullAccess_for_fourier",
      "aws_iam_role_policy_attachment.AWSLambdaFullAccess_for_fourier",
      "aws_iam_role_policy_attachment.CloudWatchFullAccess_for_fourier",
      "aws_lambda_function.lambda_function_create_fourier"
    ],
    "aws_lb.oi_stagingappalb_nlb": [
      "aws_vpc_endpoint_service.oi_staging_endpoint_service",
      "aws_lb_listener.oi_staging_listener"
    ],
    "aws_vpc_endpoint_service.oi_staging_endpoint_service": [
      "aws_route53_record.oi_staging_edge_txt"
    ],
    "aws_lb.otm_edge_lb": [
      "aws_vpc_endpoint_service.otm_edge_endpoint_service",
      "aws_lb_listener.otm_edge_lb_listener"
    ],
    "aws_vpc_endpoint_service.otm_edge_endpoint_service": [
      "aws_route53_record.otm_edge_txt"
    ],
    "aws_lb_target_group.otm_edge_target_group": [
      "aws_lb_listener.otm_edge_lb_listener",
      "aws_lb_target_group_attachment.otm_edge_tg_attachment"
    ],
    "aws_lb_target_group.oi_staging_target_group": [
      "aws_lb_listener.oi_staging_listener",
      "aws_lb_target_group_attachment.oi_staging_target_group"
    ],
    "aws_iam_user.jenkins_backup_bucket_user": [
      "aws_iam_access_key.jenkins_backup_bucket_user"
    ],
    "aws_security_group.front_sg": [
      "aws_security_group_rule.inbound_http"
    ],
    "aws_security_group.websockets_sg": [
      "aws_security_group_rule.websockets",
      "aws_security_group_rule.websockets-01"
    ],
    "aws_lb_listener.edge_listener": [
      "aws_lb_listener_certificate.ssl_cert"
    ],
    "aws_lb.edge_lb": [
      "aws_lb_listener.edge_listener",
      "aws_route53_record.front_elb",
      "aws_route53_record.mineralsoft-non-prod"
    ],
    "aws_lb_target_group.edge_tg": [
      "aws_lb_listener.edge_listener"
    ],
    "aws_security_group.front-elb": [
      "aws_security_group_rule.allow_inbound_http",
      "aws_security_group_rule.allow_inbound_https",
      "aws_security_group_rule.allow_all_outbound-elb"
    ],
    "aws_cloudfront_distribution.cdn": [
      "aws_route53_record.mineralsoft-prod"
    ],
    "aws_acm_certificate.cert": [
      "aws_acm_certificate_validation.main"
    ],
    "aws_lb_target_group.consul_tg": [
      "aws_lb_listener.consul_listener",
      "aws_autoscaling_attachment.asg_attachment_bar"
    ],
    "aws_lb.consul_lb": [
      "aws_lb_listener.consul_listener",
      "aws_route53_record.consul_ui"
    ],
    "aws_route53_zone.main": [
      "aws_route53_record.consul_ui",
      "aws_route53_record.nomad_ui"
    ],
    "aws_wafv2_web_acl.wafv2_web_acl": [
      "aws_wafv2_web_acl_association.wafv2_web_acl_association"
    ],
    "aws_subnet.f5_subnet": [
      "aws_route_table_association.f5_route_table"
    ],
    "aws_route53_resolver_endpoint.outbound": [
      "aws_route53_resolver_rule.drillinginfo"
    ],
    "aws_route53_resolver_rule.drillinginfo": [
      "aws_route53_resolver_rule_association.drillinginfo"
    ],
    "aws_route53_resolver_rule.enverus": [
      "aws_route53_resolver_rule_association.enverus"
    ],
    "aws_iam_role.iam_role_create": [
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_create1",
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_create2"
    ],
    "aws_iam_policy.iam_policy_create": [
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_create1"
    ],
    "aws_iam_role.iam_role_share": [
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_share2",
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_share1",
      "aws_lambda_function.lambda_function_share"
    ],
    "aws_iam_policy.iam_policy_share": [
      "aws_iam_role_policy_attachment.iam_role_policy_attachment_share1"
    ],
    "aws_lambda_function.lambda_function_create": [
      "aws_lambda_permission.lambda_permission_create"
    ],
    "aws_cloudwatch_event_rule.cloudwatch_event_rule_create": [
      "aws_lambda_permission.lambda_permission_create"
    ],
    "aws_cloudwatch_event_rule.cloudwatch_event_rule_share": [
      "aws_lambda_permission.lambda_permission_share"
    ],
    "aws_lambda_function.lambda_function_share": [
      "aws_lambda_permission.lambda_permission_share"
    ],
    "aws_kms_key.a": [
      "aws_kms_alias.a"
    ],
    "aws_iam_policy.logs_policy": [
      "aws_iam_role_policy_attachment.attach_logs_policy"
    ],
    "aws_iam_user.mineralsoft-user": [
      "aws_iam_user_policy.mineralsoft-policy",
      "aws_iam_access_key.mineralsoft-data-connector"
    ],
    "aws_iam_access_key.mineralsoft-data-connector": [
      "vault_generic_secret.vault_secret_iam_mineralsoft_data_connector"
    ],
    "aws_iam_user.oi-backup-data": [
      "aws_iam_user_policy.oi-backup-data-policy"
    ],
    "aws_iam_user.iam-refinery-data-user": [
      "aws_iam_user_policy.trap-data-policy",
      "aws_iam_access_key.refinery-data-connector"
    ],
    "aws_iam_access_key.refinery-data-connector": [
      "vault_generic_secret.vault_secret_iam_refinery_data_connector"
    ],
    "aws_iam_user.iam-terraform-user": [
      "aws_iam_user_policy.terraform-iam-user-policy",
      "aws_iam_user_policy_attachment.iam_user_admin_policy_attachment",
      "aws_iam_access_key.terraform_data_connector"
    ],
    "aws_iam_access_key.terraform_data_connector": [
      "vault_generic_secret.vault_secret_iam_terraform_data_connector"
    ],
    "aws_iam_user.genai-oi-bedrock": [
      "aws_iam_user_policy_attachment.genai-oi-bedrock-policy",
      "aws_iam_access_key.genai-oi-bedrock-policy-key",
      "vault_generic_secret.vault-secret-iam-genai-oi-bedrock-policy-key"
    ],
    "aws_iam_policy.genai-oi-bedrock-policy": [
      "aws_iam_user_policy_attachment.genai-oi-bedrock-policy"
    ],
    "aws_iam_access_key.genai-oi-bedrock-policy-key": [
      "vault_generic_secret.vault-secret-iam-genai-oi-bedrock-policy-key"
    ],
    "aws_iam_user.fundthrough-user1": [
      "aws_iam_access_key.fundthrough_user1_api_key",
      "vault_generic_secret.fundthrough_user1_api_key"
    ],
    "aws_iam_access_key.fundthrough_user1_api_key": [
      "vault_generic_secret.fundthrough_user1_api_key"
    ],
    "aws_iam_user.fundthrough-user2": [
      "aws_iam_access_key.fundthrough_user2_api_key",
      "vault_generic_secret.fundthrough_user2_api_key"
    ],
    "aws_iam_access_key.fundthrough_user2_api_key": [
      "vault_generic_secret.fundthrough_user2_api_key"
    ],
    "aws_iam_user.fundthrough-user3": [
      "aws_iam_access_key.fundthrough_user3_api_key",
      "vault_generic_secret.fundthrough_user3_api_key"
    ],
    "aws_iam_access_key.fundthrough_user3_api_key": [
      "vault_generic_secret.fundthrough_user3_api_key"
    ],
    "aws_iam_user.sw-attachment-reader": [
      "aws_iam_user_policy_attachment.sw-attachment-reader-policy",
      "aws_iam_access_key.sw-attachment-reader-policy-key",
      "vault_generic_secret.vault-secret-iam-sw-attachment-reader-policy-key"
    ],
    "aws_iam_policy.sw-attachment-reader-policy": [
      "aws_iam_user_policy_attachment.sw-attachment-reader-policy"
    ],
    "aws_iam_access_key.sw-attachment-reader-policy-key": [
      "vault_generic_secret.vault-secret-iam-sw-attachment-reader-policy-key"
    ],
    "aws_iam_policy.genai-bidout-policy": [
      "aws_iam_user_policy_attachment.genai-bidout-policy"
    ],
    "aws_iam_user.genai-bidout": [
      "aws_iam_user_policy_attachment.genai-bidout-policy",
      "aws_iam_access_key.genai-bidout-policy-key",
      "vault_generic_secret.vault-secret-iam-genai-bidout-policy-key"
    ],
    "aws_iam_access_key.genai-bidout-policy-key": [
      "vault_generic_secret.vault-secret-iam-genai-bidout-policy-key"
    ],
    "aws_iam_user.revenue-data-reader": [
      "aws_iam_user_policy.revenue-data-reader-policy"
    ],
    "aws_iam_user.pds-revenue-data": [
      "aws_iam_user_policy.pds-revenue-data-policy"
    ],
    "aws_iam_user.el-revenue-data": [
      "aws_iam_user_policy.el-revenue-data-policy"
    ],
    "aws_iam_user.odx-revenue-data": [
      "aws_iam_user_policy.odx-revenue-data-policy"
    ],
    "aws_iam_role.dms-access-for-endpoint": [
      "aws_iam_role_policy_attachment.dms-access-for-endpoint-AmazonDMSRedshiftS3Role"
    ],
    "aws_iam_role.dms-cloudwatch-logs-role": [
      "aws_iam_role_policy_attachment.dms-cloudwatch-logs-role-AmazonDMSCloudWatchLogsRole"
    ],
    "aws_iam_role.dms-vpc-role": [
      "aws_iam_role_policy_attachment.dms-vpc-role-AmazonDMSVPCManagementRole"
    ],
    "aws_security_group.nomad_lb_sg": [
      "aws_lb.nomad_lb"
    ],
    "aws_lb.nomad_lb": [
      "aws_lb_listener.nomad_listener",
      "aws_route53_record.nomad_ui"
    ],
    "aws_lb_target_group.nomad_tg": [
      "aws_lb_listener.nomad_listener"
    ],
    "aws_security_group.allow_mongo": [
      "aws_vpc_security_group_ingress_rule.allow_mongo_ipv4",
      "aws_vpc_security_group_ingress_rule.allow_vpn_virginia",
      "aws_vpc_security_group_ingress_rule.allow_vpn_chicago",
      "aws_vpc_security_group_ingress_rule.allow_cts_vpc_prod",
      "aws_vpc_security_group_ingress_rule.allow_azure_vm",
      "aws_vpc_security_group_ingress_rule.allow_azure_vm2",
      "aws_vpc_security_group_ingress_rule.allow_databrics_dev1",
      "aws_vpc_security_group_ingress_rule.allow_databrics_dev2",
      "aws_vpc_security_group_ingress_rule.allow_databrics_prod1",
      "aws_vpc_security_group_ingress_rule.allow_databrics_prod2",
      "aws_vpc_security_group_egress_rule.allow_all_traffic_ipv4"
    ],
    "aws_iam_user.iam_user": [
      "aws_iam_access_key.iam_access_key",
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.iam_policy": [
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "grafana_folder.firehose": [
      "grafana_dashboard.firehose"
    ],
    "aws_iam_policy.guardduty_malware_protection_policy": [
      "aws_iam_role_policy_attachment.main"
    ],
    "aws_iam_role.guardduty_malware_protection_role": [
      "aws_iam_role_policy_attachment.main"
    ],
    "aws_cloudwatch_event_rule.guardduty_malware_scan": [
      "aws_cloudwatch_event_target.send_to_lambda",
      "aws_lambda_permission.allow_eventbridge"
    ],
    "aws_lambda_function.guardduty_notify_teams": [
      "aws_cloudwatch_event_target.send_to_lambda",
      "aws_lambda_permission.allow_eventbridge"
    ],
    "aws_iam_role.lambda_exec": [
      "aws_iam_role_policy_attachment.lambda_logs"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ]
  },
  "cross_repo_references": [
    "external.oidc_discovery_url",
    "external.aws_iam_policy_document.guardduty_malware_protection",
    "external.instance_type_batch",
    "external.replication_destination_preprod_account_id",
    "external.enable_ecs_subnet",
    "external.kms_exclusion_list",
    "external.f5_cidr_block",
    "external.env",
    "external.aws_vpc.main",
    "external.aws_route53_zone.drillinginfo",
    "external.region",
    "external.aws_route_table.public_route_table",
    "external.port",
    "external.nomad_type",
    "external.archive_file.archive_file_share_snapshot",
    "external.enable_replication",
    "external.alias",
    "external.source_type",
    "external.whitelists",
    "external.aws_route53_zone.openinvoice",
    "external.grafana_folder.sre_lb_alert_folder",
    "external.zone_awareness_enabled",
    "external.vpc_options_subnet_ids",
    "external.ami",
    "external.aws_kms_alias.s3",
    "external.aws_caller_identity.caller_identity",
    "external.drillinginfo_target_ip",
    "external.resource_env",
    "external.vault_path_grafana_keys",
    "external.backup_retention_period",
    "external.transzap_dns_ip",
    "external.consul_token",
    "external.automated_snapshot_start_hour",
    "external.source_location",
    "external.mineralsoft_el_policy_resources",
    "external.availability",
    "external.bucket_policy_file",
    "external.bu",
    "external.secrets_mountpoint",
    "external.aws_iam_policy.AWSLambdaVPCAccessExecutionRole",
    "external.clusters",
    "external.aws",
    "external.vault_secrets",
    "external.aws_route53_zone.zone",
    "external.east_cidr_block",
    "external.abv",
    "external.service_names_edge_lb",
    "external.s3",
    "external.enable",
    "external.tagLocation",
    "external.aws_subnets.inside",
    "external.zone_name",
    "external.tagTeam",
    "external.keypair",
    "external.db_parameter_group_family",
    "external.cloud_wan_core_network_id",
    "external.build_timeout_minutes",
    "external.receiving_account",
    "external.dns",
    "external.create_iam_service_linked_role",
    "external.datacenter",
    "external.master_instance_type",
    "external.app_server_domain_name",
    "external.tagStack",
    "external.dmz_sg_name_tag",
    "external.tag_cloud_wan_segment",
    "external.approle_path",
    "external.aws_iam_role.codebuild_service_role",
    "external.bucket_names",
    "external.bucket_hook_environment",
    "external.aws_iam_policy.AWSLambdaFullAccess",
    "external.enable_versioning",
    "external.s3_resources",
    "external.instance_count",
    "external.assume_role_arn",
    "external.aws_lb.edge_lb",
    "external.tagComponent",
    "external.business",
    "external.vault_generic_secret.Azure_Service_Principal_Atlantis",
    "external.parameter_group_name",
    "external.validation_method",
    "external.oi_staging_alb",
    "external.enverus_domain_rules",
    "external.vault_generic_secret.master_db_creds",
    "external.instance_class",
    "external.vault_path_aws_keys",
    "external.encryption_key",
    "external.vo_routing_key",
    "external.aws_ec2_managed_prefix_list.vpn_prefix_list",
    "external.admin_role_arn",
    "external.aws_subnets.dmz",
    "external.aws_subnets.private",
    "external.source_buildspec",
    "external.aws_region.current",
    "external.consul_keys.aws_ue1_vo_routing_key",
    "external.engine_version",
    "external.west_cidr_block",
    "external.environment_compute_type",
    "external.configBackend",
    "external.ebs",
    "external.environment",
    "external.os",
    "external.wm_el_policy_resources",
    "external.aws_availability_zones.good_zone_ids",
    "external.aws_vpc.selected",
    "external.el_policy_resources",
    "external.secret_paths",
    "external.aws_security_group.ba_dmz",
    "external.list_vault_policies",
    "external.tagTerraformCreated",
    "external.cluster_instance_type",
    "external.consul_address",
    "external.cluster_id",
    "external.desired",
    "external.enable_ue1_az3",
    "external.aws_tag_component",
    "external.instance",
    "external.chef_environment",
    "external.oi_staging_zone",
    "external.aws_vpc.vpc",
    "external.ec2",
    "external.aws_security_group.inside_sg",
    "external.image",
    "external.drillinginfo_domain_rules",
    "external.consul_sg_name_tag",
    "external.internal",
    "external.domain_name",
    "external.resource_type_exclusion_list",
    "external.vault_generic_secret.grafana",
    "external.lb_tags",
    "external.subject_alternative_names",
    "external.aws_iam_policy_document.chef_bucket_policy",
    "external.enable_cloud_wan_vpc_attachment",
    "external.asg_environment",
    "external.backup_policy_resources",
    "external.ebs_volume_size",
    "external.vault_address",
    "external.vault_path_oidc_client_secret",
    "external.replication_destination_preprod_bucket_name",
    "external.consul_servers_aws",
    "external.instance_refresh",
    "external.aws_subnets.private_subnets",
    "external.vault_generic_secret.teams_webhook",
    "external.enable_cgnat_subnet",
    "external.aws_acm_certificate.star",
    "external.cluster_instance_count",
    "external.chef",
    "external.aws_iam_policy.CloudWatchFullAccess",
    "external.comment",
    "external.allocated_storage",
    "external.vault_generic_secret.di_secrets_terraform",
    "external.codebuild_service_role",
    "external.aws_region",
    "external.master_instance_count",
    "external.vpc_name_tag",
    "external.aws_lb.oi_staging_alb",
    "external.vault_identity_group_alias_sre",
    "external.project",
    "external.inside_sg_name",
    "external.bucket_name",
    "external.aws_route53_zone.selected",
    "external.aws_region.region",
    "external.oidc_client_id",
    "external.list_vault_mounts",
    "external.environment_image",
    "external.replication_role_arn",
    "external.vpc_name",
    "external.inside_subnet_filter",
    "external.lb_idle_timeout",
    "external.aws_tag_team",
    "external.multi_az",
    "external.vault_generic_secret.di_secrets_readonly_user",
    "external.aws_security_group.inside",
    "external.archive_file.lambda_zip",
    "external.aws_caller_identity.current",
    "external.aws_route53_zone.main",
    "external.environment_image_creds",
    "external.aws_subnets.selected",
    "external.secretmanager_resources",
    "external.aws_iam_policy_document.dms_assume_role",
    "external.instance_type",
    "external.mountpoint",
    "external.additional_acm_cert_arns",
    "external.ea_policy_resources",
    "external.db",
    "external.aws_iam_policy.AmazonS3FullAccess",
    "external.template_file.restart_nginx",
    "external.otm_edge_lb",
    "external.aws_security_group.consul_sg",
    "external.VAULT_ADDR",
    "external.elb",
    "external.aws_vpc.vpc_id",
    "external.environment_image_type",
    "external.node_type",
    "external.allowed_redirect_uris_prefix",
    "external.elasticsearch_domain_name",
    "external.snapshot_identifier",
    "external.num_cache_nodes",
    "external.replication_destination_disaster_recovery_bucket_name",
    "external.aws_lb.otm_edge",
    "external.vault_identity_group_alias_dev",
    "external.asg",
    "external.tagBusinessUnit",
    "external.vault_path_webhook_url",
    "external.archive_file.archive_file_create_snapshot",
    "external.http.nc_json",
    "external.vault_path_azure_service_principal_atlantis",
    "external.aws_iam_policy_document.kms",
    "external.aws_subnets.oi_alb_public",
    "external.public_lb_names",
    "external.engine",
    "external.ea_assume_role_arn",
    "external.elasticsearch_version",
    "external.multi",
    "external.aws_config_sns",
    "external.business_unit",
    "external.owner_principal",
    "external.aws_default_tags.current",
    "external.dynamodb_resources",
    "external.aws_security_groups.selected",
    "external.shared_principals",
    "external.ebs_enabled",
    "external.reader_policy_resources",
    "external.min",
    "external.vpc",
    "external.source_version",
    "external.vault_generic_secret.grafana_api",
    "external.product",
    "external.tag_name",
    "external.iam",
    "external.rds_name",
    "external.team_member_email",
    "external.user_provided_ansible_pull_playbook_list"
  ],
  "outputs": [
    "good_zone_ids",
    "aws_s3_bucket",
    "good_zone_ids",
    "private_subnets",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "vault_azuread_sso",
    "aws_s3_bucket",
    "good_zone_ids",
    "private_subnets",
    "consul_servers_aws",
    "consul_servers_aws_subnet_private_subnets",
    "aws_route53_record_consul_ui",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "good_zone_ids",
    "aws_elasticache_cluster_minerals",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "aws_s3_bucket",
    "vault_policies_and_roles",
    "private_subnets",
    "aws_sg_route53_resolver",
    "aws_route53_resolver_endpoint",
    "aws_route53_resolver_rule",
    "aws_route53_resolver_rule_association",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "good_zone_ids",
    "private_subnets",
    "private_subnets",
    "aws_elasticsearch_domain_es",
    "good_zone_ids",
    "db_instance_address",
    "db_instance_endpoint",
    "db_instance_name",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "vault_secrets",
    "good_zone_ids",
    "private_subnets",
    "aws_ec2_managed_prefix_list_vpn_prefix_list",
    "r53_zone",
    "edge-lb",
    "dns-edge-lb",
    "cluster",
    "project",
    "vault_secrets",
    "cs_temp",
    "svc_rk",
    "nc_json_uids_filtered",
    "nc_json_names_filtered",
    "name_uid",
    "good_zone_ids",
    "private_subnets",
    "vault_secrets",
    "vault_secret_shouldcost"
  ],
  "metadata": {
    "total_resources": 178,
    "resources_with_dependencies": 111,
    "resources_that_are_dependencies": 83,
    "cross_repo_refs_count": 233,
    "outputs_count": 52,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: ba/.gitignore
================
.terraform
terraform.tfsta*
jjb-macros-latest.yaml
jjb-templates-latest.yaml
.terraform.lock.hcl
.idea/
.DS_Store

================
File: ba/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.88.4
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"

================
File: ba/.tflint.hcl
================
plugin "aws" {
    enabled = true
    version = "0.17.1"
    source  = "github.com/terraform-linters/tflint-ruleset-aws"
}

rule "terraform_comment_syntax" {
  enabled = true
}

rule "terraform_deprecated_index" {
  enabled = true
}

rule "terraform_deprecated_interpolation" {
  enabled = true
}

rule "terraform_documented_outputs" {
  enabled = true
}

rule "terraform_documented_variables" {
  enabled = true
}

rule "terraform_module_pinned_source" {
  enabled = false
}

rule "terraform_module_version" {
  enabled = true
}

rule "terraform_naming_convention" {
  enabled = false
}

rule "terraform_required_providers" {
  enabled = true
}

rule "terraform_required_version" {
  enabled = false
}

rule "terraform_standard_module_structure" {
  enabled = false
}

rule "terraform_typed_variables" {
  enabled = true
}

rule "terraform_unused_declarations" {
  enabled = false
}

rule "terraform_unused_required_providers" {
  enabled = true
}

rule "terraform_workspace_remote" {
  enabled = false
}

================
File: ba/atlantis.yaml
================
version: 3
automerge: false
projects:
  ############ iam user for cloud-init #################
  - name: iam-dev-users
    dir: iam/users
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-prod-users
    dir: iam/users
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############ iam users for revenue data #################
  - name: iam-dev-revenue-data
    dir: iam/revenue-data
    workflow: dev-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-prod-revenue-data
    dir: iam/revenue-data
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############ iam users for mineralsoft #################
  - name: iam-mineralsoft-user-dev
    dir: iam/mineralsoft
    workflow: ba-vault-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-mineralsoft-user-prod
    dir: iam/mineralsoft
    workflow: ba-vault-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############ iam users for codebuild #################
  - name: iam-codebuild-role-dev
    dir: iam/codebuild
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############ codebuild poc mineralsoft #################
  - name: ms-codebuild-poc-dev
    dir: codebuild
    workflow: dev-vault
    autoplan:
      when_modified: [ "*.tf*" ]
  ############ iam users for oi backup data #################
  - name: iam-prod-oi-backup-data
    dir: iam/backup-data
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
    ############ ba vpc #################
  - name: vpc-dev
    dir: vpc
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod
    dir: vpc
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
    ############ ba waf #################
  - name: waf-prod-uw2
    dir: waf
    workflow: ba-prod-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: waf-dev-ue1
    dir: waf
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: waf-prod-ue1
    dir: waf
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
    #VPC peering OG
  # - name: s3-dev
  #   dir: s3-buckets
  #   workflow: dev
  ############### Consul East ###############
  - name: consul-dev-east
    dir: consul-aws
    workflow: ba-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: consul-prod-east
    dir: consul-aws
    workflow: ba-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: consul-prod-west
    dir: consul-aws
    workflow: ba-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
    ############### Nomad East ###############
  - name: nomad-server-dev-east
    dir: nomad-cluster-aws/server
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: nomad-clients-dev-east
    dir: nomad-cluster-aws/client
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: nomad-server-prod-east
    dir: nomad-cluster-aws/server
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: nomad-clients-prod-east
    dir: nomad-cluster-aws/client
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
    ############### Nomad West ###############
  - name: nomad-server-prod-west
    dir: nomad-cluster-aws/server
    workflow: ba-vault-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  - name: nomad-clients-prod-west
    dir: nomad-cluster-aws/client
    workflow: ba-vault-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
    ############### Nomad scheduler ###############
  - name: nomad-scheduler-aws-dev
    dir: nomad-cluster-aws-scheduler
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: nomad-scheduler-aws-prod
    dir: nomad-cluster-aws-scheduler
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
    ###############
  - name: route-53-dev
    dir: route-53
    workflow: dev-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: route-53-prod
    dir: route-53
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
    ############### vault east-1 ###############
  - name: vault-dev-east
    dir: vault
    workflow: ba-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-prod-east
    dir: vault
    workflow: ba-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### vault west-2 ###############
  - name: vault-prod-west
    dir: vault
    workflow: ba-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############### vault roles east-1 ###############
  - name: vault-policies-and-roles-dev-ue1
    dir: vault_policies_and_roles
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-policies-and-roles-prod-ue1
    dir: vault_policies_and_roles
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### vault roles west-2 ###############
  - name: vault-policies-and-roles-prod-uw2
    dir: vault_policies_and_roles
    workflow: ba-vault-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############### vault sso east-1 ###############
  - name: vault-azuread-sso-dev-ue1
    dir: vault_azuread_sso
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-azuread-sso-prod-ue1
    dir: vault_azuread_sso
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### vault sso west-2 ###############
  - name: vault-azuread-sso-prod-uw2
    dir: vault_azuread_sso
    workflow: ba-vault-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############ vault mounts ################
  - name: vault-mounts-dev
    dir: vault_mounts
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-mounts-prod
    dir: vault_mounts
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-mounts-prod-uw2
    dir: vault_mounts
    workflow: ba-vault-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############## edge proxy ###############
  - name: s3-dev-2
    dir: s3
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: s3-prod
    dir: s3
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
    ############### Elasticsearh Service role ###############
  - name: es-service-role-dev
    dir: elasticsearch-service-role
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: es-service-role-prod
    dir: elasticsearch-service-role
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############### Elasticsearch jaeger ###############
  - name: elasticsearch-cluster-jaeger-dev
    dir: elasticsearch-cluster/jaeger
    workflow: ba-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: elasticsearch-cluster-jaeger-prod
    dir: elasticsearch-cluster/jaeger
    workflow: ba-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### Elasticashe redis ue1 ###############
  - name: elasticache-dev-ue1
    dir: elasticache-mineralsoft
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: elasticache-prod-ue1
    dir: elasticache-mineralsoft
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### SSL certificates us-east-1 ###############
  - name: ssl-certificates-dev
    dir: ssl-certificates
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### SSL certificates us-west-2 ###############
  - name: ssl-certificates-prod-uw2
    dir: ssl-certificates
    workflow: ba-prod-uw2
    terraform_version: v1.8.0
    autoplan:
      when_modified: ["*.tf*"]
  # SSL certificates - mineralsoft.com - currently only prod as non-default * cert
  - name: ssl-certificates-minerals-prod
    dir: ssl-certificates-minerals
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]

  - name: ssl-certificates-minerals-prod-uw2
    dir: ssl-certificates-minerals
    workflow: ba-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############### SSL certs - us-west-2 ###############
  - name: us-west-2-ssl-certificates-minerals-prod
    dir: ssl-certificates-minerals
    workflow: ba-prod-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### lambda rds snapshot ue1 - prod ###############
  - name: us-east-1-rds-lambda-snapshot
    dir: rds/rds-lambda-snapshot
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### edge proxy ue1 - dev ###############
  - name: us-east-1-edge-proxy-dev
    dir: edge-proxy
    workflow: ba-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### edge proxy ue1 - prod ###############
  - name: us-east-1-edge-proxy-prod
    dir: edge-proxy
    workflow: ba-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### edge proxy uw2 - prod ###############
  - name: us-west-2-edge-proxy-prod
    dir: edge-proxy
    workflow: ba-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  ############### route 53 regional service records ###############
  - name: route53-regional-services-dev-ue1
    dir: route-53/regional-services
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: route53-regional-services-prod-ue1
    dir: route-53/regional-services
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: route53-regional-services-prod-uw2
    dir: route-53/regional-services
    workflow: ba-prod-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ##### dms - iam roles & policies #####
  - name: iam-dms-dev
    dir: iam/dms
    workflow: dev-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-dms-prod
    dir: iam/dms
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### cdn minieralsoft ue1 ###############
  - name: cdn-mineralsoft-dev
    dir: cdn-mineralsoft
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: cdn-mineralsoft-prod
    dir: cdn-mineralsoft
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### kms - rds mineralsoft ###############
  - name: us-east-1-kms-rds-mineralsoft-dev
    dir: rds/kms/rds-mineralsoft
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: us-east-1-kms-rds-mineralsoft-prod
    dir: rds/kms/rds-mineralsoft
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### rds redash ###############
  - name: us-east-1-rds-redash-dev
    dir: rds/rds-redash
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: us-east-1-rds-redash-prod
    dir: rds/rds-redash
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### Route-53 Resolvers ###############
  # - name: route-53-resolver-dev-uw2
  #   dir: route-53-resolver
  #   workflow: ba-dev-uw2
  #   terraform_version: v1.3.5
  #   autoplan:
  #     when_modified: ["*.tf*"]
  - name: route-53-resolver-prod-uw2
    dir: route-53-resolver
    workflow: ba-prod-uw2
    autoplan:
      when_modified: ["*.tf*"]
  - name: route-53-resolver-dev-ue1
    dir: route-53-resolver
    workflow: ba-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: route-53-resolver-prod-ue1
    dir: route-53-resolver
    workflow: ba-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############### minerals DR ###############
  - name: s3-minerals-dr
    dir: s3-minerals-dr
    workflow: ba-prod-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### log archive buckets ###############
  - name: s3-enverus-ba-log-archive-dev
    dir: s3-enverus-ba-log-archive
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: s3-enverus-ba-log-archive-prod
    dir: s3-enverus-ba-log-archive
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############### minerals buckets ###############
  - name: s3-minerals-prod
    dir: s3-minerals
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*", "bucket_policies/*.json"]
  ############### iam roles for s3 batch ops and replication for migration ###############
  - name: iam-s3-batch-operations-minerals-migration-prod
    dir: iam/s3-batch-operations/minerals-migration
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-s3-cross-account-access-minerals-migration-prod
    dir: iam/s3-cross-account-access/minerals-migration
    workflow: prod-vault
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############## Grafana datasources ###################
  - name: grafana-datasources-ba-dev-ue1
    dir: grafana/datasources
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: grafana-datasources-ba-dev-uw2
    dir: grafana/datasources
    workflow: ba-dev-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: grafana-datasources-ba-prod-ue1
    dir: grafana/datasources
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: grafana-datasources-ba-prod-uw2
    dir: grafana/datasources
    workflow: ba-prod-uw2
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############## OpenTicket Mobile S3 ue1 ###################
  - name: s3-openticket-mobile-dev-ue1
    dir: s3-openticket-mobile
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: s3-openticket-mobile-prod-ue1
    dir: s3-openticket-mobile
    workflow: ba-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############# OpenTicket Mobile secrets ue1 ################
  - name: service-openticket-mobile-secrets-prod-ue1
    dir: openticket-mobile-service/secrets
    workflow: ba-vault-prod-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############# ePayables secrets ue1 ################
  - name: epayables-secrets-dev-ue1
    dir: epayables/secrets
    workflow: ba-vault-dev-ue1
    autoplan:
      when_modified: ["*.tf*"]
  - name: epayables-secrets-prod-ue1
    dir: epayables/secrets
    workflow: ba-vault-prod-ue1
    autoplan:
      when_modified: ["*.tf*"]
  ############# invoiceclassifier-lambda ue1 ################
  - name: us-east-1-invoiceclassifier-lambda
    dir: invoiceclassifier-lambda
    workflow: ba-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############# shouldcost-service secrets ue1 ################
  - name: us-east-1-shouldcost-service-secrets
    dir: shouldcost-service/secrets
    workflow: ba-vault-dev-ue1
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  ############# aws config ################
  - name: aws-config-dev
    dir: config
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  - name: aws-config-prod
    dir: config
    workflow: prod
    autoplan:
      when_modified: ["*.tf*"]
  ############# Mobile Dev ################
  - name: mobile-dmz-dev
    dir: mobile-dmz
    workflow: dev
    terraform_version: v1.3.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: mobile-dmz-dev-ue1
    dir: mobile-dmz-ue1
    workflow: dev
    terraform_version: v1.3.5
  ############# MongoDB ################
  - name: mongodb-atlas-bidout-project-dev
    dir: mongodb/bidout-project
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: mongodb-atlas-bidout-project-prod
    dir: mongodb/bidout-project
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ### guardduty_malware_protection openinvoice buckets ###
  - name: aws_guardduty_malware_protection_plans-prod
    dir: aws_guardduty_malware_protection_plans/openinvoice
    workflow: cts-prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ### guardduty_malware_protection marketplace buckets ###
  - name: aws_guardduty_malware_protection_plans-marketplace-dev
    dir: aws_guardduty_malware_protection_plans/marketplace
    workflow: cts-dev-prod-vault
    autoplan:
      when_modified: ["*.tf*"]

================
File: ba/global-dev-backend.tfvars
================
shared_credentials_file = "/secrets/vault_atlantis_ba_dev.env"
bucket                  = "di-ba-dev-terraform"
region                  = "us-east-1"
dynamodb_table          = "terraform-state-locking"
assume_role             = { role_arn = "arn:aws:iam::603547102569:role/terraform" }

================
File: ba/global-dev.tfvars
================
bu                  = "ba"
env                 = "dev"
VAULT_ADDR          = "https://vault.dev.drillinginfo.com"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_dev"
assume_role_arn     = "arn:aws:iam::603547102569:role/terraform"
vo_routing_key      = "key-DevUptime"

================
File: ba/global-prod-backend.tfvars
================
shared_credentials_file = "/secrets/vault_atlantis_ba_prod.env"
bucket                  = "di-ba-prod-terraform"
region                  = "us-east-1"
dynamodb_table          = "terraform-state-locking"
assume_role             = { role_arn = "arn:aws:iam::512870776320:role/terraform" }

================
File: ba/global-prod.tfvars
================
bu                  = "ba"
env                 = "prod"
VAULT_ADDR          = "https://vault.drillinginfo.com"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_ba_prod"
assume_role_arn     = "arn:aws:iam::512870776320:role/terraform"
vo_routing_key      = "key-ProdUptime"

================
File: ba/README.md
================
Controlled by atlantis: runatlantis.io/docs

================
File: cts/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: cts/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: cts/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: cts/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: cts/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: cts/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: cts/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: cts/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: cts/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: cts/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: cts/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: cts/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: cts/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: cts/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: cts/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 b35ee2ce55384bd5f1b122d3c2789ac4b68bba26 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406137 -0600	clone: from github.com:enverus-cts/cts.terraform.git

================
File: cts/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 b35ee2ce55384bd5f1b122d3c2789ac4b68bba26 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406137 -0600	clone: from github.com:enverus-cts/cts.terraform.git

================
File: cts/.git/logs/HEAD
================
0000000000000000000000000000000000000000 b35ee2ce55384bd5f1b122d3c2789ac4b68bba26 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406137 -0600	clone: from github.com:enverus-cts/cts.terraform.git

================
File: cts/.git/refs/heads/main
================
b35ee2ce55384bd5f1b122d3c2789ac4b68bba26

================
File: cts/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: cts/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/cts.terraform.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: cts/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: cts/.git/HEAD
================
ref: refs/heads/main

================
File: cts/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
704ee556ffbf300b0b0c8d39c5c6b2be3d135af4 refs/remotes/origin/DAS-8078
8b4cf20e5ffefb28d7e85af09be63e900c80765a refs/remotes/origin/EDGE-3838-rms
b408b87e7526fa7d18cd92841e5e0d0431a31202 refs/remotes/origin/SRE-12253-grafana-contact-points
f8394e1f5c3272de6b5c0ec0ffa098021dc08c44 refs/remotes/origin/SRE-12812
6d015f8497b2a8028241b11de818b1429201f2bc refs/remotes/origin/SRE-12859
8b9f2a0945610eade1100aa6bb438e906f4fed4a refs/remotes/origin/SRE-13325
fcbe3fb32e7ea5ef05bc3200f52bc304c05c48c5 refs/remotes/origin/feat/SRE-13208_Updgrade_AWX_Instance
d7c0ab48d017869dc09b5ddd901740b709adcdf7 refs/remotes/origin/feat/SRE_13347-Create_AWX_SP_For_Inventory_Sync
0c1dc579dbfb68fc741933f55a48ffb756f0189b refs/remotes/origin/feat/sre-11311-awx-config
3daa13abbcc8e373905d00d9387c5fe5c69beb0f refs/remotes/origin/feat/sre-11650-update-tf-modules
344d518eb825f10e99f6d00d4ce9d11677603db8 refs/remotes/origin/feat/sre-12487-nv-genai
36c3f106ab6321bd5c7169b44d14122fb7a348df refs/remotes/origin/feat/sre-13289-add-mv-custom-role
4190fa200d991bda11d21bff3ab602c5558212d6 refs/remotes/origin/feat/sre-13958-ghe
ea64a26605e36728eed27cd9c681b6cab0bed3b4 refs/remotes/origin/feat/sre-14461-test-consul
8f484fcf27ffa0634e11297c1b71cb2511be25af refs/remotes/origin/fix/delete-runners
b35ee2ce55384bd5f1b122d3c2789ac4b68bba26 refs/remotes/origin/main
20e8fb1129dccccbff89130ed58802c44cdd7805 refs/remotes/origin/refresh-token
96d4df3801ff8c71c436dd423682910a85152610 refs/remotes/origin/set-awx-version
fe2fdd3c4b83c8f6cd73491feff489af70361020 refs/remotes/origin/sp
28edb943771a7da69ae03b1e675c389e638cde84 refs/remotes/origin/sre-14421
c529e745fef0d87291a99404b8a0ed1e710bac87 refs/remotes/origin/sre-15016
59244d801f1934c5828ff4fea803a82dfcb1e10f refs/remotes/origin/sre-15159

================
File: cts/.github/workflows/update-runner-ami.yaml
================
name: Update Runner AMI

on:
  repository_dispatch:
    types: [update-runner-ami]
  workflow_dispatch:
    inputs:
      jira_id:
        description: 'The JIRA ID for the task associated with this update'
        required: true
        type: string
      ami:
        description: 'The new AMI value to set in runner configs'
        required: true
        type: string

jobs:
  update-ami:
    runs-on: enverus-ubuntu
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: '3.x'

      - name: Install yq
        run: |
          pip install yq

      - name: Update AMI in runner configs
        env:
          NEW_AMI: ${{ github.event.client_payload.new_ami || github.event.inputs.ami }}
          JIRA_ID: ${{ github.event.client_payload.jira_id || github.event.inputs.jira_id }}
        run: |
          for file in cts.terraform/github/runners/templates/*-runner-configs/*.yaml; do
            # Update all .runner_config.ami_filter.name values
            yq -i '
              .runner_config.ami_filter.name = [env(NEW_AMI)]
            ' "$file"
          done

      # update jira issue with progress here

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@271a8d0340265f705b14b6d32b9829c1cb33d45e # v7.0.8
        with:
          commit-message: "feat(${{ env.JIRA_ID }}): update runner AMI to ${{ env.NEW_AMI }}"
          branch: feat/${{ env.JIRA_ID }}-${{ env.NEW_AMI }}
          title: "feat(${{ env.JIRA_ID }}): Update runner AMI to ${{ env.NEW_AMI }}"
          body: |
            This PR updates the runner AMI to `${{ env.NEW_AMI }}` in all runner config YAMLs.

================
File: cts/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre
/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: cts/.github/dependabot.yaml
================
version: 2
updates:
  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: terraform
    directory: acm/cts_enverus_com
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: artifactory
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: awx/awx-gh-token-issuer
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: awx/awx-rds
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: central-terraform-state-storage
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: config
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: config/remediation
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: consul-cluster
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: ecr
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/apps/gh-app-enverus-all-repos-ro
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/oidc/custom-roles/packer
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/oidc/idp
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/oidc/sre-roles
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/runners
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github/secrets-manager
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-enterprise-importer
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-organization-secrets/artifactory
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-organization-secrets/artifactory/module
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-organization-secrets/redgate-sqlcompare
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-organization-secrets/redgate-sqlcompare/module
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-sso/azuread-groups
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: github-sso/drillinginfo
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: grafana/dashboards
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: grafana/datasources
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: grafana/service-accounts
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: iam/roles/argo-cd-sts
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: iam/roles/atlantis-sts
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: lambda/github-bots/repo-settings-manager
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: packer
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: route53/cts
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: route53/enverus_com_subzones
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: s3-buckets
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: sre-windows-utility
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/atlantis
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/consul-aws
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/di_es_regulatory/master
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/nomad-cluster/nomad-client-service
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/nomad-cluster/nomad-scheduler
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: testing/nomad-cluster/nomad-server
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vault
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vault_azuread_sso
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vault_mounts
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vault_policies_and_roles
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vault_secrets
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vpc/eu-north-1
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vpc/eu-west-1
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vpc/us-east-1
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'
  - package-ecosystem: terraform
    directory: vpc/us-west-2
    schedule:
      interval: daily
    commit-message:
      prefix: fix
      prefix-development: build
      include: scope
    allow:
      - dependency-type: production
    reviewers:
      - '@enverus-cts/sre'

================
File: cts/acm/cts_enverus_com/.terraform-version
================
latest:^1.3

================
File: cts/acm/cts_enverus_com/acm.tf
================
resource "aws_acm_certificate" "cts" {
  domain_name       = "*.${var.env}.cts.enverus.com"
  validation_method = "DNS"

  lifecycle {
    create_before_destroy = true
  }
}

data "aws_route53_zone" "cts" {
  name         = "${var.env}.cts.enverus.com"
  private_zone = false
}


resource "aws_route53_record" "cts" {
  for_each = {
    for dvo in aws_acm_certificate.cts.domain_validation_options : dvo.domain_name => {
      name   = dvo.resource_record_name
      record = dvo.resource_record_value
      type   = dvo.resource_record_type
    }
  }

  allow_overwrite = true
  zone_id         = data.aws_route53_zone.cts.zone_id
  name            = each.value.name
  type            = each.value.type
  ttl             = "300"
  records         = [each.value.record]
}

resource "aws_acm_certificate_validation" "cert_validation" {
  certificate_arn         = aws_acm_certificate.cts.arn
  validation_record_fqdns = [for record in aws_route53_record.cts : record.fqdn]
}

================
File: cts/acm/cts_enverus_com/dev.backend.tfvars
================
key = "360093697111/dev/acm/terraform.tfstate"

================
File: cts/acm/cts_enverus_com/prod.backend.tfvars
================
key = "316576613383/prod/acm/terraform.tfstate"

================
File: cts/acm/cts_enverus_com/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "environment"
  type        = string
}

variable "bu" {
  description = "business unit abbreviation"
  type        = string
}

================
File: cts/acm/cts_enverus_com/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "acm"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/acm"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: cts/artifactory/.terraform-version
================
latest:^1.10

================
File: cts/artifactory/access-tokens.tf
================
resource "artifactory_scoped_token" "virtual-repo-read-write" {
  username    = "virtual-repo-read-write"
  description = "Scoped token for virtual-repo-read-write"
  scopes      = ["applied-permissions/groups:virtual-repo-read-write"]
}

resource "artifactory_scoped_token" "virtual-repo-read-only" {
  username    = "virtual-repo-read-only"
  description = "Scoped token for virtual-repo-read-only"
  scopes      = ["applied-permissions/groups:virtual-repo-read-only"]
}

resource "vault_generic_secret" "generic_secret" {
  path      = "enverus-cts/artifactory-credentials/access-tokens/virtual-repo-read-write"
  data_json = <<EOF
{
  "username": "${artifactory_scoped_token.virtual-repo-read-write.username}",
  "token": "${artifactory_scoped_token.virtual-repo-read-write.access_token}"
}
EOF
}

resource "vault_generic_secret" "read-only-credentials" {
  path      = "enverus-cts/artifactory-credentials/access-tokens/virtual-repo-read-only"
  data_json = <<EOF
{
  "username": "${artifactory_scoped_token.virtual-repo-read-only.username}",
  "token": "${artifactory_scoped_token.virtual-repo-read-only.access_token}"
}
EOF
}

================
File: cts/artifactory/groups.tf
================
resource "artifactory_group" "virtual-repo-read-write" {
  name             = "virtual-repo-read-write"
  description      = "Provide read-write access to all virtual repositories"
  admin_privileges = false
  auto_join        = true
}

resource "artifactory_group" "virtual-repo-read-only" {
  name             = "virtual-repo-read-only"
  description      = "Provide read-only access to all virtual repositories"
  admin_privileges = false
  auto_join        = true
}

================
File: cts/artifactory/permission-targets.tf
================
##IMPORTS
import {
  to = platform_permission.local-repo-read-write
  id = "local-repo-read-write"
}

import {
  to = platform_permission.remote-repo-read-write
  id = "remote-repo-read-write"
}

import {
  to = platform_permission.local-repo-read-only
  id = "local-repo-read-only"
}
##/IMPORTS
resource "platform_permission" "local-repo-read-write" {
  name = "local-repo-read-write"
  artifact = {
    actions = {
      groups = [
        {
          name = "virtual-repo-read-write"
          permissions = [
            "READ",
            "WRITE",
          ]
        }
      ]
    }
    targets = [
      {
        name             = "cargo-local"
        include_patterns = ["**"]
      },
      {
        name             = "dotnet-old"
        include_patterns = ["**"]
      },
      {
        name             = "go-local"
        include_patterns = ["**"]
      },
      {
        name             = "npm-local"
        include_patterns = ["**"]
      },
      {
        name             = "nuget-local"
        include_patterns = ["**"]
      },
      {
        name             = "pypi-local"
        include_patterns = ["**"]
      },
      {
        name             = "maven-snapshot-local"
        include_patterns = ["**"]
      },
      {
        name             = "maven-release-local"
        include_patterns = ["**"]
      },
      {
        name             = "enverus-internal"
        include_patterns = ["**"]
      }
    ]

  }
}

resource "platform_permission" "remote-repo-read-write" {
  name = "remote-repo-read-write"
  artifact = {
    actions = {
      groups = [
        {
          name = "virtual-repo-read-write"
          permissions = [
            "READ",
            "WRITE",
          ]
        },
        {
          name = "virtual-repo-read-only"
          permissions = [
            "READ",
            "WRITE",
          ]
        }
    ] }
    targets = [
      {
        name             = "npm-remote-cache"
        include_patterns = ["**"]
      },
      {
        name             = "npm-fontawesome-remote-cache"
        include_patterns = ["**"]
      },
      {
        name             = "pypi-remote-cache"
        include_patterns = ["**"]
      },
      {
        name             = "nuget-remote-cache"
        include_patterns = ["**"]
      },
      {
        name             = "maven-repo1-remote-cache"
        include_patterns = ["**"]
      },
      {
        name             = artifactory_remote_maven_repository.maven-google-remote.key
        include_patterns = ["**"]
      }
    ]
  }
}

resource "platform_permission" "local-repo-read-only" {
  name = "local-repo-read-only"
  artifact = {
    actions = {
      groups = [
        {
          name = "virtual-repo-read-only"
          permissions = [
            "READ",
          ]
        }
      ]
    }
    targets = [
      {
        name             = "cargo-local"
        include_patterns = ["**"]
      },
      {
        name             = "dotnet-old"
        include_patterns = ["**"]
      },
      {
        name             = "go-local"
        include_patterns = ["**"]
      },
      {
        name             = "npm-local"
        include_patterns = ["**"]
      },
      {
        name             = "nuget-local"
        include_patterns = ["**"]
      },
      {
        name             = "pypi-local"
        include_patterns = ["**"]
      },
      {
        name             = "maven-snapshot-local"
        include_patterns = ["**"]
      },
      {
        name             = "maven-release-local"
        include_patterns = ["**"]
      },
      {
        name             = "enverus-internal"
        include_patterns = ["**"]
      }
    ]
  }
}

================
File: cts/artifactory/prod.backend.tfvars
================
key     = "360093697111/prod/artifactory/terraform.tfstate"
encrypt = "true"

================
File: cts/artifactory/prod.tfvars
================
region                             = "us-east-1"
env                                = "prod"
artifactory_url                    = "https://drillinginfo.jfrog.io/"
vault_path_artifactory_credentials = "enverus-cts/artifactory-credentials/admin-tokens/admin-terraform"
vault_path_fontawesome_registry    = "enverus-cts/artifactory-credentials/remote-repositories/fontawesome"

================
File: cts/artifactory/repositories.tf
================
resource "artifactory_local_maven_repository" "maven-release-local" {
  key              = "maven-release-local"
  handle_releases  = true
  handle_snapshots = false
}

resource "artifactory_local_maven_repository" "maven-snapshot-local" {
  key                  = "maven-snapshot-local"
  max_unique_snapshots = 10
  handle_releases      = false
  handle_snapshots     = true
}

resource "artifactory_remote_maven_repository" "maven-repo1-remote" {
  key              = "maven-repo1-remote"
  url              = "https://repo1.maven.org/maven2/"
  excludes_pattern = "com/enverus/**,com/oildex/**"
}

resource "artifactory_remote_maven_repository" "maven-google-remote" {
  key              = "maven-google-remote"
  url              = "https://maven.google.com/"
  excludes_pattern = "com/enverus/**,com/oildex/**"
}

resource "artifactory_virtual_maven_repository" "maven" {
  key             = "maven"
  repo_layout_ref = "maven-2-default"
  repositories = [
    artifactory_local_maven_repository.maven-release-local.key,
    artifactory_local_maven_repository.maven-snapshot-local.key,
    artifactory_remote_maven_repository.maven-repo1-remote.key,
    artifactory_remote_maven_repository.maven-google-remote.key,
  ]
}

resource "artifactory_remote_npm_repository" "npm-fontawesome-remote" {
  key      = "npm-fontawesome-remote"
  url      = "https://npm.fontawesome.com/"
  username = "TOKEN"
  password = data.vault_generic_secret.npm-fontawesome-remote-token.data["token"]
}

data "vault_generic_secret" "npm-fontawesome-remote-token" {
  path = var.vault_path_fontawesome_registry
}

resource "artifactory_virtual_npm_repository" "npm" {
  key = "npm"
  repositories = [
    "npm-local",
    "npm-remote",
    artifactory_remote_npm_repository.npm-fontawesome-remote.key,
    "enverus-datis",
  ]
  default_deployment_repo = "npm-local"
}

output "artifactory_virtual_npm_repository" {
  value = artifactory_virtual_npm_repository.npm
}

resource "artifactory_local_cargo_repository" "cargo-local" {
  key                 = "cargo-local"
  anonymous_access    = false
  enable_sparse_index = true
}

================
File: cts/artifactory/TransitionREADME.md
================
This upgrade to the new version of the provider is in a two stage process.  The issue is that the artifactory_access_token resource is so old that it cannot be worked with.  The artifactory provider just doesn't know what to do with it and throws an error.
Therefore:
Stage one is to remove the original resources from the state file.  This has to be done while the provider is set to 6.37.0.  Do *not* destroy the resources, just remove for the provider.  This is done with the removed blocks at the top of access-tokens.tf and permission-target.tf.  

After removing the resources from the provider, the provider version can be upgraded to the latest (12.7.1 currently).  access-tokens.tf and permission-target.tf have to be updated to use the new resources.  
Update the following resources:
* versions.tf --> Update the provider version
* access-tokens.tf --> Comment out the removed block, comment out lines 1-53. Uncomment out lines 56-94.  This removes the removed block, and creates new scoped-tokens and writes the new tokens into a new secret version.
* permission-targets.tf --> Comment out the removed block (lines 18-36), and uncomment out the import and new resource blocks (lines 2-15, and 128-245).  Remove the artifactory_permission_target resources.

================
File: cts/artifactory/variables.tf
================
variable "artifactory_url" {
  description = "URL for artifactory"
}

variable "vault_path_artifactory_credentials" {
  description = "Path in vault to credentials for artifactory provider (used by artifactory provider)"
}

variable "vault_path_fontawesome_registry" {
  description = "Path in vault to credentials for fontawesome npm registry"
}

================
File: cts/artifactory/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    artifactory = {
      source  = "jfrog/artifactory"
      version = ">= 12.0"
    }
    platform = {
      source  = "jfrog/platform"
      version = ">= 2.0.0"
    }
  }
}

provider "artifactory" {
  url          = "${var.artifactory_url}/artifactory"
  access_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

provider "platform" {
  url          = "${var.artifactory_url}/artifactory"
  access_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

provider "vault" {}

data "vault_generic_secret" "artifactory_credentials" {
  path = var.vault_path_artifactory_credentials
}

================
File: cts/auth/auth0-backup/main.tf
================
module "S3-Bucket-example" {
  source     = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket"
  bucketname = "enverus-auth0-backups"
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
}

================
File: cts/auth/auth0-backup/prod.backend.tfvars
================
key     = "360093697111/prod/auth/auth0-backup/terraform.tfstate"
encrypt = "true"

================
File: cts/auth/auth0-backup/prod.tfvars
================
region    = "us-east-1"
dr-region = "us-west-2"

================
File: cts/auth/auth0-backup/variables.tf
================
variable "region" {}
variable "dr-region" {}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: cts/auth/auth0-backup/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  alias  = "ue1"
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "auth0"
      Environment      = var.env
      Team             = "tech-auth@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/auth/auth0-backup"
      TerraformCreated = "true"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = var.dr-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "auth0"
      Environment      = var.env
      Team             = "tech-auth@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/auth/auth0-backup"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/central-terraform-state-storage-bucket/.terraform-version
================
latest:^1.9

================
File: cts/central-terraform-state-storage-bucket/main.tf
================
data "aws_organizations_organization" "main" {
  provider = aws.parent
}

data "vault_generic_secret" "aws" {
  path = var.vault_path_aws_keys
}

# Create source and replication buckets
import {
  to = module.terraform-state-storage-s3.aws_s3_bucket.s3_bucket
  id = var.bucket_name
}

import {
  to = module.terraform-state-storage-s3.aws_s3_bucket_versioning.s3_bucket_versioning
  id = var.bucket_name
}

import {
  to = module.terraform-state-storage-s3.aws_s3_bucket_policy.bucket_policy
  id = var.bucket_name
}

module "terraform-state-storage-s3" {
  source = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket.git?ref=v1.0.2"
  # source = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket.git?ref=v1.3.1"

  bucketname          = var.bucket_name
  default_lifecycle   = false
  s3_bucket_policy    = data.aws_iam_policy_document.source.json
  DR_s3_bucket_policy = data.aws_iam_policy_document.replica.json
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
}

resource "aws_s3_bucket_lifecycle_configuration" "noncurrent_source" {
  provider = aws.ue1
  bucket   = module.terraform-state-storage-s3.primaryS3Bucket.id
  rule {
    id     = "noncurrent"
    status = "Enabled"

    noncurrent_version_expiration {
      noncurrent_days = 365
    }

    noncurrent_version_transition {
      noncurrent_days = 30
      storage_class   = "STANDARD_IA"
    }

    abort_incomplete_multipart_upload {
      days_after_initiation = 7
    }
  }
}

resource "aws_s3_bucket_lifecycle_configuration" "noncurrent_replica" {
  provider = aws.uw2
  bucket   = module.terraform-state-storage-s3.secondaryS3Bucket.id
  rule {
    id     = "noncurrent"
    status = "Enabled"

    noncurrent_version_expiration {
      noncurrent_days = 365
    }

    noncurrent_version_transition {
      noncurrent_days = 30
      storage_class   = "STANDARD_IA"
    }

    abort_incomplete_multipart_upload {
      days_after_initiation = 7
    }
  }
}

data "aws_iam_policy_document" "source" {
  statement {
    sid = "ParentAccountAccess"
    principals {
      type        = "AWS"
      identifiers = ["arn:aws:iam::361301859166:root"]
    }
    actions = [
      "s3:*"
    ]
    resources = [
      module.terraform-state-storage-s3.primaryS3Bucket.arn,
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }

  statement {
    sid = "ListBucketFolders"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:GetObject",
      "s3:ListBucket"
    ]
    resources = [
      module.terraform-state-storage-s3.primaryS3Bucket.arn,
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }

  statement {
    sid = "AllowAccountAccess"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:*"
    ]
    resources = [
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/$${aws:PrincipalAccount}",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/$${aws:PrincipalAccount}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }

  statement {
    sid = "AllowAzureStacksHCIKeys"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:*"
    ]
    resources = [
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/iad1paz01",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/iad1paz01/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/iad1paz02",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/iad1paz02/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1paz01",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1paz01/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1paz02",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1paz02/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1qaz01",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/ord1qaz01/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/sea1paz01",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/sea1paz01/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/sea1paz02",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/sea1paz02/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/iat/*",
      "${module.terraform-state-storage-s3.primaryS3Bucket.arn}/sre-rg/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
    condition {
      test     = "StringLike"
      variable = "aws:PrincipalArn"
      values   = ["arn:aws:iam::*:role/terraform"]
    }
  }

  statement {
    sid     = "AllowSSLRequestsOnly_61mbsp"
    effect  = "Deny"
    actions = ["s3:*"]
    principals {
      type        = "*"
      identifiers = ["*"]
    }
    resources = [
      "arn:aws:s3:::enverus-centralized-terraform-state",
      "arn:aws:s3:::enverus-centralized-terraform-state/*"
    ]

    condition {
      test     = "Bool"
      variable = "aws:SecureTransport"
      values   = ["false"]
    }
  }

}

data "aws_iam_policy_document" "replica" {
  statement {
    sid = "ParentAccountAccess"
    principals {
      type        = "AWS"
      identifiers = ["arn:aws:iam::361301859166:root"]
    }
    actions = [
      "s3:*"
    ]
    resources = [
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}",
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }

  statement {
    sid = "ListBucketFolders"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:GetObject",
      "s3:ListBucket"
    ]
    resources = [
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}",
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }

  statement {
    sid = "AllowAccountAccess"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:*"
    ]
    resources = [
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}/$${aws:PrincipalAccount}",
      "arn:aws:s3:::${join("-", [module.terraform-state-storage-s3.primaryS3Bucket.id, "dr"])}/$${aws:PrincipalAccount}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
  }
}

================
File: cts/central-terraform-state-storage-bucket/prod.backend.tfvars
================
key    = "316576613383/prod/central-terraform-state-storage-bucket/terraform.state"
bucket = "di-cts-prod-terraform"

================
File: cts/central-terraform-state-storage-bucket/prod.tfvars
================
bucket_name         = "enverus-centralized-terraform-state"
vault_path_aws_keys = "cts-secrets/terraform/aws_api_keys/terraform_keys_parent"

================
File: cts/central-terraform-state-storage-bucket/variables.tf
================
variable "bu" {
  description = "The business unit for the account"
  type        = string
}
variable "env" {
  description = "Name of the Environment"
  type        = string
}
variable "bucket_name" {
  description = "The name for the s3 bucket"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}
variable "vault_path_aws_keys" {
  description = "path in Vault to aws api keys to use with aws provider"
  type        = string
}

================
File: cts/central-terraform-state-storage-bucket/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

# provider for source bucket
provider "aws" {
  alias  = "ue1"
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "account"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/central-terraform-state-storage-bucket"
      Environment  = var.env
    }
  }
}

# provider for replica bucket
provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "account"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/central-terraform-state-storage-bucket"
      Environment  = var.env
    }
  }
}

# provider needed to get org data
provider "aws" {
  region     = "us-east-1"
  alias      = "parent"
  access_key = data.vault_generic_secret.aws.data["access_key"]
  secret_key = data.vault_generic_secret.aws.data["secret_key"]
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/chef-infra-server/.terraform-version
================
latest:^1.8

================
File: cts/chef-infra-server/instance-role.tf
================
# create instance role to allow chef-infra-server to access s3 bucket for backups
resource "aws_iam_role" "chef_infra_server_service_role" {
  name = "chef-infra-server-service-role"
  path = "/"

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": [
          "codebuild.amazonaws.com",
          "ec2.amazonaws.com",
          "lambda.amazonaws.com"
        ]
      },
      "Effect": "Allow"
    }
  ]
}
EOF
}

resource "aws_iam_policy" "chef_infra_server_service_role" {
  name        = "chef-infra-server-service-role-policy"
  path        = "/"
  description = "The policy for the service role attached to chef-infra-server instances"

  policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement" : [
    {
      "Action": [
        "autoscaling:DescribeAutoScalingGroups",
        "autoscaling:SetDesiredCapacity",
        "cloudwatch:*",
        "cloudwatch:GetMetricStatistics",
        "dynamodb:*Item",
        "dynamodb:Scan",
        "ec2:AttachVolume",
        "ec2:CreateTags",
        "ec2:DeleteTags",
        "ec2:DescribeAccountAttributes",
        "ec2:DescribeAvailabilityZones",
        "ec2:DescribeInstances",
        "ec2:DescribeSecurityGroups",
        "ec2:DescribeTags",
        "ec2:DescribeVolumes",
        "ec2:DescribeVpcs",
        "ec2:DetachVolume",
        "ecs:*",
        "elasticloadbalancing:DeregisterInstancesFromLoadBalancer",
        "elasticloadbalancing:DeregisterTargets",
        "elasticloadbalancing:DescribeLoadBalancers",
        "elasticloadbalancing:DescribeTargetGroups",
        "elasticloadbalancing:DescribeTargetHealth",
        "elasticloadbalancing:RegisterInstancesWithLoadBalancer",
        "elasticloadbalancing:RegisterTargets",
        "es:*",
        "iam:GetInstanceProfile",
        "iam:GetRole",
        "iam:GetUser",
        "kms:Decrypt",
        "kms:DescribeKey",
        "kms:Encrypt",
        "logs:DescribeLogStreams",
        "logs:GetLogEvents",
        "rds:Describe*",
        "rds:DownloadDBLogFilePortion",
        "rds:ListTagsForResource",
        "s3:*",
        "sns:*"
      ],
      "Effect": "Allow",
      "Resource": "*"
    },
    {
      "Action": [
        "kms:GenerateDataKey"
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:kms:us-east-1:190564612116:key/mrk-65031a59cebb4ea5a0f1fb25842f8e2f"
      }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "chef_infra_server_service_role" {
  role       = aws_iam_role.chef_infra_server_service_role.name
  policy_arn = aws_iam_policy.chef_infra_server_service_role.arn
}

resource "aws_iam_role_policy_attachment" "ssm" {
  role       = aws_iam_role.chef_infra_server_service_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

resource "aws_iam_instance_profile" "ec2_instance_profile" {
  name = "chef-infra-server-service-instance-profile"
  role = aws_iam_role.chef_infra_server_service_role.name
}

================
File: cts/chef-infra-server/main.tf
================
data "aws_ec2_managed_prefix_list" "main" {
  name = "All RFC-1918 CIDR-s - shared"
}

resource "aws_security_group" "chef-server-sg" {
  name_prefix = "chef-infra-server"
  vpc_id      = data.aws_vpc.main.id

  ingress {
    description = "80 from VPC"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = [data.aws_vpc.main.cidr_block]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

data "aws_security_group" "inside" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]

  }
  filter {
    name   = "tag:Name"
    values = ["cts-vpc-*-inside-sg"]
  }
}

# alb
resource "aws_lb" "chef-infra-server" {
  name                             = "chef-infra-server"
  internal                         = true
  load_balancer_type               = "application"
  security_groups                  = [aws_security_group.chef_infra_lb_sg.id]
  subnets                          = toset(data.aws_subnets.inside.ids)
  enable_deletion_protection       = false
  enable_http2                     = true
  enable_cross_zone_load_balancing = true
  idle_timeout                     = 60

  access_logs {
    bucket  = "enverus-central-logs"
    enabled = true
  }

  tags = {
    Name = "chef-infra-server"
  }
}

data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = ["cts-vpc-prod"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = ["use1-az3"]
  state            = "available"
}

data "aws_subnets" "inside" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*Private Subnet"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

resource "aws_security_group" "chef_infra_lb_sg" {
  name_prefix = "chef-infra-server-lb"
  vpc_id      = data.aws_vpc.main.id

  ingress {
    description     = "TLS from anywhere"
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.main.id]
  }

  ingress {
    description     = "port 80 from anywhere" #because of knife
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.main.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_lb_target_group" "chef-infra-server" {
  name     = "chef-infra-server"
  port     = 80
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.main.id

  health_check {
    path                = "/"
    protocol            = "HTTP"
    port                = "traffic-port"
    interval            = 30
    timeout             = 5
    healthy_threshold   = 2
    unhealthy_threshold = 2
    matcher             = "200-399"
  }
}

data "aws_acm_certificate" "cert" {
  domain   = "*.prod.cts.enverus.com"
  statuses = ["ISSUED"]
}

resource "aws_lb_listener" "chef-infra-server" {
  load_balancer_arn = aws_lb.chef-infra-server.arn
  port              = "443"
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06"
  certificate_arn   = data.aws_acm_certificate.cert.arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.chef-infra-server.arn
  }
}

# need this because of knife
resource "aws_lb_listener" "chef-infra-server-http" {
  load_balancer_arn = aws_lb.chef-infra-server.arn
  port              = "80"
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06"
  certificate_arn   = data.aws_acm_certificate.cert.arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.chef-infra-server.arn
  }
}

data "aws_route53_zone" "enverus" {
  name = "prod.cts.enverus.com."
}

resource "aws_route53_record" "chef-infra-server" {
  zone_id = data.aws_route53_zone.enverus.zone_id
  name    = "chef-infra-server.prod.cts.enverus.com"
  type    = "A"
  alias {
    name                   = aws_lb.chef-infra-server.dns_name
    zone_id                = aws_lb.chef-infra-server.zone_id
    evaluate_target_health = true
  }
}

# ASG for chef infra server
module "chef-infra-server-asg" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-autoscaling-group.git?ref=v10.1.2"

  # ami search filters
  ami-filters = {
    name           = var.ami_name_filter
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lt params and userdata
  environment        = var.vpc_environment
  os                 = var.operating_system
  ec2-name           = "aws-ue1-${var.vpc_environment}-chef-infra-server"
  instance-type      = var.aws_ec2_instance_type
  subnet-ids         = data.aws_subnets.inside.ids
  security-group-ids = "${aws_security_group.chef-server-sg.id},${data.aws_security_group.inside.id}"
  keypair-name       = var.ssh_key_pair
  iam-profile        = aws_iam_instance_profile.ec2_instance_profile.name
  ebs-optimized      = var.aws_ec2_ebs_optimized
  vo_routing_key     = var.vo_routing_key

  #ASG
  asg-name                  = "${var.vpc_environment}-chef-infra-server-asg"
  desired-capacity          = var.desired_capacity
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = var.min_capacity
  protect-from-scale-in     = "true"
  target-group-arns         = [aws_lb_target_group.chef-infra-server.arn]

  # Tagging
  tagComponent    = var.aws_tag_component
  tagStack        = var.aws_tag_stack
  tagAutospot     = var.aws_tag_autospot
  tagLocation     = var.aws_tag_location
  tagTeam         = var.aws_tag_team
  tagEnv          = var.aws_tag_env
  tagBusinessUnit = var.business_unit_tag
  tagSourceCode   = "https://github.com/enverus-cts/cts.terraform/chef-infra-server"
  tagProduct      = "shared"

  # Ansible pull
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

================
File: cts/chef-infra-server/prod.backend.tfvars
================
key    = "316576613383/prod/chef-infra-server/terraform.state"
bucket = "enverus-centralized-terraform-state"

================
File: cts/chef-infra-server/prod.tfvars
================
vpc_name              = "cts-vpc-prod"
iam_profile           = "service-instance-profile"
vpc_environment       = "prod"
aws_tag_stack         = "prod"
aws_tag_autospot      = "false"
aws_tag_location      = "us-east-1"
aws_tag_team          = "sre@enverus.com"
aws_tag_env           = "prod"
aws_tag_business_unit = "cts"
# ref: https://www.naukri.com/code360/library/capacity-planning-in-chef-infra-server
aws_ec2_instance_type    = "m7a.large"
aws_ec2_ebs_optimized    = "true"
aws_ec2_volume_type      = "gp3"
aws_ec2_root_volume_size = "80"
ami_name_filter          = "drillinginfo/ubuntu1804/base-ubuntu-18.04-amd64-*"
desired_capacity         = "1"
min_capacity             = "1"
vo_routing_key           = "key-ProdUptime"

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"ansible_environment_name=prod ansible_business_unit=cts\"",
      "-C main"
    ],
  },
  {
    playbook_repo = "enverus-cts/sre.ansible.chef-infra-server",
    playbook_file = "chef-infra-server.yml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"chefserver_hostname=chef-infra-server.prod.cts.enverus.com\"",
      "-C main"
    ],
  }
]

================
File: cts/chef-infra-server/s3-buckets.tf
================
# create s3 bucket for chef-infra-server backups
module "s3-bucket" {
  source       = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket?ref=v1.3.1"
  bucketprefix = "enverus-chef-infra-server-backups-"
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
  default_lifecycle = false
}

resource "aws_s3_bucket_lifecycle_configuration" "primary" {
  provider = aws.ue1
  bucket   = module.s3-bucket.primaryS3Bucket.id
  rule {
    id = "rule-1"
    expiration {
      days = 30
    }
    noncurrent_version_expiration {
      noncurrent_days = 60
    }
    filter {
      prefix = "/"
    }
    status = "Enabled"
  }
}

resource "aws_s3_bucket_lifecycle_configuration" "secondary" {
  provider = aws.uw2
  bucket   = module.s3-bucket.secondaryS3Bucket[0].id
  rule {
    id = "rule-1"
    expiration {
      days = 30
    }
    noncurrent_version_expiration {
      noncurrent_days = 60
    }
    filter {
      prefix = "/"
    }
    status = "Enabled"
  }
}

================
File: cts/chef-infra-server/variables.tf
================
variable "bu" {
  description = "The business unit for the account"
  type        = string
}

variable "env" {
  description = "Name of the Environment"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "ssh_key_pair" {
  default     = "cm@drillinginfo.com"
  description = "ssh key file"
}

variable "operating_system" {
  default     = "ubuntu18"
  description = "The operating system being used"
}

variable "region" {
  default     = "us-east-1"
  description = "AWS Region"
}

variable "business_unit_tag" {
  default = "cts"
}

variable "aws_tag_component" {
  default     = "3scale-api-proxy"
  description = "The primary purpose of the node"
}

variable "ami_name_filter" {
  description = "String used to filter AMIs based on name"
  type        = string
}

variable "vpc_name" {
  description = "Name of the vpc"
}

variable "iam_profile" {
  description = "The iam profile to be used"
}

variable "vpc_environment" {
  description = "Vpc environment: dev preprod or prod"
}

variable "aws_tag_stack" {
  description = "AWS tag: dev preprod or prod"
}

variable "aws_tag_autospot" {
  description = "True or False: Use spot instances"
}

variable "aws_tag_team" {
  description = "The team that owns the resource"
}

variable "aws_tag_env" {
  description = "Yet another environment tag"
}

variable "aws_tag_location" {
  description = "This is the AWS region"
}

variable "aws_tag_business_unit" {
  description = "The business uit that is the proponent of the instance"
}

variable "desired_capacity" {
  description = "Number nodes desired"
}

variable "min_capacity" {
  description = "Minimum number nodes"
}

variable "aws_ec2_instance_type" {
  description = "Instance size. eg. mx5large"
}

variable "aws_ec2_ebs_optimized" {
  description = "EBS optimized?  True/False"
}

variable "aws_ec2_root_volume_size" {
  description = "Root volume size"
}

variable "aws_ec2_volume_type" {
  description = "EBS volume type.  eg. gp2"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
  default = []
}

================
File: cts/chef-infra-server/versions.tf
================
terraform {
  required_version = "~> 1.8.1"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

# default
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "shared"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/chef-infra-server"
      Environment  = var.env
      Product      = "shared"
    }
  }
}

# s3 bucket providers
provider "aws" {
  alias  = "ue1"
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "shared"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/chef-infra-server"
      Environment  = var.env
      Product      = "shared"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "shared"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/chef-infra-server"
      Environment  = var.env
      Product      = "shared"
    }
  }
}

================
File: cts/cloudfront/rudderstack/.terraform-version
================
latest:^1.9

================
File: cts/cloudfront/rudderstack/acm.tf
================
module "ext_rs_cdn_enverus_acm" {
  source  = "terraform-aws-modules/acm/aws"
  version = "~> 5"

  validation_allow_overwrite_records = true
  domain_name                        = "${var.cdn_subdomain}.${var.environment}.${var.domain}"
  key_algorithm                      = "EC_prime256v1" # ACM only supports RSA_2048 and EC_prime256v1
  validation_method                  = "DNS"
  zone_id                            = data.aws_route53_zone.enverus_com.zone_id

  tags = {
    Name = "ext_rs_cdn_rudderstack_enverus_com_certificate"
  }
}
output "ext_rs_cdn_enverus_acm" { value = module.ext_rs_cdn_enverus_acm }

module "ext_rs_api_enverus_acm" {
  source  = "terraform-aws-modules/acm/aws"
  version = "~> 5"

  validation_allow_overwrite_records = true
  domain_name                        = "${var.api_subdomain}.${var.environment}.${var.domain}"
  key_algorithm                      = "EC_prime256v1" # ACM only supports RSA_2048 and EC_prime256v1
  validation_method                  = "DNS"
  zone_id                            = data.aws_route53_zone.enverus_com.zone_id

  tags = {
    Name = "ext_rs_api_rudderstack_enverus_com_certificate"
  }
}
output "ext_rs_api_enverus_acm" { value = module.ext_rs_api_enverus_acm }

module "ext_rs_dp_enverus_acm" {
  source  = "terraform-aws-modules/acm/aws"
  version = "~> 5"

  validation_allow_overwrite_records = true
  domain_name                        = "${var.dataplane_subdomain}.${var.environment}.${var.domain}"
  key_algorithm                      = "EC_prime256v1" # ACM only supports RSA_2048 and EC_prime256v1
  validation_method                  = "DNS"
  zone_id                            = data.aws_route53_zone.enverus_com.zone_id

  tags = {
    Name = "ext_rs_dp_rudderstack_enverus_com_certificate"
  }
}
output "ext_rs_dp_enverus_acm" { value = module.ext_rs_dp_enverus_acm }

================
File: cts/cloudfront/rudderstack/dev.backend.tfvars
================
key = "360093697111/dev/cloudfront/rudderstack/terraform.state"

================
File: cts/cloudfront/rudderstack/dev.tfvars
================
environment                   = "dev"
dataplane_origin_account_name = "enveruswyupccs"

================
File: cts/cloudfront/rudderstack/main.tf
================
data "aws_caller_identity" "current" {}

locals {
  account_id = data.aws_caller_identity.current.account_id
}

resource "aws_cloudfront_distribution" "cdn_distribution" {
  aliases      = ["${var.cdn_subdomain}.${var.environment}.${var.domain}"]
  comment      = "CloudFront distribution for RudderStack SDK"
  enabled      = true
  http_version = "http2and3"
  price_class  = "PriceClass_All"

  origin {
    domain_name = "cdn.rudderlabs.com"
    origin_id   = "cdn_rudderlabs"

    custom_origin_config {
      http_port              = 80
      https_port             = 443
      origin_protocol_policy = "https-only"
      origin_ssl_protocols   = ["TLSv1.2"]
    }
  }

  default_cache_behavior {
    target_origin_id         = "cdn_rudderlabs"
    viewer_protocol_policy   = "redirect-to-https"
    allowed_methods          = ["GET", "HEAD", "OPTIONS"]
    cached_methods           = ["GET", "HEAD"]
    compress                 = true
    cache_policy_id          = data.aws_cloudfront_cache_policy.cachingoptimized.id
    origin_request_policy_id = aws_cloudfront_origin_request_policy.rudderstack_allow_headers.id
  }

  viewer_certificate {
    acm_certificate_arn      = module.ext_rs_cdn_enverus_acm.acm_certificate_arn
    ssl_support_method       = "sni-only"
    minimum_protocol_version = "TLSv1.2_2021"
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  logging_config {
    include_cookies = false
    bucket          = "enverus-central-cloudfront-logs.s3.amazonaws.com"
    prefix          = "AWSLogs/${data.aws_caller_identity.current.account_id}/rudderstack/rudderstack-cdn-distribution-logs/"
  }
}
output "cdn_distribution" { value = aws_cloudfront_distribution.cdn_distribution }

resource "aws_cloudfront_distribution" "api_distribution" {
  aliases      = ["${var.api_subdomain}.${var.environment}.${var.domain}"]
  comment      = "CloudFront distribution for RudderStack API"
  enabled      = true
  http_version = "http2and3"
  price_class  = "PriceClass_All"

  origin {
    domain_name = "api.rudderstack.com"
    origin_id   = "api_rudderstack"

    custom_origin_config {
      http_port              = 80
      https_port             = 443
      origin_protocol_policy = "https-only"
      origin_ssl_protocols   = ["TLSv1.2"]
    }
  }

  default_cache_behavior {
    target_origin_id           = "api_rudderstack"
    viewer_protocol_policy     = "redirect-to-https"
    allowed_methods            = ["GET", "HEAD", "OPTIONS"]
    cached_methods             = ["GET", "HEAD"]
    compress                   = true
    cache_policy_id            = aws_cloudfront_cache_policy.rudderstack_cache_policy.id
    origin_request_policy_id   = aws_cloudfront_origin_request_policy.rudderstack_allow_headers.id
    response_headers_policy_id = data.aws_cloudfront_response_headers_policy.cors_with_preflight.id
  }

  viewer_certificate {
    acm_certificate_arn      = module.ext_rs_api_enverus_acm.acm_certificate_arn
    ssl_support_method       = "sni-only"
    minimum_protocol_version = "TLSv1.2_2021"
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  logging_config {
    include_cookies = false
    bucket          = "enverus-central-cloudfront-logs.s3.amazonaws.com"
    prefix          = "AWSLogs/${data.aws_caller_identity.current.account_id}/rudderstack/rudderstack-api-distribution-logs/"
  }
}
output "api_distribution" { value = aws_cloudfront_distribution.api_distribution }

resource "aws_cloudfront_distribution" "dataplane_distribution" {
  aliases      = ["${var.dataplane_subdomain}.${var.environment}.${var.domain}"]
  comment      = "CloudFront distribution for RudderStack Data Plane"
  enabled      = true
  http_version = "http2and3"
  price_class  = "PriceClass_All"

  origin {
    domain_name = "${var.dataplane_origin_account_name}.dataplane.rudderstack.com"
    origin_id   = "dataplane_rudderstack"


    custom_origin_config {
      http_port              = 80
      https_port             = 443
      origin_protocol_policy = "https-only"
      origin_ssl_protocols   = ["TLSv1.2"]
    }
  }

  default_cache_behavior {
    target_origin_id           = "dataplane_rudderstack"
    viewer_protocol_policy     = "redirect-to-https"
    allowed_methods            = ["GET", "HEAD", "OPTIONS", "PUT", "POST", "PATCH", "DELETE"]
    cached_methods             = ["GET", "HEAD"]
    compress                   = true
    cache_policy_id            = data.aws_cloudfront_cache_policy.cachingdisabled.id
    origin_request_policy_id   = aws_cloudfront_origin_request_policy.rudderstack_allow_headers.id
    response_headers_policy_id = data.aws_cloudfront_response_headers_policy.cors_with_preflight.id
  }

  viewer_certificate {
    acm_certificate_arn      = module.ext_rs_dp_enverus_acm.acm_certificate_arn
    ssl_support_method       = "sni-only"
    minimum_protocol_version = "TLSv1.2_2021"
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  logging_config {
    include_cookies = false
    bucket          = "enverus-central-cloudfront-logs.s3.amazonaws.com"
    prefix          = "AWSLogs/${data.aws_caller_identity.current.account_id}/rudderstack/rudderstack-dataplane-distribution-logs/"
  }
}

output "dataplane_distribution" { value = aws_cloudfront_distribution.dataplane_distribution }

data "aws_cloudfront_cache_policy" "cachingoptimized" {
  name = "Managed-CachingOptimized"
}
output "data_aws_cloudfront_cache_policy_cachingoptimized" { value = data.aws_cloudfront_cache_policy.cachingoptimized }

data "aws_cloudfront_cache_policy" "cachingdisabled" {
  name = "Managed-CachingDisabled"
}
output "data_aws_cloudfront_cache_policy_cachingdisabled" { value = data.aws_cloudfront_cache_policy.cachingdisabled }

resource "aws_cloudfront_cache_policy" "rudderstack_cache_policy" {
  name        = "rudderstack_cache_policy"
  default_ttl = 300
  max_ttl     = 86400
  min_ttl     = 1

  parameters_in_cache_key_and_forwarded_to_origin {
    headers_config {
      header_behavior = "whitelist"
      headers {
        items = ["Authorization", "Origin"]
      }
    }

    cookies_config {
      cookie_behavior = "none"
    }

    query_strings_config {
      query_string_behavior = "all"
    }
  }
}

resource "aws_cloudfront_origin_request_policy" "rudderstack_allow_headers" {
  name = "rudderstack-allow-headers"

  headers_config {
    header_behavior = "whitelist"
    headers {
      items = ["Access-Control-Request-Headers", "Access-Control-Request-Method", "Origin", "Content-Encoding"]
    }
  }

  query_strings_config {
    query_string_behavior = "all"
  }

  cookies_config {
    cookie_behavior = "none"
  }
}

data "aws_cloudfront_response_headers_policy" "cors_with_preflight" {
  name = "Managed-CORS-With-Preflight"
}
output "data_aws_cloudfront_response_headers_policy_cors_with_preflight" { value = data.aws_cloudfront_response_headers_policy.cors_with_preflight }

================
File: cts/cloudfront/rudderstack/prod.backend.tfvars
================
key = "316576613383/prod/cloudfront/rudderstack/terraform.state"

================
File: cts/cloudfront/rudderstack/prod.tfvars
================
environment                   = "prod"
dataplane_origin_account_name = "enverusluies"

================
File: cts/cloudfront/rudderstack/route53.tf
================
data "aws_route53_zone" "enverus_com" {
  name = "${var.environment}.${var.domain}"
}

resource "aws_route53_record" "cdn_alias" {
  zone_id = data.aws_route53_zone.enverus_com.zone_id
  name    = "${var.cdn_subdomain}.${var.environment}.${var.domain}"
  type    = "A"

  alias {
    name                   = aws_cloudfront_distribution.cdn_distribution.domain_name
    zone_id                = aws_cloudfront_distribution.cdn_distribution.hosted_zone_id
    evaluate_target_health = false
  }
}

resource "aws_route53_record" "api_alias" {
  zone_id = data.aws_route53_zone.enverus_com.zone_id
  name    = "${var.api_subdomain}.${var.environment}.${var.domain}"
  type    = "A"

  alias {
    name                   = aws_cloudfront_distribution.api_distribution.domain_name
    zone_id                = aws_cloudfront_distribution.api_distribution.hosted_zone_id
    evaluate_target_health = false
  }
}

resource "aws_route53_record" "dataplane_alias" {
  zone_id = data.aws_route53_zone.enverus_com.zone_id
  name    = "${var.dataplane_subdomain}.${var.environment}.${var.domain}"
  type    = "A"

  alias {
    name                   = aws_cloudfront_distribution.dataplane_distribution.domain_name
    zone_id                = aws_cloudfront_distribution.dataplane_distribution.hosted_zone_id
    evaluate_target_health = false
  }
}

================
File: cts/cloudfront/rudderstack/variables.tf
================
variable "aws_region" {
  type    = string
  default = "us-east-1"
}

variable "assume_role_arn" {
  description = "Assume role for terraform provider"
  type        = string
}

variable "environment" {
  description = "deployment environment, dev, preprod, prod"
  type        = string
}

variable "domain" {
  description = "domain root to use"
  type        = string
  default     = "cts.enverus.com"
}

variable "cdn_subdomain" {
  description = "cdn subdomain name to use"
  type        = string
  default     = "ext-rs-cdn"
}

variable "api_subdomain" {
  description = "api subdomain name to use"
  type        = string
  default     = "ext-rs-api"
}

variable "dataplane_subdomain" {
  description = "dataplane sub domain name to use"
  type        = string
  default     = "ext-rs-dp"
}

variable "dataplane_origin_account_name" {
  description = "origin dataplane account name to use"
  type        = string
  default     = "enverusluies"
}

================
File: cts/cloudfront/rudderstack/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.19"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "enverus"
      component         = "rudderstack"
      team              = "CorpDataAnalytics@enverus.com"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/main/cloudfront/rudderstack"
      environment       = var.environment
      product           = "shared"
      terraform_created = "true"
    }
  }
}

================
File: cts/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)
        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: cts/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response) 
            return { "parameter": response,"errorMessage":"none" } 
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'
          
          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}
        
        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled' 
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added' 
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'    
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'  
          
          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter'] 
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']
                 
          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)   
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'    
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)           
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.' 

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')
          
          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id) 
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: cts/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: cts/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: cts/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: cts/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: cts/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: cts/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: cts/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: cts/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: cts/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: cts/config/.terraform-version
================
latest:^1.8

================
File: cts/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: cts/config/dev.backend.tfvars
================
key = "360093697111/dev/aws_config/terraform.tfstate"

================
File: cts/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = "2fd6188a-21f3-4014-9e13-012c32f135c3"

================
File: cts/config/main.tf
================
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: cts/config/outputs.tf
================


================
File: cts/config/prod.backend.tfvars
================
key = "316576613383/prod/aws_config/terraform.tfstate"

================
File: cts/config/prod.tfvars
================
environment             = "prod"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: cts/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}

variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: cts/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: cts/consul-cluster/.terraform-version
================
latest

================
File: cts/consul-cluster/dev.backend.tfvars
================
key = "360093697111/dev/consul-cluster/terraform.tfstate"

================
File: cts/consul-cluster/dev.tfvars
================
env                  = "dev"
business-unit        = "cts"
encryption-key       = "ohrDXjezwaIRmcf1sa5kXpDpjKjVS59LX3s8ufupUJE="
aws_region           = "us-east-1"
datacenter           = "aws-ue1"
recursors            = "10.53.8.26 10.52.8.36"
aws-clusters-to-join = "aws-ue1@us-east-1"
vpc-name-tag         = "cts-vpc-dev"
subnet-name-tag      = "*| INSIDE | Private Subnet"
instance_type        = "c6a.large"
vault_path_awx       = "enverus-cts/cts.terraform/awx/dev/"


# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yml",
    git_host      = "enterprise",
    additional_args = [
      "--extra-vars \"ansible_environment_name=dev ansible_business_unit=cts\"",
      "-C main"
    ],
  }
]

================
File: cts/consul-cluster/main.tf
================
# update terraform to plan to test skip apply feature.
module "consul_servers" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.consul-cluster-aws.git?ref=v0.18.7"

  env                     = var.env
  bu                      = var.business-unit
  tagLocation             = var.aws_region
  tagTeam                 = "cts"
  tagSourceCode           = "https://github.com/enverus-cts/cts.terraform/tree/main/consul-cluster"
  encryption_key          = var.encryption-key
  datacenter              = var.datacenter
  recursors               = var.recursors
  aws_clusters_to_join    = var.aws-clusters-to-join
  vmware_clusters_to_join = var.vmware-clusters-to-join
  vpc_name_tag            = var.vpc-name-tag
  spot_price              = var.spot_price
  instance_type           = var.instance_type
  #ansible pull
  vo_routing_key                           = var.vo_routing_key
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

output "consul_servers" {
  value     = module.consul_servers
  sensitive = true
}

# Create network lb to handle TCP connections to edge proxy
data "aws_route53_zone" "cts" {
  name         = "${var.env}.cts.enverus.com"
  private_zone = false
}

data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc-name-tag]
  }
}

data "aws_subnets" "private" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }
  filter {
    name   = "tag:Name"
    values = [var.subnet-name-tag]
  }
}

resource "aws_route53_record" "consul-server-lb" {
  zone_id = data.aws_route53_zone.cts.zone_id
  name    = "consul-aws.${var.env}.cts.enverus.com"
  type    = "A"

  alias {
    name                   = aws_lb.consul-server-lb.dns_name
    zone_id                = aws_lb.consul-server-lb.zone_id
    evaluate_target_health = true
  }
  allow_overwrite = true
}

resource "aws_lb" "consul-server-lb" {
  name                             = "${var.business-unit}-${var.env}-consul-lb"
  internal                         = true
  subnets                          = data.aws_subnets.private.ids
  load_balancer_type               = "network"
  enable_cross_zone_load_balancing = true

  tags = {
    Component = "consul"
    Name      = "${var.business-unit}-${var.env}-consul-lb"
  }
}

resource "aws_lb_target_group" "consul-tg" {
  name                 = "${var.business-unit}-${var.env}-consul-tg"
  port                 = 8500
  protocol             = "TCP"
  vpc_id               = data.aws_vpc.main.id
  deregistration_delay = 30

  health_check {
    path    = "/"
    matcher = "200-399"
  }
}

resource "aws_lb_listener" "consul-listener" {
  load_balancer_arn = aws_lb.consul-server-lb.arn
  port              = 80
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.consul-tg.arn
  }
}

resource "aws_autoscaling_attachment" "consul" {
  autoscaling_group_name = module.consul_servers.asg_name
  lb_target_group_arn    = aws_lb_target_group.consul-tg.arn
}

================
File: cts/consul-cluster/prod.backend.tfvars
================
key = "316576613383/prod/consul-cluster/terraform.tfstate"

================
File: cts/consul-cluster/prod.tfvars
================
env                  = "prod"
business-unit        = "cts"
encryption-key       = "Y1fB1emKjtmr5FLwYa1yFZu54yXlrjww5G6VPmkwX3s="
aws_region           = "us-east-1"
datacenter           = "aws-ue1"
recursors            = "10.53.8.26 10.52.8.36"
aws-clusters-to-join = "aws-ue1@us-east-1"
vpc-name-tag         = "cts-vpc-prod"
subnet-name-tag      = "*| INSIDE | Private Subnet"
instance_type        = "c6a.large"
vault_path_awx       = "enverus-cts/cts.terraform/awx/prod/"


# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=cts\"",
      "-C main"
    ],
  }
]

================
File: cts/consul-cluster/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {
  description = "Environment, eg 'dev'"
}

variable "VAULT_ADDR" {
  description = "Vault Addr"
  type        = string
}

variable "business-unit" {
  description = "Business Unit of cluster, eg. 'cds'"
}

variable "encryption-key" {
  description = "Consul encrypt key used to secure comm. in the cluster (and separate clusters)"
}

variable "recursors" {
  description = "DNS recursors for consul"
}

variable "datacenter" {
  description = "Name of datacenter for consul"
}

variable "vpc-name-tag" {
  description = "Value of tag Name for vpc - used to identify vpc in data sources"
}

variable "subnet-name-tag" {
  description = "Value of tag Name for subnets - used to get private subnets"
}

variable "aws-clusters-to-join" {
  description = "space sep. strings indication clusters to join, format: dc@region"
  default     = ""
}

variable "vmware-clusters-to-join" {
  description = "space sep. strings indication clusters to join, format: di-chi@Chicago"
  default     = ""
}

variable "spot_price" {
  description = "The maximum hourly price to pay for EC2 Spot Instances."
  type        = number
  default     = null
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "assume_role_arn" {}


variable "vo_routing_key" {
  description = "Provide a Victor Ops Routing Key"
  type        = string
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
  default = []
}

================
File: cts/consul-cluster/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4" # this is blocked by hashicorp module using an old version of the ASG resource.
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.business-unit
      Component        = "consul"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/consul-cluster"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "consul" {
  address    = aws_route53_record.consul-server-lb.fqdn
  datacenter = var.datacenter
}

================
File: cts/ecr/.terraform-version
================
latest:^1.10

================
File: cts/ecr/ecr.tf
================
module "sre_ecr" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ecr.git?ref=v0.4.0"

  ecr_name = [
    "argo-cd-target-cluster-manager",
    "argo-cd-target-cluster-manager-chart",
    "enverus-deployment-chart",
    "env-one-api",
    "env-one-frontend"
  ]
  Team         = "sre@enverus.com"
  BusinessUnit = "cts"
}
output "ecr" { value = module.sre_ecr }

================
File: cts/ecr/prod.backend.tfvars
================
key     = "360093697111/prod/ecr/terraform.tfstate"
encrypt = "true"

================
File: cts/ecr/prod.tfvars
================
#Tags
region = "us-east-1"
env    = "prod"

================
File: cts/ecr/variables.tf
================
variable "env" {}

variable "bu" {}

variable "region" {}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: cts/ecr/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.75"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Component        = "ecr"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/ecr"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

================
File: cts/ecr-pull-through-cache/.terraform-version
================
latest:^1.10

================
File: cts/ecr-pull-through-cache/data.tf
================
data "vault_generic_secret" "docker_hub_token" {
  path = "enverus-cts/docker/docker_hub_token"
}

data "vault_generic_secret" "azure_token" {
  path = "enverus-cts/azure-login-creds"
}

================
File: cts/ecr-pull-through-cache/ecr.tf
================
locals {
  docker_secret = {
    username    = data.vault_generic_secret.docker_hub_token.data["username"]
    accessToken = data.vault_generic_secret.docker_hub_token.data["password"]
  }
  azure_secret = {
    username    = data.vault_generic_secret.azure_token.data["ACR_SP_CLIENT_ID"]
    accessToken = data.vault_generic_secret.azure_token.data["ACR_SP_CLIENT_SECRET"]
  }
}

module "secrets_manager_docker" {
  source  = "terraform-aws-modules/secrets-manager/aws"
  version = "~> 1"

  name                    = "ecr-pullthroughcache/docker"
  secret_string           = jsonencode(local.docker_secret)
  recovery_window_in_days = 0 # Set to 0 for testing purposes, this will immediately delete the secret. This action is irreversible.
}

module "secrets_manager_enverus_acr" {
  source  = "terraform-aws-modules/secrets-manager/aws"
  version = "~> 1"

  name                    = "ecr-pullthroughcache/enverus-acr"
  secret_string           = jsonencode(local.azure_secret)
  recovery_window_in_days = 0 # Set to 0 for testing purposes, this will immediately delete the secret. This action is irreversible.
}

module "sre_ecr" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ecr.git?ref=v0.4.0"
  pull_through_cache = true

  registry_pull_through_cache_rules = {
    ecr = {
      ecr_repository_prefix = "ecr-public"
      upstream_registry_url = "public.ecr.aws"
    }
    k8s = {
      ecr_repository_prefix = "k8s"
      upstream_registry_url = "registry.k8s.io"
    }
    quay = {
      ecr_repository_prefix = "quay"
      upstream_registry_url = "quay.io"
    }
    dockerhub = {
      ecr_repository_prefix = "docker-hub"
      upstream_registry_url = "registry-1.docker.io"
      credential_arn        = module.secrets_manager_docker.secret_arn
    }
    devprismcr-acr = {
      ecr_repository_prefix = "devprismcr-acr"
      upstream_registry_url = "devprismcr.azurecr.io"
      credential_arn        = module.secrets_manager_enverus_acr.secret_arn
    }
    enverus-acr = {
      ecr_repository_prefix = "enverus-acr"
      upstream_registry_url = "enverus.azurecr.io"
      credential_arn        = module.secrets_manager_enverus_acr.secret_arn
    }
    enverusforecast-acr = {
      ecr_repository_prefix = "enverusforecast-acr"
      upstream_registry_url = "enverusforecast.azurecr.io"
      credential_arn        = module.secrets_manager_enverus_acr.secret_arn
    }
    enverusprism-acr = {
      ecr_repository_prefix = "enverusprism-acr"
      upstream_registry_url = "enverusprism.azurecr.io"
      credential_arn        = module.secrets_manager_enverus_acr.secret_arn
    }
    rsegdatascience-acr = {
      ecr_repository_prefix = "rsegdatascience-acr"
      upstream_registry_url = "rsegdatascience.azurecr.io"
      credential_arn        = module.secrets_manager_enverus_acr.secret_arn
    }
  }

  manage_registry_scanning_configuration = true
  registry_scan_type                     = "ENHANCED"
  registry_scan_rules = [
    {
      scan_frequency = "CONTINUOUS_SCAN"
      filter = [
        {
          filter      = "*"
          filter_type = "WILDCARD"
        },
      ]
    }
  ]

  ecr_name     = var.ecr_name
  Team         = "sre@enverus.com"
  BusinessUnit = "cts"
}
output "ecr" { value = module.sre_ecr }

================
File: cts/ecr-pull-through-cache/prod.backend.tfvars
================
key     = "360093697111/prod/ecr-pull-through-cache/terraform.tfstate"
encrypt = "true"

================
File: cts/ecr-pull-through-cache/prod.tfvars
================
env    = "prod"
ecr_name = [
    "pull-through-cache",
]

================
File: cts/ecr-pull-through-cache/variables.tf
================
variable "env" {}

variable "bu" {}

variable "region" {}

variable "ecr_name" {
  description = "ecr name"
  type        = list(string)
}

variable "VAULT_ADDR" {
  description = "Address of Hashicorp Vault"
  type        = string
  default     = "https://vault.prod.cts.enverus.com"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: cts/ecr-pull-through-cache/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.75"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Component        = "ecr"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/ecr"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/enverus-cts/cts.terraform.tfvars
================
vpc_tag          = "cts-vpc-dev"
cluster_basename = "cts-dev-013"
aws_region       = "us-east-1"
enverus_tags = {
  BusinessUnit = "CTS-Dev"
  Team         = "sre@enverus.com"
  SourceCode   = "https://github.com/enverus-cts/cts.terraform/eks-clusters"
  Environment  = "dev"
  Product      = "nexus"
  Component    = "ekscluster-"
}

================
File: cts/github/oidc/custom-roles/packer/.terraform-version
================
latest:^1.6

================
File: cts/github/oidc/custom-roles/packer/dev.backend.tfvars
================
key = "360093697111/dev/github-oidc/custom-role/packer/terraform.state"

================
File: cts/github/oidc/custom-roles/packer/dev.tfvars
================
environment = "dev"
allow_list_github_organizations = [
  "repo:enverus-cts/terraform-aws-github-runner:*",
  "repo:enverus-cts/sre.packer.spike:*",
]

================
File: cts/github/oidc/custom-roles/packer/main.tf
================
data "aws_caller_identity" "current" {}

# This policy enables a runner to perform Packer actions using aws ec2 instances

data "aws_iam_openid_connect_provider" "gh_oidc_provider" {
  url = "https://token.actions.githubusercontent.com"
}
data "aws_iam_policy_document" "github_actions_oidc_packer_trust_relationship" {
  statement {
    sid    = "ExplicitSelfRoleAssumption"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]

    principals {
      type        = "AWS"
      identifiers = ["*"]
    }

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values   = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:github_actions_oidc_packer_role"]
    }
  }

  statement {
    sid    = "AWSRootAllowAssumeRole"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]
    principals {
      type        = "AWS"
      identifiers = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"]
    }
  }

  statement {
    sid    = "AllowEc2InstanceAssumeRole"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]
    principals {
      type        = "Service"
      identifiers = ["ec2.amazonaws.com"]
    }
  }
  statement {
    sid    = "GitHubActionsOidcPackerAssumeRole"
    effect = "Allow"
    principals {
      type        = "Federated"
      identifiers = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:oidc-provider/${data.aws_iam_openid_connect_provider.gh_oidc_provider.url}"]
    }
    actions = ["sts:AssumeRoleWithWebIdentity"]
    condition {
      test     = "StringLike"
      variable = "token.actions.githubusercontent.com:sub"
      values   = var.allow_list_github_organizations
    }
    condition {
      test     = "ForAllValues:StringEquals"
      variable = "token.actions.githubusercontent.com:iss"
      values   = ["https://token.actions.githubusercontent.com"]
    }
    condition {
      test     = "ForAllValues:StringEquals"
      variable = "token.actions.githubusercontent.com:aud"
      values   = ["sts.amazonaws.com"]
    }
  }
}

data "aws_iam_policy_document" "github_actions_oidc_packer_policy" {
  statement {
    sid    = "AllPackerActions"
    effect = "Allow"
    actions = [
      "ec2:AttachVolume",
      "ec2:AuthorizeSecurityGroupIngress",
      "ec2:CopyImage",
      "ec2:CreateImage",
      "ec2:CreateKeypair",
      "ec2:CreateSecurityGroup",
      "ec2:CreateSnapshot",
      "ec2:CreateTags",
      "ec2:CreateVolume",
      "ec2:DeleteKeyPair",
      "ec2:DeleteSecurityGroup",
      "ec2:DeleteSnapshot",
      "ec2:DeleteVolume",
      "ec2:DeregisterImage",
      "ec2:DescribeImageAttribute",
      "ec2:DescribeImages",
      "ec2:DescribeInstances",
      "ec2:DescribeInstanceStatus",
      "ec2:DescribeRegions",
      "ec2:DescribeSecurityGroups",
      "ec2:DescribeSnapshots",
      "ec2:DescribeSubnets",
      "ec2:DescribeTags",
      "ec2:DescribeVolumes",
      "ec2:DetachVolume",
      "ec2:GetPasswordData",
      "ec2:ModifyImageAttribute",
      "ec2:ModifyInstanceAttribute",
      "ec2:ModifySnapshotAttribute",
      "ec2:RegisterImage",
      "ec2:RunInstances",
      "ec2:StopInstances",
      "ec2:TerminateInstances",
      "iam:PassRole",
      "iam:GetInstanceProfile"
    ]
    resources = [
      "*"
    ]
  }
}

resource "aws_iam_role" "github_actions_oidc_packer_role" {
  name                 = "github_actions_oidc_packer_role"
  description          = "GitHub Actions Runner instance role can perform Packer operations through OIDC filtered by GitHub Org ACL"
  assume_role_policy   = data.aws_iam_policy_document.github_actions_oidc_packer_trust_relationship.json
  max_session_duration = 10800 # 3 hours - Packer builds take < 3 hours
}
output "aws_iam_role_github_actions_oidc_packer_role" { value = aws_iam_role.github_actions_oidc_packer_role }

resource "aws_iam_role_policy" "github_actions_runner_packer_policy" {
  name_prefix = "github_actions_runner_oidc_packer_policy-" # Use alphanumeric and '+=,.@-_' characters. Maximum 128 characters. # Minus 26 from the prefix
  role        = aws_iam_role.github_actions_oidc_packer_role.name
  policy      = data.aws_iam_policy_document.github_actions_oidc_packer_policy.json
}
output "aws_iam_role_policy_github_actions_runner_packer_policy" { value = aws_iam_role_policy.github_actions_runner_packer_policy }

================
File: cts/github/oidc/custom-roles/packer/prod.backend.tfvars
================
key = "316576613383/prod/github-oidc/custom-role/packer/terraform.state"

================
File: cts/github/oidc/custom-roles/packer/prod.tfvars
================
environment = "prod"
allow_list_github_organizations = [
  "repo:enverus-cts/terraform-aws-github-runner:*",
  "repo:enverus-cts/sre.packer.spike:*",
]

================
File: cts/github/oidc/custom-roles/packer/variables.tf
================
variable "aws_region" {
  type    = string
  default = "us-east-1"
}
variable "assume_role_arn" {
  description = "Assume role for terraform provider"
  type        = string
}
variable "environment" {
  description = "deployment environment, dev, preprod, prod"
  type        = string
}

variable "allow_list_github_organizations" {
  description = "ACL for which enverus GH orgs can assume this role"
  type        = list(string)
}

================
File: cts/github/oidc/custom-roles/packer/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "cts"
      component         = "github-oidc"
      team              = "sre@enverus.com"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/oidc/custom-roles/packer"
      environment       = var.environment
      product           = "nexus"
      terraform_created = "true"
    }
  }
}

================
File: cts/github/oidc/custom-roles/.terraform-version
================
latest:^1.3

================
File: cts/github/oidc/idp/.terraform-version
================
latest:^1.6

================
File: cts/github/oidc/idp/dev.backend.tfvars
================
key = "360093697111/dev/github/oidc/idp/terraform.state"

================
File: cts/github/oidc/idp/main.tf
================
data "tls_certificate" "github" {
  # Per https://github.blog/changelog/2023-06-27-github-actions-update-on-oidc-integration-with-aws/
  url = "https://token.actions.githubusercontent.com/.well-known/openid-configuration"
}
output "data_tls_certificate_github" { value = data.tls_certificate.github }

resource "aws_iam_openid_connect_provider" "gh_oidc_provider" {
  url = "https://token.actions.githubusercontent.com"
  client_id_list = [
    "sts.amazonaws.com"
  ]

  # Add any _known_ thumbprints here. If they do change you will need to update.
  # At least this will capture any new ones that might be added.
  thumbprint_list = distinct(
    concat(
      [
        "6938fd4d98bab03faadb97b34396831e3780aea1",
        "1c58a3a8518e8759bf075b76b750d4f2df264fcd",
      ],
      [for certificate in data.tls_certificate.github.certificates : certificate.sha1_fingerprint if certificate.is_ca]
    )
  )
}
output "aws_iam_openid_connect_provider_gh_oidc_provider" { value = aws_iam_openid_connect_provider.gh_oidc_provider }

================
File: cts/github/oidc/idp/prod.backend.tfvars
================
key = "316576613383/prod/github/oidc/idp/terraform.state"

================
File: cts/github/oidc/idp/variables.tf
================
variable "aws_region" {
  type    = string
  default = "us-east-1"
}

variable "assume_role_arn" {
  type = string
}

================
File: cts/github/oidc/idp/versions.tf
================
terraform {
  required_version = ">= 1.6"
  backend "s3" {}
  required_providers {
    aws = {
      source = "hashicorp/aws",
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "cts"
      component         = "github-oidc"
      product           = "nexus"
      team              = "sre@enverus.com"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/oidc/ipd"
      terraform_created = "true"
    }
  }
}

================
File: cts/github/oidc/sre-roles/.terraform-version
================
latest:^1.6

================
File: cts/github/oidc/sre-roles/dev.backend.tfvars
================
key = "360093697111/dev/github-oidc/terraform.state"

================
File: cts/github/oidc/sre-roles/dev.tfvars
================
environment = "dev"
allow_list_github_organizations = [
  "CourthouseDirect/*",
  "drillinginfo-private/*",
  "DrillingInfo/*",
  "enverus-cts-sandbox/*",
  "enverus-cts/*",
  "enverus-ea/*",
  "enverus-it/*",
  "enverus-pr/*",
  "enverus-tr/*",
  "Enverus/*",
  "Q-Engineering/*",
  "RSEnergyGroup/*",
]

================
File: cts/github/oidc/sre-roles/main.tf
================
data "aws_caller_identity" "current" {}

# This policy enables a runner to perform actions against AWS ECR

data "aws_iam_openid_connect_provider" "gh_oidc_provider" {
  url = "https://token.actions.githubusercontent.com"
}
data "aws_iam_policy_document" "github_actions_oidc_trust_relationship" {
  statement {
    sid    = "ExplicitSelfRoleAssumption"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]

    principals {
      type        = "AWS"
      identifiers = ["*"]
    }

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values   = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:github_actions_oidc_ecr_role"]
    }
  }

  statement {
    sid    = "AWSRootAllowAssumeRole"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]
    principals {
      type        = "AWS"
      identifiers = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"]
    }
  }

  statement {
    sid    = "AllowEc2InstanceAssumeRole"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]
    principals {
      type        = "Service"
      identifiers = ["ec2.amazonaws.com"]
    }
  }
  statement {
    sid    = "GitHubActionsOidcAssumeRole"
    effect = "Allow"
    principals {
      type        = "Federated"
      identifiers = ["arn:aws:iam::${data.aws_caller_identity.current.account_id}:oidc-provider/${data.aws_iam_openid_connect_provider.gh_oidc_provider.url}"]
    }
    actions = ["sts:AssumeRoleWithWebIdentity"]
    condition {
      test     = "StringLike"
      variable = "token.actions.githubusercontent.com:sub"
      values = [
        "repo:Bid-Out/*",
        "repo:CourthouseDirect/*",
        "repo:drillinginfo-private/*",
        "repo:DrillingInfo/*",
        "repo:enverus-ba/*",
        "repo:enverus-cts/*",
        "repo:enverus-cts-sandbox/*",
        "repo:enverus-ea/*",
        "repo:enverus-it/*",
        "repo:enverus-nv/*",
        "repo:enverus-pr/*",
        "repo:enverus-tr/*",
        "repo:Enverus/*",
        "repo:Q-Engineering/*",
        "repo:RSEnergyGroup/*",
      ]
    }
    condition {
      test     = "ForAllValues:StringEquals"
      variable = "token.actions.githubusercontent.com:iss"
      values   = ["https://token.actions.githubusercontent.com"]
    }
    condition {
      test     = "ForAllValues:StringEquals"
      variable = "token.actions.githubusercontent.com:aud"
      values   = ["sts.amazonaws.com"]
    }
  }
}

data "aws_iam_policy_document" "github_actions_oidc_ecr_policy" {
  statement {
    sid    = "AllEcrActions"
    effect = "Allow"
    actions = [
      "ecr:BatchCheckLayerAvailability",
      "ecr:BatchGetImage",
      "ecr:CompleteLayerUpload",
      "ecr:DescribeRepositories",
      "ecr:GetAuthorizationToken",
      "ecr:GetDownloadUrlForLayer",
      "ecr:InitiateLayerUpload",
      "ecr:ListImages",
      "ecr:PutImage",
      "ecr:TagResource",
      "ecr:UploadLayerPart",
      "secretsmanager:GetSecretValue",
    ]
    resources = [
      "*"
    ]
  }
}

# Note: If you change the name of this role, plese chage it here as well (see Sid: AllowPullPush).
# https://git.drillinginfo.com/TF-Modules/tf_module_ecr/blob/master/ecr.tf
resource "aws_iam_role" "github_actions_oidc_ecr_role" {
  name               = "github_actions_oidc_ecr_role"
  description        = "Github Actions Runner instance role can perform ECR operations though OIDC filtered by Gihub Org ACL"
  assume_role_policy = data.aws_iam_policy_document.github_actions_oidc_trust_relationship.json
}
output "aws_iam_role_github_actions_oidc_ecr_role" { value = aws_iam_role.github_actions_oidc_ecr_role }

resource "aws_iam_role_policy" "github_actions_runner_ecr_policy" {
  name_prefix = "github_actions_runner_oidc_ecr_policy-" # Use alphanumeric and '+=,.@-_' characters. Maximum 128 characters. # Minus 26 from the prefix
  role        = aws_iam_role.github_actions_oidc_ecr_role.name
  policy      = data.aws_iam_policy_document.github_actions_oidc_ecr_policy.json
}
output "aws_iam_role_policy_github_actions_runner_ecr_policy" { value = aws_iam_role_policy.github_actions_runner_ecr_policy }

================
File: cts/github/oidc/sre-roles/prod.backend.tfvars
================
key = "316576613383/prod/github-oidc/terraform.state"

================
File: cts/github/oidc/sre-roles/prod.tfvars
================
environment = "prod"
allow_list_github_organizations = [
  "CourthouseDirect/*",
  "drillinginfo-private/*",
  "DrillingInfo/*",
  "enverus-cts-sandbox/*",
  "enverus-cts/*",
  "enverus-ea/*",
  "enverus-it/*",
  "enverus-pr/*",
  "enverus-tr/*",
  "Enverus/*",
  "Q-Engineering/*",
  "RSEnergyGroup/*",
]

================
File: cts/github/oidc/sre-roles/variables.tf
================
variable "aws_region" {
  type    = string
  default = "us-east-1"
}
variable "assume_role_arn" {
  description = "Assume role for terraform provider"
  type        = string
}
variable "environment" {
  description = "deployment environment, dev, preprod, prod"
  type        = string
}

================
File: cts/github/oidc/sre-roles/versions.tf
================
terraform {
  required_version = ">= 1.6"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.5"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "cts"
      component         = "github-oidc"
      team              = "sre@enverus.com"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/oidc/sre-roles"
      environment       = var.environment
      product           = "nexus"
      terraform_created = "true"
    }
  }
}

================
File: cts/github/runners/templates/ba-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/ba-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/bidout-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/bidout-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 3
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/cts-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/cts-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/ea-runner-configs/arm64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-arm64-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: arm64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - x2gd.large
    - x2gd.xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-arm64-202507302219
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/ea-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/ea-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-7"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/nv-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/nv-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-7"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/pr-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/pr-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/rseg-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/rseg-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 3
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/sandbox-runner-configs/arm64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-arm64-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: arm64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - x2gd.large
    - x2gd.xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-arm64-202507302219
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/sandbox-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  # runner_name_prefix: enverus-cts-sandbox-lg
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202507291511
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/sandbox-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  # runner_name_prefix: enverus-cts-sandbox
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202507291511
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 1
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/tr-runner-configs/x64-lg.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu-large]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - m6i.4xlarge
    - m6a.4xlarge
  instance_target_capacity_type: "on-demand"
  instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 4
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 0
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/templates/tr-runner-configs/x64.yaml
================
matcherConfig:
  exactMatch: true
  labelMatchers:
    - [enverus-ubuntu]
fifo: true
redrive_build_queue:
  enabled: false
  maxReceiveCount: null
runner_config:
  vpc_id: ${vpc_id}
  subnet_ids: ${subnet_ids}
  runner_os: linux
  runner_architecture: x64
  runner_run_as: ubuntu
  enable_ssm_on_runners: true
  enable_job_queued_check: true
  instance_types:
    - r7a.xlarge
    - r7i.xlarge
    - r6a.xlarge
    - r6i.xlarge
    - r5a.xlarge
    - m7a.2xlarge
    - m7i.2xlarge
    - c7a.4xlarge
    - c7i.4xlarge
  instance_target_capacity_type: "on-demand"
  # instance_allocation_strategy: "price-capacity-optimized"
  runners_maximum_count: 30
  delay_webhook_event: 0
  scale_down_schedule_expression: cron(* * * * ? *)
  userdata_template: ""
  instance_profile_path: "/github-action-runners/"
  role_path: "/github-action-runners/"
  enable_organization_runners: true
  ami_owners:
    - "316576613383" # CTS-Prod
  ami_filter:
    name:
      - github-runner-ubuntu-noble-amd64-202505201821
    state:
      - available
  idle_config:
    - cron: "* * * * * 1-5"
      timeZone: "America/Chicago"
      idleCount: 3
      evictionStrategy: "oldest_first"
  block_device_mappings:
    - device_name: /dev/xvda
      delete_on_termination: true
      volume_type: gp3
      volume_size: 200
      encrypted: true
      iops: null
      throughput: null
      kms_key_id: null
      snapshot_id: null
  runner_log_files:
    - log_group_name: syslog
      prefix_log_group: true
      file_path: /var/log/syslog
      log_stream_name: "{instance_id}"
    - log_group_name: user_data
      prefix_log_group: true
      file_path: /var/log/user-data.log
      log_stream_name: "{instance_id}/user_data"
    - log_group_name: runner
      prefix_log_group: true
      file_path: /opt/actions-runner/_diag/Runner_**.log
      log_stream_name: "{instance_id}/runner"
  runner_metadata_options:
    instance_metadata_tags: disabled
    http_endpoint: enabled
    http_tokens: optional
    http_put_response_hop_limit: 3
  runner_iam_role_managed_policy_arns:
    - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  runner_additional_security_group_ids:
    - sg-0f4582978b3f60c9c

================
File: cts/github/runners/.terraform-version
================
latest:^1.12

================
File: cts/github/runners/iam.tf
================
# Runner Tools S3 Bucket Access Policy Document
data "aws_iam_policy_document" "github_actions_runner_s3_tools_access" {
  statement {
    sid    = "AllowS3ToolsBucketAccess"
    effect = "Allow"
    actions = [
      "s3:GetObject",
      "s3:ListBucket"
    ]
    resources = [
      "arn:aws:s3:::${var.runner_tools_bucket_name}",
      "arn:aws:s3:::${var.runner_tools_bucket_name}/*"
    ]
  }
}

data "aws_iam_policy_document" "runner_imdsv2_policy" {
  statement {
    effect = "Allow"
    actions = [
      "ec2:ModifyInstanceMetadataOptions",
      "ec2:DescribeInstances"
    ]
    resources = ["*"]
  }
}

# Helix security Policy Document
data "aws_iam_policy_document" "helix_agent_policy" {
  statement {
    effect = "Allow"
    actions = [
      "s3:GetObjectAcl",
      "s3:GetObject",
      "s3:GetObjectRetention",
      "s3:GetObjectVersionTagging",
      "s3:ListBucketVersions",
      "s3:GetObjectAttributes",
      "s3:GetObjectVersionAcl",
      "s3:GetObjectTagging",
      "s3:ListBucket",
      "s3:GetObjectVersionForReplication",
      "s3:GetObjectVersionAttributes",
      "s3:GetObjectVersion"
    ]
    resources = [
      "arn:aws:s3:::enverus-security-shared-files/*",
      "arn:aws:s3:::enverus-security-shared-files"
    ]
  }
  statement {
    effect = "Allow"
    actions = [
      "s3:ListAllMyBuckets"
    ]
    resources = ["*"]
  }

  statement {
    effect = "Allow"
    actions = [
      "kms:Decrypt"
    ]
    resources = ["*"]
  }
}

# ECR Policy Document Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_ecr" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleECR"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/github_actions_oidc_ecr_role"
    ]
  }
}

# Packer Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_packer" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRolePacker"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/github_actions_oidc_packer_role"
    ]
  }
}

# refinery-dev Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_refinery_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleRefineryDev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::070551638384:role/gh_actions_oidc_refinery_dev_role"
    ]
  }
}

# refinery-preprod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_refinery_preprod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleRefineryPreprod"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::155171951664:role/gh_actions_oidc_refinery_preprod_role"
    ]
  }
}

# refinery-prod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_refinery_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleRefineryProd"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::155171951664:role/gh_actions_oidc_refinery_prod_role"
    ]
  }
}

# mv-conn-pythonsdk-s3-dev Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleMvConnPythons3Dev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::281213658332:role/gh_actions_oidc_mv_connectivity_pythonsdk_s3_role"
    ]
  }
}

# mv-conn-pythonsdk-s3-prod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleRoleMvConnPythons3Prod"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::255488600921:role/gh_actions_oidc_mv_connectivity_matlabsdk_role"
    ]
  }
}

# mv-conn-matlabsdk-s3-dev Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleMvConnMatlabs3Dev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::281213658332:role/gh_actions_oidc_mv_connectivity_matlabsdk_role"
    ]
  }
}

# mv-conn-matlabsdk-s3-prod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleRoleMvConnMatlabs3Prod"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::255488600921:role/gh_actions_oidc_mv_connectivity_matlabsdk_s3_role"
    ]
  }
}


# NV Infra Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_nv_infra" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleNVInfra"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::772933491746:role/github_actions_oidc_nv_infra_role"
    ]
  }
}

# TR Dev Infra Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_tr_dev_infra" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleTRDevInfra"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::476940017439:role/github_actions_oidc_tr_dev_infra_role"
    ]
  }
}

# TR prod Infra Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_tr_prod_infra" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleTRProdInfra"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::255488600921:role/github_actions_oidc_tr_prod_infra_role"
    ]
  }
}


# SharedGenAI Dev Infra Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_shared_genai_dev_infra" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleSharedGenAiInfra"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::891150701981:role/github_actions_oidc_shared_genai_infra_role"
    ]
  }
}

# SharedGenAI Prod Infra Policy Document
data "aws_iam_policy_document" "github_actions_runner_assume_role_oidc_shared_genai_prod_infra" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleSharedGenAiInfra"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::126127704198:role/github_actions_oidc_shared_genai_infra_role"
    ]
  }
}

# llandman dev policy document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_llandman_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleLandmanDev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::070551638384:role/gh_actions_oidc_llandman_dev_role"
    ]
  }
}

# llandman prod policy document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_llandman_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleLandmanProd"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::070551638384:role/gh_actions_oidc_llandman_prod_role"
    ]
  }
}

# directaccess-dev Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_directaccess_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleDirectAccessDev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::070551638384:role/gh_actions_oidc_directaccess_dev_role"
    ]
  }
}

# directaccess-preprod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_directaccess_preprod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleDirectAccessPreprod"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::155171951664:role/gh_actions_oidc_directaccess_preprod_role"
    ]
  }
}

# directaccess-prod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_directaccess_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleDirectAccessProd"
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    resources = [
      "arn:aws:iam::155171951664:role/gh_actions_oidc_directaccess_prod_role"
    ]
  }
}

# PR cdr-exporter-dev Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_cdr_exporter_dev" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleCDRExporterDev"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession"
    ]
    resources = [
      "arn:aws:iam::040927785588:role/cdr_exporter_role"
    ]
  }
}

# PR cdr-exporter-prod Policy Document
data "aws_iam_policy_document" "gh_actions_runner_assume_role_oidc_cdr_exporter_prod" {
  statement {
    sid    = "GithubRunnerInstanceAssumeRoleCDRExporterProd"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession"
    ]
    resources = [
      "arn:aws:iam::330682006453:role/cdr_exporter_role"
    ]
  }
}


# ECR Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_ecr_policy" {
  name        = "github_actions_runner_assume_role_oidc_ecr_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_ecr_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_ecr.json
}

# Packer Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_packer_policy" {
  name        = "github_actions_runner_assume_role_oidc_packer_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_packer_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_packer.json
}

# NV Prod Infra Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_nv_infra_policy" {
  name        = "github_actions_runner_assume_role_oidc_nv_infra_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_nv_infra_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_nv_infra.json
}

# TR Dev Infra Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_tr_dev_infra_policy" {
  name        = "github_actions_runner_assume_role_oidc_tr_dev_infra_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_tr_dev_infra_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_tr_dev_infra.json
}

# TR Prod Infra Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_tr_prod_infra_policy" {
  name        = "github_actions_runner_assume_role_oidc_tr_prod_infra_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_tr_prod_infra_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_tr_prod_infra.json
}

# Shared GenAI Dev Infra Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_shared_genai_dev_infra_policy" {
  name        = "github_actions_runner_assume_role_oidc_shared_genai_dev_infra_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_shared_genai_dev_infra_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_shared_genai_dev_infra.json
}

# Shared GenAI Prod Infra Policy
resource "aws_iam_policy" "github_actions_runner_assume_role_oidc_shared_genai_prod_infra_policy" {
  name        = "github_actions_runner_assume_role_oidc_shared_genai_prod_infra_policy"
  description = "Allows Github Runner Instances to assume role to github_actions_oidc_shared_genai_prod_infra_role"
  policy      = data.aws_iam_policy_document.github_actions_runner_assume_role_oidc_shared_genai_prod_infra.json
}

# Refinery Dev Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_refinery_dev_policy" {
  name        = "gh_actions_runner_assume_role_oidc_refinery_dev_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_refinery_dev_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_dev.json
}

# Refinery Preprod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_refinery_preprod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_refinery_preprod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_refinery_preprod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_preprod.json
}

# Refinery Prod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_refinery_prod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_refinery_prod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_refinery_prod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_prod.json
}

# Helix Agent Policy
resource "aws_iam_policy" "github_actions_runner_imdsv2_policy" {
  name_prefix = "github_actions_runner_imdsv2_policy"
  description = "IAM Policy to allow runner to modify its imdsv2 metadata"
  policy      = data.aws_iam_policy_document.runner_imdsv2_policy.json
}

# Helix Agent Policy
resource "aws_iam_policy" "github_actions_runner_helix_agent_policy" {
  name_prefix = "github_actions_runner_helix_agent_policy"
  description = "IAM Policy to allow installation of Helix-Agent securiy"
  policy      = data.aws_iam_policy_document.helix_agent_policy.json
}

# Runner Tools S3 Bucket Access Policy
resource "aws_iam_policy" "github_actions_runner_s3_tools_access_policy" {
  name        = "github_actions_runner_s3_tools_access_policy"
  description = "Allows Github Runner Instances to download tools from S3 bucket"
  policy      = data.aws_iam_policy_document.github_actions_runner_s3_tools_access.json
}

# gh_actions_oidc_mv_connectivity_pythonsdk_s3_role Dev Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev_policy" {
  name        = "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_mv_conn_pythonsdk_s3_dev_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev.json
}

# gh_actions_oidc_mv_connectivity_pythonsdk_s3_role Prod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_mv_conn_pythonsdk_s3_prod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod.json
}

# gh_actions_oidc_mv_connectivity_matlabsdk_s3_role Dev Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev_policy" {
  name        = "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_mv_conn_matlabsdk_s3_dev_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev.json
}

# gh_actions_oidc_mv_connectivity_matlabsdk_s3_role Prod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_mv_conn_matlabsdk_s3_prod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod.json
}

# llandman Dev Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_llandman_dev_policy" {
  name        = "gh_actions_runner_assume_role_oidc_llandman_dev_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_llandman_dev_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_llandman_dev.json
}

# llandman Prod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_llandman_prod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_llandman_prod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_llandman_prod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_llandman_prod.json
}

# DirectAccess Dev Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_directaccess_dev_policy" {
  name        = "gh_actions_runner_assume_role_oidc_directaccess_dev_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_directaccess_dev_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_dev.json
}

# DirectAccess Preprod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_directaccess_preprod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_directaccess_preprod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_directaccess_preprod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_preprod.json
}

# DirectAccess Prod Policy
resource "aws_iam_policy" "gh_actions_runner_assume_role_oidc_directaccess_prod_policy" {
  name        = "gh_actions_runner_assume_role_oidc_directaccess_prod_policy"
  description = "Allows Github Runner Instances to assume role to gh_actions_oidc_directaccess_prod_role"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_prod.json
}

# CDR Exporter Policy Dev
resource "aws_iam_policy" "github_actions_runner_assume_role_cdr_exporter_dev_policy" {
  name        = "github_actions_runner_assume_role_cdr_exporter_dev_policy"
  description = "Allows Github Runner Instances to assume role to cdr_exporter_role dev"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_cdr_exporter_dev.json
}

# CDR Exporter Policy Prod
resource "aws_iam_policy" "github_actions_runner_assume_role_cdr_exporter_prod_policy" {
  name        = "github_actions_runner_assume_role_cdr_exporter_prod_policy"
  description = "Allows Github Runner Instances to assume role to cdr_exporter_role prod"
  policy      = data.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_cdr_exporter_prod.json
}

================
File: cts/github/runners/main.tf
================
locals {
  # GitHub App Ids
  # github app id from the GitHub app configured in this step: https://github.com/enverus-cts/terraform-aws-github-runner#setup-github-app-part-1
  bidout_github_app_id              = "980486" # bid-out-gha-runners github app name
  enverus_ba_github_app_id          = "294277" # enverus-ba-gha-runners github app name
  enverus_cts_github_app_id         = "169636" # enverus-cts-terraform github app name
  enverus_cts_sandbox_github_app_id = "167604" # ghe runner app github app name
  enverus_ea_github_app_id          = "188034" # enverus-ea-terraform github app name
  enverus_nv_github_app_id          = "303261" # enverus-nv-gha-runners github app name
  enverus_pr_github_app_id          = "172715" # enverus-pr-gha-runners github app name
  enverus_tr_github_app_id          = "171809" # enverus-tr-gha-runner-app github app name
  rseg_github_app_id                = "173116" # enverus-rseg-gha-runners github app name

  # GitHub App Installation IDS
  # Comes from the URL of the install github app
  bidout_github_app_installation_id              = "54210148"
  enverus_ba_github_app_installation_id          = "34265536"
  enverus_cts_github_app_installation_id         = "23087522"
  enverus_cts_sandbox_github_app_installation_id = "22670687"
  enverus_ea_github_app_installation_id          = "24743421"
  enverus_nv_github_app_installation_id          = "35061924"
  enverus_pr_github_app_installation_id          = "23300949"
  enverus_tr_github_app_installation_id          = "23186239"
  rseg_github_app_installation_id                = "23335912"

  # Github Orgnization Names
  bidout_org_name              = "Bid-Out"
  enverus_ba_org_name          = "enverus-ba"
  enverus_cts_org_name         = "enverus-cts"
  enverus_cts_sandbox_org_name = "enverus-cts-sandbox"
  enverus_ea_org_name          = "enverus-ea"
  enverus_nv_org_name          = "enverus-nv"
  enverus_pr_org_name          = "enverus-pr"
  enverus_tr_org_name          = "enverus-tr"
  rseg_org_name                = "RSEnergyGroup"

  # Load ba runner configurations from Yaml files
  ba_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/ba-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/ba-runner-configs/${c}"))
  }

  # Load bidout runner configurations from Yaml files
  bidout_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/bidout-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/bidout-runner-configs/${c}"))
  }

  # Load cts runner configurations from Yaml files
  cts_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/cts-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/cts-runner-configs/${c}"))
  }

  # Load ea runner configurations from Yaml files
  ea_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/ea-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/ea-runner-configs/${c}"))
  }

  # Load nv runner configurations from Yaml files
  nv_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/nv-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/nv-runner-configs/${c}"))
  }

  # Load nv runner configurations from Yaml files
  pr_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/pr-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/pr-runner-configs/${c}"))
  }

  # Load nv runner configurations from Yaml files
  rseg_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/rseg-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/rseg-runner-configs/${c}"))
  }

  # Load sandbox runner configurations from Yaml files
  sandbox_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/sandbox-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/sandbox-runner-configs/${c}"))
  }

  # Load tr runner configurations from Yaml files
  tr_multi_runner_config_files = {
    for c in fileset("${path.module}/templates/tr-runner-configs", "*.yaml") :

    trimsuffix(c, ".yaml") => yamldecode(file("${path.module}/templates/tr-runner-configs/${c}"))
  }

  ba_multi_runner_config = {
    for k, v in local.ba_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  bidout_multi_runner_config = {
    for k, v in local.bidout_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  cts_multi_runner_config = {
    for k, v in local.cts_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  ea_multi_runner_config = {
    for k, v in local.ea_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  nv_multi_runner_config = {
    for k, v in local.nv_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  pr_multi_runner_config = {
    for k, v in local.pr_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  rseg_multi_runner_config = {
    for k, v in local.rseg_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  sandbox_multi_runner_config = {
    for k, v in local.sandbox_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

  tr_multi_runner_config = {
    for k, v in local.tr_multi_runner_config_files :

    k => merge(
      v,
      {
        runner_config = merge(
          v.runner_config,
          {
            subnet_ids = lookup(v.runner_config, "subnet_ids", null) != null ? [data.aws_subnets.private_subnets.ids[0]] : null
            vpc_id     = lookup(v.runner_config, "vpc_id", null) != null ? data.aws_vpc.main.id : null
          }
        )
      }
    )
  }

}

data "aws_caller_identity" "current" {}

data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*| INSIDE |*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

module "enverus-ba" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-ba
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_ba_org_name])
  github_app_id                        = local.enverus_ba_github_app_id
  business_unit                        = "ba"
  environment                          = var.environment
  github_organization_name             = local.enverus_ba_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore",
  ]

  multi_runner_config = local.ba_multi_runner_config
}

module "enverus-bidout" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.bidout
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.bidout_org_name])
  github_app_id                        = local.bidout_github_app_id
  business_unit                        = "bidout"
  environment                          = var.environment
  github_organization_name             = local.bidout_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.bidout_multi_runner_config
}

module "enverus-cts" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-cts
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_cts_org_name])
  github_app_id                        = local.enverus_cts_github_app_id
  business_unit                        = "cts"
  environment                          = var.environment
  github_organization_name             = local.enverus_cts_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_packer_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    aws_iam_policy.github_actions_runner_s3_tools_access_policy.arn,
    "arn:aws:iam::316576613383:policy/github-runner-policy",
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.cts_multi_runner_config
}

module "enverus-cts-sandbox" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-cts-sandbox
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_cts_sandbox_org_name])
  github_app_id                        = local.enverus_cts_sandbox_github_app_id
  business_unit                        = "cts"
  environment                          = "dev"
  github_organization_name             = local.enverus_cts_sandbox_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore",
  ]

  multi_runner_config = local.sandbox_multi_runner_config
}

module "enverus-ea" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-ea
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_ea_org_name])
  github_app_id                        = local.enverus_ea_github_app_id
  business_unit                        = "ea"
  environment                          = var.environment
  github_organization_name             = local.enverus_ea_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.gh_actions_runner_assume_role_oidc_directaccess_dev_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_directaccess_preprod_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_directaccess_prod_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_llandman_dev_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_llandman_prod_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.ea_multi_runner_config
}

module "enverus-pr" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-pr
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_pr_org_name])
  github_app_id                        = local.enverus_pr_github_app_id
  business_unit                        = "pr"
  environment                          = var.environment
  github_organization_name             = local.enverus_pr_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_cdr_exporter_dev_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_cdr_exporter_prod_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.pr_multi_runner_config
}

module "enverus-rseg" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.rseg
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.rseg_org_name])
  github_app_id                        = local.rseg_github_app_id
  business_unit                        = "rseg"
  environment                          = var.environment
  github_organization_name             = local.rseg_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore",
    aws_iam_policy.gh_actions_runner_assume_role_oidc_refinery_dev_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_refinery_preprod_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_refinery_prod_policy.arn
  ]

  multi_runner_config = local.rseg_multi_runner_config
}

module "enverus-nv" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-nv
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_nv_org_name])
  github_app_id                        = local.enverus_nv_github_app_id
  business_unit                        = "nv"
  environment                          = var.environment
  github_organization_name             = local.enverus_nv_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_shared_genai_dev_infra_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_shared_genai_prod_infra_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_nv_infra_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_tr_dev_infra_policy.arn,
    aws_iam_policy.github_actions_runner_assume_role_oidc_tr_prod_infra_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.nv_multi_runner_config
}

module "enverus-tr" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-module.github-runner.git?ref=v1.19.0"

  providers = {
    github = github.enverus-tr
  }

  aws_region = var.aws_region
  vpc_id     = data.aws_vpc.main.id
  subnet_ids = data.aws_subnets.private_subnets.ids

  runners_maximum_count                = 2
  base_64_pem                          = base64encode(data.vault_generic_secret.org_pems.data[local.enverus_tr_org_name])
  github_app_id                        = local.enverus_tr_github_app_id
  business_unit                        = "tr"
  environment                          = var.environment
  github_organization_name             = local.enverus_tr_org_name
  runner_additional_security_group_ids = [data.aws_security_group.inside_sg.id]
  runner_iam_role_managed_policy_arns = [
    aws_iam_policy.github_actions_runner_assume_role_oidc_ecr_policy.arn,
    aws_iam_policy.github_actions_runner_helix_agent_policy.arn,
    aws_iam_policy.github_actions_runner_imdsv2_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev_policy.arn,
    aws_iam_policy.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod_policy.arn,
    "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
  ]

  multi_runner_config = local.tr_multi_runner_config
}

================
File: cts/github/runners/prod.backend.tfvars
================
key = "316576613383/prod/github-actions/runners/terraform.state"

================
File: cts/github/runners/prod.tfvars
================
#######  GENERAL CONFIG  #############

aws_region    = "us-east-1"
vpc_name      = "cts-vpc-prod"
business_unit = "cts"
environment   = "prod"

================
File: cts/github/runners/variables.tf
================
variable "assume_role_arn" {
  description = "Assume role for terraform provider"
  type        = string
}

variable "aws_region" {
  description = "AWS region to delpoy to"
  type        = string
}

variable "business_unit" {
  description = "Business unit to attribute resources to"
  type        = string
}

variable "environment" {
  description = "deployment environment, dev, preprod, prod"
  type        = string
}

variable "vpc_name" {
  description = "Name of the vpc"
  type        = string
}

variable "runner_tools_bucket_name" {
  description = "name of s3 bucket that holds tools"
  type        = string
  default     = "enverus-sre-github-runner-tool-bucket"
}

================
File: cts/github/runners/vault.tf
================
data "vault_generic_secret" "org_pems" {
  path = "enverus-cts/github/runners/github_org_app_pems"
}

resource "vault_auth_backend" "aws" {
  description = "Auth Method for IAM"
  type        = "aws"
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.main.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg", "*-INSIDE-SG"]
  }
}

data "vault_policy_document" "all-read" {
  rule {
    path         = "enverus-cts/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-cts"
  }
  rule {
    path         = "enverus-it/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-it"
  }
  rule {
    path         = "enverus-ba/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-ba"
  }
  rule {
    path         = "enverus-tr/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-tr"
  }
  rule {
    path         = "enverus-pr/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-pr"
  }
  rule {
    path         = "enverus-ea/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-ea"
  }
  rule {
    path         = "enverus-nv/*"
    capabilities = ["read"]
    description  = "allow read on all enverus-nv"
  }
}
resource "vault_policy" "github-runner-read" {
  name   = "github-runner-read"
  policy = data.vault_policy_document.all-read.hcl
}

resource "vault_aws_auth_backend_role" "ci_builder_role" {
  backend           = "aws"
  role              = "ci-builder-role"
  auth_type         = "iam"
  bound_account_ids = [data.aws_caller_identity.current.account_id]
  bound_vpc_ids     = [data.aws_vpc.main.id]
  bound_iam_principal_arns = [
    "arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/github_actions_oidc_assume_role/*",
    "arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/github_actions_oidc_ecr_role",
    "arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/github-action-runners/*",
  ]
  token_ttl      = 300
  token_max_ttl  = 3600
  token_policies = ["github-runner-read"]

  depends_on = [
    vault_auth_backend.aws,
  ]
}

================
File: cts/github/runners/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws",
      version = ">= 5.27"
      ## https://github.com/hashicorp/terraform-provider-aws/issues/31633
    }
    github = {
      source  = "integrations/github"
      version = ">= 5"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "cts"
      component         = "github-actions"
      team              = "sre@enverus.com"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/runners"
      environment       = var.environment
      product           = "nexus"
      terraform_created = "true"
    }
  }
}

provider "github" {
  alias = "enverus-cts-sandbox"
  owner = local.enverus_cts_sandbox_org_name
  app_auth {
    id              = local.enverus_cts_sandbox_github_app_id
    installation_id = local.enverus_cts_sandbox_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_cts_sandbox_org_name]
  }

}

provider "github" {
  alias = "enverus-cts"
  owner = local.enverus_cts_org_name
  app_auth {
    id              = local.enverus_cts_github_app_id
    installation_id = local.enverus_cts_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_cts_org_name]
  }
}

provider "github" {
  alias = "enverus-tr"
  owner = local.enverus_tr_org_name
  app_auth {
    id              = local.enverus_tr_github_app_id
    installation_id = local.enverus_tr_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_tr_org_name]
  }
}

provider "github" {
  alias = "enverus-pr"
  owner = local.enverus_pr_org_name
  app_auth {
    id              = local.enverus_pr_github_app_id
    installation_id = local.enverus_pr_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_pr_org_name]
  }
}

provider "github" {
  alias = "enverus-ea"
  owner = local.enverus_ea_org_name
  app_auth {
    id              = local.enverus_ea_github_app_id
    installation_id = local.enverus_ea_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_ea_org_name]
  }
}

provider "github" {
  alias = "rseg"
  owner = local.rseg_org_name
  app_auth {
    id              = local.rseg_github_app_id
    installation_id = local.rseg_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.rseg_org_name]
  }
}

provider "github" {
  alias = "enverus-ba"
  owner = local.enverus_ba_org_name
  app_auth {
    id              = local.enverus_ba_github_app_id
    installation_id = local.enverus_ba_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_ba_org_name]
  }
}

provider "github" {
  alias = "enverus-nv"
  owner = local.enverus_nv_org_name
  app_auth {
    id              = local.enverus_nv_github_app_id
    installation_id = local.enverus_nv_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.enverus_nv_org_name]
  }
}

provider "github" {
  alias = "bidout"
  owner = local.bidout_org_name
  app_auth {
    id              = local.bidout_github_app_id
    installation_id = local.bidout_github_app_installation_id
    pem_file        = data.vault_generic_secret.org_pems.data[local.bidout_org_name]
  }
}

================
File: cts/github/s3/.terraform-version
================
latest:^1.3

================
File: cts/github/s3/buckets.tf
================
data "aws_iam_policy_document" "access" {
  statement {
    sid = "AllowGitHubRunnersReadAccess"

    principals {
      type        = "AWS"
      identifiers = ["*"]
    }

    actions = [
      "s3:GetObject",
      "s3:ListBucket",
    ]

    resources = [
      module.runner-tool-bucket.primaryS3Bucket.arn,
      "${module.runner-tool-bucket.primaryS3Bucket.arn}/*",
    ]

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values = [
        "arn:aws:iam::360093697111:role/enverus-cts-*-runner-role"
      ]
    }
  }

  # Require HTTPS
  statement {
    sid    = "DenyInsecureConnections"
    effect = "Deny"

    principals {
      type        = "*"
      identifiers = ["*"]
    }

    actions = ["s3:*"]

    resources = [
      module.runner-tool-bucket.primaryS3Bucket.arn,
      "${module.runner-tool-bucket.primaryS3Bucket.arn}/*"
    ]

    condition {
      test     = "Bool"
      variable = "aws:SecureTransport"
      values   = ["false"]
    }
  }
}

module "runner-tool-bucket" {
  source     = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket?ref=v1.3.2"
  bucketname = var.bucketname
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
  disable_bucket_versioning = true
  disable_bucket_replication = true
  s3_bucket_policy = data.aws_iam_policy_document.access.json
}

================
File: cts/github/s3/prod.backend.tfvars
================
key = "316576613383/prod/github-actions/s3/terraform.state"

================
File: cts/github/s3/prod.tfvars
================
region    = "us-east-1"
dr-region = "us-west-2"
bucketname = "enverus-sre-github-runner-tool-bucket"

================
File: cts/github/s3/variables.tf
================
variable "region" {}
variable "dr-region" {}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bucketname" {
  description = "The name of the bucket to create"
  type        = string
}

================
File: cts/github/s3/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  alias  = "ue1"
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "github-actions"
      Environment      = var.env
      Team             = "tech-sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/s3"
      TerraformCreated = "true"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = var.dr-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "github-actions"
      Environment      = var.env
      Team             = "tech-sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/github/s3"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/github/secrets-manager/files/sre-gha-secrets-reader-role-policy.json
================
{
    "Version": "2012-10-17",
    "Statement": [
       {
          "Sid": "AllowroleToReadSecret",
          "Effect": "Allow",
          "Action": [
             "secretsmanager:GetSecretValue"
          ],
          "Resource": "arn:aws:secretsmanager:us-east-1:360093697111:secret:cts/github/*"
       }
    ]
 }

================
File: cts/github/secrets-manager/files/trust-policy.json.tpl
================
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Federated": "${openid_provider_arn}"
            },
            "Action": "sts:AssumeRoleWithWebIdentity",
            "Condition": {
                "StringLike": {
                    "token.actions.githubusercontent.com:sub": ["*:job_workflow_ref:enverus-cts/sre.shared-action.*","*:job_workflow_ref:enverus-cts/sre.shared-workflow.*"]
                },
                "ForAllValues:StringEquals": {
                    "token.actions.githubusercontent.com:iss": "https://token.actions.githubusercontent.com",
                    "token.actions.githubusercontent.com:aud": "sts.amazonaws.com"
                }
            }
        }
    ]
}

================
File: cts/github/secrets-manager/.terraform-version
================
latest:^1

================
File: cts/github/secrets-manager/dev.backend.tfvars
================
key = "360093697111/dev/github-actions/secrets-manager/terraform.state"

================
File: cts/github/secrets-manager/dev.tfvars
================
environment     = "dev"
github_oidc_arn = "arn:aws:iam::449228620267:role/github_oidc_role"
secret_manager_secrets = {
  github_atlantis_webhook = {
    name       = "cts/github/secrets-manager/atlantis_webhook"
    vault_path = "enverus-cts/atlantis/github.com-webhook-secret"
    vault_key  = "github_secret"
  }
  sre_cross_repo_pull = {
    name       = "cts/github/secrets-manager/sre-cross-org-repo-access"
    vault_path = "cts-secrets/terraform/github-application/sre-cross-org-repo-access"
    vault_key  = "pem"
  }
}

================
File: cts/github/secrets-manager/main.tf
================
data "aws_iam_openid_connect_provider" "gh_oidc" {
  url = "https://token.actions.githubusercontent.com"
}

data "template_file" "oidc_assume_role_policy_template" {
  template = file("${path.module}/files/trust-policy.json.tpl")
  vars = {
    openid_provider_arn = data.aws_iam_openid_connect_provider.gh_oidc.arn
  }

}

resource "aws_iam_role" "resource_role" {
  name               = format("%s_%s", "gha_oidc", "sre_shared_secret_reader")
  assume_role_policy = data.template_file.oidc_assume_role_policy_template.rendered
}

resource "aws_iam_policy" "aws_iam_policy_read_secret" {
  name   = "gha_read_secret"
  policy = file("${path.module}/files/sre-gha-secrets-reader-role-policy.json")

}

resource "aws_iam_role_policy_attachment" "policy-attach" {
  role       = aws_iam_role.resource_role.name
  policy_arn = aws_iam_policy.aws_iam_policy_read_secret.arn
}

resource "aws_secretsmanager_secret" "secret_name" {
  for_each = var.secret_manager_secrets
  name     = each.value.name
}

data "vault_generic_secret" "vault_secret" {
  for_each = var.secret_manager_secrets
  path     = each.value.vault_path
}


resource "aws_secretsmanager_secret_version" "secret_version" {
  for_each      = var.secret_manager_secrets
  secret_id     = aws_secretsmanager_secret.secret_name[each.key].id
  secret_string = data.vault_generic_secret.vault_secret[each.key].data[each.value.vault_key]
}

================
File: cts/github/secrets-manager/prod.backend.tfvars
================
key = "316576613383/prod/github-actions/secrets-manager/terraform.state"

================
File: cts/github/secrets-manager/variables.tf
================
variable "environment" {
  type        = string
  description = "Deployment Environment"
}

variable "aws_region" {
  description = "Default AWS region"
  type        = string
  default     = "us-east-1"
}

variable "assume_role_arn" {
  description = "AWS role to assum"
  type        = string
}

variable "github_oidc_arn" {
  description = "arn of the githuboidc role"
  type        = string
}

variable "secret_manager_secrets" {
  description = "secrets to pull from vault and add to AWS secrets manager"
}

================
File: cts/github/secrets-manager/versions.tf
================
terraform {
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }

  required_version = ">= 1.3"
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "sre"
      Component        = "github actions"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/github-actions/secrets-manager"
      TerraformCreated = "true"
      Environment      = var.environment
      Product          = "nexus"
    }
  }
}

================
File: cts/github-enterprise-importer/.terraform-version
================
latest:^1.3

================
File: cts/github-enterprise-importer/dev.backend.tfvars
================
key = "360093697111/dev/github-enterprise-migrator/terraform.tfstate"

================
File: cts/github-enterprise-importer/dev.tfvars
================
ec2-region = "us-east-1"

================
File: cts/github-enterprise-importer/main.tf
================
#  Resources needed by the gh enterprise importer
#  The objects in the bucket are only used during the migration.
resource "aws_s3_bucket" "gei-bucket" {
  bucket = "enverus-cts-github-enterprise-importer"
}

resource "aws_s3_bucket_lifecycle_configuration" "gei-bucket" {
  bucket = aws_s3_bucket.gei-bucket.id
  rule {
    id = "whole-bucket"

    expiration {
      days = 10
    }

    status = "Enabled"
  }

  rule {
    id = "noncurrent-expire"

    noncurrent_version_expiration {
      noncurrent_days = 7
    }

    status = "Enabled"
  }
}

resource "aws_iam_user" "gei" {
  name = "enverus-cts-github-enterprise-importer"
}

resource "aws_iam_access_key" "gei" {
  user = aws_iam_user.gei.name
}

resource "vault_generic_secret" "gei-aws-keys" {
  path = "cts-secrets/terraform/aws-api-keys/github-enterprise-importer-bucket-user"

  data_json = <<EOT
{
  "AWS_SECRET_ACCESS_KEY":   "${aws_iam_access_key.gei.secret}",
  "AWS_ACCESS_KEY_ID": "${aws_iam_access_key.gei.id}"
}
EOT
}

data "aws_iam_policy_document" "full_control" {
  statement {
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:DeleteObject"
    ]

    resources = [
      "${aws_s3_bucket.gei-bucket.arn}/*",
    ]
  }

  statement {
    actions = [
      "s3:ListBucket",
    ]

    resources = [
      aws_s3_bucket.gei-bucket.arn
    ]
  }
}

resource "aws_iam_user_policy" "gei" {
  name = "s3-bucket-enverus-cts-github-enterprise-importer-policy"
  user = aws_iam_user.gei.name

  policy = data.aws_iam_policy_document.full_control.json
}

================
File: cts/github-enterprise-importer/README.md
================
The github enterprise importer (https ://github.com/github/gh-gei) needs access to cloud storage
in order to migrate from github enterprise to github cloud.

We use AWS S3 and and IAM user.

================
File: cts/github-enterprise-importer/variables.tf
================
variable "assume_role_arn" {
  description = "AWS role arn for provider"
  type        = string
}

variable "ec2-region" {
  description = "ec2 region for provider"
  type        = string
}

variable "env" {
  description = "environment, eg. dev"
  type        = string
}

================
File: cts/github-enterprise-importer/versions.tf
================
terraform {
  required_version = ">= 1.3.0"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.12.1"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.env
      SourceCode  = "https://github.com/enverus-cts/cts.terraform/tree/master/github-enterprise-importer"
      Team        = "sre@enverus.com"
      Product     = "nexus"
    }
  }
}

================
File: cts/github-organization-secrets/artifactory/module/github-org-secret.tf
================
# deploy org secrets
resource "github_actions_organization_secret" "user" {
  secret_name     = var.user_secret_name
  visibility      = "private"
  plaintext_value = var.artifactory_user
}

resource "github_actions_organization_secret" "token" {
  secret_name     = var.token_secret_name
  visibility      = "private"
  plaintext_value = var.artifactory_token
}

================
File: cts/github-organization-secrets/artifactory/module/inputs.tf
================
variable "user_secret_name" {
  description = "Name of github secret that holds artifactory username"
}

variable "token_secret_name" {
  description = "Name of github secret that holds artifactory token"
}

variable "artifactory_user" {
  description = "artifactory username associated with token"
}
variable "artifactory_token" {
  description = "artifactory token"
}

================
File: cts/github-organization-secrets/artifactory/module/versions.tf
================
terraform {
  required_version = ">= 1.3"
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    github = {
      source  = "integrations/github"
      version = "~> 6.2"
    }
  }
}

================
File: cts/github-organization-secrets/artifactory/.terraform-version
================
latest:^1.3

================
File: cts/github-organization-secrets/artifactory/main.tf
================
data "vault_generic_secret" "github_pat" {
  path = var.vault_path_github_pat
}

data "vault_generic_secret" "artifactory_credentials" {
  path = var.vault_path_artifactory_credentials
}

module "github_org_secret_enverus-cts-sandbox" {
  providers = {
    github = github.enverus-cts-sandbox
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

module "github_org_secret_enverus-cts" {
  providers = {
    github = github.enverus-cts
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

module "github_org_secret_enverus-tr" {
  providers = {
    github = github.enverus-tr
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

module "github_org_secret_enverus-pr" {
  providers = {
    github = github.enverus-pr
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

module "github_org_secret_enverus-ea" {
  providers = {
    github = github.enverus-ea
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

module "github_org_secret_RSEnergyGroup" {
  providers = {
    github = github.RSEnergyGroup
  }
  source            = "./module"
  user_secret_name  = "SRE_ARTIFACTORY_USER_VIRTUAL_REPO_RW"
  token_secret_name = "SRE_ARTIFACTORY_TOKEN_VIRTUAL_REPO_RW"
  artifactory_user  = data.vault_generic_secret.artifactory_credentials.data["username"]
  artifactory_token = data.vault_generic_secret.artifactory_credentials.data["token"]
}

================
File: cts/github-organization-secrets/artifactory/prod.backend.tfvars
================
key     = "360093697111/prod/github-organization-secrets/artifactory/terraform.tfstate"
encrypt = "true"

================
File: cts/github-organization-secrets/artifactory/prod.tfvars
================
region                             = "us-east-1"
env                                = "prod"
vault_path_artifactory_credentials = "enverus-cts/artifactory-credentials/access-tokens/virtual-repo-read-write"
vault_path_github_pat              = "enverus-cts/cts.terraform/github-pat/svc-git-sre-github-org-admin-secrets-management"

================
File: cts/github-organization-secrets/artifactory/variables.tf
================
variable "env" {}

variable "bu" {}

variable "region" {}

variable "vault_path_artifactory_credentials" {
  description = "Path in vault to artifactory creds to deploy to orgs"
}

variable "vault_path_github_pat" {
  description = "Path in vault to github PAT - used by github providers"
}

================
File: cts/github-organization-secrets/artifactory/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    github = {
      source  = "integrations/github"
      version = "~> 6.2"
    }
  }
}

provider "vault" {}

# github api providers - we need one per org.
provider "github" {
  alias = "enverus-cts"
  owner = "enverus-cts"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-cts-sandbox"
  owner = "enverus-cts-sandbox"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-tr"
  owner = "enverus-tr"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-pr"
  owner = "enverus-pr"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-ea"
  owner = "enverus-ea"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "RSEnergyGroup"
  owner = "RSEnergyGroup"
  token = data.vault_generic_secret.github_pat.data["token"]
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/module/inputs.tf
================
variable "username_secret_name" {
  description = "Name of github secret that holds sqlserver username"
}

variable "password_secret_name" {
  description = "Name of github secret that holds sqlserver password"
}

variable "sqlserver_username" {
  description = "redgate sqlserver username"
}
variable "sqlserver_password" {
  description = "redgate sqlserver password"
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/module/redgate-sqlcompare-database-credentials.tf
================
# deploy org secrets
resource "github_actions_organization_secret" "sqlserver-username" {
  secret_name     = var.username_secret_name
  visibility      = "private"
  plaintext_value = var.sqlserver_username
}

resource "github_actions_organization_secret" "sqlserver-password" {
  secret_name     = var.password_secret_name
  visibility      = "private"
  plaintext_value = var.sqlserver_password
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/module/versions.tf
================
terraform {
  required_version = ">= 1.4"
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    github = {
      source  = "integrations/github"
      version = "~> 6.2"
    }
  }
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/.terraform-version
================
latest:^1.4

================
File: cts/github-organization-secrets/redgate-sqlcompare/main.tf
================
data "vault_generic_secret" "github_pat" {
  path = var.vault_path_github_pat
}

data "vault_generic_secret" "redgate_sqlserver_credentials" {
  path = var.vault_path_redgate_sqlserver_credentials
}

module "github_org_secret_enverus-cts" {
  providers = {
    github = github.enverus-cts
  }
  source               = "./module"
  username_secret_name = "REDGATE_SQLCOMPARE_USERNAME"
  password_secret_name = "REDGATE_SQLCOMPARE_PASSWORD"
  sqlserver_username   = data.vault_generic_secret.redgate_sqlserver_credentials.data["sqlServerUser"]
  sqlserver_password   = data.vault_generic_secret.redgate_sqlserver_credentials.data["sqlServerPassword"]
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/prod.backend.tfvars
================
# 360093697111 - cts-dev aws account id.
key     = "360093697111/prod/github-organization-secrets/redgate-sqlcompare/terraform.tfstate"
encrypt = "true"

================
File: cts/github-organization-secrets/redgate-sqlcompare/prod.tfvars
================
region                                   = "us-east-1"
env                                      = "prod"
vault_path_redgate_sqlserver_credentials = "enverus-cts/redgate-sqlcompare/database-credentials"
vault_path_github_pat                    = "enverus-cts/cts.terraform/github-pat/svc-git-sre-github-org-admin-secrets-management"

================
File: cts/github-organization-secrets/redgate-sqlcompare/variables.tf
================
variable "env" {}

variable "bu" {}

variable "region" {}

variable "vault_path_redgate_sqlserver_credentials" {
  description = "Path in vault to artifactory creds to deploy to orgs"
}

variable "vault_path_github_pat" {
  description = "Path in vault to github PAT - used by github providers"
}

================
File: cts/github-organization-secrets/redgate-sqlcompare/versions.tf
================
terraform {
  required_version = ">= 1.4"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    github = {
      source  = "integrations/github"
      version = "~> 6.2"
    }
  }
}

provider "vault" {}

# github api providers - we need one per org.
# currently, only enverus-cts is used.
provider "github" {
  alias = "enverus-cts"
  owner = "enverus-cts"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-cts-sandbox"
  owner = "enverus-cts-sandbox"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-tr"
  owner = "enverus-tr"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-pr"
  owner = "enverus-pr"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "enverus-ea"
  owner = "enverus-ea"
  token = data.vault_generic_secret.github_pat.data["token"]
}

provider "github" {
  alias = "RSEnergyGroup"
  owner = "RSEnergyGroup"
  token = data.vault_generic_secret.github_pat.data["token"]
}

================
File: cts/github-sso/azuread-groups/.terraform-version
================
latest

================
File: cts/github-sso/azuread-groups/data.tf
================
data "azuread_client_config" "current" {}

data "azuread_service_principal" "Atlantis_Group_Manager_Service_Principal" {
  display_name = "Atlantis Group Manager"
}

data "azuread_group" "SRE_Team_AzureRole" {
  display_name     = "Tech-SRE"
  security_enabled = true
}

================
File: cts/github-sso/azuread-groups/main.tf
================
# create the azuread groups that will manage sso access to github orgs
# groups will utimately be owned by github org owners rather than SRE team
# SRE will own the cts groups.
resource "azuread_group" "adgroup" {
  for_each = toset(var.github_sso_azuread_group_names)

  display_name            = each.key
  description             = "used for SSO for github.com orgs"
  mail_enabled            = false
  security_enabled        = true
  prevent_duplicate_names = true

  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members,
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )

  lifecycle {
    ignore_changes = [owners]
  }
}
output "azuread_group_adgroup" { value = azuread_group.adgroup }

================
File: cts/github-sso/azuread-groups/prod.backend.tfvars
================
dynamodb_table = null
key            = "316576613383/prod/github-sso/azuread-groups/terraform.tfstate"
use_lockfile   = true

================
File: cts/github-sso/azuread-groups/prod.tfvars
================
vault_path_azure_service_principal_atlantis = "enverus-cts/Azure_Service_Principal_Atlantis"
github_sso_azuread_group_names = [
  "SEC_ENTITLE_GIT_CLOUD_BIDOUT",
  "SEC_ENTITLE_GIT_CLOUD_COURTHOUSEDIRECT",
  "SEC_ENTITLE_GIT_CLOUD_DRILLINGINFO-PRIVATE",
  "SEC_ENTITLE_GIT_CLOUD_DRILLINGINFO",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS_BUSINESSANALYTICS",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-BA",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-CTS-SANDBOX",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-CTS",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-EA",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-IT",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-NV",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-PR",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS-TR",
  "SEC_ENTITLE_GIT_CLOUD_ENVERUS",
  "SEC_ENTITLE_GIT_CLOUD_PST",
  "SEC_ENTITLE_GIT_CLOUD_Q-ENGINEERING",
  "SEC_ENTITLE_GIT_CLOUD_RSENERGYGROUP",
]

================
File: cts/github-sso/azuread-groups/variables.tf
================
variable "vault_path_azure_service_principal_atlantis" {
  description = "path to Azure service principal credentials in Vault"
  type        = string
}

variable "github_sso_azuread_group_names" {
  description = "names of the azure ad groups managing sso for github orgs"
  type        = list(string)
}

================
File: cts/github-sso/azuread-groups/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: cts/github-sso/bid-out/.terraform-version
================
latest

================
File: cts/github-sso/bid-out/azuread_application.tf
================
resource "azuread_application" "github_sso" {
  display_name = "GitHub Enterprise Cloud - org - bid-out"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
    # data.azuread_users.owners.object_ids,
  )
  template_id             = data.azuread_application_template.github_cloud_org_app_template.template_id
  prevent_duplicate_names = true

  web {
    redirect_uris = ["https://github.com/orgs/Bid-Out/saml/consume"]

    implicit_grant {
      access_token_issuance_enabled = false
      id_token_issuance_enabled     = false
    }
  }

  feature_tags {
    enterprise = true
    gallery    = false
    hide       = true
  }

  lifecycle {
    ignore_changes = [
      identifier_uris,
    ]
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "msiam_access"
    display_name         = "msiam_access"
    enabled              = true
    id                   = random_uuid.msiam_access.result
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "User"
    display_name         = "User"
    enabled              = true
    id                   = random_uuid.user.result
  }

}
output "azuread_application" { value = azuread_application.github_sso }

================
File: cts/github-sso/bid-out/data.tf
================
data "azuread_client_config" "current" {}

data "azuread_application_template" "github_cloud_org_app_template" {
  display_name = "GitHub Enterprise Cloud - Organization"
}
# output "github_cloud_org_app_template" { value = data.azuread_application_template.github_cloud_org_app_template }

data "azuread_service_principal" "Atlantis_Group_Manager_Service_Principal" {
  display_name = "Atlantis Group Manager"
}

data "azuread_group" "SRE_Team_AzureRole" {
  display_name     = "Tech-SRE"
  security_enabled = true
}

# data "azuread_users" "owners" {
#   user_principal_names = [
#     "kevin.daniels@drillinginfo.com",
#     "fernando.pereira@drillinginfo.com",
#   ]
# }

data "azuread_application_published_app_ids" "well_known" {}

resource "random_uuid" "user" {}
resource "random_uuid" "msiam_access" {}

================
File: cts/github-sso/bid-out/members.tf
================
# resource "azuread_app_role_assignment" "Team_AzureRole" {
#   app_role_id         = "00000000-0000-0000-0000-000000000000" # Default access
#   principal_object_id = data.azuread_group.Team_AzureRole.object_id
#   resource_object_id  = azuread_service_principal.github_sso_sp.object_id
# }
# output "azuread_app_role_assignment_Team_AzureRole" { value = azuread_app_role_assignment.Team_AzureRole }

================
File: cts/github-sso/bid-out/prod.backend.tfvars
================
dynamodb_table = null
key            = "316576613383/prod/github-sso/bid-out/terraform.tfstate"
use_lockfile   = true

================
File: cts/github-sso/bid-out/service_principal.tf
================
resource "azuread_service_principal" "msgraph" {
  client_id    = data.azuread_application_published_app_ids.well_known.result.MicrosoftGraph
  use_existing = true
}

resource "azuread_application_identifier_uri" "azuread_application_identifier_uri" {
  application_id = azuread_application.github_sso.id
  identifier_uri = "https://github.com/orgs/Bid-Out"

  depends_on = [azuread_service_principal.github_sso_sp]
}
output "azuread_application_identifier_uri" { value = azuread_application_identifier_uri.azuread_application_identifier_uri }

resource "azuread_service_principal" "github_sso_sp" {
  client_id = azuread_application.github_sso.client_id
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
    # data.azuread_users.owners.object_ids,
  )
  use_existing                  = true
  app_role_assignment_required  = true
  preferred_single_sign_on_mode = "saml"
  login_url                     = "https://github.com/orgs/Bid-Out/sso"
  notification_email_addresses  = ["sre@enverus.com"]

}
output "azuread_service_principal_github_sso_sp" { value = azuread_service_principal.github_sso_sp }

resource "azuread_service_principal_token_signing_certificate" "azuread_service_principal_token_signing_certificate" {
  service_principal_id = azuread_service_principal.github_sso_sp.id
}
# output "azuread_service_principal_token_signing_certificate" { value = azuread_service_principal_token_signing_certificate.azuread_service_principal_token_signing_certificate }

resource "azuread_claims_mapping_policy" "saml_nameid_fix" {
  display_name = "Github SSO SP SAML NameID Fix"

  definition = [
    jsonencode(
      {
        ClaimsMappingPolicy = {
          ClaimsSchema = [
            {
              ID               = "userprincipalname"
              SamlClaimType    = "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier",
              SamlNameIdFormat = "urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress",
              Source           = "user"
            }
          ]
          IncludeBasicClaimSet = "true"
          Version              = 1
        }
      }
    ),
  ]
}
output "azuread_claims_mapping_policy" { value = azuread_claims_mapping_policy.saml_nameid_fix }

resource "azuread_service_principal_claims_mapping_policy_assignment" "saml_nameid_fix" {
  claims_mapping_policy_id = azuread_claims_mapping_policy.saml_nameid_fix.id
  service_principal_id     = azuread_service_principal.github_sso_sp.id
}
output "azuread_service_principal_claims_mapping_policy_assignment" { value = azuread_service_principal_claims_mapping_policy_assignment.saml_nameid_fix }

================
File: cts/github-sso/bid-out/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = "enverus-cts/Azure_Service_Principal_Atlantis"
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: cts/github-sso/business-analytics/.terraform-version
================
latest:^1.9

================
File: cts/github-sso/business-analytics/azuread_application.tf
================
resource "azuread_application" "github_sso" {
  display_name = "GitHub Enterprise Cloud - org - enverus-businessanalytics"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members,
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  template_id             = data.azuread_application_template.github_cloud_org_app_template.template_id
  prevent_duplicate_names = true

  web {
    redirect_uris = ["https://github.com/orgs/enverus-businessanalytics/saml/consume"]

    implicit_grant {
      access_token_issuance_enabled = false
      id_token_issuance_enabled     = false
    }
  }

  feature_tags {
    enterprise = true
    gallery    = false
    hide       = true
  }

  lifecycle {
    ignore_changes = [
      identifier_uris,
    ]
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "msiam_access"
    display_name         = "msiam_access"
    enabled              = true
    id                   = random_uuid.msiam_access.result
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "User"
    display_name         = "User"
    enabled              = true
    id                   = random_uuid.user.result
  }

}
output "azuread_application" { value = azuread_application.github_sso }

================
File: cts/github-sso/business-analytics/data.tf
================
data "azuread_client_config" "current" {}

data "azuread_application_template" "github_cloud_org_app_template" {
  display_name = "GitHub Enterprise Cloud - Organization"
}
# output "github_cloud_org_app_template" { value = data.azuread_application_template.github_cloud_org_app_template }

data "azuread_service_principal" "Atlantis_Group_Manager_Service_Principal" {
  display_name = "Atlantis Group Manager"
}

data "azuread_group" "SRE_Team_AzureRole" {
  display_name     = "Tech-SRE"
  security_enabled = true
}


data "azuread_application_published_app_ids" "well_known" {}

resource "random_uuid" "user" {}
resource "random_uuid" "msiam_access" {}

================
File: cts/github-sso/business-analytics/prod.backend.tfvars
================
key = "316576613383/prod/github-sso/business-analytics/terraform.tfstate"

================
File: cts/github-sso/business-analytics/service_principal.tf
================
resource "azuread_service_principal" "msgraph" {
  client_id    = data.azuread_application_published_app_ids.well_known.result.MicrosoftGraph
  use_existing = true
}

resource "azuread_application_identifier_uri" "azuread_application_identifier_uri" {
  application_id = azuread_application.github_sso.id
  identifier_uri = "https://github.com/orgs/enverus-businessanalytics"

  depends_on = [azuread_service_principal.github_sso_sp]
}

resource "azuread_service_principal" "github_sso_sp" {
  client_id = azuread_application.github_sso.client_id
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members,
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  use_existing                  = true
  preferred_single_sign_on_mode = "saml"
  login_url                     = "https://github.com/orgs/enverus-businessanalytics/sso"
  notification_email_addresses  = ["sre@enverus.com"]
}

resource "azuread_service_principal_token_signing_certificate" "azuread_service_principal_token_signing_certificate" {
  service_principal_id = azuread_service_principal.github_sso_sp.id
}

resource "azuread_claims_mapping_policy" "saml_nameid_fix" {
  display_name = "Github SSO SP SAML NameID Fix"

  definition = [
    jsonencode(
      {
        ClaimsMappingPolicy = {
          ClaimsSchema = [
            {
              ID               = "userprincipalname"
              SamlClaimType    = "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier",
              SamlNameIdFormat = "urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress",
              Source           = "user"
            }
          ]
          IncludeBasicClaimSet = "true"
          Version              = 1
        }
      }
    ),
  ]
}

resource "azuread_service_principal_claims_mapping_policy_assignment" "saml_nameid_fix" {
  claims_mapping_policy_id = azuread_claims_mapping_policy.saml_nameid_fix.id
  service_principal_id     = azuread_service_principal.github_sso_sp.id
}

================
File: cts/github-sso/business-analytics/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = "enverus-cts/Azure_Service_Principal_Atlantis"
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: cts/github-sso/drillinginfo/.terraform-version
================
latest:^1.8

================
File: cts/github-sso/drillinginfo/main.tf
================
data "azuread_application_template" "github_cloud_org_app_template" {
  display_name = "GitHub Enterprise Cloud - Organization"
}

data "azuread_application_template" "github_ent_svr_app_template" {
  display_name = "GitHub Enterprise Server"
}

data "azuread_user" "dave" {
  user_principal_name = "dave.goodine@drillinginfo.com"
}

data "azuread_client_config" "current" {}

resource "azuread_application" "Enverus" {
  display_name = "GitHub Enterprise Cloud - org - Enverus"
  owners       = [data.azuread_client_config.current.object_id, data.azuread_user.dave.object_id]
  template_id  = data.azuread_application_template.github_cloud_org_app_template.template_id

  identifier_uris = [
    "https://github.com/orgs/Enverus",
  ]

  web {
    redirect_uris = ["https://github.com/orgs/Enverus/saml/consume"]

    implicit_grant {
      access_token_issuance_enabled = false
      id_token_issuance_enabled     = false
    }
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "User"
    display_name         = "User"
    enabled              = true
    id                   = "8d17fe88-c0ca-4903-ae2a-a51098998bc2"
    value                = "foo"
  }
}

resource "azuread_application" "TestingApp" {
  display_name = "GitHub Enterprise Cloud - org - TestingApp"
  owners       = [data.azuread_client_config.current.object_id, data.azuread_user.dave.object_id]
  template_id  = data.azuread_application_template.github_cloud_org_app_template.template_id

  identifier_uris = [
    "https://github.com/orgs/dmg-enverus-test-org-1",
  ]

  web {
    redirect_uris = ["https://github.com/orgs/dmg-enverus-test-org-1/saml/consume"]

    implicit_grant {
      access_token_issuance_enabled = false
      id_token_issuance_enabled     = false
    }
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "User"
    display_name         = "User"
    enabled              = true
    id                   = "e11404a5-7bd5-44e0-9a70-a916152e23dd"
    value                = "foo"
  }
}

================
File: cts/github-sso/drillinginfo/outputs.tf
================
output "application_template_id" {
  value = data.azuread_application_template.github_cloud_org_app_template.template_id
}
output "application_categories" {
  value = data.azuread_application_template.github_cloud_org_app_template.categories
}
output "app_display_name" {
  value = data.azuread_application_template.github_cloud_org_app_template.display_name
}

output "app_publisher" {
  value = data.azuread_application_template.github_cloud_org_app_template.publisher
}
output "app_supported_provisioning_types" {
  value = data.azuread_application_template.github_cloud_org_app_template.supported_provisioning_types
}
output "app_single_sign_on_modes" {
  value = data.azuread_application_template.github_cloud_org_app_template.supported_single_sign_on_modes
}

================
File: cts/github-sso/drillinginfo/prod.backend.tfvars
================
key = "316576613383/prod/github-sso/drillinginfo/terraform.tfstate"

================
File: cts/github-sso/drillinginfo/prod.tfvars
================
vault_path_azure_service_principal_atlantis = "enverus-cts/Azure_Service_Principal_Atlantis"

================
File: cts/github-sso/drillinginfo/variables.tf
================
variable "env" {
  description = "Environment, eg 'dev'"
}

variable "vault_path_azure_service_principal_atlantis" {
  description = "path to Azure service principal credentials in Vault"
}

================
File: cts/github-sso/drillinginfo/versions.tf
================
provider "vault" {}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

terraform {
  required_version = ">= 1.0"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

================
File: cts/github-sso/pearlstreettechnologies/.terraform-version
================
latest

================
File: cts/github-sso/pearlstreettechnologies/azuread_application.tf
================
resource "azuread_application" "github_sso" {
  display_name = "GitHub Enterprise Cloud - org - Pearl Street Technologies"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
    # data.azuread_users.owners.object_ids,
  )
  template_id             = data.azuread_application_template.github_cloud_org_app_template.template_id
  prevent_duplicate_names = true

  web {
    redirect_uris = ["https://github.com/orgs/pearlstreettechnologies/saml/consume"]

    implicit_grant {
      access_token_issuance_enabled = false
      id_token_issuance_enabled     = false
    }
  }

  feature_tags {
    enterprise = true
    gallery    = false
    hide       = true
  }

  lifecycle {
    ignore_changes = [
      identifier_uris,
    ]
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "msiam_access"
    display_name         = "msiam_access"
    enabled              = true
    id                   = random_uuid.msiam_access.result
  }

  app_role {
    allowed_member_types = ["User"]
    description          = "User"
    display_name         = "User"
    enabled              = true
    id                   = random_uuid.user.result
  }

}
output "azuread_application" { value = azuread_application.github_sso }

================
File: cts/github-sso/pearlstreettechnologies/data.tf
================
data "azuread_client_config" "current" {}

data "azuread_application_template" "github_cloud_org_app_template" {
  display_name = "GitHub Enterprise Cloud - Organization"
}
# output "github_cloud_org_app_template" { value = data.azuread_application_template.github_cloud_org_app_template }

data "azuread_service_principal" "Atlantis_Group_Manager_Service_Principal" {
  display_name = "Atlantis Group Manager"
}

data "azuread_group" "SRE_Team_AzureRole" {
  display_name     = "Tech-SRE"
  security_enabled = true
}

data "azuread_users" "owners" {
  user_principal_names = [
    "casey.schmit@drillinginfo.com",
  ]
}

data "azuread_application_published_app_ids" "well_known" {}

resource "random_uuid" "user" {}
resource "random_uuid" "msiam_access" {}

================
File: cts/github-sso/pearlstreettechnologies/members.tf
================
# resource "azuread_app_role_assignment" "Team_AzureRole" {
#   app_role_id         = "00000000-0000-0000-0000-000000000000" # Default access
#   principal_object_id = data.azuread_group.Team_AzureRole.object_id
#   resource_object_id  = azuread_service_principal.github_sso_sp.object_id
# }
# output "azuread_app_role_assignment_Team_AzureRole" { value = azuread_app_role_assignment.Team_AzureRole }

================
File: cts/github-sso/pearlstreettechnologies/prod.backend.tfvars
================
dynamodb_table = null
key            = "316576613383/prod/github-sso/pearlstreettechnologies/terraform.tfstate"
use_lockfile   = true

================
File: cts/github-sso/pearlstreettechnologies/service_principal.tf
================
resource "azuread_service_principal" "msgraph" {
  client_id    = data.azuread_application_published_app_ids.well_known.result.MicrosoftGraph
  use_existing = true
}

resource "azuread_application_identifier_uri" "azuread_application_identifier_uri" {
  application_id = azuread_application.github_sso.id
  identifier_uri = "https://github.com/orgs/pearlstreettechnologies"

  depends_on = [azuread_service_principal.github_sso_sp]
}
output "azuread_application_identifier_uri" { value = azuread_application_identifier_uri.azuread_application_identifier_uri }

resource "azuread_service_principal" "github_sso_sp" {
  client_id = azuread_application.github_sso.client_id
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members,
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
    data.azuread_users.owners.object_ids,
  )
  use_existing                  = true
  app_role_assignment_required  = true
  preferred_single_sign_on_mode = "saml"
  login_url                     = "https://github.com/orgs/pearlstreettechnologies/sso"
  notification_email_addresses  = ["sre@enverus.com"]

}
output "azuread_service_principal_github_sso_sp" { value = azuread_service_principal.github_sso_sp }

resource "azuread_service_principal_token_signing_certificate" "azuread_service_principal_token_signing_certificate" {
  service_principal_id = azuread_service_principal.github_sso_sp.id
}
# output "azuread_service_principal_token_signing_certificate" { value = azuread_service_principal_token_signing_certificate.azuread_service_principal_token_signing_certificate }

resource "azuread_claims_mapping_policy" "saml_nameid_fix" {
  display_name = "Github SSO SP SAML NameID Fix"

  definition = [
    jsonencode(
      {
        ClaimsMappingPolicy = {
          ClaimsSchema = [
            {
              ID               = "userprincipalname"
              SamlClaimType    = "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier",
              SamlNameIdFormat = "urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress",
              Source           = "user"
            }
          ]
          IncludeBasicClaimSet = "true"
          Version              = 1
        }
      }
    ),
  ]
}
output "azuread_claims_mapping_policy" { value = azuread_claims_mapping_policy.saml_nameid_fix }

resource "azuread_service_principal_claims_mapping_policy_assignment" "saml_nameid_fix" {
  claims_mapping_policy_id = azuread_claims_mapping_policy.saml_nameid_fix.id
  service_principal_id     = azuread_service_principal.github_sso_sp.id
}
output "azuread_service_principal_claims_mapping_policy_assignment" { value = azuread_service_principal_claims_mapping_policy_assignment.saml_nameid_fix }

================
File: cts/github-sso/pearlstreettechnologies/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = "enverus-cts/Azure_Service_Principal_Atlantis"
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: cts/grafana/access-policies/open-invoice/.terraform-version
================
latest

================
File: cts/grafana/access-policies/open-invoice/main.tf
================
# grafana cloud access policies and tokens for open invoice

data "vault_generic_secret" "terraform_access_policy_token" {
  path = var.vault_path_grafana_api_key
}

data "grafana_cloud_stack" "current" {
  slug = "enverus"
}

resource "grafana_cloud_access_policy" "open_invoice" {
  region       = data.grafana_cloud_stack.current.region_slug
  name         = "open-invoice-frontend-observability-access-policy"
  display_name = "OpenInvoice Frontend Observability Access Policy"

  scopes = ["sourcemaps:read", "sourcemaps:write", "sourcemaps:delete"]

  realm {
    type       = "stack"
    identifier = "114286"
  }
}

resource "grafana_cloud_access_policy_token" "open_invoice" {
  region           = data.grafana_cloud_stack.current.region_slug
  access_policy_id = grafana_cloud_access_policy.open_invoice.policy_id
  name             = "open-invoice-frontend-observability-access-policy-token"
  display_name     = "OpenInvoice Frontend Observability Access Policy Token"
  expires_at       = "2026-06-18T00:00:00Z"
}

resource "vault_generic_secret" "open_invoice_access_policy_token" {
  path = "enverus-cts/cts.terraform/grafana/access-policies/open-invoice-access-policy-token"

  data_json = <<EOT
{
  "grafana_api_token":   "${grafana_cloud_access_policy_token.open_invoice.token}"
}
EOT
}

================
File: cts/grafana/access-policies/open-invoice/prod.backend.tfvars
================
# 316576613383 - the cts-prod AWS account ID.
key = "316576613383/prod/grafana/access-policies/open_invoice/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: cts/grafana/access-policies/open-invoice/prod.tfvars
================
# this page intentionally left blank
vault_path_grafana_api_key = "enverus-cts/sre/grafana/access-policy-tokens/terraform-access-policy"

================
File: cts/grafana/access-policies/open-invoice/variables.tf
================
variable "region" {
  description = "Region"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Environment level (dev/preprod/prod)"
  type        = string
}

variable "vault_path_grafana_api_key" {
  description = "vault path for the grafana api key"
  type        = string
}

================
File: cts/grafana/access-policies/open-invoice/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    grafana = {
      source  = "grafana/grafana"
      version = "> 3.2"
    }
  }
}

provider "vault" {
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  cloud_access_policy_token = data.vault_generic_secret.terraform_access_policy_token.data["token"]
}

================
File: cts/grafana/access-policies/prism/.terraform-version
================
latest

================
File: cts/grafana/access-policies/prism/main.tf
================
# grafana cloud access policies and tokens for prism

data "vault_generic_secret" "terraform_access_policy_token" {
  path = var.vault_path_grafana_api_key
}

data "vault_generic_secret" "terraform_service_account" {
  path = "enverus-cts/sre/grafana/service-account-tokens/sa-1-terraform-sre"
}

data "grafana_cloud_stack" "current" {
  slug = "enverus"
}

resource "grafana_cloud_access_policy" "prism" {
  region       = data.grafana_cloud_stack.current.region_slug
  name         = "prism-frontend-observability-access-policy"
  display_name = "Prism Frontend Observability Access Policy"

  scopes = ["sourcemaps:read", "sourcemaps:write", "sourcemaps:delete"]

  realm {
    type       = "stack"
    identifier = "114286"
  }
}

resource "grafana_cloud_access_policy_token" "prism" {
  region           = data.grafana_cloud_stack.current.region_slug
  access_policy_id = grafana_cloud_access_policy.prism.policy_id
  name             = "prism-frontend-observability-access-policy-token"
  display_name     = "Prism Frontend Observability Access Policy Token"
  expires_at       = "2026-06-17T00:00:00Z"
}

resource "vault_generic_secret" "prism_access_policy_token" {
  path = "enverus-cts/cts.terraform/grafana/access-policies/prism-access-policy-token"

  data_json = <<EOT
{
  "grafana_api_token":   "${grafana_cloud_access_policy_token.prism.token}"
}
EOT
}

================
File: cts/grafana/access-policies/prism/prod.backend.tfvars
================
# 316576613383 - the cts-prod AWS account ID.
key = "316576613383/prod/grafana/access-olicies/prism/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: cts/grafana/access-policies/prism/prod.tfvars
================
# this page intentionally left blank
vault_path_grafana_api_key = "enverus-cts/sre/grafana/access-policy-tokens/terraform-access-policy"

================
File: cts/grafana/access-policies/prism/variables.tf
================
variable "region" {
  description = "Region"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Environment level (dev/preprod/prod)"
  type        = string
}

variable "vault_path_grafana_api_key" {
  description = "vault path for the grafana api key"
  type        = string
}

================
File: cts/grafana/access-policies/prism/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    grafana = {
      source  = "grafana/grafana"
      version = "> 3.2"
    }
  }
}

provider "vault" {
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  cloud_access_policy_token = data.vault_generic_secret.terraform_access_policy_token.data["token"]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_dev_panels/accounts_service_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Dev - 4",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "f3492c6d-5152-4959-a0fa-d7e221b170ff",
                    "title": "Accounts Service - Errors Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7z",
                    "panelId": 4,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14113",
                        "__dashboardUid__": "l7-2zNe7z",
                        "__panelId__": "4",
                        "description": "",
                        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Dev. There may be an issue with the service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\"",
                        "rule_uid": "f3492c6d-5152-4959-a0fa-d7e221b170ff"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_dev_panels/accounts_service_errors_panel.json
================
{
    "datasource": {
      "type": "loki",
      "uid": "grafanacloud-logs"
    },
    "alert": {
      "alertRuleTags": {},
      "conditions": [
        {
          "evaluator": {
            "params": [
              10
            ],
            "type": "gt"
          },
          "operator": {
            "type": "and"
          },
          "query": {
            "params": [
              "A",
              "5m",
              "now"
            ]
          },
          "reducer": {
            "params": [],
            "type": "max"
          },
          "type": "query"
        }
      ],
      "executionErrorState": "keep_state",
      "for": "0",
      "frequency": "1m",
      "handler": 1,
      "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Dev. There may be an issue with the service.",
      "name": "Accounts Service - Errors Alert - Dev",
      "noDataState": "ok",
      "notifications": [
        {
          "uid": "K3ux9de7k"
        }
      ]
    },
    "fieldConfig": {
      "defaults": {
        "custom": {
          "drawStyle": "line",
          "lineInterpolation": "linear",
          "barAlignment": 0,
          "lineWidth": 1,
          "fillOpacity": 0,
          "gradientMode": "none",
          "spanNulls": false,
          "insertNulls": false,
          "showPoints": "auto",
          "pointSize": 5,
          "stacking": {
            "mode": "none",
            "group": "A"
          },
          "axisPlacement": "auto",
          "axisLabel": "",
          "axisColorMode": "text",
          "axisBorderShow": false,
          "scaleDistribution": {
            "type": "linear"
          },
          "axisCenteredZero": false,
          "hideFrom": {
            "tooltip": false,
            "viz": false,
            "legend": false
          },
          "thresholdsStyle": {
            "mode": "off"
          }
        },
        "color": {
          "mode": "palette-classic"
        },
        "mappings": [],
        "thresholds": {
          "mode": "absolute",
          "steps": [
            {
              "color": "green",
              "value": null
            },
            {
              "color": "red",
              "value": 80
            }
          ]
        }
      },
      "overrides": []
    },
    "gridPos": {
      "h": 8,
      "w": 12,
      "x": 0,
      "y": 0
    },
    "id": 4,
    "options": {
      "tooltip": {
        "mode": "single",
        "sort": "none"
      },
      "legend": {
        "showLegend": true,
        "displayMode": "list",
        "placement": "bottom",
        "calcs": []
      }
    },
    "targets": [
      {
        "datasource": {
          "type": "loki",
          "uid": "grafanacloud-logs"
        },
        "editorMode": "code",
        "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
        "queryType": "range",
        "refId": "A"
      }
    ],
    "thresholds": [
      {
        "colorMode": "critical",
        "op": "gt",
        "value": 10,
        "visible": true
      }
    ],
    "title": "Accounts Service - Errors",
    "type": "timeseries"
  }

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_dev_panels/accounts_service_salesforce_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Dev - 7",
            "folder": "Core Tech Services - Auth",
            "interval": "2m",
            "rules": [
                {
                    "uid": "b6db971f-6581-434a-bea2-147fa7b4052c",
                    "title": "Accounts Service - Salesforce Errors Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
                                "intervalMs": 500,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                3
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7z",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14124",
                        "__dashboardUid__": "l7-2zNe7z",
                        "__panelId__": "7",
                        "description": "",
                        "message": "Salesforce integration for the Accounts Service in Dev has not been available in the last minutes, and may be down.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\"",
                        "rule_uid": "b6db971f-6581-434a-bea2-147fa7b4052c"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_dev_panels/accounts_service_salesforce_errors_panel.json
================
{
    "datasource": {
      "type": "loki",
      "uid": "grafanacloud-logs"
    },
    "alert": {
      "alertRuleTags": {},
      "conditions": [
        {
          "evaluator": {
            "params": [
              3
            ],
            "type": "gt"
          },
          "operator": {
            "type": "and"
          },
          "query": {
            "params": [
              "A",
              "10m",
              "now"
            ]
          },
          "reducer": {
            "params": [],
            "type": "max"
          },
          "type": "query"
        }
      ],
      "executionErrorState": "keep_state",
      "for": "0s",
      "frequency": "2m",
      "handler": 1,
      "message": "Salesforce integration for the Accounts Service in Dev has not been available in the last minutes, and may be down.",
      "name": "Accounts Service - Salesforce Errors Alert - Dev",
      "noDataState": "ok",
      "notifications": [
        {
          "uid": "K3ux9de7k"
        }
      ]
    },
    "fieldConfig": {
      "defaults": {
        "custom": {
          "drawStyle": "line",
          "lineInterpolation": "linear",
          "barAlignment": 0,
          "lineWidth": 1,
          "fillOpacity": 0,
          "gradientMode": "none",
          "spanNulls": false,
          "insertNulls": false,
          "showPoints": "auto",
          "pointSize": 5,
          "stacking": {
            "mode": "none",
            "group": "A"
          },
          "axisPlacement": "auto",
          "axisLabel": "",
          "axisColorMode": "text",
          "axisBorderShow": false,
          "scaleDistribution": {
            "type": "linear"
          },
          "axisCenteredZero": false,
          "hideFrom": {
            "tooltip": false,
            "viz": false,
            "legend": false
          },
          "thresholdsStyle": {
            "mode": "off"
          }
        },
        "color": {
          "mode": "palette-classic"
        },
        "mappings": [],
        "thresholds": {
          "mode": "absolute",
          "steps": [
            {
              "color": "green",
              "value": null
            },
            {
              "color": "red",
              "value": 80
            }
          ]
        }
      },
      "overrides": []
    },
    "gridPos": {
      "h": 8,
      "w": 12,
      "x": 12,
      "y": 0
    },
    "id": 7,
    "options": {
      "tooltip": {
        "mode": "single",
        "sort": "none"
      },
      "legend": {
        "showLegend": true,
        "displayMode": "list",
        "placement": "bottom",
        "calcs": []
      }
    },
    "targets": [
      {
        "datasource": {
          "type": "loki",
          "uid": "grafanacloud-logs"
        },
        "editorMode": "code",
        "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
        "queryType": "range",
        "refId": "A"
      }
    ],
    "thresholds": [
      {
        "colorMode": "critical",
        "op": "gt",
        "value": 3,
        "visible": true
      }
    ],
    "title": "Accounts Service - Salesforce Errors",
    "type": "timeseries"
  }

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_preprod_panels/accounts_service_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Preprod - 4",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "c62f6e26-08db-4122-829d-fe4da8981e0a",
                    "title": "Accounts Service - Errors Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7y",
                    "panelId": 4,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14189",
                        "__dashboardUid__": "l7-2zNe7y",
                        "__panelId__": "4",
                        "description": "",
                        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Preprod. There may be an issue with the service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "c62f6e26-08db-4122-829d-fe4da8981e0a"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_preprod_panels/accounts_service_errors_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0",
    "frequency": "1m",
    "handler": 1,
    "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Preprod. There may be an issue with the service.",
    "name": "Accounts Service - Errors Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 4,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Accounts Service - Errors",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_preprod_panels/accounts_service_salesforce_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Preprod - 7",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "2m",
            "rules": [
                {
                    "uid": "bec2ea53-93f0-461c-9159-5ff1bb4ddddc",
                    "title": "Accounts Service - Salesforce Errors Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
                                "intervalMs": 500,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                3
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7y",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14190",
                        "__dashboardUid__": "l7-2zNe7y",
                        "__panelId__": "7",
                        "description": "",
                        "message": "Salesforce integration for the Accounts Service in Preprod has not been available in the last minutes, and may be down.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "bec2ea53-93f0-461c-9159-5ff1bb4ddddc"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_preprod_panels/accounts_service_salesforce_errors_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            3
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "10m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "2m",
    "handler": 1,
    "message": "Salesforce integration for the Accounts Service in Preprod has not been available in the last minutes, and may be down.",
    "name": "Accounts Service - Salesforce Errors Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 7,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 3,
      "visible": true
    }
  ],
  "title": "Accounts Service - Salesforce Errors",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_prod_panels/accounts_service_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Prod - 4",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "d828efc7-2fd5-4ecc-8102-ab7fedfa5ea7",
                    "title": "Accounts Service - Errors Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7zProd1",
                    "panelId": 4,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14200",
                        "__dashboardUid__": "l7-2zNe7zProd1",
                        "__panelId__": "4",
                        "description": "",
                        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Prod. There may be an issue with the service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "d828efc7-2fd5-4ecc-8102-ab7fedfa5ea7"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_prod_panels/accounts_service_errors_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0",
    "frequency": "1m",
    "handler": 1,
    "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Prod. There may be an issue with the service.",
    "name": "Accounts Service - Errors Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 4,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Accounts Service - Errors",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_prod_panels/accounts_service_salesforce_errors_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Accounts Service - Prod - 7",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "2m",
            "rules": [
                {
                    "uid": "e79e7c93-5bd3-4c29-af4e-ed2f1862c159",
                    "title": "Accounts Service - Salesforce Errors Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
                                "intervalMs": 500,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                3
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "l7-2zNe7zProd1",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14201",
                        "__dashboardUid__": "l7-2zNe7zProd1",
                        "__panelId__": "7",
                        "description": "",
                        "message": "Salesforce integration for the Accounts Service in Prod has not been available in the last minutes, and may be down.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "e79e7c93-5bd3-4c29-af4e-ed2f1862c159"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_prod_panels/accounts_service_salesforce_errors_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            3
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "10m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "2m",
    "handler": 1,
    "message": "Salesforce integration for the Accounts Service in Prod has not been available in the last minutes, and may be down.",
    "name": "Accounts Service - Salesforce Errors Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 7,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 3,
      "visible": true
    }
  ],
  "title": "Accounts Service - Salesforce Errors",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_dev_panels/failures_firehose_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Firehose - Dev - 2",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "f8cb657c-b36f-428a-bba5-4f6f14cf8a30",
                    "title": "Accounts Service - Firehose Failures Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"dev\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dashboardUid": "8D32GHenz",
                    "panelId": 2,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "annotations": {
                        "__alertId__": "14114",
                        "__dashboardUid__": "8D32GHenz",
                        "__panelId__": "2",
                        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Dev in the last minutes. There may be an issue with the container or the service."
                    },
                    "labels": {
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "f8cb657c-b36f-428a-bba5-4f6f14cf8a30"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_dev_panels/failures_firehose_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "One or more containers for the Accounts Service ended abnormally in Nomad Dev in the last minutes. There may be an issue with the container or the service.",
    "name": "Accounts Service - Firehose Failures Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "color": {
        "mode": "palette-classic"
      },
      "custom": {
        "axisBorderShow": false,
        "axisCenteredZero": false,
        "axisColorMode": "text",
        "axisLabel": "",
        "axisPlacement": "auto",
        "barAlignment": 0,
        "barWidthFactor": 0.6,
        "drawStyle": "line",
        "fillOpacity": 0,
        "gradientMode": "none",
        "hideFrom": {
          "legend": false,
          "tooltip": false,
          "viz": false
        },
        "insertNulls": false,
        "lineInterpolation": "linear",
        "lineWidth": 1,
        "pointSize": 5,
        "scaleDistribution": {
          "type": "linear"
        },
        "showPoints": "auto",
        "spanNulls": false,
        "stacking": {
          "group": "A",
          "mode": "none"
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green"
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 11,
    "w": 24,
    "x": 0,
    "y": 0
  },
  "id": 2,
  "options": {
    "legend": {
      "calcs": [],
      "displayMode": "list",
      "placement": "bottom",
      "showLegend": true
    },
    "tooltip": {
      "hideZeros": false,
      "mode": "single",
      "sort": "none"
    }
  },
  "pluginVersion": "12.1.0-88106",
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "direction": "backward",
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"dev\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "Firehose Failures",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_preprod_panels/failures_firehose_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Firehose - Preprod - 2",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "cc771bf7-60b3-4f2c-9cbf-34a97affabd4",
                    "title": "Accounts Service - Firehose Failures Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"preprod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dashboardUid": "8D32GHeOz",
                    "panelId": 2,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "annotations": {
                        "__alertId__": "14192",
                        "__dashboardUid__": "8D32GHeOz",
                        "__panelId__": "2",
                        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Preprod in the last minutes. There may be an issue with the container or the service."
                    },
                    "labels": {
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "cc771bf7-60b3-4f2c-9cbf-34a97affabd4"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_preprod_panels/failures_firehose_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "One or more containers for the Accounts Service ended abnormally in Nomad Preprod in the last minutes. There may be an issue with the container or the service.",
    "name": "Accounts Service - Firehose Failures Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "color": {
        "mode": "palette-classic"
      },
      "custom": {
        "axisBorderShow": false,
        "axisCenteredZero": false,
        "axisColorMode": "text",
        "axisLabel": "",
        "axisPlacement": "auto",
        "barAlignment": 0,
        "barWidthFactor": 0.6,
        "drawStyle": "line",
        "fillOpacity": 0,
        "gradientMode": "none",
        "hideFrom": {
          "legend": false,
          "tooltip": false,
          "viz": false
        },
        "insertNulls": false,
        "lineInterpolation": "linear",
        "lineWidth": 1,
        "pointSize": 5,
        "scaleDistribution": {
          "type": "linear"
        },
        "showPoints": "auto",
        "spanNulls": false,
        "stacking": {
          "group": "A",
          "mode": "none"
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green"
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 9,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 2,
  "options": {
    "legend": {
      "calcs": [],
      "displayMode": "list",
      "placement": "bottom",
      "showLegend": true
    },
    "tooltip": {
      "hideZeros": false,
      "mode": "single",
      "sort": "none"
    }
  },
  "pluginVersion": "12.1.0-88106",
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "direction": "backward",
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"preprod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "Firehose Failures",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_prod_panels/failures_firehose_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Firehose - Prod - 2",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "a1682e4a-cf60-410c-9b74-b0ae6130e022",
                    "title": "Accounts Service - Firehose Failures Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"prod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
                                "intervalMs": 200,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dashboardUid": "8D32GHeOzProd1",
                    "panelId": 2,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "annotations": {
                        "__alertId__": "14203",
                        "__dashboardUid__": "8D32GHeOzProd1",
                        "__panelId__": "2",
                        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Prod in the last minutes. There may be an issue with the container or the service."
                    },
                    "labels": {
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "a1682e4a-cf60-410c-9b74-b0ae6130e022"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_prod_panels/failures_firehose_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "One or more containers for the Accounts Service ended abnormally in Nomad Prod in the last minutes. There may be an issue with the container or the service.",
    "name": "Accounts Service - Firehose Failures Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "color": {
        "mode": "palette-classic"
      },
      "custom": {
        "axisBorderShow": false,
        "axisCenteredZero": false,
        "axisColorMode": "text",
        "axisLabel": "",
        "axisPlacement": "auto",
        "barAlignment": 0,
        "barWidthFactor": 0.6,
        "drawStyle": "line",
        "fillOpacity": 0,
        "gradientMode": "none",
        "hideFrom": {
          "legend": false,
          "tooltip": false,
          "viz": false
        },
        "insertNulls": false,
        "lineInterpolation": "linear",
        "lineWidth": 1,
        "pointSize": 5,
        "scaleDistribution": {
          "type": "linear"
        },
        "showPoints": "auto",
        "spanNulls": false,
        "stacking": {
          "group": "A",
          "mode": "none"
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green"
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 9,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 2,
  "options": {
    "legend": {
      "calcs": [],
      "displayMode": "list",
      "placement": "bottom",
      "showLegend": true
    },
    "tooltip": {
      "hideZeros": false,
      "mode": "single",
      "sort": "none"
    }
  },
  "pluginVersion": "12.1.0-88106",
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "direction": "backward",
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"prod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "Firehose Failures",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Dev - 9",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "be953723-941b-4a42-a505-1a51635b08a1",
                    "title": "Accounts Service - AWS ALB 5XX Balancer Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "_nhYNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "_nhYNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_ELB_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q37z",
                    "panelId": 9,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14116",
                        "__dashboardUid__": "GWHu_Q37z",
                        "__panelId__": "9",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "be953723-941b-4a42-a505-1a51635b08a1"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "_nhYNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 9,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_ELB_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Load Balancer",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_targets_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Dev - 7",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "a09d93f0-0e94-4dea-b34f-58570578a7c2",
                    "title": "Accounts Service - AWS ALB 5XX Target Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "_nhYNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "_nhYNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_Target_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q37z",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14111",
                        "__dashboardUid__": "GWHu_Q37z",
                        "__panelId__": "7",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "a09d93f0-0e94-4dea-b34f-58570578a7c2"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_targets_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "_nhYNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Target Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 7,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_Target_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Targets",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_unhealthy_hosts_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Dev - 6",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "ba845e1d-5614-450d-9c60-4ed18b5a75dc",
                    "title": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "_nhYNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "_nhYNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "COUNT",
                                        "parameters": [
                                            {
                                                "name": "UnHealthyHostCount",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q37z",
                    "panelId": 6,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14108",
                        "__dashboardUid__": "GWHu_Q37z",
                        "__panelId__": "6",
                        "description": "",
                        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Dev. There may be some issue where hosts (allocations) have been terminated.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "ba845e1d-5614-450d-9c60-4ed18b5a75dc"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev_panels/failures_load_balancer_unhealthy_hosts_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "_nhYNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "There is at least one unhealthy host in the target group for the Accounts Service in Dev. There may be some issue where hosts (allocations) have been terminated.",
    "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 8
  },
  "id": 6,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "COUNT",
          "parameters": [
            {
              "name": "UnHealthyHostCount",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "AWS ALB - Target Group - Unhealthy Hosts",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Preprod - 9",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "f1b61f2f-df68-46e5-9626-8e968f21fd44",
                    "title": "Accounts Service - AWS ALB 5XX Balancer Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "oAOPHBOnk",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "oAOPHBOnk"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_ELB_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38z",
                    "panelId": 9,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14196",
                        "__dashboardUid__": "GWHu_Q38z",
                        "__panelId__": "9",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "f1b61f2f-df68-46e5-9626-8e968f21fd44"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "oAOPHBOnk"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 9,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_ELB_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Load Balancer",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_targets_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Preprod - 7",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "e3a66b15-d971-49aa-ae85-c711c11695cf",
                    "title": "Accounts Service - AWS ALB 5XX Target Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "oAOPHBOnk",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "oAOPHBOnk"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_Target_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38z",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14197",
                        "__dashboardUid__": "GWHu_Q38z",
                        "__panelId__": "7",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "e3a66b15-d971-49aa-ae85-c711c11695cf"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_targets_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "oAOPHBOnk"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Target Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 7,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_Target_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Targets",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_unhealthy_hosts_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Preprod - 6",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "e93e8063-9498-40f4-8ef6-7f7a6880d1bd",
                    "title": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "oAOPHBOnk",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "oAOPHBOnk"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "COUNT",
                                        "parameters": [
                                            {
                                                "name": "UnHealthyHostCount",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38z",
                    "panelId": 6,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14198",
                        "__dashboardUid__": "GWHu_Q38z",
                        "__panelId__": "6",
                        "description": "",
                        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Preprod. There may be some issue where hosts (allocations) have been terminated.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "e93e8063-9498-40f4-8ef6-7f7a6880d1bd"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod_panels/failures_load_balancer_unhealthy_hosts_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "oAOPHBOnk"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "There is at least one unhealthy host in the target group for the Accounts Service in Preprod. There may be some issue where hosts (allocations) have been terminated.",
    "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "deUlqCqnz"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 8
  },
  "id": 6,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "COUNT",
          "parameters": [
            {
              "name": "UnHealthyHostCount",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "AWS ALB - Target Group - Unhealthy Hosts",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Prod - 9",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "b3183ad6-1bf0-43bd-ad20-68975c6b00c3",
                    "title": "Accounts Service - AWS ALB 5XX Balancer Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "-ZgsNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "-ZgsNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_ELB_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38zProd1",
                    "panelId": 9,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14204",
                        "__dashboardUid__": "GWHu_Q38zProd1",
                        "__panelId__": "9",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "b3183ad6-1bf0-43bd-ad20-68975c6b00c3"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "-ZgsNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 9,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_ELB_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Load Balancer",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_targets_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Prod - 7",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "c77ae8f2-ecae-4011-9489-0daaebc9c987",
                    "title": "Accounts Service - AWS ALB 5XX Target Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "-ZgsNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "-ZgsNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "SUM",
                                        "parameters": [
                                            {
                                                "name": "HTTPCode_Target_5XX_Count",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38zProd1",
                    "panelId": 7,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14205",
                        "__dashboardUid__": "GWHu_Q38zProd1",
                        "__panelId__": "7",
                        "description": "",
                        "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "c77ae8f2-ecae-4011-9489-0daaebc9c987"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_targets_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "-ZgsNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
    "name": "Accounts Service - AWS ALB 5XX Target Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "Hpo3qC37z"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 7,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "SUM",
          "parameters": [
            {
              "name": "HTTPCode_Target_5XX_Count",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "AWS ALB - Error 5XX - Targets",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_unhealthy_hosts_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Load Balancer - Prod - 6",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "fa95f201-aef3-4035-b722-347d650cbb04",
                    "title": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "relativeTimeRange": {
                                "from": 300,
                                "to": 0
                            },
                            "datasourceUid": "-ZgsNfd7k",
                            "model": {
                                "alias": "",
                                "datasource": {
                                    "type": "cloudwatch",
                                    "uid": "-ZgsNfd7k"
                                },
                                "dimensions": {
                                    "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                                },
                                "expression": "",
                                "id": "",
                                "intervalMs": 200,
                                "label": "",
                                "matchExact": true,
                                "maxDataPoints": 1500,
                                "metricEditorMode": 0,
                                "metricName": "HTTPCode_ELB_5XX_Count",
                                "metricQueryType": 1,
                                "namespace": "AWS/ApplicationELB",
                                "period": "",
                                "queryMode": "Metrics",
                                "refId": "A",
                                "region": "us-east-1",
                                "sql": {
                                    "from": {
                                        "property": {
                                            "name": "AWS/ApplicationELB",
                                            "type": "string"
                                        },
                                        "type": "property"
                                    },
                                    "select": {
                                        "name": "COUNT",
                                        "parameters": [
                                            {
                                                "name": "UnHealthyHostCount",
                                                "type": "functionParameter"
                                            }
                                        ],
                                        "type": "function"
                                    },
                                    "where": {
                                        "expressions": [
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                                                },
                                                "property": {
                                                    "name": "LoadBalancer",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            },
                                            {
                                                "operator": {
                                                    "name": "=",
                                                    "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
                                                },
                                                "property": {
                                                    "name": "TargetGroup",
                                                    "type": "string"
                                                },
                                                "type": "operator"
                                            }
                                        ],
                                        "type": "and"
                                    }
                                },
                                "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
                                "statistic": "Sum"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                0
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "GWHu_Q38zProd1",
                    "panelId": 6,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14206",
                        "__dashboardUid__": "GWHu_Q38zProd1",
                        "__panelId__": "6",
                        "description": "",
                        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Prod. There may be some issue where hosts (allocations) have been terminated.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "fa95f201-aef3-4035-b722-347d650cbb04"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod_panels/failures_load_balancer_unhealthy_hosts_panel.json
================
{
  "datasource": {
    "type": "cloudwatch",
    "uid": "-ZgsNfd7k"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            0
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "There is at least one unhealthy host in the target group for the Accounts Service in Prod. There may be some issue where hosts (allocations) have been terminated.",
    "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": [
      {
        "__systemRef": "hideSeriesFrom",
        "matcher": {
          "id": "byNames",
          "options": {
            "mode": "exclude",
            "names": [
              "query59e36329b34547d0968477d6110c8615"
            ],
            "prefix": "All except:",
            "readOnly": true
          }
        },
        "properties": [
          {
            "id": "custom.hideFrom",
            "value": {
              "legend": false,
              "tooltip": false,
              "viz": true
            }
          }
        ]
      }
    ]
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 0,
    "y": 8
  },
  "id": 6,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "alias": "",
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "dimensions": {
        "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
      },
      "expression": "",
      "id": "",
      "label": "",
      "matchExact": true,
      "metricEditorMode": 0,
      "metricName": "HTTPCode_ELB_5XX_Count",
      "metricQueryType": 1,
      "namespace": "AWS/ApplicationELB",
      "period": "",
      "queryMode": "Metrics",
      "refId": "A",
      "region": "us-east-1",
      "sql": {
        "from": {
          "property": {
            "name": "AWS/ApplicationELB",
            "type": "string"
          },
          "type": "property"
        },
        "select": {
          "name": "COUNT",
          "parameters": [
            {
              "name": "UnHealthyHostCount",
              "type": "functionParameter"
            }
          ],
          "type": "function"
        },
        "where": {
          "expressions": [
            {
              "operator": {
                "name": "=",
                "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
              },
              "property": {
                "name": "LoadBalancer",
                "type": "string"
              },
              "type": "operator"
            },
            {
              "operator": {
                "name": "=",
                "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
              },
              "property": {
                "name": "TargetGroup",
                "type": "string"
              },
              "type": "operator"
            }
          ],
          "type": "and"
        }
      },
      "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
      "statistic": "Sum"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 0,
      "visible": true
    }
  ],
  "title": "AWS ALB - Target Group - Unhealthy Hosts",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_dev_panels/failures_other_apps_admin_portal_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Dev - 8",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "b6d4fa1f-66f1-4ab2-9f89-410f135049f1",
                    "title": "Accounts Service - Admin Portal Errors Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "instant",
                            "relativeTimeRange": {
                                "from": 1800,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "max(sum(count_over_time({service=\"admin-portal\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m])))",
                                "intervalMs": 1000,
                                "maxDataPoints": 1500,
                                "queryType": "instant",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "params": [],
                                            "type": "last"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67z",
                    "panelId": 8,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14117",
                        "__dashboardUid__": "il89IN67z",
                        "__panelId__": "8",
                        "description": "",
                        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "b6d4fa1f-66f1-4ab2-9f89-410f135049f1"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_dev_panels/failures_other_apps_admin_portal_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "30m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
    "name": "Accounts Service - Admin Portal Errors Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 8,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Admin Portal Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_dev_panels/failures_other_apps_prism_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Dev - 4",
            "folder": "Core Tech Services - Auth",
            "interval": "1m",
            "rules": [
                {
                    "uid": "cb7e0c05-cb41-4cdd-b044-234ff214cdac",
                    "title": "Accounts Service - Errors from Prism Alert - Dev",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({cluster=\"prism-dev-crunch\", namespace=\"ci-develop\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
                                "intervalMs": 500,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67z",
                    "panelId": 4,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14115",
                        "__dashboardUid__": "il89IN67z",
                        "__panelId__": "4",
                        "description": "",
                        "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\"",
                        "rule_uid": "cb7e0c05-cb41-4cdd-b044-234ff214cdac"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_dev_panels/failures_other_apps_prism_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "10m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
    "name": "Accounts Service - Errors from Prism Alert - Dev",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 7,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 4,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({cluster=\"prism-dev-crunch\", namespace=\"ci-develop\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Prism Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_preprod_panels/failures_other_apps_admin_portal_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Preprod - 8",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "e9e6fc46-6da9-49a6-80c5-860806555bbb",
                    "title": "Accounts Service - Admin Portal Errors Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 1800,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
                                "intervalMs": 1000,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67y",
                    "panelId": 8,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14194",
                        "__dashboardUid__": "il89IN67y",
                        "__panelId__": "8",
                        "description": "",
                        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "e9e6fc46-6da9-49a6-80c5-860806555bbb"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_preprod_panels/failures_other_apps_admin_portal_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "30m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
    "name": "Accounts Service - Admin Portal Errors Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 12,
    "x": 12,
    "y": 0
  },
  "id": 8,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Admin Portal Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_preprod_panels/failures_other_apps_prism_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Preprod - 4",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "cd2eec69-79d9-4334-bbf0-f0291affbe39",
                    "title": "Accounts Service - Errors from Prism Alert - Preprod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 600,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({cluster=\"prism-prod-bix\", namespace=\"prism-beta\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
                                "intervalMs": 500,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67y",
                    "panelId": 4,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14193",
                        "__dashboardUid__": "il89IN67y",
                        "__panelId__": "4",
                        "description": "",
                        "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Dev\"",
                        "rule_uid": "cd2eec69-79d9-4334-bbf0-f0291affbe39"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_preprod_panels/failures_other_apps_prism_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "10m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
    "name": "Accounts Service - Errors from Prism Alert - Preprod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "deUlqCqnz"
      },
      {
        "uid": "K3ux9de7k"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 7,
    "w": 12,
    "x": 0,
    "y": 0
  },
  "id": 4,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({cluster=\"prism-prod-bix\", namespace=\"prism-beta\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Prism Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_prod_panels/failures_other_apps_admin_portal_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Prod - 8",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "a50143b4-e0ad-4c9f-9eb9-0cbea40e5c01",
                    "title": "Accounts Service - Admin Portal Errors Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 1800,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
                                "intervalMs": 1000,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67yProd1",
                    "panelId": 8,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14208",
                        "__dashboardUid__": "il89IN67yProd1",
                        "__panelId__": "8",
                        "description": "",
                        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "a50143b4-e0ad-4c9f-9eb9-0cbea40e5c01"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_prod_panels/failures_other_apps_admin_portal_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "30m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
    "name": "Accounts Service - Admin Portal Errors Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 8,
    "w": 24,
    "x": 0,
    "y": 15
  },
  "id": 8,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Admin Portal Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_prod_panels/failures_other_apps_prism_alert_rule.json
================
{
    "apiVersion": 1,
    "groups": [
        {
            "orgId": 1,
            "name": "Accounts - Failures and Alerts - Other Apps - Prod - 8",
            "folder": "Core Tech Services - Auth Alerts - 82076c5c7d17b595bcc29656c7dd5507",
            "interval": "1m",
            "rules": [
                {
                    "uid": "a50143b4-e0ad-4c9f-9eb9-0cbea40e5c01",
                    "title": "Accounts Service - Admin Portal Errors Alert - Prod",
                    "condition": "B",
                    "data": [
                        {
                            "refId": "A",
                            "queryType": "range",
                            "relativeTimeRange": {
                                "from": 1800,
                                "to": 0
                            },
                            "datasourceUid": "grafanacloud-logs",
                            "model": {
                                "datasource": {
                                    "type": "loki",
                                    "uid": "grafanacloud-logs"
                                },
                                "editorMode": "code",
                                "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
                                "intervalMs": 1000,
                                "maxDataPoints": 1500,
                                "queryType": "range",
                                "refId": "A"
                            }
                        },
                        {
                            "refId": "B",
                            "relativeTimeRange": {
                                "from": 0,
                                "to": 0
                            },
                            "datasourceUid": "__expr__",
                            "model": {
                                "conditions": [
                                    {
                                        "evaluator": {
                                            "params": [
                                                10
                                            ],
                                            "type": "gt"
                                        },
                                        "operator": {
                                            "type": "and"
                                        },
                                        "query": {
                                            "params": [
                                                "A"
                                            ]
                                        },
                                        "reducer": {
                                            "type": "max"
                                        }
                                    }
                                ],
                                "intervalMs": 1000,
                                "maxDataPoints": 43200,
                                "refId": "B",
                                "type": "classic_conditions"
                            }
                        }
                    ],
                    "dasboardUid": "il89IN67yProd1",
                    "panelId": 8,
                    "noDataState": "OK",
                    "execErrState": "OK",
                    "for": "0s",
                    "annotations": {
                        "__alertId__": "14208",
                        "__dashboardUid__": "il89IN67yProd1",
                        "__panelId__": "8",
                        "description": "",
                        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
                        "runbook_url": "",
                        "summary": ""
                    },
                    "labels": {
                        "": "",
                        "__contacts__": "\"CTS Auth Alerts\",\"VictorOps Alert - key-Auth-Prod\"",
                        "rule_uid": "a50143b4-e0ad-4c9f-9eb9-0cbea40e5c01"
                    },
                    "isPaused": false
                }
            ]
        }
    ]
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_prod_panels/failures_other_apps_prism_panel.json
================
{
  "datasource": {
    "type": "loki",
    "uid": "grafanacloud-logs"
  },
  "alert": {
    "alertRuleTags": {},
    "conditions": [
      {
        "evaluator": {
          "params": [
            10
          ],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        },
        "query": {
          "params": [
            "A",
            "5m",
            "now"
          ]
        },
        "reducer": {
          "params": [],
          "type": "max"
        },
        "type": "query"
      }
    ],
    "executionErrorState": "keep_state",
    "for": "0s",
    "frequency": "1m",
    "handler": 1,
    "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
    "name": "Accounts Service - Errors from Prism Alert - Prod",
    "noDataState": "ok",
    "notifications": [
      {
        "uid": "K3ux9de7k"
      },
      {
        "uid": "Hpo3qC37z"
      }
    ]
  },
  "fieldConfig": {
    "defaults": {
      "custom": {
        "drawStyle": "line",
        "lineInterpolation": "linear",
        "barAlignment": 0,
        "lineWidth": 1,
        "fillOpacity": 0,
        "gradientMode": "none",
        "spanNulls": false,
        "insertNulls": false,
        "showPoints": "auto",
        "pointSize": 5,
        "stacking": {
          "mode": "none",
          "group": "A"
        },
        "axisPlacement": "auto",
        "axisLabel": "",
        "axisColorMode": "text",
        "axisBorderShow": false,
        "scaleDistribution": {
          "type": "linear"
        },
        "axisCenteredZero": false,
        "hideFrom": {
          "tooltip": false,
          "viz": false,
          "legend": false
        },
        "thresholdsStyle": {
          "mode": "off"
        }
      },
      "color": {
        "mode": "palette-classic"
      },
      "mappings": [],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          {
            "color": "green",
            "value": null
          },
          {
            "color": "red",
            "value": 80
          }
        ]
      }
    },
    "overrides": []
  },
  "gridPos": {
    "h": 7,
    "w": 24,
    "x": 0,
    "y": 0
  },
  "id": 4,
  "options": {
    "tooltip": {
      "mode": "single",
      "sort": "none"
    },
    "legend": {
      "showLegend": true,
      "displayMode": "list",
      "placement": "bottom",
      "calcs": []
    }
  },
  "targets": [
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "editorMode": "code",
      "expr": "sum(count_over_time({cluster=\"prism-prod-bix\", namespace=\"prism-production\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [5m]))",
      "queryType": "range",
      "refId": "A"
    }
  ],
  "thresholds": [
    {
      "colorMode": "critical",
      "op": "gt",
      "value": 10,
      "visible": true
    }
  ],
  "title": "Prism Errors from Accounts Service",
  "type": "timeseries"
}

================
File: cts/grafana/dashboards/templates/accounts-service/drill_in_kubernetes.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12669,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 5,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 1
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "rate(http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"2..\"}[$__rate_interval])",
          "interval": "",
          "legendFormat": "{{ pod }}",
          "refId": "A"
        }
      ],
      "title": "2xx HTTP Request Duration by Pod (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 1
      },
      "id": 3,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\"}[$__rate_interval]) )",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "max(rate(http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\"}[$__rate_interval]) )",
          "hide": false,
          "interval": "",
          "legendFormat": "",
          "refId": "B"
        }
      ],
      "title": "2xx Avg vs Max HTTP Request Duration (seconds)",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 9
      },
      "id": 7,
      "panels": [],
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 10
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"2..\"}[1m]) / rate(http_request_duration_seconds_count{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"2..\"}[1m])) by (service, route, method, code)",
          "hide": false,
          "interval": "",
          "legendFormat": "{{ service }} - {{ method }} - {{ route }} - {{ code }}",
          "refId": "B"
        }
      ],
      "title": "2xx Average Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 10
      },
      "id": 11,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"2..\"}[1m])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{ service }} - {{ method }} - {{ route }} - {{ code }}",
          "refId": "A"
        }
      ],
      "title": "2xx 95th Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 18
      },
      "id": 13,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"2..\"}[1m])) by (service, route, method, code)",
          "interval": "",
          "legendFormat": "{{ service }} - {{ method }} - {{ route }} - {{ code }}",
          "refId": "A"
        }
      ],
      "title": "Request Per Minute",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 18
      },
      "id": 15,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(increase(http_request_duration_seconds_count{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\", code=~\"4..\"}[1m])) /  sum(increase(http_request_duration_seconds_count{cluster=\"$Cluster\", container=\"$Deployment\", route=\"$Route\"}[1m]))",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "WIP - Error Rate (seconds) ",
      "type": "timeseries"
    }
  ],
  "refresh": false,
  "schemaVersion": 37,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "prism-dev-crunch",
          "value": "prism-dev-crunch"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\"}, cluster) ",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Cluster",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\"}, cluster) ",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "global-ci-permissions",
          "value": "global-ci-permissions"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\"}, exported_namespace)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Namespace",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\"}, exported_namespace)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "permissions-service",
          "value": "permissions-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\", exported_namespace=~\"^$Namespace$\"}, deployment)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Deployment",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\", exported_namespace=~\"^$Namespace$\"}, deployment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "/.*(permissions-service)/",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "/permissions/:productName/az/:azId",
          "value": "/permissions/:productName/az/:azId"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\"}",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Route",
        "options": [],
        "query": {
          "query": "http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\"}",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "/.*route=\"([^\"]*).*/",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "2021-11-04T17:02:17.519Z",
    "to": "2021-11-04T17:17:17.519Z"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Drill-in (Kubernetes)",
  "uid": "C6CRxtYnk",
  "version": 1,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/drill_in_nomad_2.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12875,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 5,
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "10.135.8.155:23897 - "
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 1
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "exemplar": true,
          "expr": "rate(http_request_duration_seconds_sum{instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}[$__rate_interval])/ rate(http_request_duration_seconds_count{instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}[$__rate_interval])\n",
          "format": "time_series",
          "instant": false,
          "interval": "",
          "legendFormat": "{{ instance }} - {{__rate_interval}}",
          "refId": "A"
        }
      ],
      "title": "2xx HTTP Request Duration by Allocation (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "10.135.8.155:23897 - "
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 1
      },
      "id": 17,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "exemplar": true,
          "expr": "http_request_duration_seconds_sum{instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}/ http_request_duration_seconds_count{instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}\n",
          "format": "time_series",
          "instant": false,
          "interval": "",
          "legendFormat": "{{ instance }} - {{__rate_interval}}",
          "refId": "A"
        }
      ],
      "title": "2xx HTTP Request Duration by Allocation (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "10.135.8.155:23897 - /permissions/:productName/az/:azId"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 9
      },
      "id": 16,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "exemplar": false,
          "expr": "http_request_duration_seconds_count{service=\"$Service\", environment=\"$Environment\", instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}\n",
          "format": "time_series",
          "hide": false,
          "instant": false,
          "legendFormat": "{{instance}} - {{route}}",
          "range": true,
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "sum(http_request_duration_seconds_count{service=\"$Service\", environment=\"$Environment\", route=\"$Route\", code=~\"2..\"})",
          "hide": false,
          "legendFormat": "all allocations {{ route }}",
          "range": true,
          "refId": "C"
        }
      ],
      "title": "2xx HTTP Request Count by Allocation",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 9
      },
      "id": 3,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\",route=\"$Route\"}[$__rate_interval]) )",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "max(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\",route=\"$Route\"}[$__rate_interval]) )",
          "hide": false,
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "B"
        }
      ],
      "title": "2xx Avg vs Max HTTP Request Duration (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 17
      },
      "id": 13,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[1m])) by (service, route, method, code)",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Request Per Minute",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 25
      },
      "id": 7,
      "panels": [],
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 26
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[1m])) / sum(rate(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[1m])))by (service, route, method, code)",
          "hide": false,
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "B"
        }
      ],
      "title": "2xx Average Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 26
      },
      "id": 11,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", route=\"$Route\", code=~\"2..\"}[1m])) by (le, service, route, method))",
          "instant": false,
          "interval": "",
          "legendFormat": "{{ service }} - {{ method }} - {{ route }} - {{ code }}",
          "refId": "A"
        }
      ],
      "title": "2xx 95th Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 34
      },
      "id": 15,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(increase(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"4..\"}[1m])) /  sum(increase(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\"}[1m]))",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "WIP - Error Rate (seconds) ",
      "type": "timeseries"
    }
  ],
  "refresh": false,
  "schemaVersion": 37,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "accounts-service",
          "value": "accounts-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(service)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Service",
        "options": [],
        "query": {
          "query": "label_values(service)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "prod",
          "value": "prod"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, environment)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Environment",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, environment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "oga",
          "value": "oga"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, business_unit)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "BusinessUnit",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, business_unit)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
        "hide": 0,
        "includeAll": true,
        "multi": true,
        "name": "Deployment",
        "options": [],
        "query": {
          "query": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "/permissions/:productName/az/:azId",
          "value": "/permissions/:productName/az/:azId"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "http_request_duration_seconds_sum{service=\"$Service\"}",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Route",
        "options": [],
        "query": {
          "query": "http_request_duration_seconds_sum{service=\"$Service\"}",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "/.*route=\"([^\"]*).*/",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-12h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Drill-in (Nomad) 2",
  "uid": "LGV02L9nz",
  "version": 1,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/drill_in_nomad.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12670,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 5,
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 1
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "rate(http_request_duration_seconds_sum{instance=~\"$Deployment\", route=\"$Route\", code=~\"2..\"}[$__rate_interval])",
          "instant": false,
          "interval": "",
          "legendFormat": "{{ instance }}",
          "refId": "A"
        }
      ],
      "title": "2xx HTTP Request Duration by Allocation (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 1
      },
      "id": 3,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\",route=\"$Route\"}[$__rate_interval]) )",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "max(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\",route=\"$Route\"}[$__rate_interval]) )",
          "hide": false,
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "B"
        }
      ],
      "title": "2xx Avg vs Max HTTP Request Duration (seconds)",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 9
      },
      "id": 7,
      "panels": [],
      "title": "Row title",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 10
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[5m])))by (service, route, method, code)",
          "hide": false,
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "B"
        }
      ],
      "title": "2xx Average Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 10
      },
      "id": 11,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", route=\"$Route\", code=~\"2..\"}[5m])) by (le, service, route, method))",
          "instant": false,
          "interval": "",
          "legendFormat": "{{ service }} - {{ method }} - {{ route }} - {{ code }}",
          "refId": "A"
        }
      ],
      "title": "2xx 95th Response Time (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 18
      },
      "id": 13,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"2..\"}[5m])) by (service, route, method, code)",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Request Per Minute",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 18
      },
      "id": 15,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(increase(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\", code=~\"4..\"}[1m])) /  sum(increase(http_request_duration_seconds_count{environment=\"$Environment\", service=\"$Service\", route=\"$Route\"}[1m]))",
          "instant": false,
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "WIP - Error Rate (seconds) ",
      "type": "timeseries"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 37,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "accounts-service",
          "value": "accounts-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(service)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Service",
        "options": [],
        "query": {
          "query": "label_values(service)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "prod",
          "value": "prod"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, environment)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Environment",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, environment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "oga",
          "value": "oga"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, business_unit)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "BusinessUnit",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, business_unit)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
        "hide": 0,
        "includeAll": true,
        "multi": true,
        "name": "Deployment",
        "options": [],
        "query": {
          "query": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "/permissions/:productName/az/:azId",
          "value": "/permissions/:productName/az/:azId"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "http_request_duration_seconds_sum{service=\"$Service\"}",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Route",
        "options": [],
        "query": {
          "query": "http_request_duration_seconds_sum{service=\"$Service\"}",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "/.*route=\"([^\"]*).*/",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-15m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Drill-in (Nomad)",
  "uid": "MBjkbtYnz",
  "version": 11,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_dev.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12890,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0",
        "frequency": "1m",
        "handler": 1,
        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Dev. There may be an issue with the service.",
        "name": "Accounts Service - Errors Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Accounts Service - Errors",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                3
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Salesforce integration for the Accounts Service in Dev has not been available in the last minutes, and may be down.",
        "name": "Accounts Service - Salesforce Errors Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 3,
          "visible": true
        }
      ],
      "title": "Accounts Service - Salesforce Errors",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Error Logs",
      "type": "logs"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 8,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Salesforce Error Logs",
      "type": "logs"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "B",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "C",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "D",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "E",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "F",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Average HTTP Request Durations (seconds) in the Accounts Service have exceeded 2 seconds in the last minutes in Dev. There may be a performance issue with the service.",
        "name": "Accounts Service - 2xx Avg HTTP Request Duration (seconds) Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 10,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/organizations\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/organizations\"}[5m]))) by (service)",
          "legendFormat": "__auto",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "D"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "E"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"dev\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"dev\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "F"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 2,
          "visible": true
        }
      ],
      "title": "Accounts Service - 2xx Avg HTTP Request Duration (seconds)",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Accounts Service - Dev",
  "uid": "l7-2zNe7z",
  "version": 66,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_preprod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12951,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0",
        "frequency": "1m",
        "handler": 1,
        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Preprod. There may be an issue with the service.",
        "name": "Accounts Service - Errors Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Accounts Service - Errors",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                3
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Salesforce integration for the Accounts Service in Preprod has not been available in the last minutes, and may be down.",
        "name": "Accounts Service - Salesforce Errors Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 3,
          "visible": true
        }
      ],
      "title": "Accounts Service - Salesforce Errors",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Error Logs",
      "type": "logs"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 8,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Salesforce Error Logs",
      "type": "logs"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "B",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "C",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "D",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "E",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "F",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Average HTTP Request Durations (seconds) in the Accounts Service have exceeded 2 seconds in the last minutes in Preprod. There may be a performance issue with the service.",
        "name": "Accounts Service - 2xx Avg HTTP Request Duration (seconds) Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 10,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/organizations\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/organizations\"}[5m]))) by (service)",
          "legendFormat": "__auto",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "D"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "E"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"preprod\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"preprod\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "F"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 2,
          "visible": true
        }
      ],
      "title": "Accounts Service - 2xx Avg HTTP Request Duration (seconds)",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Accounts Service - Preprod",
  "uid": "l7-2zNe7y",
  "version": 23,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_accounts_service_prod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12964,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0",
        "frequency": "1m",
        "handler": 1,
        "message": "The Accounts Service has logged more than 10 errors in the last 5 minutes in Prod. There may be an issue with the service.",
        "name": "Accounts Service - Errors Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\" [5m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Accounts Service - Errors",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                3
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Salesforce integration for the Accounts Service in Prod has not been available in the last minutes, and may be down.",
        "name": "Accounts Service - Salesforce Errors Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\" [10m])\n)",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 3,
          "visible": true
        }
      ],
      "title": "Accounts Service - Salesforce Errors",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" !~ \"ValidationError\" !~ \"Bad Authorization\" !~ \"UnauthorizedError\" !~ \"user with id.*does not exist\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Error Logs",
      "type": "logs"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 8,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"accounts-service\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"Salesforce\" |~ \"(SERVER_UNAVAILABLE|ECONNRESET)\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Salesforce Error Logs",
      "type": "logs"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "B",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "C",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "D",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "E",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          },
          {
            "evaluator": {
              "params": [
                2
              ],
              "type": "gt"
            },
            "operator": {
              "type": "or"
            },
            "query": {
              "params": [
                "F",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "2m",
        "handler": 1,
        "message": "Average HTTP Request Durations (seconds) in the Accounts Service has exceeded 2 seconds in the last minutes in Prod. There may be a performance issue with the service.",
        "name": "Accounts Service - 2xx Avg HTTP Request Duration (seconds) Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 10,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/organizations\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/organizations\"}[5m]))) by (service)",
          "legendFormat": "__auto",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/organizations/:organizationId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/users/management/idp\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/users/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "D"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/users/management/:userId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "E"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "expr": "avg(sum(rate(http_request_duration_seconds_sum{environment=\"prod\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m])) / sum(rate(http_request_duration_seconds_count{environment=\"prod\", service=\"accounts-service\",route=\"/permissions/:productName/az/:azId\"}[5m]))) by (service)",
          "hide": false,
          "legendFormat": "__auto",
          "range": true,
          "refId": "F"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 2,
          "visible": true
        }
      ],
      "title": "Accounts Service - 2xx Avg HTTP Request Duration (seconds)",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Accounts Service - Prod",
  "uid": "l7-2zNe7zProd1",
  "version": 28,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_dev.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12892,
  "links": [],
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Dev in the last minutes. There may be an issue with the container or the service.",
        "name": "Accounts Service - Firehose Failures Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 11,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"dev\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
       "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "Firehose Failures",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 13,
        "w": 24,
        "x": 0,
        "y": 11
      },
      "id": 4,
      "options": {
        "dedupStrategy": "none",
        "enableInfiniteScrolling": false,
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "{service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"dev\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Firehose Failures Logs",
      "type": "logs"
    }
  ],
  "preload": false,
  "refresh": "",
  "schemaVersion": 41,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Firehose - Dev",
  "uid": "8D32GHenz",
  "version": 31
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_preprod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12952,
  "links": [],
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Preprod in the last minutes. There may be an issue with the container or the service.",
        "name": "Accounts Service - Firehose Failures Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"preprod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "Firehose Failures",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 9
      },
      "id": 4,
      "options": {
        "dedupStrategy": "none",
        "enableInfiniteScrolling": false,
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "{service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"preprod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Firehose Failures Logs",
      "type": "logs"
    }
  ],
  "preload": false,
  "refresh": "",
  "schemaVersion": 41,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Firehose - Preprod",
  "uid": "8D32GHeOz",
  "version": 15
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_firehose_prod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12965,
  "links": [],
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "One or more containers for the Accounts Service ended abnormally in Nomad Prod in the last minutes. There may be an issue with the container or the service.",
        "name": "Accounts Service - Firehose Failures Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"prod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\" [1m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "Firehose Failures",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 9
      },
      "id": 4,
      "options": {
        "dedupStrategy": "none",
        "enableInfiniteScrolling": false,
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "pluginVersion": "12.1.0-88106",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "direction": "backward",
          "editorMode": "code",
          "expr": "{service=\"di-nomad-firehose\", business_unit=\"oga\", environment=\"prod\"} | json | TaskEvent_ExitCode!=0 |~ \"accounts-service\" !~ \"due to job update\" !~ \"alloc is lost since its node is down\" !~ \"alloc is being migrated\" !~ \"Exit Code: 137\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Firehose Failures Logs",
      "type": "logs"
    }
  ],
  "preload": false,
  "refresh": "",
  "schemaVersion": 41,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Firehose - Prod",
  "uid": "8D32GHeOzProd1",
  "version": 14
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_dev.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12889,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "_nhYNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_ELB_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Load Balancer",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Dev has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Target Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "_nhYNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_Target_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Targets",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Dev. There may be some issue where hosts (allocations) have been terminated.",
        "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "_nhYNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "_nhYNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "COUNT",
              "parameters": [
                {
                  "name": "UnHealthyHostCount",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-dev-alb/e6eaca349e4ff0e6' AND TargetGroup = 'targetgroup/ea-dev-accounts-service-tg/9fafb2a9c797943f'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "AWS ALB - Target Group - Unhealthy Hosts",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Load Balancer - Dev",
  "uid": "GWHu_Q37z",
  "version": 99,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_preprod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12956,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "oAOPHBOnk"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_ELB_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Load Balancer",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Preprod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Target Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "oAOPHBOnk"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_Target_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Targets",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Preprod. There may be some issue where hosts (allocations) have been terminated.",
        "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "deUlqCqnz"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "oAOPHBOnk"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "oAOPHBOnk"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "COUNT",
              "parameters": [
                {
                  "name": "UnHealthyHostCount",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-preprod-alb/0f3f5ab57f3546b5"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-preprod-alb/0f3f5ab57f3546b5' AND TargetGroup = 'targetgroup/ea-preprod-accounts-service-tg/a7ff8c154666c1d2'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "AWS ALB - Target Group - Unhealthy Hosts",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Load Balancer - Preprod",
  "uid": "GWHu_Q38z",
  "version": 14,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_load_balancer_prod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12966,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the loader itself,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Balancer Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 9,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "-ZgsNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_ELB_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_ELB_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Load Balancer",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The AWS Application Loader Balancer for the Accounts Service in Prod has logged multiple 5XX HTTP response codes generated by the targets,\nduring the last 5 minutes. Something may be wrong with the load balancer or the targets.",
        "name": "Accounts Service - AWS ALB 5XX Target Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "Hpo3qC37z"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 7,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "-ZgsNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "SUM",
              "parameters": [
                {
                  "name": "HTTPCode_Target_5XX_Count",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT SUM(HTTPCode_Target_5XX_Count) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "AWS ALB - Error 5XX - Targets",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                0
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "There is at least one unhealthy host in the target group for the Accounts Service in Prod. There may be some issue where hosts (allocations) have been terminated.",
        "name": "Accounts Service - AWS ALB Unhealthy Hosts Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "cloudwatch",
        "uid": "-ZgsNfd7k"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "query59e36329b34547d0968477d6110c8615"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "alias": "",
          "datasource": {
            "type": "cloudwatch",
            "uid": "-ZgsNfd7k"
          },
          "dimensions": {
            "LoadBalancer": "app/accounts-service-dev-alb/e6eaca349e4ff0e6"
          },
          "expression": "",
          "id": "",
          "label": "",
          "matchExact": true,
          "metricEditorMode": 0,
          "metricName": "HTTPCode_ELB_5XX_Count",
          "metricQueryType": 1,
          "namespace": "AWS/ApplicationELB",
          "period": "",
          "queryMode": "Metrics",
          "refId": "A",
          "region": "us-east-1",
          "sql": {
            "from": {
              "property": {
                "name": "AWS/ApplicationELB",
                "type": "string"
              },
              "type": "property"
            },
            "select": {
              "name": "COUNT",
              "parameters": [
                {
                  "name": "UnHealthyHostCount",
                  "type": "functionParameter"
                }
              ],
              "type": "function"
            },
            "where": {
              "expressions": [
                {
                  "operator": {
                    "name": "=",
                    "value": "app/accounts-service-prod-alb/20f03262015e0c6a"
                  },
                  "property": {
                    "name": "LoadBalancer",
                    "type": "string"
                  },
                  "type": "operator"
                },
                {
                  "operator": {
                    "name": "=",
                    "value": "targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9"
                  },
                  "property": {
                    "name": "TargetGroup",
                    "type": "string"
                  },
                  "type": "operator"
                }
              ],
              "type": "and"
            }
          },
          "sqlExpression": "SELECT MAX(UnHealthyHostCount) FROM \"AWS/ApplicationELB\" WHERE LoadBalancer = 'app/accounts-service-prod-alb/20f03262015e0c6a' AND TargetGroup = 'targetgroup/ea-prod-accounts-service-tg/3f325378fc697df9'",
          "statistic": "Sum"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 0,
          "visible": true
        }
      ],
      "title": "AWS ALB - Target Group - Unhealthy Hosts",
      "type": "timeseries"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Load Balancer - Prod",
  "uid": "GWHu_Q38zProd1",
  "version": 17,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_dev.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12893,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
        "name": "Accounts Service - Errors from Prism Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({cluster=\"prism-dev-crunch\", namespace=\"ci-develop\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Prism Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "30m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Dev. It may not be able to connect to that service.",
        "name": "Accounts Service - Admin Portal Errors Alert - Dev",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 8,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Admin Portal Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 7
      },
      "id": 10,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{cluster=\"prism-dev-crunch\", namespace=\"ci-develop\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Prism Error Logs from Accounts Service",
      "type": "logs"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"admin-portal\", environment=\"dev\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Admin Portal Error Logs from Accounts Service",
      "type": "logs"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Other Apps - Dev",
  "uid": "il89IN67z",
  "version": 47,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_preprod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12957,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "10m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
        "name": "Accounts Service - Errors from Prism Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({cluster=\"prism-prod-bix\", namespace=\"prism-beta\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [10m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Prism Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "30m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Preprod. It may not be able to connect to that service.",
        "name": "Accounts Service - Admin Portal Errors Alert - Preprod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "deUlqCqnz"
          },
          {
            "uid": "K3ux9de7k"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 8,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Admin Portal Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 7
      },
      "id": 10,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{cluster=\"prism-prod-bix\", namespace=\"prism-beta\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Prism Error Logs from Accounts Service",
      "type": "logs"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"admin-portal\", environment=\"preprod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Admin Portal Error Logs from Accounts Service",
      "type": "logs"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Other Apps - Preprod",
  "uid": "il89IN67y",
  "version": 15,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/failures_other_apps_prod.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 12967,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "5m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "Prism has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
        "name": "Accounts Service - Errors from Prism Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({cluster=\"prism-prod-bix\", namespace=\"prism-production\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [5m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Prism Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 7
      },
      "id": 10,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{cluster=\"prism-prod-bix\", namespace=\"prism-production\", container=\"prism\"} |= \"error\" |~ \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Prism Error Logs from Accounts Service",
      "type": "logs"
    },
    {
      "alert": {
        "alertRuleTags": {},
        "conditions": [
          {
            "evaluator": {
              "params": [
                10
              ],
              "type": "gt"
            },
            "operator": {
              "type": "and"
            },
            "query": {
              "params": [
                "A",
                "30m",
                "now"
              ]
            },
            "reducer": {
              "params": [],
              "type": "max"
            },
            "type": "query"
          }
        ],
        "executionErrorState": "keep_state",
        "for": "0s",
        "frequency": "1m",
        "handler": 1,
        "message": "The Admin Portal has logged multiple errors in the last minutes, related to the Accounts Service in Prod. It may not be able to connect to that service.",
        "name": "Accounts Service - Admin Portal Errors Alert - Prod",
        "noDataState": "ok",
        "notifications": [
          {
            "uid": "K3ux9de7k"
          },
          {
            "uid": "Hpo3qC37z"
          }
        ]
      },
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 15
      },
      "id": 8,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "sum(count_over_time({service=\"admin-portal\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\" [30m]))",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "thresholds": [
        {
          "colorMode": "critical",
          "op": "gt",
          "value": 10,
          "visible": true
        }
      ],
      "title": "Admin Portal Errors from Accounts Service",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 23
      },
      "id": 6,
      "options": {
        "dedupStrategy": "none",
        "enableLogDetails": true,
        "prettifyLogMessage": false,
        "showCommonLabels": false,
        "showLabels": false,
        "showTime": false,
        "sortOrder": "Descending",
        "wrapLogMessage": false
      },
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "editorMode": "code",
          "expr": "{service=\"admin-portal\", environment=\"prod\"} | json | level=\"error\" __error__!=\"JSONParserErr\" |= \"accounts\" !~ \"Request failed with status code 40\\\\d{1}\"",
          "queryType": "range",
          "refId": "A"
        }
      ],
      "title": "Admin Portal Error Logs from Accounts Service",
      "type": "logs"
    }
  ],
  "refresh": "",
  "schemaVersion": 39,
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts / Failures and Alerts - Other Apps - Prod",
  "uid": "il89IN67yProd1",
  "version": 19,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/nodejs_application_kubernetes.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "node.js prometheus client basic metrics",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "gnetId": 11159,
  "graphTooltip": 0,
  "id": 12665,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 10,
        "x": 0,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 6,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "irate(process_cpu_user_seconds_total{instance=~\"$instance\"}[2m]) * 100",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "User CPU - {{instance}}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "irate(process_cpu_system_seconds_total{instance=~\"$instance\"}[2m]) * 100",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Sys CPU - {{instance}}",
          "refId": "B"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Process CPU Usage",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "percent",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 9,
        "x": 10,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 8,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_eventloop_lag_seconds{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Event Loop Lag",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "s",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 3,
        "w": 5,
        "x": 19,
        "y": 0
      },
      "id": 2,
      "interval": "",
      "links": [],
      "maxDataPoints": 100,
      "options": {
        "colorMode": "none",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "horizontal",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "/^__name__$/",
          "values": false
        },
        "text": {},
        "textMode": "name"
      },
      "pluginVersion": "9.2.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "sum(nodejs_version_info{instance=~\"$instance\"}) by (version)",
          "format": "time_series",
          "instant": false,
          "interval": "",
          "intervalFactor": 1,
          "legendFormat": "{{version}}",
          "refId": "A"
        }
      ],
      "title": "Node.js Version",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "fixedColor": "#F2495C",
            "mode": "fixed"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 5,
        "x": 19,
        "y": 3
      },
      "id": 4,
      "links": [],
      "maxDataPoints": 100,
      "options": {
        "colorMode": "none",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "horizontal",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "9.2.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "sum(changes(process_start_time_seconds{instance=~\"$instance\"}[1m]))",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "title": "Process Restart Times",
      "type": "stat"
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 16,
        "x": 0,
        "y": 7
      },
      "hiddenSeries": false,
      "id": 7,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "process_resident_memory_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Process Memory - {{instance}}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_heap_size_total_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Total - {{instance}}",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_heap_size_used_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}}",
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_external_memory_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "External Memory - {{instance}}",
          "refId": "D"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Process Memory Usage",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 8,
        "x": 16,
        "y": 7
      },
      "hiddenSeries": false,
      "id": 9,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_active_handles_total{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Active Handler - {{instance}}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_active_requests_total{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Active Request - {{instance}}",
          "refId": "B"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Active Handlers/Requests Total",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "short",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 0,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 10,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_heap_space_size_total_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Total - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Total Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 8,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 11,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_heap_space_size_used_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Used Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 16,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 12,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "nodejs_heap_space_size_available_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Available Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    }
  ],
  "refresh": "5s",
  "schemaVersion": 37,
  "style": "dark",
  "tags": [
    "accounts-service",
    "NodeJS"
  ],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "prism-dev-crunch",
          "value": "prism-dev-crunch"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_pod_info, cluster)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Cluster",
        "options": [],
        "query": {
          "query": "label_values(kube_pod_info, cluster)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "acuity-prefect",
          "value": "acuity-prefect"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_pod_info{cluster=\"$Cluster\"}, exported_namespace)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Namespace",
        "options": [],
        "query": {
          "query": "label_values(kube_pod_info{cluster=\"$Cluster\"}, exported_namespace)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(nodejs_version_info{cluster=\"$Cluster\", namespace=\"$Namespace\"},  instance)",
        "hide": 0,
        "includeAll": true,
        "label": "instance",
        "multi": true,
        "name": "instance",
        "options": [],
        "query": {
          "query": "label_values(nodejs_version_info{cluster=\"$Cluster\", namespace=\"$Namespace\"},  instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "tagValuesQuery": "",
        "tagsQuery": "",
        "type": "query",
        "useTags": false
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "5s",
      "10s",
      "30s",
      "1m",
      "5m",
      "15m",
      "30m",
      "1h",
      "2h",
      "1d"
    ],
    "time_options": [
      "5m",
      "15m",
      "1h",
      "6h",
      "12h",
      "24h",
      "2d",
      "7d",
      "30d"
    ]
  },
  "timezone": "",
  "title": "NodeJS Application Dashboard - Accounts Service (Kubernetes)",
  "uid": "lREFudYnz",
  "version": 3,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/nodejs_application_nomad.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "node.js prometheus client basic metrics",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "gnetId": 11159,
  "graphTooltip": 0,
  "id": 12666,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 10,
        "x": 0,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 6,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "irate(process_cpu_user_seconds_total{instance=~\"$instance\"}[2m]) * 100",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "User CPU - {{instance}}",
          "refId": "A"
        },
        {
          "expr": "irate(process_cpu_system_seconds_total{instance=~\"$instance\"}[2m]) * 100",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Sys CPU - {{instance}}",
          "refId": "B"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Process CPU Usage",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "percent",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 9,
        "x": 10,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 8,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "nodejs_eventloop_lag_seconds{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Event Loop Lag",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "s",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 3,
        "w": 5,
        "x": 19,
        "y": 0
      },
      "id": 2,
      "interval": "",
      "links": [],
      "maxDataPoints": 100,
      "options": {
        "colorMode": "none",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "horizontal",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "/^__name__$/",
          "values": false
        },
        "text": {},
        "textMode": "name"
      },
      "pluginVersion": "9.2.0",
      "targets": [
        {
          "expr": "sum(nodejs_version_info{instance=~\"$instance\"}) by (version)",
          "format": "time_series",
          "instant": false,
          "interval": "",
          "intervalFactor": 1,
          "legendFormat": "{{version}}",
          "refId": "A"
        }
      ],
      "title": "Node.js Version",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "fixedColor": "#F2495C",
            "mode": "fixed"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 5,
        "x": 19,
        "y": 3
      },
      "id": 4,
      "links": [],
      "maxDataPoints": 100,
      "options": {
        "colorMode": "none",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "horizontal",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "9.2.0",
      "targets": [
        {
          "expr": "sum(changes(process_start_time_seconds{instance=~\"$instance\"}[1m]))",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "title": "Process Restart Times",
      "type": "stat"
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 16,
        "x": 0,
        "y": 7
      },
      "hiddenSeries": false,
      "id": 7,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "process_resident_memory_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Process Memory - {{instance}}",
          "refId": "A"
        },
        {
          "expr": "nodejs_heap_size_total_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Total - {{instance}}",
          "refId": "B"
        },
        {
          "expr": "nodejs_heap_size_used_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}}",
          "refId": "C"
        },
        {
          "expr": "nodejs_external_memory_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "External Memory - {{instance}}",
          "refId": "D"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Process Memory Usage",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 7,
        "w": 8,
        "x": 16,
        "y": 7
      },
      "hiddenSeries": false,
      "id": 9,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "nodejs_active_handles_total{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Active Handler - {{instance}}",
          "refId": "A"
        },
        {
          "expr": "nodejs_active_requests_total{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Active Request - {{instance}}",
          "refId": "B"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Active Handlers/Requests Total",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "short",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 0,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 10,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "nodejs_heap_space_size_total_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Total - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Total Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 8,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 11,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "nodejs_heap_space_size_used_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Used Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 8,
        "x": 16,
        "y": 14
      },
      "hiddenSeries": false,
      "id": 12,
      "legend": {
        "alignAsTable": true,
        "avg": true,
        "current": true,
        "max": true,
        "min": true,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": true
      },
      "lines": true,
      "linewidth": 1,
      "links": [],
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "paceLength": 10,
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "nodejs_heap_space_size_available_bytes{instance=~\"$instance\"}",
          "format": "time_series",
          "intervalFactor": 1,
          "legendFormat": "Heap Used - {{instance}} - {{space}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Heap Available Detail",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    }
  ],
  "refresh": "5s",
  "schemaVersion": 37,
  "style": "dark",
  "tags": [
    "accounts-service",
    "NodeJS"
  ],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "prod",
          "value": "prod"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, environment)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Environment",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, environment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "accounts-service",
          "value": "accounts-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(service)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Service",
        "options": [],
        "query": {
          "query": "label_values(service)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\", environment=\"$Environment\"},instance)",
        "hide": 0,
        "includeAll": true,
        "label": "instance",
        "multi": true,
        "name": "instance",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\", environment=\"$Environment\"},instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "tagValuesQuery": "",
        "tagsQuery": "",
        "type": "query",
        "useTags": false
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "5s",
      "10s",
      "30s",
      "1m",
      "5m",
      "15m",
      "30m",
      "1h",
      "2h",
      "1d"
    ],
    "time_options": [
      "5m",
      "15m",
      "1h",
      "6h",
      "12h",
      "24h",
      "2d",
      "7d",
      "30d"
    ]
  },
  "timezone": "",
  "title": "NodeJS Application Dashboard - Accounts Service (Nomad)",
  "uid": "vQiTXdY7z",
  "version": 4,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/view_kubernetes_2.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      },
      {
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "enable": true,
        "expr": "changes(kube_deployment_status_observed_generation{cluster=\"$Cluster\",exported_namespace=\"$Namespace\",deployment=~\"permissions-$Deployment$\"}[1m])",
        "hide": true,
        "iconColor": "blue",
        "name": "Deploy Changed",
        "step": "",
        "tagKeys": "",
        "textFormat": "Redeployed: {{deployment}}",
        "titleFormat": ""
      },
      {
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "enable": true,
        "expr": "avg by(cluster,node) (kured_reboot_required) * avg by(cluster,node) (kube_pod_info{cluster=\"$Cluster\",exported_namespace=\"$Namespace\",exported_pod=~\"permissions-$Deployment-[^-]+-[^-]+\"})",
        "iconColor": "orange",
        "name": "Node Reboot Requests",
        "tagKeys": "",
        "textFormat": "Reboot Req: {{node}}",
        "titleFormat": "",
        "useValueForTime": false
      },
      {
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "enable": true,
        "expr": "kube_pod_container_status_terminated_reason{cluster=\"$Cluster\",exported_namespace=\"$Namespace\",exported_pod=~\"permissions-$Deployment-[^-]+-[^-]+\",reason!=\"Completed\"}",
        "hide": false,
        "iconColor": "rgba(255, 96, 96, 1)",
        "limit": 100,
        "name": "Termination Reason",
        "showIn": 0,
        "step": "15s",
        "tagKeys": "reason",
        "tags": [],
        "textFormat": "Terminated: {{exported_namespace}}/{{exported_pod}}",
        "titleFormat": "",
        "type": "tags"
      }
    ]
  },
  "description": "",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": 12667,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 21,
      "panels": [],
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Resources",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "description": "",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.7
              },
              {
                "color": "red",
                "value": 0.85
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 5,
        "x": 0,
        "y": 1
      },
      "id": 6,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "9.2.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum by(namespace,pod) (container_memory_working_set_bytes{cluster=\"$Cluster\",namespace=\"$Namespace\",pod=~\"permissions-$Deployment-[^-]+-[^-]+\"}) /\nsum by(namespace,pod) (label_replace(label_replace(kube_pod_container_resource_limits{resource=\"memory\"},\"namespace\",\"$1\",\"exported_namespace\",\"(.*)\"),\"pod\",\"$1\",\"exported_pod\",\"(.*)\"))",
          "interval": "",
          "legendFormat": "{{namespace}}/{{pod}}",
          "refId": "A"
        }
      ],
      "title": "RAM Usage",
      "type": "stat"
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fill": 1,
      "fillGradient": 7,
      "gridPos": {
        "h": 13,
        "w": 24,
        "x": 0,
        "y": 7
      },
      "hiddenSeries": false,
      "id": 4,
      "legend": {
        "alignAsTable": false,
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "rightSide": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "9.2.0",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum by(namespace,pod) (container_memory_working_set_bytes{cluster=\"$Cluster\",namespace=\"$Namespace\",pod=~\"permissions-$Deployment-[^-]+-[^-]+\"})",
          "interval": "",
          "legendFormat": "{{namespace}}/{{pod}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeRegions": [],
      "title": "Memory Usage - Pod",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "mode": "time",
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "$$hashKey": "object:52",
          "format": "bytes",
          "logBase": 1,
          "show": true
        },
        {
          "$$hashKey": "object:53",
          "format": "short",
          "logBase": 1,
          "show": true
        }
      ],
      "yaxis": {
        "align": false
      }
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "normal"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byRegexp",
              "options": ".*"
            },
            "properties": [
              {
                "id": "custom.stacking",
                "value": {
                  "group": "A",
                  "mode": "normal"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 10,
        "w": 12,
        "x": 0,
        "y": 20
      },
      "id": 37,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.1.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(nodejs_external_memory_bytes{cluster=\"$Cluster\",namespace=\"$Namespace\",pod=~\"permissions-$Deployment-[^-]+-[^-]+\"})",
          "hide": false,
          "interval": "",
          "legendFormat": "External Memory",
          "refId": "External"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(nodejs_heap_size_used_bytes{cluster=\"$Cluster\",namespace=\"$Namespace\",pod=~\"permissions-$Deployment-[^-]+-[^-]+\"})",
          "interval": "",
          "legendFormat": "Heap",
          "refId": "Heap"
        }
      ],
      "title": "Memory Usage Average",
      "transformations": [],
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineStyle": {
              "fill": "solid"
            },
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "normal"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byRegexp",
              "options": ".*"
            },
            "properties": [
              {
                "id": "custom.stacking",
                "value": {
                  "group": "A",
                  "mode": "normal"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 10,
        "w": 12,
        "x": 12,
        "y": 20
      },
      "id": 40,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.1.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(container_cpu_usage_seconds_total{cluster=\"$Cluster\",namespace=\"$Namespace\",pod=~\"permissions-$Deployment-[^-]+-[^-]+\"}[$__rate_interval])) by (pod)",
          "hide": false,
          "interval": "",
          "legendFormat": "{{ pod }}",
          "refId": "External"
        }
      ],
      "title": "CPU usage by Pod",
      "transformations": [],
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 30
      },
      "id": 23,
      "panels": [],
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Throughput",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "index": 0,
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "orange",
                "value": 0.1
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 4,
        "x": 0,
        "y": 31
      },
      "id": 25,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": true,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "8.4.1",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(increase(http_request_duration_seconds_count{code=~\"^5..$\"}[1m])) /  sum(increase(http_request_duration_seconds_count[1m]))",
          "interval": "",
          "intervalFactor": 2,
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Error Rate",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 10,
        "x": 4,
        "y": 31
      },
      "id": 19,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.0.6",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{cluster=\"$Cluster\", container=\"$Deployment\"}[1m])) by (service, route, method, code)  * 60",
          "hide": false,
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}} {{code}}",
          "refId": "B"
        }
      ],
      "title": "Throughput",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 10,
        "x": 14,
        "y": 31
      },
      "id": 27,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.0.6",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.5, sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", container=\"$Deployment\"}[1m])) by (le, service, route, method))",
          "interval": "",
          "intervalFactor": 2,
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Median Response Time",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 41
      },
      "id": 33,
      "panels": [],
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Response Time",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 42
      },
      "id": 17,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "8.4.1",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_response_size_bytes_sum{cluster=\"$Cluster\", container=\"$Deployment\"}[5m]) ) by (route)",
          "interval": "",
          "legendFormat": "{{route}}",
          "refId": "A"
        }
      ],
      "title": "HTTP Response size bytes",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              }
            ]
          },
          "unit": "dtdurations"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 56
      },
      "id": 15,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "8.4.1",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_sum{cluster=\"$Cluster\", container=\"$Deployment\"}[5m]) ) by (route)",
          "hide": false,
          "interval": "",
          "legendFormat": "{{route}}",
          "refId": "B"
        }
      ],
      "title": "HTTP Req Duration (seconds)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 0,
        "y": 70
      },
      "id": 31,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", container=\"$Deployment\"}[1m])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p50",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 8,
        "y": 70
      },
      "id": 30,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.90, sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", container=\"$Deployment\"}[1m])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p90",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 16,
        "y": 70
      },
      "id": 29,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", container=\"$Deployment\"}[1m])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p95",
      "type": "timeseries"
    },
    {
      "cards": {},
      "color": {
        "cardColor": "#b4ff00",
        "colorScale": "sqrt",
        "colorScheme": "interpolateOranges",
        "exponent": 0.5,
        "mode": "spectrum"
      },
      "dataFormat": "tsbuckets",
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "description": "Histogram of request duration for all endpoints",
      "gridPos": {
        "h": 7,
        "w": 24,
        "x": 0,
        "y": 78
      },
      "heatmap": {},
      "hideZeroBuckets": true,
      "highlightCards": true,
      "id": 39,
      "legend": {
        "show": true
      },
      "reverseYBuckets": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_bucket{cluster=\"$Cluster\", namespace=\"$Namespace\", container=\"$Deployment\"}[$__rate_interval])) by (le)",
          "format": "heatmap",
          "interval": "",
          "legendFormat": "{{le}}",
          "refId": "A"
        }
      ],
      "title": "Http Request Durations",
      "tooltip": {
        "show": true,
        "showHistogram": false
      },
      "type": "heatmap",
      "xAxis": {
        "show": true
      },
      "yAxis": {
        "format": "s",
        "logBase": 1,
        "show": true
      },
      "yBucketBound": "auto"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 85
      },
      "id": 35,
      "panels": [],
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "refId": "A"
        }
      ],
      "title": "Business",
      "type": "row"
    }
  ],
  "refresh": "",
  "schemaVersion": 37,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "prism-dev-crunch",
          "value": "prism-dev-crunch"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\"}, cluster) ",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Cluster",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\"}, cluster) ",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "lee1",
          "value": "lee1"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\"}, exported_namespace)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Namespace",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\"}, exported_namespace)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "allValue": ".*",
        "current": {
          "selected": false,
          "text": "permissions-service",
          "value": "permissions-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\", exported_namespace=~\"^$Namespace$\"}, deployment)",
        "hide": 0,
        "includeAll": true,
        "multi": false,
        "name": "Deployment",
        "options": [],
        "query": {
          "query": "label_values(kube_deployment_labels{deployment=\"permissions-permissions-service\", cluster=\"$Cluster\", exported_namespace=~\"^$Namespace$\"}, deployment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "/.*(permissions-service)/",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-15m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts Service View 2 (Kubernetes)",
  "uid": "h5WNjdL7k",
  "version": 2,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/templates/accounts-service/view_nomad_2.json
================
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "datasource",
          "uid": "grafana"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "target": {
          "limit": 100,
          "matchAny": false,
          "tags": [],
          "type": "dashboard"
        },
        "type": "dashboard"
      }
    ]
  },
  "description": "",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": 12668,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 65,
      "panels": [],
      "title": "Quick stats",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "orange",
                "value": 50
              },
              {
                "color": "green",
                "value": 70
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 6,
        "x": 0,
        "y": 1
      },
      "id": 67,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "(\n        (   \n                sum(http_request_duration_seconds_bucket{service=\"$Service\",environment=\"$Environment\", le=\"$Target\",code=~\"2..\"})\n                + (\n                        sum(http_request_duration_seconds_bucket{service=\"$Service\",environment=\"$Environment\", le=\"$Tolerated\",code=~\"2..\"})\n                        - sum(http_request_duration_seconds_bucket{service=\"$Service\",environment=\"$Environment\", le=\"$Target\",code=~\"2..\"})\n                ) / 2\n        ) / sum(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\", code=~\"2..\"})\n) * 100",
          "hide": false,
          "interval": "",
          "legendFormat": "Score",
          "refId": "A"
        }
      ],
      "title": "Apdex Score: target $Target s, tolerated $Tolerated s",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "#EAB839",
                "value": 90
              },
              {
                "color": "green",
                "value": 95
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 5,
        "x": 6,
        "y": 1
      },
      "id": 69,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "editorMode": "code",
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_bucket{service=\"$Service\",environment=\"$Environment\", le=\"$Target\"}[$interval])) by (job)\n/\nsum(rate(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"}[$interval])) by (job) * 100\n",
          "hide": false,
          "interval": "",
          "legendFormat": "",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "% Reqs in $Target(s) in $interval (95% SLO) ",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 100
              },
              {
                "color": "red",
                "value": 200
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 2,
        "x": 11,
        "y": 1
      },
      "id": 71,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"}[$interval]))",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "QPS in $interval",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 2,
        "x": 13,
        "y": 1
      },
      "id": 73,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"})",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Requests",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 5
              },
              {
                "color": "red",
                "value": 10
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 2,
        "x": 15,
        "y": 1
      },
      "id": 75,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "(\n\tsum(\n\t\thttp_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\",code=~\"^[5]..$\"} OR on() vector(0)\n\t) / \n\tsum(\n\t\thttp_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"}\n\t)\n)*100",
          "interval": "",
          "legendFormat": "error %",
          "refId": "A"
        }
      ],
      "title": "Error %",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "blue",
                "value": null
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 2,
        "x": 17,
        "y": 1
      },
      "id": 77,
      "options": {
        "colorMode": "none",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(http_response_size_bytes_sum{service=\"$Service\",environment=\"$Environment\"}) + sum(http_request_size_bytes_sum{service=\"$Service\",environment=\"$Environment\"})",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Transferred",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "blue",
                "value": null
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 3,
        "x": 19,
        "y": 1
      },
      "id": 79,
      "options": {
        "colorMode": "none",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_response_size_bytes_sum{service=\"$Service\",environment=\"$Environment\"}[$interval])) + sum(rate(http_request_size_bytes_sum{service=\"$Service\",environment=\"$Environment\"}[$interval]))",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Transfer Rate in $interval",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "#EAB839",
                "value": 1
              },
              {
                "color": "red",
                "value": 2
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 5,
        "w": 2,
        "x": 22,
        "y": 1
      },
      "id": 81,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(changes(process_start_time_seconds{service=\"$Service\",environment=\"$Environment\"}[$restarts_interval]))",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Restarts in $restarts_interval",
      "type": "stat"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 6
      },
      "id": 23,
      "panels": [],
      "title": "Throughput",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "match": "null",
                "result": {
                  "index": 0,
                  "text": "N/A"
                }
              },
              "type": "special"
            }
          ],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 0.1
              }
            ]
          },
          "unit": "none"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 4,
        "x": 0,
        "y": 7
      },
      "id": 25,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": true,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "exemplar": true,
          "expr": "sum(increase(http_request_duration_seconds_count{code=~\"^5..$\"}[1m])) /  sum(increase(http_request_duration_seconds_count[1m]))",
          "interval": "",
          "intervalFactor": 2,
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "title": "Error Rate",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 10,
        "x": 4,
        "y": 7
      },
      "id": 19,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.0.6",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{instance=~\"$Deployment\"}[$interval])) by (service, route, method, code)  * 60",
          "hide": false,
          "instant": false,
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}} {{code}}",
          "refId": "B"
        }
      ],
      "title": "Throughput",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 10,
        "w": 10,
        "x": 14,
        "y": 7
      },
      "id": 27,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "8.0.6",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.5, sum(rate(http_request_duration_seconds_bucket{instance=~\"$Deployment\"}[$interval])) by (le, service, route, method))",
          "interval": "",
          "intervalFactor": 2,
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Median Response Time",
      "type": "timeseries"
    },
    {
      "collapsed": true,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 17
      },
      "id": 41,
      "panels": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 26,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "stepBefore",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "never",
                "spanNulls": true,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": [
              {
                "__systemRef": "hideSeriesFrom",
                "matcher": {
                  "id": "byNames",
                  "options": {
                    "mode": "exclude",
                    "names": [
                      "info"
                    ],
                    "prefix": "All except:",
                    "readOnly": true
                  }
                },
                "properties": [
                  {
                    "id": "custom.hideFrom",
                    "value": {
                      "legend": false,
                      "tooltip": false,
                      "viz": true
                    }
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 7,
            "w": 24,
            "x": 0,
            "y": 18
          },
          "id": 43,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "multi",
              "sort": "none"
            }
          },
          "pluginVersion": "8.4.0-beta1",
          "targets": [
            {
              "datasource": {
                "type": "loki",
                "uid": "grafanacloud-logs"
              },
              "expr": "sum(count_over_time({ service=\"$Service\", environment=\"$Environment\"} | json | level!=\"info\" __error__!=\"JSONParserErr\" [$__interval]))",
              "hide": false,
              "legendFormat": "error",
              "refId": "A"
            },
            {
              "datasource": {
                "type": "loki",
                "uid": "grafanacloud-logs"
              },
              "expr": "sum(count_over_time({service=\"$Service\", environment=\"$Environment\"} | json | level=\"info\" __error__!=\"JSONParserErr\" [$__interval]))",
              "hide": false,
              "legendFormat": "info",
              "refId": "B"
            }
          ],
          "title": "Log Volume",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "gridPos": {
            "h": 8,
            "w": 24,
            "x": 0,
            "y": 25
          },
          "id": 45,
          "options": {
            "dedupStrategy": "none",
            "enableLogDetails": true,
            "prettifyLogMessage": false,
            "showCommonLabels": false,
            "showLabels": false,
            "showTime": false,
            "sortOrder": "Descending",
            "wrapLogMessage": false
          },
          "targets": [
            {
              "datasource": {
                "type": "loki",
                "uid": "grafanacloud-logs"
              },
              "expr": "{service=\"$Service\", environment=\"$Environment\"} | json | level!=\"info\" __error__!=\"JSONParserErr\" | line_format \"{{.timestamp}} {{.level}} {{.meta_method}} {{.meta_response}} {{.meta_userId}} {{.pod}} {{.meta_url}} {{ .message }}\"",
              "refId": "A"
            }
          ],
          "title": "Log Errors",
          "type": "logs"
        },
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "gridPos": {
            "h": 8,
            "w": 24,
            "x": 0,
            "y": 33
          },
          "id": 110,
          "options": {
            "dedupStrategy": "none",
            "enableLogDetails": true,
            "prettifyLogMessage": false,
            "showCommonLabels": false,
            "showLabels": false,
            "showTime": false,
            "sortOrder": "Descending",
            "wrapLogMessage": false
          },
          "targets": [
            {
              "datasource": {
                "type": "loki",
                "uid": "grafanacloud-logs"
              },
              "expr": "{service=\"$Service\", environment=\"$Environment\"} | json | level=\"info\" __error__!=\"JSONParserErr\" | line_format \"{{.timestamp}} {{.level}} {{.meta_method}} {{.meta_response}} {{.meta_userId}} {{.pod}} {{.meta_url}} {{ .message }}\"",
              "refId": "A"
            }
          ],
          "title": "Log Info",
          "type": "logs"
        }
      ],
      "title": "Logs for all allocations",
      "type": "row"
    },
    {
      "collapsed": true,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 18
      },
      "id": 47,
      "panels": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "s"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Field"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 341
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 11,
            "w": 11,
            "x": 0,
            "y": 42
          },
          "id": 49,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Last *"
              }
            ]
          },
          "pluginVersion": "9.0.5",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "topk(5, sum by (route)(http_request_duration_seconds_sum{service=\"$Service\", environment=\"$Environment\"}))",
              "interval": "",
              "legendFormat": "{{route}}",
              "refId": "A"
            }
          ],
          "title": "Top 5 Request Duration (SUM)",
          "transformations": [
            {
              "id": "reduce",
              "options": {
                "reducers": [
                  "lastNotNull"
                ]
              }
            }
          ],
          "type": "table"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 13,
            "x": 11,
            "y": 42
          },
          "id": 51,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "9.0.5",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "topk(5, sum by (route)(http_request_duration_seconds_sum{service=\"$Service\", environment=\"$Environment\", code=~\"[23]..\"}))",
              "interval": "",
              "legendFormat": "{{route}}",
              "refId": "A"
            }
          ],
          "title": "Top 5 Success Duration (SUM)",
          "transformations": [
            {
              "id": "reduce",
              "options": {
                "reducers": [
                  "lastNotNull"
                ]
              }
            }
          ],
          "type": "table"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Field"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 281
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 11,
            "w": 7,
            "x": 0,
            "y": 53
          },
          "id": 57,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "9.0.5",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "topk(5, http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\",code=~\"[45]..$\"})",
              "interval": "",
              "legendFormat": "{{code}}  {{route}}",
              "refId": "A"
            }
          ],
          "title": "Top 5 Error Count",
          "transformations": [
            {
              "id": "reduce",
              "options": {
                "reducers": [
                  "lastNotNull"
                ]
              }
            }
          ],
          "type": "table"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 8,
            "x": 7,
            "y": 53
          },
          "id": 55,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Last *"
              }
            ]
          },
          "pluginVersion": "9.0.5",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "topk(5, sum by (route)(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"}))",
              "interval": "",
              "legendFormat": "{{route}}",
              "refId": "A"
            }
          ],
          "title": "Top 5 Request Count",
          "transformations": [
            {
              "id": "reduce",
              "options": {
                "reducers": [
                  "lastNotNull"
                ]
              }
            }
          ],
          "type": "table"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 9,
            "x": 15,
            "y": 53
          },
          "id": 53,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Last *"
              }
            ]
          },
          "pluginVersion": "9.0.5",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "topk(5, sum by (route)(http_request_duration_seconds_sum{service=\"$Service\",environment=\"$Environment\",code=~\"[45]..\"}))",
              "interval": "",
              "legendFormat": "{{route}}",
              "refId": "A"
            }
          ],
          "title": "Top 5 Error Duration (SUM)",
          "transformations": [
            {
              "id": "reduce",
              "options": {
                "reducers": [
                  "lastNotNull"
                ]
              }
            }
          ],
          "type": "table"
        }
      ],
      "title": "Top 5s",
      "type": "row"
    },
    {
      "collapsed": false,
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 19
      },
      "id": 33,
      "panels": [],
      "title": "Response Time",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 24,
        "x": 0,
        "y": 20
      },
      "id": 95,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_request_duration_seconds_sum{service=\"$Service\", environment=\"$Environment\"}[$interval]) ) by (route)",
          "interval": "",
          "legendFormat": "avg - {{ route }}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "max(rate(http_request_duration_seconds_sum{service=\"$Service\", environment=\"$Environment\"}[$interval]) ) by (route)",
          "hide": false,
          "interval": "",
          "legendFormat": "max -  {{ route }}",
          "refId": "B"
        }
      ],
      "title": "HTTP Req Duration (seconds)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 29
      },
      "id": 103,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "avg(rate(http_response_size_bytes_sum{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (route)",
          "interval": "",
          "legendFormat": "avg - {{ route }}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "max(rate(http_response_size_bytes_sum{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (route)",
          "hide": false,
          "interval": "",
          "legendFormat": "max -  {{ route }}",
          "refId": "B"
        }
      ],
      "title": "AVG + MAX HTTP Response size bytes",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 29
      },
      "id": 107,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (code,le))",
          "interval": "",
          "legendFormat": "{{code}} (95%)",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(1, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (code,le))",
          "hide": false,
          "interval": "",
          "legendFormat": "{{code}} (100%)",
          "refId": "B"
        }
      ],
      "title": "Response Latency in $interval",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 38
      },
      "id": 109,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "expr": "sum(rate(http_request_duration_seconds_bucket{service=\"$Service\",environment=\"$Environment\", le=\"$Target\"}[$interval])) by (route)\n/\nsum(rate(http_request_duration_seconds_count{service=\"$Service\",environment=\"$Environment\"}[$interval])) by (route) * 100",
          "refId": "A"
        }
      ],
      "title": "APEX score by route",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 38
      },
      "id": 105,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(http_request_duration_seconds_count{service=\"$Service\", environment=\"$Environment\"}) by (route)",
          "interval": "",
          "legendFormat": "{{code}}",
          "refId": "A"
        }
      ],
      "title": "Request Count by Route",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 15,
        "w": 8,
        "x": 0,
        "y": 47
      },
      "id": 97,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p50",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 15,
        "w": 8,
        "x": 8,
        "y": 47
      },
      "id": 99,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.90, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p90",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 15,
        "w": 8,
        "x": 16,
        "y": 47
      },
      "id": 101,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (le, service, route, method))",
          "interval": "",
          "legendFormat": "{{service}} - {{method}} {{route}}",
          "refId": "A"
        }
      ],
      "title": "Response Time p99",
      "type": "timeseries"
    },
    {
      "cards": {},
      "color": {
        "cardColor": "#b4ff00",
        "colorScale": "sqrt",
        "colorScheme": "interpolateOranges",
        "exponent": 0.5,
        "mode": "spectrum"
      },
      "dataFormat": "tsbuckets",
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "description": "Histogram of request duration for all endpoints",
      "fieldConfig": {
        "defaults": {
          "custom": {
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "scaleDistribution": {
              "type": "linear"
            }
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 24,
        "x": 0,
        "y": 62
      },
      "heatmap": {},
      "hideZeroBuckets": true,
      "highlightCards": true,
      "id": 39,
      "legend": {
        "show": true
      },
      "options": {
        "calculate": false,
        "calculation": {},
        "cellGap": 2,
        "cellValues": {},
        "color": {
          "exponent": 0.5,
          "fill": "#b4ff00",
          "mode": "scheme",
          "reverse": false,
          "scale": "exponential",
          "scheme": "Oranges",
          "steps": 128
        },
        "exemplars": {
          "color": "rgba(255,0,255,0.7)"
        },
        "filterValues": {
          "le": 1e-9
        },
        "legend": {
          "show": true
        },
        "rowsFrame": {
          "layout": "auto"
        },
        "showValue": "never",
        "tooltip": {
          "show": true,
          "yHistogram": false
        },
        "yAxis": {
          "axisPlacement": "left",
          "reverse": false,
          "unit": "s"
        }
      },
      "pluginVersion": "9.3.2-45365",
      "reverseYBuckets": false,
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_bucket{instance=~\"$Deployment\"}[$interval])) by (le)",
          "format": "heatmap",
          "interval": "",
          "legendFormat": "{{le}}",
          "refId": "A"
        }
      ],
      "title": "Http Request Durations",
      "tooltip": {
        "show": true,
        "showHistogram": false
      },
      "type": "heatmap",
      "xAxis": {
        "show": true
      },
      "yAxis": {
        "format": "s",
        "logBase": 1,
        "show": true
      },
      "yBucketBound": "auto"
    },
    {
      "collapsed": true,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 69
      },
      "id": 93,
      "panels": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineStyle": {
                  "fill": "solid"
                },
                "lineWidth": 1,
                "pointSize": 1,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "dtdurations"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 24,
            "x": 0,
            "y": 21
          },
          "id": 87,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "nodejs_eventloop_lag_seconds{service=\"$Service\",environment=\"$Environment\"}",
              "interval": "",
              "legendFormat": "last {{ instance }}",
              "range": true,
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "nodejs_eventloop_lag_p99_seconds{service=\"$Service\",environment=\"$Environment\"}",
              "hide": false,
              "interval": "",
              "legendFormat": "p99 {{ instance }}",
              "range": true,
              "refId": "B"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "nodejs_eventloop_lag_p50_seconds{service=\"$Service\",environment=\"$Environment\"}",
              "hide": false,
              "interval": "",
              "legendFormat": "p50 {{ instance }}",
              "range": true,
              "refId": "C"
            }
          ],
          "title": "Event Loop Latency",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineStyle": {
                  "fill": "solid"
                },
                "lineWidth": 1,
                "pointSize": 1,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "dtdurations"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 34
          },
          "id": 83,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "avg(nodejs_eventloop_lag_seconds{service=\"$Service\",environment=\"$Environment\"})",
              "hide": false,
              "interval": "",
              "legendFormat": "last {{ pod }}",
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "avg(nodejs_eventloop_lag_p99_seconds{service=\"$Service\",environment=\"$Environment\"})",
              "hide": false,
              "interval": "",
              "legendFormat": "p99 {{ pod }}",
              "refId": "B"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "avg(nodejs_eventloop_lag_p50_seconds{service=\"$Service\",environment=\"$Environment\"})",
              "hide": false,
              "interval": "",
              "legendFormat": "p50 {{ pod }}",
              "refId": "C"
            }
          ],
          "title": "AVG Event Loop Latency",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 1,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 34
          },
          "id": 85,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "avg(nodejs_active_handles_total{service=\"$Service\",environment=\"$Environment\"})",
              "interval": "",
              "legendFormat": "Active Handler {{instance}}",
              "range": true,
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "avg(nodejs_active_requests_total{service=\"$Service\",environment=\"$Environment\"})",
              "hide": false,
              "interval": "",
              "legendFormat": "Active Request {{instance}}",
              "range": true,
              "refId": "B"
            }
          ],
          "title": "AVG Active Handlers/Requests",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 42
          },
          "id": 91,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "exemplar": true,
              "expr": "koajs_number_of_open_connections{service=\"$Service\",environment=\"$Environment\"}",
              "interval": "",
              "legendFormat": "{{ instance }}",
              "refId": "A"
            }
          ],
          "title": "koajs Number of Open Connections",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 1,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 42
          },
          "id": 89,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "nodejs_active_handles_total{service=\"$Service\",environment=\"$Environment\"}",
              "interval": "",
              "legendFormat": "Active Handler {{instance}}",
              "range": true,
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "grafanacloud-prom"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "nodejs_active_requests_total{service=\"$Service\",environment=\"$Environment\"}",
              "hide": false,
              "interval": "",
              "legendFormat": "Active Request {{instance}}",
              "range": true,
              "refId": "B"
            }
          ],
          "title": "Active Handlers/Requests",
          "type": "timeseries"
        }
      ],
      "title": "Resources",
      "type": "row"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 70
      },
      "id": 61,
      "panels": [],
      "title": "Performance",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafanacloud-prom"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 14,
        "w": 24,
        "x": 0,
        "y": 71
      },
      "id": 63,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafanacloud-prom"
          },
          "exemplar": true,
          "expr": "sum(rate(http_request_duration_seconds_count{service=\"$Service\", environment=\"$Environment\"}[$interval])) by (code)",
          "interval": "",
          "legendFormat": "{{code}}",
          "refId": "A"
        }
      ],
      "title": "Requests Per Second in $interval",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "grafanacloud-logs"
      },
      "description": "",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "center",
            "displayMode": "auto",
            "filterable": true,
            "inspect": false,
            "minWidth": 175
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Response"
            },
            "properties": [
              {
                "id": "thresholds",
                "value": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green"
                    },
                    {
                      "color": "green",
                      "value": 100
                    },
                    {
                      "color": "semi-dark-green",
                      "value": 200
                    },
                    {
                      "color": "dark-green",
                      "value": 300
                    },
                    {
                      "color": "yellow",
                      "value": 400
                    },
                    {
                      "color": "dark-red",
                      "value": 500
                    }
                  ]
                }
              },
              {
                "id": "custom.displayMode",
                "value": "color-text"
              }
            ]
          },
          {
            "matcher": {
              "id": "byRegexp",
              "options": "/Duration/"
            },
            "properties": [
              {
                "id": "unit",
                "value": "ms"
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Route"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 230
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 10,
        "w": 24,
        "x": 0,
        "y": 85
      },
      "id": 59,
      "options": {
        "footer": {
          "fields": "",
          "reducer": [
            "sum"
          ],
          "show": false
        },
        "showHeader": true,
        "sortBy": [
          {
            "desc": true,
            "displayName": "Count"
          }
        ]
      },
      "pluginVersion": "9.3.2-45365",
      "targets": [
        {
          "datasource": {
            "type": "loki",
            "uid": "grafanacloud-logs"
          },
          "expr": "{ service=\"$Service\",environment=\"$Environment\" } | json",
          "hide": false,
          "refId": "A"
        }
      ],
      "title": "Logs (Performance)",
      "transformations": [
        {
          "id": "labelsToFields",
          "options": {}
        },
        {
          "id": "merge",
          "options": {}
        },
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "TraceID": true,
              "build": true,
              "business_unit": true,
              "cluster": true,
              "container": true,
              "container_id": true,
              "email": true,
              "environment": true,
              "filename": true,
              "id": true,
              "job": true,
              "label": true,
              "level": true,
              "line": true,
              "message": true,
              "meta_additionalLogs_create_req_kernel_entryType": true,
              "meta_additionalLogs_create_req_kernel_startTime": true,
              "meta_additionalLogs_overall_req_entryType": true,
              "meta_additionalLogs_overall_req_startTime": true,
              "meta_additionalLogs_perms_middleware_entryType": true,
              "meta_additionalLogs_perms_middleware_startTime": true,
              "meta_clientIP": true,
              "meta_domain": true,
              "meta_event": true,
              "meta_method": true,
              "meta_request_body_createView": true,
              "meta_request_body_paging_size": true,
              "meta_response": true,
              "meta_route": true,
              "meta_url": false,
              "meta_user_agent": true,
              "name": true,
              "namespace": true,
              "pod": true,
              "stream": true,
              "team": true,
              "ts": true,
              "tsNs": true
            },
            "indexByName": {
              "TraceID": 5,
              "build": 19,
              "business_unit": 13,
              "cluster": 9,
              "container": 14,
              "container_id": 10,
              "email": 15,
              "environment": 22,
              "filename": 11,
              "id": 3,
              "job": 12,
              "label": 6,
              "level": 16,
              "line": 2,
              "message": 7,
              "meta_additionalLogs_create_req_kernel_duration": 37,
              "meta_additionalLogs_create_req_kernel_entryType": 42,
              "meta_additionalLogs_create_req_kernel_startTime": 28,
              "meta_additionalLogs_overall_req_duration": 35,
              "meta_additionalLogs_overall_req_entryType": 38,
              "meta_additionalLogs_overall_req_startTime": 39,
              "meta_additionalLogs_perms_middleware_duration": 43,
              "meta_additionalLogs_perms_middleware_entryType": 25,
              "meta_additionalLogs_perms_middleware_startTime": 33,
              "meta_clientIP": 40,
              "meta_domain": 23,
              "meta_event": 36,
              "meta_method": 29,
              "meta_request_body_createView": 24,
              "meta_request_body_datasourceName": 34,
              "meta_request_body_paging_size": 32,
              "meta_response": 31,
              "meta_route": 30,
              "meta_url": 41,
              "meta_userId": 26,
              "meta_user_agent": 27,
              "name": 20,
              "namespace": 21,
              "pod": 17,
              "stream": 8,
              "team": 18,
              "timestamp": 0,
              "ts": 1,
              "tsNs": 4
            },
            "renameByName": {
              "email": "Email",
              "meta_additionalLogs_create_req_kernel_duration": "Create Req Kernel Duration",
              "meta_additionalLogs_overall_req_duration": "Overall Req Duration",
              "meta_additionalLogs_perms_middleware_duration": "Perms Middleware Duration",
              "meta_headers_ismlaas": "",
              "meta_method": "Method",
              "meta_request_body_datasourceName": "Datasource",
              "meta_response": "Response",
              "meta_route": "Route",
              "meta_url": "url",
              "meta_userId": "UserId"
            }
          }
        },
        {
          "id": "groupBy",
          "options": {
            "fields": {
              "Create Req Kernel Duration": {
                "aggregations": [
                  "min",
                  "max",
                  "range"
                ],
                "operation": "aggregate"
              },
              "Datasource": {
                "aggregations": [],
                "operation": "groupby"
              },
              "Method": {
                "aggregations": [],
                "operation": "groupby"
              },
              "Overall Req Duration": {
                "aggregations": [
                  "min",
                  "max",
                  "range"
                ],
                "operation": "aggregate"
              },
              "Perms Middleware Duration": {
                "aggregations": [
                  "min",
                  "max",
                  "range"
                ],
                "operation": "aggregate"
              },
              "Response": {
                "aggregations": [],
                "operation": "groupby"
              },
              "Route": {
                "aggregations": [],
                "operation": "groupby"
              },
              "timestamp": {
                "aggregations": [
                  "count"
                ],
                "operation": "aggregate"
              },
              "url": {
                "aggregations": [],
                "operation": "groupby"
              }
            }
          }
        },
        {
          "id": "organize",
          "options": {
            "excludeByName": {},
            "indexByName": {
              "Create Req Kernel Duration (max)": 9,
              "Create Req Kernel Duration (min)": 8,
              "Create Req Kernel Duration (range)": 10,
              "Datasource": 4,
              "Method": 1,
              "Overall Req Duration (max)": 6,
              "Overall Req Duration (min)": 5,
              "Overall Req Duration (range)": 7,
              "Perms Middleware Duration (max)": 12,
              "Perms Middleware Duration (min)": 11,
              "Perms Middleware Duration (range)": 13,
              "Response": 3,
              "Route": 2,
              "timestamp (count)": 0
            },
            "renameByName": {
              "Create Req Kernel Duration (max)": "Req Kernel (max)",
              "Create Req Kernel Duration (min)": "Req Kernel (min)",
              "Create Req Kernel Duration (range)": "Req Kernel (range)",
              "Overall Req Duration (max)": "Overall Duration (max)",
              "Overall Req Duration (min)": "Overall Duration (min)",
              "Overall Req Duration (range)": "Overall Duration (range)",
              "Perms Middleware Duration (max)": "Perms Duration (max)",
              "Perms Middleware Duration (min)": "Perms Duration (min)",
              "Perms Middleware Duration (range)": "Perms Duration (range)",
              "timestamp (count)": "Count"
            }
          }
        },
        {
          "id": "sortBy",
          "options": {
            "fields": {},
            "sort": [
              {
                "field": "url"
              }
            ]
          }
        }
      ],
      "type": "table"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 37,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "accounts-service",
          "value": "accounts-service"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values(service)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Service",
        "options": [],
        "query": {
          "query": "label_values(service)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "oga",
          "value": "oga"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({service=\"$Service\"}, business_unit)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "BusinessUnit",
        "options": [],
        "query": {
          "query": "label_values({service=\"$Service\"}, business_unit)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "prod",
          "value": "prod"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\"},environment)",
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Environment",
        "options": [],
        "query": {
          "query": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\"},environment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafanacloud-prom"
        },
        "definition": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
        "hide": 0,
        "includeAll": true,
        "multi": true,
        "name": "Deployment",
        "options": [],
        "query": {
          "query": "label_values({business_unit=\"$BusinessUnit\", service=\"$Service\", environment=\"$Environment\"},instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "auto": false,
        "auto_count": 30,
        "auto_min": "10s",
        "current": {
          "selected": false,
          "text": "5m",
          "value": "5m"
        },
        "hide": 0,
        "name": "interval",
        "options": [
          {
            "selected": true,
            "text": "5m",
            "value": "5m"
          },
          {
            "selected": false,
            "text": "10m",
            "value": "10m"
          },
          {
            "selected": false,
            "text": "30m",
            "value": "30m"
          },
          {
            "selected": false,
            "text": "1h",
            "value": "1h"
          },
          {
            "selected": false,
            "text": "6h",
            "value": "6h"
          },
          {
            "selected": false,
            "text": "12h",
            "value": "12h"
          },
          {
            "selected": false,
            "text": "1d",
            "value": "1d"
          },
          {
            "selected": false,
            "text": "7d",
            "value": "7d"
          },
          {
            "selected": false,
            "text": "14d",
            "value": "14d"
          },
          {
            "selected": false,
            "text": "30d",
            "value": "30d"
          }
        ],
        "query": "5m,10m,30m,1h,6h,12h,1d,7d,14d,30d",
        "queryValue": "",
        "refresh": 2,
        "skipUrlSync": false,
        "type": "interval"
      },
      {
        "current": {
          "selected": false,
          "text": "0.05",
          "value": "0.05"
        },
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Target",
        "options": [
          {
            "selected": true,
            "text": "0.05",
            "value": "0.05"
          },
          {
            "selected": false,
            "text": "0.1",
            "value": "0.1"
          },
          {
            "selected": false,
            "text": "0.2",
            "value": "0.2"
          },
          {
            "selected": false,
            "text": "0.3",
            "value": "0.3"
          },
          {
            "selected": false,
            "text": "0.4",
            "value": "0.4"
          },
          {
            "selected": false,
            "text": "0.5",
            "value": "0.5"
          }
        ],
        "query": "0.05,0.1,0.2,0.3,0.4,0.5",
        "skipUrlSync": false,
        "type": "custom"
      },
      {
        "current": {
          "selected": false,
          "text": "0.1",
          "value": "0.1"
        },
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "name": "Tolerated",
        "options": [
          {
            "selected": true,
            "text": "0.1",
            "value": "0.1"
          },
          {
            "selected": false,
            "text": "0.2",
            "value": "0.2"
          },
          {
            "selected": false,
            "text": "0.3",
            "value": "0.3"
          },
          {
            "selected": false,
            "text": "0.4",
            "value": "0.4"
          },
          {
            "selected": false,
            "text": "0.5",
            "value": "0.5"
          }
        ],
        "query": "0.1,0.2,0.3,0.4,0.5",
        "skipUrlSync": false,
        "type": "custom"
      },
      {
        "auto": false,
        "auto_count": 30,
        "auto_min": "10s",
        "current": {
          "selected": false,
          "text": "7d",
          "value": "7d"
        },
        "hide": 0,
        "name": "restarts_interval",
        "options": [
          {
            "selected": false,
            "text": "1m",
            "value": "1m"
          },
          {
            "selected": false,
            "text": "10m",
            "value": "10m"
          },
          {
            "selected": false,
            "text": "30m",
            "value": "30m"
          },
          {
            "selected": false,
            "text": "1h",
            "value": "1h"
          },
          {
            "selected": false,
            "text": "6h",
            "value": "6h"
          },
          {
            "selected": false,
            "text": "12h",
            "value": "12h"
          },
          {
            "selected": false,
            "text": "1d",
            "value": "1d"
          },
          {
            "selected": false,
            "text": "2d",
            "value": "2d"
          },
          {
            "selected": false,
            "text": "3d",
            "value": "3d"
          },
          {
            "selected": false,
            "text": "4d",
            "value": "4d"
          },
          {
            "selected": false,
            "text": "5d",
            "value": "5d"
          },
          {
            "selected": false,
            "text": "6d",
            "value": "6d"
          },
          {
            "selected": true,
            "text": "7d",
            "value": "7d"
          },
          {
            "selected": false,
            "text": "14d",
            "value": "14d"
          },
          {
            "selected": false,
            "text": "30d",
            "value": "30d"
          }
        ],
        "query": "1m,10m,30m,1h,6h,12h,1d,2d,3d,4d,5d,6d,7d,14d,30d",
        "queryValue": "",
        "refresh": 2,
        "skipUrlSync": false,
        "type": "interval"
      }
    ]
  },
  "time": {
    "from": "now-15m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Accounts Service View 2 (Nomad)",
  "uid": "sJOvjdYnz",
  "version": 36,
  "weekStart": ""
}

================
File: cts/grafana/dashboards/dev.backend.tfvars
================
key = "360093697111/dev/cts.terraform/grafana/dashboards/terraform.state"

================
File: cts/grafana/dashboards/dev.tfvars
================
vault_path_grafana_api_key = "di-secrets/terraform/grafana-provider"

================
File: cts/grafana/dashboards/main.tf
================
data "vault_generic_secret" "grafana" {
  path = var.vault_path_grafana_api_key
}

data "grafana_folder" "grafana_folder_cts_accounts" {
  title = "Core Tech Services - Auth"
}
output "grafana_folder_cts_accounts" { value = data.grafana_folder.grafana_folder_cts_accounts }

resource "grafana_dashboard" "grafana_dashboard_accounts_service" {
  for_each = fileset(path.module, "templates/accounts-service/*.json")

  folder      = data.grafana_folder.grafana_folder_cts_accounts.id
  config_json = file(each.key)
}
output "grafana_dashboard_accounts_service" { value = grafana_dashboard.grafana_dashboard_accounts_service }

output "fileset" { value = fileset(path.module, "templates/accounts-service/*.json") }

================
File: cts/grafana/dashboards/variables.tf
================
variable "vault_path_grafana_api_key" {
  description = "vault path for the grafana api key"
  type        = string
}

================
File: cts/grafana/dashboards/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    grafana = {
      source  = "grafana/grafana"
      version = "~> 4.0"
    }
  }
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

================
File: cts/grafana/datasources/.terraform-version
================
latest:^1.3

================
File: cts/grafana/datasources/dev.backend.tfvars
================
key = "360093697111/dev/us-east-1/grafana/datasources/terraform.tfstate"

================
File: cts/grafana/datasources/dev.tfvars
================
region = "us-east-1"

================
File: cts/grafana/datasources/main.tf
================
data "vault_generic_secret" "grafana_api" {
  path = "cts-secrets/terraform/grafana-provider"
}

resource "aws_iam_policy" "iam_policy" {
  name        = "grafana-cloudwatch-access-${var.env}-${var.region}"
  path        = "/"
  description = "IAM policy for enverus.grafana.net IAM user to access cloudwatch metrics"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        "Sid" : "AllowReadingMetricsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "cloudwatch:DescribeAlarmsForMetric",
          "cloudwatch:DescribeAlarmHistory",
          "cloudwatch:DescribeAlarms",
          "cloudwatch:ListMetrics",
          "cloudwatch:GetInsightRuleReport",
          "cloudwatch:GetMetricStatistics",
          "cloudwatch:GetMetricData"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingLogsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "logs:DescribeLogGroups",
          "logs:GetLogGroupFields",
          "logs:StartQuery",
          "logs:StopQuery",
          "logs:GetQueryResults",
          "logs:GetLogEvents"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingTagsInstancesRegionsFromEC2",
        "Effect" : "Allow",
        "Action" : [
          "ec2:DescribeTags",
          "ec2:DescribeInstances",
          "ec2:DescribeRegions"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingResourcesForTags",
        "Effect" : "Allow",
        "Action" : "tag:GetResources",
        "Resource" : "*"
      },
    ]
  })
}

# Create IAM User
resource "aws_iam_user" "iam_user" {
  name = "grafana-cloudwatch-metrics-${var.env}-${var.region}"
  path = "/"
}

resource "aws_iam_access_key" "iam_access_key" {
  user = aws_iam_user.iam_user.name
}

# Attach IAM policy to IAM User
resource "aws_iam_user_policy_attachment" "iam_user_policy_attachment" {
  user       = aws_iam_user.iam_user.name
  policy_arn = aws_iam_policy.iam_policy.arn
}

# Stash IAM user in Vault
resource "vault_generic_secret" "generic_secret" {
  path      = "cts-secrets/terraform/aws/grafana/cts/${var.env}/${var.region}"
  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.iam_access_key.id}",
  "secret_key": "${aws_iam_access_key.iam_access_key.secret}"
}
EOF
}

# Create Grafana Datasource
module "datasource" {
  source          = "git@git.drillinginfo.com:TF-Modules/hosted_grafana.git//datasources"
  datasource_name = "Cloudwatch-${var.bu}-${var.env}-${var.region}"
  grafana_API_key = data.vault_generic_secret.grafana_api.data["api_key"]
  region          = var.region
  env             = var.env
  datasource_type = "cloudwatch"
  access_key      = aws_iam_access_key.iam_access_key.id
  secret_key      = aws_iam_access_key.iam_access_key.secret
}

================
File: cts/grafana/datasources/prod.backend.tfvars
================
key = "316576613383/prod/us-east-1/grafana/datasources/terraform.tfstate"

================
File: cts/grafana/datasources/prod.tfvars
================
region = "us-east-1"

================
File: cts/grafana/datasources/variables.tf
================
variable "region" {
  description = "Region"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Environment level (dev/preprod/prod)"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: cts/grafana/datasources/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/blob/main/grafana/datasources"
      Team             = "sre@enverus.com"
      Component        = "grafana"
      Product          = "nexus"
    }
  }
}

provider "vault" {
}

================
File: cts/grafana/service-accounts/.terraform-version
================
latest:^1.6

================
File: cts/grafana/service-accounts/main.tf
================
# grafana service accounts and tokens

data "vault_generic_secret" "grafana" {
  path = var.vault_path_grafana_api_key
}

# tr contact points
resource "grafana_service_account" "tr_contact_points" {
  name        = "tr_contact_points_admin"
  role        = "Admin"
  is_disabled = false
}

resource "grafana_service_account_token" "tr_contact_points" {
  name               = "tr_contact_points_admin"
  service_account_id = grafana_service_account.tr_contact_points.id
  seconds_to_live    = 31536000
}

resource "vault_generic_secret" "tr_contact_points_api_token" {
  path = "enverus-cts/cts.terraform/grafana/service-accounts/tr_contact_points_api_token"

  data_json = <<EOT
{
  "grafana_api_token":   "${grafana_service_account_token.tr_contact_points.key}"
}
EOT
}

================
File: cts/grafana/service-accounts/prod.backend.tfvars
================
# 316576613383 - the cts-prod AWS account ID.
key = "316576613383/prod/grafana/service-accounts/terraform.tfstate"

================
File: cts/grafana/service-accounts/prod.tfvars
================
# this page intentionally left blank
vault_path_grafana_api_key = "cts-secrets/terraform/grafana-provider"

================
File: cts/grafana/service-accounts/variables.tf
================
variable "region" {
  description = "Region"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Environment level (dev/preprod/prod)"
  type        = string
}

variable "vault_path_grafana_api_key" {
  description = "vault path for the grafana api key"
  type        = string
}

================
File: cts/grafana/service-accounts/versions.tf
================
terraform {
  required_version = ">= 1.6"
  backend "s3" {}
  required_providers {
    vault = {
      source = "hashicorp/vault"
    }
    grafana = {
      source  = "grafana/grafana"
      version = "~> 4.0"
    }
  }
}

provider "vault" {
}

provider "grafana" {
  url  = "https://enverus.grafana.net/"
  auth = data.vault_generic_secret.grafana.data["api_key"]
}

================
File: cts/iam/hci/.terraform-version
================
latest

================
File: cts/iam/hci/data.tf
================
data "azuread_client_config" "current" {}

data "azuread_service_principal" "Atlantis_Group_Manager_Service_Principal" {
  display_name = "Atlantis Group Manager"
}

data "azuread_group" "SRE_Team_AzureRole" {
  display_name     = "Tech-SRE"
  security_enabled = true
}

data "azapi_resource" "resource_groups" {
  for_each = var.resource_groups

  type = "Microsoft.Resources/resourceGroups@2024-03-01"
  name = each.key
}

data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = "enverus-cts/Azure_Service_Principal_Atlantis"
}

data "vault_generic_secret" "hci" {
  path = "enverus-cts/azure/hci/prod"
}

data "vault_generic_secret" "hci-jenkins" {
  path = "enverus-cts/azure/hci/prod-jenkins"
}

data "azuread_application" "HCIApplication" {
  display_name = var.azure_stack_hci_application
}

================
File: cts/iam/hci/prod.backend.tfvars
================
key = "316576613383/prod/iam/hci/awx-sp/terraform.tfstate"

================
File: cts/iam/hci/service_principal_awx.tf
================
resource "azuread_application" "hci_awx_service_principal" {
  display_name = "sre-awx"
  description  = "Service principal for AWX to access HCI to build inventories"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  prevent_duplicate_names = true

  feature_tags {
    enterprise = false
    gallery    = false
    hide       = true
  }

}

resource "azuread_service_principal" "hci_awx_service_principal" {
  client_id = azuread_application.hci_awx_service_principal.client_id
  description = "Service principal for AWX to access HCI to build inventories"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  notification_email_addresses = ["sre@enverus.com"]
  use_existing                 = false
}

resource "azurerm_role_assignment" "azurerm_role_assignments_hci_awx_service_principal" {
  scope                = "/subscriptions/da2f2025-e4a4-416b-8a1c-5fc403c237f8/resourceGroups/sre-rg"
  principal_id         = azuread_service_principal.hci_awx_service_principal.object_id
  role_definition_name = "Reader"
}

resource "time_rotating" "time_rotating_sp" {
  rotation_days = 270
}

# Create a password for SP
resource "azuread_application_password" "hci_awx_service_principal" {
  display_name      = "sre-awx"
  application_id    = azuread_application.hci_awx_service_principal.id
  end_date_relative = "8640h" # 360 days
  rotate_when_changed = {
    rotation = time_rotating.time_rotating_sp.rotation_rfc3339
  }
}

resource "vault_generic_secret" "vault_secret_awx_service_principal" {
  path = "enverus-cts/azure/awx/prod"

  data_json = jsonencode(
    {
      "client_id"       = azuread_application.hci_awx_service_principal.client_id
      "client_secret"   = azuread_application_password.hci_awx_service_principal.value
      "subscription_id" = data.vault_generic_secret.hci.data["subscription_id"]
      "tenant_id"       = data.vault_generic_secret.hci.data["tenant_id"]
    }
  )
}
#trigger

================
File: cts/iam/hci/sre-azure-stack-hci-secret.tf
================
#This creates 2 client_id / secrets, and stores one of them in the vault for applications to use.  The other one is used for the next rotation.
#The rotation is based off of the time terraform is run, and the second rotation is based off of the first rotation.
#This code will have to be run every 6 months to rotate the password, but should do so seamlessly.
#The first rotation will be 12 months, the second rotation will be 6 months.  This will allow for a 6 month overlap between the two passwords.

resource "azuread_application" "sre_azure_stack_hci_application" {
  display_name = "SRE-Azure-Stack-HCI"
  description  = "Service principal for SRE to access HCI"
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  prevent_duplicate_names = false
  required_resource_access {
    resource_app_id = "00000003-0000-0000-c000-000000000000"
    resource_access {
      id   = "e1fe6dd8-ba31-4d61-89e7-88639da4683d"
      type = "Scope"
    }
  }
  feature_tags {
    enterprise = false
    gallery    = false
    hide       = false
  }

}

resource "azuread_service_principal" "sre_azure_stack_hci_sp" {
  client_id = azuread_application.sre_azure_stack_hci_application.client_id
  owners = concat(
    [data.azuread_client_config.current.object_id],
    data.azuread_group.SRE_Team_AzureRole.members, ## CloudOps wants this to be limited to 3 people
    [data.azuread_service_principal.Atlantis_Group_Manager_Service_Principal.object_id],
  )
  notification_email_addresses = ["sre@enverus.com"]
  use_existing                 = true
}

#Two rotation timestamps.  The first one is based off of the time terraform is run, the second one is based off of the first rotation timestamp
resource "time_rotating" "sre_azure_stack_hci_rotation_1" {
  rotation_months = 8
}

resource "time_rotating" "sre_azure_stack_hci_rotation_2" {
  rfc3339         = time_rotating.sre_azure_stack_hci_rotation_1.rfc3339
  rotation_months = 4
  lifecycle {
    ignore_changes = [rfc3339]
  }
}

#end_date_relative would be a better option here, but it is not recommended due to deprecation in the azuread_application_password resource
resource "azuread_application_password" "sre_azure_stack_hci_password_1" {
  display_name   = "SRE Azure Stack HCI Atlantis Password - Blue"
  application_id = azuread_application.sre_azure_stack_hci_application.id
  end_date       = timeadd(timestamp(), "11680h") # 16 months
  rotate_when_changed = {
    rotation = time_rotating.sre_azure_stack_hci_rotation_1.id #start to rotate every 12 months
  }
  lifecycle {
    ignore_changes = [end_date]
  }
}

resource "azuread_application_password" "sre_azure_stack_hci_password_2" {
  display_name   = "SRE Azure Stack HCI Atlantis Password - Green"
  application_id = data.azuread_application.HCIApplication.id
  end_date       = timeadd(timestamp(), "11680h") # 16 months
  rotate_when_changed = {
    rotation = time_rotating.sre_azure_stack_hci_rotation_2.id #start to rotate every 12 months
  }
  lifecycle {
    ignore_changes = [end_date]
  }
}

resource "azuread_application_password" "sre_azure_stack_jenkins_password_1" {
  display_name   = "SRE Azure Stack HCI Jenkins Password - Blue"
  application_id = azuread_application.sre_azure_stack_hci_application.id
  end_date       = timeadd(timestamp(), "11680h") # 16 months
  rotate_when_changed = {
    rotation = time_rotating.sre_azure_stack_hci_rotation_1.id #start to rotate every 12 months
  }
  lifecycle {
    ignore_changes = [end_date]
  }
}

resource "azuread_application_password" "sre_azure_stack_jenkins_password_2" {
  display_name   = "SRE Azure Stack HCI Jenkins Password - Green"
  application_id = data.azuread_application.HCIApplication.id
  end_date       = timeadd(timestamp(), "11680h") # 16 months
  rotate_when_changed = {
    rotation = time_rotating.sre_azure_stack_hci_rotation_2.id #start to rotate every 12 months
  }
  lifecycle {
    ignore_changes = [end_date]
  }
}


#Store the password with the longest life left in the vault for applications to use.  This will be the password that is used until the next rotation
resource "vault_generic_secret" "vault_secret_sre_azure_stack_hci" {
  path = "enverus-cts/azure/hci/prod"
  data_json = time_rotating.sre_azure_stack_hci_rotation_1.unix > time_rotating.sre_azure_stack_hci_rotation_2.unix ? jsonencode(
    {
      "client_id"       = azuread_application.sre_azure_stack_hci_application.client_id
      "client_secret"   = azuread_application_password.sre_azure_stack_hci_password_1.value
      "subscription_id" = data.vault_generic_secret.hci.data["subscription_id"]
      "tenant_id"       = data.vault_generic_secret.hci.data["tenant_id"]
    }
    ) : jsonencode(
    {
      "client_id"       = azuread_application.sre_azure_stack_hci_application.client_id
      "client_secret"   = azuread_application_password.sre_azure_stack_hci_password_2.value
      "subscription_id" = data.vault_generic_secret.hci.data["subscription_id"]
      "tenant_id"       = data.vault_generic_secret.hci.data["tenant_id"]
    }
  )
}

resource "vault_generic_secret" "vault_secret_sre_azure_stack_jenkins" {
  path = "enverus-cts/azure/hci/prod-jenkins"
  data_json = time_rotating.sre_azure_stack_hci_rotation_1.unix > time_rotating.sre_azure_stack_hci_rotation_2.unix ? jsonencode(
    {
      "client_id"            = azuread_application.sre_azure_stack_hci_application.client_id
      "client_secret"        = azuread_application_password.sre_azure_stack_jenkins_password_1.value
      "hci_blob_storage_key" = data.vault_generic_secret.hci-jenkins.data["hci_blob_storage_key"]
      "subscription_id"      = data.vault_generic_secret.hci-jenkins.data["subscription_id"]
      "tenant_id"            = data.vault_generic_secret.hci-jenkins.data["tenant_id"]
    }
    ) : jsonencode(
    {
      "client_id"            = azuread_application.sre_azure_stack_hci_application.client_id
      "client_secret"        = azuread_application_password.sre_azure_stack_jenkins_password_2.value
      "hci_blob_storage_key" = data.vault_generic_secret.hci-jenkins.data["hci_blob_storage_key"]
      "subscription_id"      = data.vault_generic_secret.hci-jenkins.data["subscription_id"]
      "tenant_id"            = data.vault_generic_secret.hci-jenkins.data["tenant_id"]
    }
  )
}

================
File: cts/iam/hci/variables.tf
================
variable "resource_groups" {
  description = "Resource groups where to list VMs. ex: 'ord1paz01'..."
  type        = set(string)
  default = [
    "ord1paz01",
    "sre-rg",
  ]
}

variable "azure_stack_hci_application" {
  description = "Name of the Azure AD application"
  type        = string
  default     = "SRE-Azure-Stack-HCI"
}

================
File: cts/iam/hci/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  required_providers {
    azuread = {
      source  = "hashicorp/azuread"
      version = ">= 3"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = ">= 4.5"
    }
    azapi = {
      source  = "azure/azapi"
      version = "2.0.0-beta"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3.0"
    }
  }
}

provider "vault" {}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

provider "azurerm" {
  features {}
  resource_provider_registrations = "none" # This is only required when the User, Service Principal, or Identity running Terraform lacks the permissions to register Azure Resource Providers.

  client_id       = data.vault_generic_secret.hci.data["client_id"]
  client_secret   = data.vault_generic_secret.hci.data["client_secret"]
  subscription_id = data.vault_generic_secret.hci.data["subscription_id"]
  tenant_id       = data.vault_generic_secret.hci.data["tenant_id"]
}

provider "azapi" {
  client_id       = data.vault_generic_secret.hci.data["client_id"]
  client_secret   = data.vault_generic_secret.hci.data["client_secret"]
  subscription_id = data.vault_generic_secret.hci.data["subscription_id"]
  tenant_id       = data.vault_generic_secret.hci.data["tenant_id"]
}

================
File: cts/iam/policies/github-action-runner/.terraform-version
================
latest:^1.7

================
File: cts/iam/policies/github-action-runner/main.tf
================
data "aws_iam_policy_document" "policy_document" {
  # give read/write access to s3 bucket for vault backups
  statement {
    sid = "1"

    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:DeleteObject",
    ]

    resources = [
      "arn:aws:s3:::vault-cts-prod-aws-ue1-backup-20240130114515712400000002/*",
    ]
  }

  statement {
    actions = [
      "s3:ListBucket",
    ]

    resources = [
      "arn:aws:s3:::vault-cts-prod-aws-ue1-backup-20240130114515712400000002",
    ]
  }

  # allow to assume role in backup account to write to bucket there
  statement {
    sid = "2"

    actions = [
      "sts:AssumeRole",
    ]

    resources = [
      "arn:aws:iam::282611858855:role/cross-account-github-action-runner-role",
    ]
  }

  # allow assumption of role in legacy prod
  statement {
    sid = "assumeLegacyProdDiAlertsRole"

    actions = [
      "sts:AssumeRole",
    ]

    resources = [
      "arn:aws:iam::155171951664:role/cross-account-github-action-runner-role",
    ]
  }
}

# create policy
resource "aws_iam_policy" "runner" {
  name   = "github-runner-policy"
  policy = data.aws_iam_policy_document.policy_document.json
}

output "policy_arn" {
  description = "The ARN of the github runner policy"
  value = aws_iam_policy.runner.arn
}

================
File: cts/iam/policies/github-action-runner/prod.backend.tfvars
================
key = "316576613383/prod/iam/roles/github-action-runner/terraform.tfstate"

================
File: cts/iam/policies/github-action-runner/prod.tfvars
================
# prod vars go here, if any

================
File: cts/iam/policies/github-action-runner/variables.tf
================
variable "env" {
  description = "The environment, eg. prod"
  type = string
}

variable "region" {
  description = "AWS region for provider"
  type = string
}

variable "assume_role_arn" {
  description = "ARN for role that terraform provider assumes to use AWS API"
  type = string
}

================
File: cts/iam/policies/github-action-runner/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = var.env
      BusinessUnit     = "cts"
      Component        = "iam"
      Product          = "nexus"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/iam/policies/github-action-runner"
      Team             = "sre@enverus.com"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/iam/roles/argo-cd-sts/.terraform-version
================
latest:^1.6

================
File: cts/iam/roles/argo-cd-sts/dev.backend.tfvars
================
key = "360093697111/dev/iam/roles/argo-cd-sts/terraform.tfstate"

================
File: cts/iam/roles/argo-cd-sts/main.tf
================
data "aws_iam_policy_document" "assume_role" {
  statement {
    sid     = "argocdsts"
    effect  = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession",
    ]

    principals {
      type        = "AWS"
      identifiers = ["*"]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values   = ["o-lypgui0jlj"]
    }

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values   = ["arn:aws:iam::*:role/*-argo-cd-sts-*"]
    }
  }
}

resource "aws_iam_role" "role" {
  name_prefix           = "Argo-cd-sts-${var.env}-"
  max_session_duration  = "3600"
  description           = "The Argo-cd IAM Role used to assume by Argo-cd clusters, to login to target EKS clusters"
  force_detach_policies = true
  assume_role_policy    = data.aws_iam_policy_document.assume_role.json
}
output "aws_iam_role" { value = aws_iam_role.role }
output "aws_iam_role_arn" { value = aws_iam_role.role.arn }

================
File: cts/iam/roles/argo-cd-sts/prod.backend.tfvars
================
key = "316576613383/dev/iam/roles/argo-cd-sts/terraform.tfstate"

================
File: cts/iam/roles/argo-cd-sts/variables.tf
================
variable "env" {}

variable "region" {
  description = "AWS region for provider"
}

variable "assume_role_arn" {
  description = "ARN for role that terraform provider assumes to use AWS API"
}

================
File: cts/iam/roles/argo-cd-sts/versions.tf
================
terraform {
  required_version = ">= 1.6"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = var.env
      BusinessUnit     = "cts"
      Component        = "iam"
      Product          = "nexus"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/iam/roles/argo-cd-sts"
      Team             = "sre@enverus.com"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/iam/roles/ssm-agent/.terraform-version
================
latest:^1.7

================
File: cts/iam/roles/ssm-agent/dev.backend.tfvars
================
key = "360093697111/dev/iam/roles/ssm-agent/terraform.tfstate"

================
File: cts/iam/roles/ssm-agent/prod.backend.tfvars
================
key = "316576613383/dev/iam/roles/ssm-agent/terraform.tfstate"

================
File: cts/iam/roles/ssm-agent/ssmAgent.tf
================
data "aws_iam_policy_document" "instance_assume_role_policy" {
  statement {
    actions = ["sts:AssumeRole"]

    principals {
      type        = "Service"
      identifiers = ["ec2.amazonaws.com"]
    }
  }
}

data "aws_iam_policy_document" "helix_agent_policy" {
  statement {
    effect = "Allow"
    actions = [
      "s3:GetObjectAcl",
      "s3:GetObject",
      "s3:GetObjectRetention",
      "s3:GetObjectVersionTagging",
      "s3:ListBucketVersions",
      "s3:GetObjectAttributes",
      "s3:GetObjectVersionAcl",
      "s3:GetObjectTagging",
      "s3:ListBucket",
      "s3:GetObjectVersionForReplication",
      "s3:GetObjectVersionAttributes",
      "s3:GetObjectVersion"
    ]
    resources = [
      "arn:aws:s3:::enverus-security-shared-files/*",
      "arn:aws:s3:::enverus-security-shared-files"
    ]
  }
  statement {
    effect = "Allow"
    actions = [
      "s3:ListAllMyBuckets"
    ]
    resources = ["*"]
  }

  statement {
    effect = "Allow"
    actions = [
      "kms:Decrypt"
    ]
    resources = ["*"]
  }
}

resource "aws_iam_instance_profile" "ssm_profile" {
  name = "ssm_access_role"
  role = aws_iam_role.ssm_role.name
}

resource "aws_iam_role" "ssm_role" {
  name               = "ssm_access_role"
  assume_role_policy = data.aws_iam_policy_document.instance_assume_role_policy.json
}

resource "aws_iam_role_policy_attachment" "ssm_attachment" {
  role       = aws_iam_role.ssm_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

resource "aws_iam_policy" "helix_agent_policy" {
  name_prefix = "Helix-Agent-policy"
  description = "IAM Policy to allow installation of Helix-Agent securiy"
  policy      = data.aws_iam_policy_document.helix_agent_policy.json
}

resource "aws_iam_role_policy_attachment" "helix_agent_attachment" {
  role       = aws_iam_role.ssm_role.name
  policy_arn = aws_iam_policy.helix_agent_policy.arn
}

================
File: cts/iam/roles/ssm-agent/variables.tf
================
variable "env" {
  description = "aws account env: dev, prod"
  type = string
}

variable "region" {
  description = "AWS region for provider"
  type = string
}

variable "assume_role_arn" {
  description = "ARN for role that terraform provider assumes to use AWS API"
  type =  string
}

================
File: cts/iam/roles/ssm-agent/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = var.env
      BusinessUnit     = "cts"
      Component        = "iam"
      Product          = "nexus"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/iam/roles/ssm-agent"
      Team             = "sre@enverus.com"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/iam/roles/tf-atlantis-test/.terraform-version
================
latest:^1.7

================
File: cts/iam/roles/tf-atlantis-test/dev.backend.tfvars
================
key = "360093697111/dev/iam/roles/tf-atlantis-test/terraform.tfstate"

================
File: cts/iam/roles/tf-atlantis-test/main.tf
================
data "aws_iam_policy_document" "terraform-assume-role-policy" {

  statement {
    sid    = "TerraformAtlantisSts"
    effect = "Allow"
    actions = [
      "sts:AssumeRole",
      "sts:TagSession"
    ]

    principals {
      type        = "AWS"
      identifiers = ["arn:aws:iam::360093697111:root"]
    }

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values = [
        "arn:aws:iam::360093697111:*-atlantis-ghe-dev-irsa"
      ]
    }
  }
}

resource "aws_iam_role" "role" {
  name                  = "terraform-test-${var.env}"
  max_session_duration  = "3600"
  description           = "IAM Role assumed by atlantis in cts-dev for testing"
  force_detach_policies = true
  assume_role_policy    = data.aws_iam_policy_document.terraform-assume-role-policy.json
}

data "aws_iam_policy_document" "tf-permissions" {
  statement {
    sid     = "ebs"
    effect  = "Allow"
    actions = [
      "ebs:*",
      "ec2:CreateVolume",
    ]

    resources = [
      "arn:aws:ec2:*:*:volume/*",
    ]
  }
  statement {
    sid   = "s3backend"
    effect = "Allow"
    actions = [
      "s3:listBucket",
      "s3:GetObject",
      "s3:PutObject"
    ]
    resources = [
      "arn:aws:s3:::enverus-centralized-terraform-state",
      "arn:aws:s3:::enverus-centralized-terraform-state/360093697111/atlantis-ghe-test/*"
    ]
  }
  statement {
    sid   = "dynamodb"
    effect = "Allow"
    actions = [
      "dynamodb:PutItem",
      "dynamodb:GetItem",
      "dynamodb:DeleteItem"

    ]
    resources = [
      "arn:aws:dynamodb:us-east-1:360093697111:table/terraform-state-locking"
    ]
  }
    statement {
    sid   = "AllowUseOfKMSKey"
    effect = "Allow"
    actions = [
      "kms:GenerateDataKey"
    ]
    resources = [
      "arn:aws:kms:us-east-1:360093697111:*"
    ]
  }
}

resource "aws_iam_policy" "tf-permissions" {
  name        = "tf-permissions-policy"
  description = "allow to create ebs volumes"
  policy      = data.aws_iam_policy_document.tf-permissions.json
}

resource "aws_iam_role_policy_attachment" "tf-permissions" {
  role       = aws_iam_role.role.name
  policy_arn = aws_iam_policy.tf-permissions.arn
}


resource "aws_iam_role_policy_attachment" "terraform_attach" {
  role       = aws_iam_role.role.name
  policy_arn = "arn:aws:iam::aws:policy/AdministratorAccess"
}

================
File: cts/iam/roles/tf-atlantis-test/variables.tf
================
variable "env" {}

variable "region" {
  description = "AWS region for provider"
}

variable "assume_role_arn" {
  description = "ARN for role that terraform provider assumes to use AWS API"
}

================
File: cts/iam/roles/tf-atlantis-test/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment      = var.env
      BusinessUnit     = "cts"
      Component        = "iam"
      Product          = "nexus"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/iam/roles/tf-atlantis-test"
      Team             = "sre@enverus.com"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/kubecost/.terraform-version
================
latest:^1.8

================
File: cts/kubecost/dev.backend.tfvars
================
key      = "360093697111/dev/kubecost/terraform.tfstate"
encrypt  = "true"
role_arn = "arn:aws:iam::360093697111:role/terraform"

================
File: cts/kubecost/federated-store.yaml.tftpl
================
type: S3
config:
  bucket: "${bucket}"
  endpoint: "s3.amazonaws.com"
  region: "us-east-1"
  insecure: false
  signature_version2: false
  put_user_metadata:
      "X-Amz-Acl": "bucket-owner-full-control"
  http_config:
    idle_conn_timeout: 90s
    response_header_timeout: 2m
    insecure_skip_verify: false
  part_size: 134217728

================
File: cts/kubecost/main.tf
================
module "kubecost_bucket" {
  source           = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket?ref=v1.2.0"
  bucketprefix     = "enverus-kubecost-aggregator-${var.env}-"
  s3_bucket_policy = data.aws_iam_policy_document.iam_policy_document.json
  providers = {
    aws.primary = aws
    aws.dr      = aws.uw2
  }
}

data "aws_organizations_organization" "main" {
}

locals {
  bucket = module.kubecost_bucket.primaryS3Bucket
}

resource "vault_generic_secret" "main" {
  path = "enverus-cts/sre/sre-kubecost/${var.env}/federated-store/"

  data_json = jsonencode(
    {
      "federated-store.yaml" = templatefile("federated-store.yaml.tftpl", { bucket = local.bucket.id })
    }
  )
}

data "aws_iam_policy_document" "iam_policy_document" {
  statement {
    sid = "AllowKubecostAccessBucket"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:ListBucket",
      "s3:GetBucketLocation",
    ]
    resources = [
      local.bucket.arn,
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
    condition {
      test     = "StringLike"
      variable = "aws:PrincipalArn"
      values = [
        "arn:aws:iam::*:role/*kubecost*",
      ]
    }
  }

  statement {
    sid = "AllowKubecostAccessObject"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:ListBucketMultipartUploads",
      "s3:AbortMultipartUpload",
      "s3:ListBucket",
      "s3:DeleteObject",
      "s3:ListMultipartUploadParts"
    ]
    resources = [
      local.bucket.arn,
      "${local.bucket.arn}/*",
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalOrgID"
      values = [
        data.aws_organizations_organization.main.id,
      ]
    }
    condition {
      test     = "StringLike"
      variable = "aws:PrincipalArn"
      values = [
        "arn:aws:iam::*:role/*kubecost*",
      ]
    }
  }
}

================
File: cts/kubecost/prod.backend.tfvars
================
key      = "316576613383/prod/kubecost/terraform.tfstate"
encrypt  = "true"
role_arn = "arn:aws:iam::316576613383:role/terraform"

================
File: cts/kubecost/variables.tf
================
variable "bu" {
  description = "The business unit for the account"
  type        = string
}

variable "env" {
  description = "Name of the Environment"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "VAULT_ADDR" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: cts/kubecost/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3.0"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "shared"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/kubecost"
      Environment  = var.env
      Product      = "shared"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Component    = "shared"
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/kubecost"
      Environment  = var.env
      Product      = "shared"
    }
  }
}

================
File: cts/lambda/bottlerocket-parameter/EKSPortions/iam.tf
================
data "get_caller_identity" "current" {}

data "aws_iam_policy_document" "instance_assume_role_policy" {
  statement {
    sid = "Logs"
    effect = "Allow"
    actions = [
              "logs:CreateLogStream",
              "logs:PutLogEvents"
              ]
    resources = [
              "arn:aws:logs:us-east-1:${data.get_caller_identity.current.id}:log-group:/aws/lambda/nodegroupupdate:*"
              ]
  }
  statement {
    sid = "EKS"
    effect = "Allow"
    actions = [
              "eks:UpdateNodegroupVersion",
              "eks:ListNodegroups",
              "eks:UpdateNodegroupConfig",
              "eks:DescribeNodegroup"
          ]
    resources = [
              "arn:aws:eks:us-east-1:${data.get_caller_identity.current.account_id}:nodegroup/cts-alpha-ue1-tc/*/*",
              "arn:aws:eks:us-east-1:${data.get_caller_identity.current.account_id}:cluster/cts-alpha-ue1-tc"
          ]
  }
  statement {
    sid = "CreateLogGroup"
    effect = "Allow"
    actions = ["logs:CreateLogGroup"]
    resources = ["arn:aws:logs:${var.region}:${data.get_caller_identity.current.account_id}:*"]
  }
  statement {
    sid = "GetParameter"
    effect = "Allow"
    actions = [
              "ssm:GetParameterHistory",
              "ssm:GetParametersByPath",
              "ssm:GetParameters",
              "ssm:GetParameter"
          ]
    resources = ["*"]
  }
}

================
File: cts/lambda/bottlerocket-parameter/EKSPortions/lambda.tf
================
resource "random_integer" "nightly_lambda" {
  min = 1
  max = 7
}

resource "aws_lambda_function" "nodegroup_update" {
  filename         = data.archive_file.lambda_zip.output_path
  function_name    = "EKS-ManagedNodeGroupUpdate-${var.environment}"
  role             = aws_iam_role.lambda_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.9"
  timeout          = 120
  source_code_hash = data.archive_file.lambda_zip.output_base64sha256

  environment {
    variables = {
      ENVIRONMENT      = var.environment
      CLUSTER_NAME     = "/${var.environment}/bottlerocket/alpha_bottlerocketOS"
    }
  }
}

# Create zip file for Lambda code
data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/lambda_function.py"
  output_path = "${path.module}/nodegroup_update.zip"
}

# CloudWatch Events rule to trigger the lambda daily at midnight UTC
resource "aws_cloudwatch_event_rule" "daily_nodegroup_check" {
  name                = "daily-nodegroup-check-${var.environment}"
  description         = "Triggers EKS Managed Node Group Update Lambda daily at midnight UTC"
  schedule_expression = "cron(0 0 * * ${random_integer.nightly_lambda.value})"
}

resource "aws_cloudwatch_event_target" "nodegroup_check_target" {
  rule      = aws_cloudwatch_event_rule.daily_nodegroup_check.name
  target_id = "EKS-ManagedNodeGroupUpdate"
  arn       = aws_lambda_function.nodegroup_update.arn
}

resource "aws_lambda_permission" "allow_cloudwatch" {
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.nodegroup_update.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.daily_nodegroup_check.arn
}


# IAM role for the Lambda function
resource "aws_iam_role" "lambda_role" {
  name = "nodegroup_update_role_${var.environment}"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "lambda.amazonaws.com"
        }
      }
    ]
  })
}

# Attach AWS managed policy for basic Lambda execution
resource "aws_iam_role_policy_attachment" "lambda_basic_execution" {
  role       = aws_iam_role.lambda_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

================
File: cts/lambda/bottlerocket-parameter/EKSPortions/nodegroup_update_iam.json
================
{
  "Version": "2012-10-17",
  "Statement": [
      {
          "Sid": "logs",
          "Effect": "Allow",
          "Action": [
              "logs:CreateLogStream",
              "logs:PutLogEvents"
          ],
          "Resource": [
              "arn:aws:logs:us-east-1:360093697111:log-group:/aws/lambda/nodegroupupdate:*"
          ]
      },
      {
          "Sid": "EKS",
          "Effect": "Allow",
          "Action": [
              "eks:UpdateNodegroupVersion",
              "eks:ListNodegroups",
              "eks:UpdateNodegroupConfig",
              "eks:DescribeNodegroup"
          ],
          "Resource": [
              "arn:aws:eks:us-east-1:${AccountId}:nodegroup/${ClusterName}/*/*",
              "arn:aws:eks:us-east-1:${AccountId}:cluster/${ClusterName}"
          ]
      },
      {
          "Sid": "VisualEditor1",
          "Effect": "Allow",
          "Action": "logs:CreateLogGroup",
          "Resource": "arn:aws:logs:us-east-1:360093697111:*"
      },
      {
          "Sid": "VisualEditor2",
          "Effect": "Allow",
          "Action": [
              "ssm:GetParameterHistory",
              "ssm:GetParametersByPath",
              "ssm:GetParameters",
              "ssm:GetParameter"
          ],
          "Resource": "*"
      }
  ]
}

================
File: cts/lambda/bottlerocket-parameter/EKSPortions/nodegroup_update_lambda.py
================
#This script is an AWS Lambda function that updates EKS nodegroups to a specified Bottlerocket OS version.
# It retrieves the version from AWS Systems Manager Parameter Store and applies it to all nodegroups in the specified EKS cluster.
# The function is designed to be triggered by an event, which includes the cluster name and environment.
# The script uses the Boto3 library to interact with AWS services and includes error handling and logging for better traceability.
# Import necessary libraries

#This script is to be deployed with the EKS cluster.  It is located here for reference.
import os
import json
import boto3
import logging

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize AWS clients
ssm_client = boto3.client('ssm')
eks_client = boto3.client('eks')

def get_bottlerocket_version(environment):
    """
    Retrieves the Bottlerocket OS version from Parameter Store
    
    Args:
        environment (str): The environment name (dev, prod, alpha, etc.)
        
    Returns:
        str: The Bottlerocket OS version
    """
    try:
        # Construct the parameter path dynamically based on the environment
        param_path = f"/{environment}/bottlerocket/{environment}_bottlerocketOS"
        logger.info(f"Getting Bottlerocket version from parameter: {param_path}")
        
        # Get the parameter
        response = ssm_client.get_parameter(Name=param_path)
        param_value = json.loads(response['Parameter']['Value'])
        
        # Extract the version
        version = param_value.get('version')
        if not version:
            raise ValueError(f"No version found in parameter {param_path}")
            
        logger.info(f"Retrieved Bottlerocket version: {version}")
        return version
    except Exception as e:
        logger.error(f"Error retrieving Bottlerocket version: {str(e)}")
        raise

def update_nodegroups(cluster_name, bottlerocket_version):
    """
    Updates all nodegroups in the specified EKS cluster with the given Bottlerocket version
    
    Args:
        cluster_name (str): The name of the EKS cluster
        bottlerocket_version (str): The Bottlerocket OS version to update to
        
    Returns:
        list: List of updated nodegroup names
    """
    try:
        # Get all nodegroups for the cluster
        logger.info(f"Getting nodegroups for cluster: {cluster_name}")
        nodegroups_response = eks_client.list_nodegroups(clusterName=cluster_name)
        nodegroup_names = nodegroups_response['nodegroups']
        
        if not nodegroup_names:
            logger.info(f"No nodegroups found for cluster {cluster_name}")
            return []
            
        updated_nodegroups = []
        
        # Update each nodegroup with the new Bottlerocket version
        for nodegroup_name in nodegroup_names:
            try:
                logger.info(f"Updating nodegroup {nodegroup_name} to Bottlerocket version {bottlerocket_version}")
                
                # Get current nodegroup config
                nodegroup_info = eks_client.describe_nodegroup(
                    clusterName=cluster_name,
                    nodegroupName=nodegroup_name
                )
                
                # Check if it's a Bottlerocket nodegroup by looking at the AMI type
                ami_type = nodegroup_info['nodegroup'].get('amiType', '')
                if 'BOTTLEROCKET' not in ami_type and 'CUSTOM' not in ami_type:
                    logger.info(f"Skipping nodegroup {nodegroup_name} as it's not using Bottlerocket (AMI type: {ami_type})")
                    continue
                
                # Update the nodegroup with the new release version
                eks_client.update_nodegroup_version(
                    clusterName=cluster_name,
                    nodegroupName=nodegroup_name,
                    releaseVersion=bottlerocket_version
                )
                
                updated_nodegroups.append(nodegroup_name)
                logger.info(f"Successfully initiated update for nodegroup {nodegroup_name}")
                
            except Exception as e:
                logger.error(f"Error updating nodegroup {nodegroup_name}: {str(e)}")
                # Continue with other nodegroups even if one fails
                continue
                
        return updated_nodegroups
        
    except Exception as e:
        logger.error(f"Error updating nodegroups: {str(e)}")
        raise

def lambda_handler(event, context):
    """
    Main Lambda handler function
    
    Expected event format:
    {
        "cluster_name": "my-eks-cluster",
        "environment": "dev"
    }
    """
    try:
        # Extract parameters from the event
        cluster_name = event.get('cluster_name')
        environment = event.get('environment')
        
        if not cluster_name or not environment:
            error_msg = "Missing required parameters: 'cluster_name' and 'environment' must be provided"
            logger.error(error_msg)
            return {
                'statusCode': 400,
                'body': json.dumps({'error': error_msg})
            }
            
        logger.info(f"Starting nodegroup update for cluster: {cluster_name}, environment: {environment}")
        
        # Get the Bottlerocket version from Parameter Store
        bottlerocket_version = get_bottlerocket_version(environment)
        
        # Update the nodegroups
        updated_nodegroups = update_nodegroups(cluster_name, bottlerocket_version)
        
        # Return the result
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f"Successfully initiated update for {len(updated_nodegroups)} nodegroups",
                'cluster_name': cluster_name,
                'environment': environment,
                'bottlerocket_version': bottlerocket_version,
                'updated_nodegroups': updated_nodegroups
            })
        }
        
    except Exception as e:
        logger.error(f"Lambda execution failed: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }

================
File: cts/lambda/bottlerocket-parameter/EKSPortions/README.md
================
These files are to go into the EKS deployment.  There are here only to facilitate deployment and should be deleted after they have been moved to EKS Base.

================
File: cts/lambda/bottlerocket-parameter/.terraform-version
================
latest

================
File: cts/lambda/bottlerocket-parameter/dev.backend.tfvars
================
key            = "360093697111/dev/lambda/bottlerocket-parameter/terraform.state"
dynamodb_table = null
use_lockfile   = true

================
File: cts/lambda/bottlerocket-parameter/dev.tfvars
================
environment     = "dev"
initial_version = "1.39.0-0968c061"

================
File: cts/lambda/bottlerocket-parameter/lambda_function.py
================
import os
import json
import urllib.request
import boto3
import logging
import datetime
from datetime import timezone

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Environment variables
ENVIRONMENT = os.environ.get('ENVIRONMENT')
ALPHA_PARAM_NAME = os.environ.get('ALPHA_PARAM_NAME')
DEV_PARAM_NAME = os.environ.get('DEV_PARAM_NAME')
PROD_PARAM_NAME = os.environ.get('PROD_PARAM_NAME')

# Constants for time intervals (in days)
DEV_PROMOTION_DAYS = 7
PROD_PROMOTION_DAYS = 14

def get_latest_bottlerocket_version():
    """
    Fetches the latest Bottlerocket OS version and commit ID from GitHub releases
    Returns format: <version>-<commit id>
    """
    try:
        # First, get the latest release information
        request = urllib.request.Request(
            "https://api.github.com/repos/bottlerocket-os/bottlerocket/releases/latest",
            headers={"Accept": "application/vnd.github.v3+json", "User-Agent": "AWS Lambda"}
        )
        
        with urllib.request.urlopen(request) as response:
            release_data = json.loads(response.read().decode())
            # The tag_name typically has a 'v' prefix, so we remove it
            tag_name = release_data['tag_name']
            version = tag_name.lstrip('v')
            
            # Now get the commit SHA for this tag
            tag_ref_request = urllib.request.Request(
                f"https://api.github.com/repos/bottlerocket-os/bottlerocket/git/refs/tags/{tag_name}",
                headers={"Accept": "application/vnd.github.v3+json", "User-Agent": "AWS Lambda"}
            )
            
            with urllib.request.urlopen(tag_ref_request) as tag_ref_response:
                tag_ref_data = json.loads(tag_ref_response.read().decode())
                
                # Get the SHA - may be a commit or a tag object
                object_type = tag_ref_data['object']['type']
                object_sha = tag_ref_data['object']['sha']
                
                # If it's a tag object, we need to get the commit it points to
                if object_type == 'tag':
                    tag_obj_request = urllib.request.Request(
                        f"https://api.github.com/repos/bottlerocket-os/bottlerocket/git/tags/{object_sha}",
                        headers={"Accept": "application/vnd.github.v3+json", "User-Agent": "AWS Lambda"}
                    )
                    
                    with urllib.request.urlopen(tag_obj_request) as tag_obj_response:
                        tag_obj_data = json.loads(tag_obj_response.read().decode())
                        commit_sha = tag_obj_data['object']['sha']
                else:
                    # It's already a commit reference
                    commit_sha = object_sha
                
                # Get the first 8 characters of the commit SHA
                short_commit_id = commit_sha[:8]
            
            # Combine version and commit ID in the requested format
            versioned_release = f"{version}-{short_commit_id}"
            logger.info(f"Latest Bottlerocket version fetched: {versioned_release} (version: {version}, commit: {short_commit_id})")
            return versioned_release
    except Exception as e:
        logger.error(f"Error fetching Bottlerocket version: {str(e)}")
        raise

def get_parameter_value(ssm_client, param_name):
    """
    Gets parameter value from SSM and parses JSON
    """
    try:
        response = ssm_client.get_parameter(Name=param_name)
        return json.loads(response['Parameter']['Value'])
    except Exception as e:
        logger.error(f"Error getting parameter {param_name}: {str(e)}")
        raise

def get_parameter_history(ssm_client, param_name):
    """
    Gets parameter version history from SSM
    """
    try:
        response = ssm_client.get_parameter_history(Name=param_name, MaxResults=25)
        return response['Parameters']
    except Exception as e:
        logger.error(f"Error getting parameter history for {param_name}: {str(e)}")
        raise

def find_version_older_than_days(parameter_history, days):
    """
    Finds a parameter version that is at least the specified number of days old
    Returns the version and when it was set
    """
    current_time = datetime.datetime.now(timezone.utc)
    
    # Sort by last modified date (newest first)
    sorted_history = sorted(parameter_history, key=lambda x: x['LastModifiedDate'], reverse=True)
    
    for param in sorted_history:
        last_modified = param['LastModifiedDate'].replace(tzinfo=timezone.utc)
        days_since_modified = (current_time - last_modified).days
        
        if days_since_modified >= days:
            # Parse the parameter value to get the version
            param_value = json.loads(param['Value'])
            return param_value['version'], last_modified
    
    # If no version is old enough, return None, None
    return None, None

def update_parameter_store(latest_version):
    """
    Updates AWS Parameter Store with the latest Bottlerocket versions based on rules
    Only updates if the new version is newer than the N-1 version in the history
    """
    ssm_client = boto3.client('ssm')
    current_time = datetime.datetime.now(timezone.utc).isoformat()
    updates = []
    
    try:
        # Get all parameters
        alpha_param = get_parameter_value(ssm_client, ALPHA_PARAM_NAME)
        dev_param = get_parameter_value(ssm_client, DEV_PARAM_NAME)
        prod_param = get_parameter_value(ssm_client, PROD_PARAM_NAME)
        
        # Get parameter histories
        alpha_history = get_parameter_history(ssm_client, ALPHA_PARAM_NAME)
        dev_history = get_parameter_history(ssm_client, DEV_PARAM_NAME)
        prod_history = get_parameter_history(ssm_client, PROD_PARAM_NAME)
        
        # Helper function to get N-1 version from history
        def get_previous_version(history):
            if len(history) < 2:
                return None
            # Sort by last modified date (newest first)
            sorted_history = sorted(history, key=lambda x: x['LastModifiedDate'], reverse=True)
            # Get the second entry (N-1)
            if len(sorted_history) > 1:
                prev_param_value = json.loads(sorted_history[1]['Value'])
                return prev_param_value.get('version')
            return None
        
        # Get N-1 versions
        alpha_prev_version = get_previous_version(alpha_history)
        dev_prev_version = get_previous_version(dev_history)
        prod_prev_version = get_previous_version(prod_history)
        
        # ---------- ALPHA UPDATES ----------
        # Alpha always gets the latest version, but only if it's newer than N-1
        if alpha_param['version'] != latest_version:
            update_alpha = True
            if alpha_prev_version:
                # Check if the proposed update (latest_version) is newer than the previous version
                if alpha_prev_version == latest_version:
                    logger.info(f"Skipping Alpha update: Latest version {latest_version} is the same as N-1 version")
                    update_alpha = False
                    
            if update_alpha:
                alpha_param['version'] = latest_version
                alpha_param['timestamp'] = current_time
                ssm_client.put_parameter(
                    Name=ALPHA_PARAM_NAME,
                    Value=json.dumps(alpha_param),
                    Type='String',
                    Overwrite=True
                )
                logger.info(f"Updated Alpha Bottlerocket version to {latest_version}")
                updates.append("alpha")
        
        # ---------- DEVELOPMENT UPDATES ----------
        # Find a version that has been in alpha for at least DEV_PROMOTION_DAYS
        stable_version, last_modified = find_version_older_than_days(alpha_history, DEV_PROMOTION_DAYS)
        
        if stable_version and stable_version != dev_param['version']:
            update_dev = True
            if dev_prev_version:
                # Check if the proposed update (stable_version) is newer than the previous version
                if dev_prev_version == stable_version:
                    logger.info(f"Skipping Development update: Stable version {stable_version} is the same as N-1 version")
                    update_dev = False
                    
            if update_dev:
                logger.info(f"Found stable version {stable_version} in alpha from {last_modified.isoformat()}")
                dev_param['version'] = stable_version
                dev_param['timestamp'] = current_time
                ssm_client.put_parameter(
                    Name=DEV_PARAM_NAME,
                    Value=json.dumps(dev_param),
                    Type='String',
                    Overwrite=True
                )
                logger.info(f"Updated Development Bottlerocket version to {stable_version}")
                updates.append("development")
        
        # ---------- PRODUCTION UPDATES ----------
        # Find a version that has been in development for at least PROD_PROMOTION_DAYS
        stable_dev_version, dev_last_modified = find_version_older_than_days(dev_history, PROD_PROMOTION_DAYS)
        
        if stable_dev_version and stable_dev_version != prod_param['version']:
            update_prod = True
            if prod_prev_version:
                # Check if the proposed update (stable_dev_version) is newer than the previous version
                if prod_prev_version == stable_dev_version:
                    logger.info(f"Skipping Production update: Stable version {stable_dev_version} is the same as N-1 version")
                    update_prod = False
                    
            if update_prod:
                logger.info(f"Found stable version {stable_dev_version} in development from {dev_last_modified.isoformat()}")
                prod_param['version'] = stable_dev_version
                prod_param['timestamp'] = current_time
                ssm_client.put_parameter(
                    Name=PROD_PARAM_NAME,
                    Value=json.dumps(prod_param),
                    Type='String',
                    Overwrite=True
                )
                logger.info(f"Updated Production Bottlerocket version to {stable_dev_version}")
                updates.append("production")
        
        return updates
    except Exception as e:
        logger.error(f"Error updating Parameter Store: {str(e)}")
        raise

def lambda_handler(event, context):
    """
    Main Lambda handler function
    """
    try:
        logger.info(f"Starting Bottlerocket version check for environment: {ENVIRONMENT}")
        
        # Get the latest Bottlerocket version
        latest_version = get_latest_bottlerocket_version()
        
        # Update Parameter Store based on rules
        updated_tiers = update_parameter_store(latest_version)
        
        if updated_tiers:
            return {
                'statusCode': 200,
                'body': json.dumps(f'Bottlerocket versions updated for tiers: {", ".join(updated_tiers)}')
            }
        else:
            return {
                'statusCode': 200,
                'body': json.dumps('No Bottlerocket version updates needed')
            }
            
    except Exception as e:
        logger.error(f"Lambda execution failed: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps(f'Error: {str(e)}')
        }

================
File: cts/lambda/bottlerocket-parameter/main.tf
================
data "aws_organizations_organization" "org" {}

resource "aws_lambda_function" "bottlerocket_version_checker" {
  filename         = data.archive_file.lambda_zip.output_path
  function_name    = "bottlerocket-version-checker-${var.environment}"
  role             = aws_iam_role.lambda_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.9"
  timeout          = 120
  source_code_hash = data.archive_file.lambda_zip.output_base64sha256

  environment {
    variables = {
      ENVIRONMENT      = var.environment
      ALPHA_PARAM_NAME = "/${var.environment}/bottlerocket/alpha_bottlerocketOS"
      DEV_PARAM_NAME   = "/${var.environment}/bottlerocket/development_bottlerocketOS"
      PROD_PARAM_NAME  = "/${var.environment}/bottlerocket/production_bottlerocketOS"
    }
  }
}

# Create zip file for Lambda code
data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/lambda_function.py"
  output_path = "${path.module}/bottlerocket_version_checker.zip"
}

# CloudWatch Events rule to trigger the lambda daily at midnight UTC
resource "aws_cloudwatch_event_rule" "daily_bottlerocket_check" {
  name                = "daily-bottlerocket-check-${var.environment}"
  description         = "Triggers Bottlerocket version checker Lambda daily at midnight UTC"
  schedule_expression = "cron(0 0 * * ? *)"
}

resource "aws_cloudwatch_event_target" "bottlerocket_check_target" {
  rule      = aws_cloudwatch_event_rule.daily_bottlerocket_check.name
  target_id = "bottlerocket-version-checker"
  arn       = aws_lambda_function.bottlerocket_version_checker.arn
}

resource "aws_lambda_permission" "allow_cloudwatch" {
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.bottlerocket_version_checker.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.daily_bottlerocket_check.arn
}

# IAM role for the Lambda function
resource "aws_iam_role" "lambda_role" {
  name = "bottlerocket_version_checker_role_${var.environment}"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "lambda.amazonaws.com"
        }
      }
    ]
  })
}

# Attach AWS managed policy for basic Lambda execution
resource "aws_iam_role_policy_attachment" "lambda_basic_execution" {
  role       = aws_iam_role.lambda_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

# Attach SSM parameter access policy
resource "aws_iam_role_policy_attachment" "lambda_ssm_access" {
  role       = aws_iam_role.lambda_role.name
  policy_arn = aws_iam_policy.lambda_policy.arn
}

# Parameter Store parameters with JSON structure for versioning and timestamps
resource "aws_ssm_parameter" "alpha_bottlerocket_version" {
  name        = "/${var.environment}/bottlerocket/alpha_bottlerocketOS"
  description = "Alpha Bottlerocket OS version"
  type        = "String"
  tier        = "Advanced"
  value = jsonencode({
    version : var.initial_version,
    timestamp : timestamp()
  })
  lifecycle {
    prevent_destroy = true
    ignore_changes  = [value]
  }
}

resource "aws_ssm_parameter" "development_bottlerocket_version" {
  name        = "/${var.environment}/bottlerocket/development_bottlerocketOS"
  description = "Development Bottlerocket OS version"
  type        = "String"
  tier        = "Advanced"
  value = jsonencode({
    version : var.initial_version,
    timestamp : timestamp()
  })
  lifecycle {
    prevent_destroy = true
    ignore_changes  = [value]
  }
}

resource "aws_ssm_parameter" "production_bottlerocket_version" {
  name        = "/${var.environment}/bottlerocket/production_bottlerocketOS"
  description = "Production Bottlerocket OS version"
  type        = "String"
  tier        = "Advanced"
  value = jsonencode({
    version : var.initial_version,
    timestamp : timestamp()
  })
  lifecycle {
    prevent_destroy = true
    ignore_changes  = [value]
  }
}

# RAM Share for SSM parameters
resource "aws_ram_resource_share" "dev_alpha_bottlerocket_ssm_share" {
  count = var.environment == "dev" ? 1 : 0
  # Only create this share from dev environment
  name                      = "DEV Alpha Bottlerocket Version"
  allow_external_principals = false
  permission_arns = [
    "arn:aws:ram::aws:permission/AWSRAMPermissionSSMParameterReadOnlyWithHistory"
  ]
}

resource "aws_ram_principal_association" "dev_alpha_bottlerocket_ssm_share_principal" {
  count              = var.environment == "dev" ? 1 : 0
  principal          = data.aws_organizations_organization.org.arn
  resource_share_arn = aws_ram_resource_share.dev_alpha_bottlerocket_ssm_share[count.index].arn
}


resource "aws_ram_resource_share" "alpha_bottlerocket_ssm_share" {
  count = var.environment == "prod" ? 1 : 0
  # Only create this share in production environment
  name                      = "Alpha Bottlerocket OS Version"
  allow_external_principals = false
  permission_arns = [
    "arn:aws:ram::aws:permission/AWSRAMPermissionSSMParameterReadOnlyWithHistory"
  ]
}

resource "aws_ram_principal_association" "alpha_bottlerocket_ssm_share_principal" {
  count              = var.environment == "prod" ? 1 : 0
  principal          = data.aws_organizations_organization.org.arn
  resource_share_arn = aws_ram_resource_share.alpha_bottlerocket_ssm_share[count.index].arn
}

resource "aws_ram_resource_share" "development_bottlerocket_ssm_share" {
  count                     = var.environment == "prod" ? 1 : 0
  name                      = "Development Bottlerocket OS Version"
  allow_external_principals = false
  permission_arns = [
    "arn:aws:ram::aws:permission/AWSRAMPermissionSSMParameterReadOnlyWithHistory"
  ]
}

resource "aws_ram_principal_association" "development_bottlerocket_ssm_share_principal" {
  count              = var.environment == "prod" ? 1 : 0
  principal          = data.aws_organizations_organization.org.arn
  resource_share_arn = aws_ram_resource_share.development_bottlerocket_ssm_share[count.index].arn
}

resource "aws_ram_resource_share" "production_bottlerocket_ssm_share" {
  count                     = var.environment == "prod" ? 1 : 0
  name                      = "Production Bottlerocket OS Version"
  allow_external_principals = false
  permission_arns = [
    "arn:aws:ram::aws:permission/AWSRAMPermissionSSMParameterReadOnlyWithHistory"
  ]
}

resource "aws_ram_principal_association" "production_bottlerocket_ssm_share_principal" {
  count              = var.environment == "prod" ? 1 : 0
  principal          = data.aws_organizations_organization.org.arn
  resource_share_arn = aws_ram_resource_share.production_bottlerocket_ssm_share[count.index].arn
}

# IAM policy for Lambda to access Parameter Store
resource "aws_iam_policy" "lambda_policy" {
  name        = "bottlerocket_version_checker_policy_${var.environment}"
  description = "Policy for Bottlerocket version checker Lambda"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = [
          "ssm:GetParameter",
          "ssm:PutParameter",
          "ssm:GetParameterHistory",
        ]
        Effect = "Allow"
        Resource = [
          "arn:aws:ssm:*:*:parameter/${var.environment}/bottlerocket/*"
        ]
      }
    ]
  })
}

================
File: cts/lambda/bottlerocket-parameter/outputs.tf
================
# output "lambda_function_name" {
#   description = "Name of the Lambda function"
#   value       = aws_lambda_function.bottlerocket_version_checker.function_name
# }

# output "lambda_function_arn" {
#   description = "ARN of the Lambda function"
#   value       = aws_lambda_function.bottlerocket_version_checker.arn
# }

# output "cloudwatch_rule_name" {
#   description = "Name of the CloudWatch rule"
#   value       = aws_cloudwatch_event_rule.daily_bottlerocket_check.name
# }

# output "alpha_version_parameter" {
#   description = "SSM parameter name for alpha Bottlerocket version"
#   value       = aws_ssm_parameter.alpha_bottlerocket_version.name
# }

# output "development_version_parameter" {
#   description = "SSM parameter name for development Bottlerocket version"
#   value       = aws_ssm_parameter.development_bottlerocket_version.name
# }

# output "production_version_parameter" {
#   description = "SSM parameter name for production Bottlerocket version"
#   value       = aws_ssm_parameter.production_bottlerocket_version.name
# }

================
File: cts/lambda/bottlerocket-parameter/prod.backend.tfvars
================
key            = "360093697111/prod/lambda/bottlerocket-parameter/terraform.state"
dynamodb_table = null
use_lockfile   = true

================
File: cts/lambda/bottlerocket-parameter/prod.tfvars
================
environment     = "prod"
initial_version = "1.39.0-0968c061"

================
File: cts/lambda/bottlerocket-parameter/variables.tf
================
variable "aws_region" {
  description = "AWS region to deploy resources"
  type        = string
  default     = "us-east-1"
}

variable "assume_role_arn" {
  description = "AWS role to assume"
  type        = string
}

variable "environment" {
  description = "Environment name (e.g., dev, test, prod)"
  type        = string
}

variable "initial_version" {
  description = "Initial version of Bottlerocket OS"
  type        = string
}

================
File: cts/lambda/bottlerocket-parameter/versions.tf
================
terraform {
  required_version = ">= 1.12"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
    random = {
      source  = "hashicorp/random"
      version = ">= 3.7"
    }
  }

}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "Bottlerocket OS Tracking"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/lambda/bottlerocket-parameter"
      TerraformCreated = "true"
      Environment      = var.environment
      Product          = "nexusv2"
    }
  }
}

================
File: cts/lambda/github-bots/repo-settings-manager/files/bucket-policy.json.tpl
================
{
    "Version": "2012-10-17",
    "Statement": [
       {
          "Sid": "Allow bucket access",
          "Effect": "Allow",
          "Principal": {
             "AWS": "arn:aws:iam::${account}:role/gha_oidc_s3_sre-lambda-${environment}-repo-settings-manager"
          },
          "Action": [
             "s3:*"
          ],
          "Resource": [
             "arn:aws:s3:::sre-lambda-${environment}-repo-settings-manager",
             "arn:aws:s3:::sre-lambda-${environment}-repo-settings-manager/*"
          ]
       }
    ]
 }

================
File: cts/lambda/github-bots/repo-settings-manager/files/lambda-cross-account-access-policy.json
================
{
    "Version": "2012-10-17",
    "Statement": [
       {
          "Sid": "Allow bucket access from sre-dev-admin",
          "Effect": "Allow",
          "Principal": {
             "AWS": "arn:aws:iam::449228620267:root"
          },
          "Action": [
             "lambda:UpdateFunctionCode"
          ],
          "Resource": [
             "arn:aws:lambda:us-east-1:360093697111:function:repo-requirement-management",
             "arn:aws:lambda:us-east-1:360093697111:function:timed-repo-requirement-management"
          ]
       }
    ]
 }

================
File: cts/lambda/github-bots/repo-settings-manager/files/oidc_lambda_maintenance_policy.tpl
================
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:ListBucket"],
      "Resource": ["${lambda_bucket_arn}"]
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:*Object"
      ],
      "Resource": ["${lambda_bucket_arn}/*"]
    },
    {
        "Effect": "Allow",
        "Action": [
            "lambda:UpdateFunctionCode"
        ],
        "Resource": ${lambda_arns}
    }
  ]
}

================
File: cts/lambda/github-bots/repo-settings-manager/files/oidc_lambda_maintenance_trust_policy.tpl
================
{
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow",
        "Principal": {"Federated": "arn:aws:iam::${account_id}:oidc-provider/${oidc_url}"},
        "Action": "sts:AssumeRoleWithWebIdentity",
        "Condition": {
          "StringLike": {
            "token.actions.githubusercontent.com:sub": ["repo:${github_org}/sre.probot.repository_settings_manager:*"]
            },
          "ForAllValues:StringEquals": {
            "token.actions.githubusercontent.com:iss": "https://token.actions.githubusercontent.com",
            "token.actions.githubusercontent.com:aud": "sts.amazonaws.com"
          }
        }
      }
    ]
}

================
File: cts/lambda/github-bots/repo-settings-manager/files/secret-policy.json.template
================
{
    "Version" : "2012-10-17",
    "Statement" : [ {
      "Effect" : "Allow",
      "Principal" : {
        "AWS" : "${lambda_arn}"
      },
      "Action" : "secretsmanager:GetSecretValue",
      "Resource" : "${secret_arn}"
    } ]
  }

================
File: cts/lambda/github-bots/repo-settings-manager/.terraform-version
================
latest:^1.3

================
File: cts/lambda/github-bots/repo-settings-manager/app-gateway.tf
================
resource "aws_apigatewayv2_api" "lambda" {
  name          = "sre-lambda-repo-settings-lambda-gw"
  protocol_type = "HTTP"
}

resource "aws_apigatewayv2_stage" "lambda" {
  api_id = aws_apigatewayv2_api.lambda.id

  name        = "sre-lambda-repo-settings-management"
  auto_deploy = true

  access_log_settings {
    destination_arn = aws_cloudwatch_log_group.api_gw.arn

    format = jsonencode({
      requestId               = "$context.requestId"
      sourceIp                = "$context.identity.sourceIp"
      requestTime             = "$context.requestTime"
      protocol                = "$context.protocol"
      httpMethod              = "$context.httpMethod"
      resourcePath            = "$context.resourcePath"
      routeKey                = "$context.routeKey"
      status                  = "$context.status"
      responseLength          = "$context.responseLength"
      integrationErrorMessage = "$context.integrationErrorMessage"
      }
    )
  }
}

resource "aws_apigatewayv2_integration" "repo-requirement-manager" {
  api_id = aws_apigatewayv2_api.lambda.id

  integration_uri    = aws_lambda_function.repo-settings-management.invoke_arn
  integration_type   = "AWS_PROXY"
  integration_method = "POST"
}

resource "aws_apigatewayv2_route" "repo-requirement-manager" {
  api_id = aws_apigatewayv2_api.lambda.id

  route_key = "POST /api/github/webhooks"
  target    = "integrations/${aws_apigatewayv2_integration.repo-requirement-manager.id}"
}

resource "aws_cloudwatch_log_group" "api_gw" {
  name = "/aws/api_gw/${aws_apigatewayv2_api.lambda.name}"

  retention_in_days = 30
}

resource "aws_lambda_permission" "api_gw" {
  statement_id  = "AllowExecutionFromAPIGateway"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.repo-settings-management.function_name
  principal     = "apigateway.amazonaws.com"

  source_arn = "${aws_apigatewayv2_api.lambda.execution_arn}/*/*"
}

================
File: cts/lambda/github-bots/repo-settings-manager/aws-secrets-manager.tf
================
resource "aws_secretsmanager_secret" "secret_name" {
  for_each = var.secret_manager_secrets
  name     = each.value.name

}

data "vault_generic_secret" "vault_secret" {
  for_each = var.secret_manager_secrets
  path     = each.value.vault_path
}


resource "aws_secretsmanager_secret_version" "secret_version" {
  for_each      = var.secret_manager_secrets
  secret_id     = aws_secretsmanager_secret.secret_name[each.key].id
  secret_string = each.value.vault_key != "" ? data.vault_generic_secret.vault_secret[each.key].data[each.value.vault_key] : data.vault_generic_secret.vault_secret[each.key].data_json
}

data "template_file" "secret_policy" {
  for_each = var.secret_manager_secrets
  template = file("${path.module}/files/secret-policy.json.template")
  vars = {
    secret_arn = aws_secretsmanager_secret.secret_name[each.key].arn
    lambda_arn = aws_iam_role.lambda_exec.arn
  }
}

resource "aws_secretsmanager_secret_policy" "secret_policy" {
  for_each   = var.secret_manager_secrets
  secret_arn = aws_secretsmanager_secret.secret_name[each.key].arn
  policy     = data.template_file.secret_policy[each.key].rendered
}

================
File: cts/lambda/github-bots/repo-settings-manager/dev.backend.tfvars
================
key = "360093697111/dev/lambda/github-bots/repo-requirement-manager/terraform.state"

================
File: cts/lambda/github-bots/repo-settings-manager/dev.tfvars
================
environment = "dev"

secret_manager_secrets = {
  github_atlantis_webhook = {
    name       = "cts/github/atlantis-webhook-secret"
    vault_path = "enverus-cts/atlantis/github.com-webhook-secret"
    vault_key  = "github_secret"
  },
  repository_settings_manager_authentication = {
    name       = "cts/github-apps/repository-setting-manager-authentication"
    vault_path = "cts-secrets/terraform/repository_settings_manager/dev"
    vault_key  = ""
  },
}

================
File: cts/lambda/github-bots/repo-settings-manager/iam.tf
================
data "template_file" "oidc_lambda_maintenance_role_policies" {
  template = file("${path.module}/files/oidc_lambda_maintenance_policy.tpl")
  vars = {
    lambda_bucket_arn = aws_s3_bucket.lambda_bucket.arn
    lambda_arns = jsonencode([
      aws_lambda_function.timed-repo-settings-management.arn,
      aws_lambda_function.repo-settings-management.arn
    ])
  }
}
data "aws_caller_identity" "current" {}

data "template_file" "oidc_lambda_maintenance_trust_policy" {
  template = file("${path.module}/files/oidc_lambda_maintenance_trust_policy.tpl")
  vars = {
    github_org      = var.repo_settings_manager_organization
    repository_name = var.repo_settings_manager_repository
    account_id      = data.aws_caller_identity.current.account_id
    oidc_url        = "token.actions.githubusercontent.com"
  }
}

resource "aws_iam_role" "oidc_s3_update_role" {
  name               = format("%s_%s", "gha_oidc_s3", aws_s3_bucket.lambda_bucket.bucket)
  assume_role_policy = data.template_file.oidc_lambda_maintenance_trust_policy.rendered
}

resource "aws_iam_role_policy" "resource_policy" {
  name   = format("%s_%s", aws_iam_role.oidc_s3_update_role.name, "_policy")
  role   = aws_iam_role.oidc_s3_update_role.name
  policy = data.template_file.oidc_lambda_maintenance_role_policies.rendered
}

================
File: cts/lambda/github-bots/repo-settings-manager/lambda-function.tf
================
data "vault_generic_secret" "github_application" {
  path = "cts-secrets/terraform/repository_settings_manager/${var.environment}"
}

resource "aws_lambda_function" "repo-settings-management" {
  function_name = "repo-settings-management"

  s3_bucket = aws_s3_bucket.lambda_bucket.id

  s3_key  = "repo-settings-management.zip"
  runtime = "nodejs16.x"
  handler = "src/app-runner.handler"
  timeout = 180
  role    = aws_iam_role.lambda_exec.arn

}

resource "aws_lambda_function" "timed-repo-settings-management" {
  function_name = "timed-repo-settings-management"

  s3_bucket = aws_s3_bucket.lambda_bucket.id

  s3_key  = "repo-settings-management.zip"
  runtime = "nodejs16.x"
  handler = "src/timed-runner.handler"
  timeout = 180
  role    = aws_iam_role.lambda_exec.arn

}

resource "aws_cloudwatch_log_group" "repo-settings-management" {
  name = "/aws/lambda/${aws_lambda_function.repo-settings-management.function_name}"

  retention_in_days = 30
}

resource "aws_cloudwatch_log_group" "timed-repo-settings-management" {
  name = "/aws/lambda/${aws_lambda_function.timed-repo-settings-management.function_name}"

  retention_in_days = 30
}

resource "aws_iam_role" "lambda_exec" {
  name = "serverless_lambda"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Sid    = ""
      Principal = {
        Service = "lambda.amazonaws.com"
      }
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_policy" {
  role       = aws_iam_role.lambda_exec.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}


resource "aws_lambda_permission" "oidc-account-access" {
  statement_id  = "AllowCodeUpdateFromGHActions"
  action        = "lambda:UpdateFunctionCode"
  function_name = aws_lambda_function.repo-settings-management.function_name
  principal     = aws_iam_role.oidc_s3_update_role.arn

}

resource "aws_lambda_permission" "timed-oidc-account-access" {
  statement_id  = "AllowCodeUpdateFromGHActions"
  action        = "lambda:UpdateFunctionCode"
  function_name = aws_lambda_function.timed-repo-settings-management.function_name
  principal     = aws_iam_role.oidc_s3_update_role.arn

}

resource "aws_cloudwatch_event_rule" "bulk_updates" {
  name                = "gh-repository-updates"
  description         = "Executes every night at midnight"
  schedule_expression = "cron(0 0 * * ? *)"
}

resource "aws_cloudwatch_event_target" "bulk_updates" {
  rule = aws_cloudwatch_event_rule.bulk_updates.name
  arn  = aws_lambda_function.timed-repo-settings-management.arn
}

resource "aws_lambda_permission" "allow_cloudwatch_to_lambda" {
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.timed-repo-settings-management.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.bulk_updates.arn
}

================
File: cts/lambda/github-bots/repo-settings-manager/main.tf
================
resource "aws_s3_bucket" "lambda_bucket" {
  bucket        = "sre-lambda-${var.environment}-repo-settings-manager"
  force_destroy = true
}


resource "aws_s3_bucket_ownership_controls" "ownership" {
  bucket = aws_s3_bucket.lambda_bucket.id

  rule {
    object_ownership = "BucketOwnerPreferred"
  }
}

resource "aws_s3_bucket_acl" "lambda_bucket_acl" {
  bucket = aws_s3_bucket.lambda_bucket.id
  acl    = "private"
}


data "template_file" "bucket_policy_template" {
  template = file("${path.module}/files/bucket-policy.json.tpl")
  vars = {
    environment = var.environment
    account     = data.aws_caller_identity.current.account_id
  }

}

resource "aws_s3_bucket_policy" "allow_access_oidc" {
  bucket = aws_s3_bucket.lambda_bucket.id
  policy = data.template_file.bucket_policy_template.rendered
}

================
File: cts/lambda/github-bots/repo-settings-manager/prod.backend.tfvars
================
key = "316576613383/prod/lambda/github-bots/repo-settings-manager/terraform.state"

================
File: cts/lambda/github-bots/repo-settings-manager/prod.tfvars
================
environment = "prod"
secret_manager_secrets = {
  github_atlantis_webhook = {
    name       = "cts/github/atlantis-webhook-secret"
    vault_path = "enverus-cts/atlantis/github.com-webhook-secret"
    vault_key  = "github_secret"
  },
  repository_settings_manager_authentication = {
    name       = "cts/github-apps/repository-setting-manager-authentication"
    vault_path = "cts-secrets/terraform/repository_settings_manager/prod"
    vault_key  = ""
  },
}

================
File: cts/lambda/github-bots/repo-settings-manager/variables.tf
================
variable "aws_region" {
  description = "Default AWS region"
  type        = string
  default     = "us-east-1"
}

variable "assume_role_arn" {
  description = "AWS role to assum"
  type        = string
}

variable "environment" {
  description = "Deployment Environment"
  type        = string
}

variable "secret_manager_secrets" {
  description = "secrets to pull from vault and add to AWS secrets manager"
}

variable "repo_settings_manager_repository" {
  description = "The repository where the repo where requirement manger config lives"
  type        = string
  default     = "sre.probot.repository_settings_manger_config"
}

variable "repo_settings_manager_organization" {
  description = "The org where the repo where settings manger config lives"
  type        = string
  default     = "enverus-cts"
}

================
File: cts/lambda/github-bots/repo-settings-manager/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.7.2"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }

}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "sre"
      Component        = "GitHub App"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/lambda/github-bots/repo-requirement-manager"
      TerraformCreated = "true"
      Environment      = "prod"
      Product          = "nexus"
    }
  }
}

================
File: cts/packer/.terraform-version
================
latest:^1.2

================
File: cts/packer/packer-iam-user.tf
================
resource "aws_iam_user" "packer" {
  name = var.username
}

resource "aws_iam_access_key" "packer" {
  user = aws_iam_user.packer.name
}

# Stash IAM user keys
resource "vault_generic_secret" "generic_secret" {
  path      = "enverus-cts/packer/aws-api-keys"
  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.packer.id}",
  "secret_key": "${aws_iam_access_key.packer.secret}"
}
EOF
}

resource "aws_iam_user_policy" "packer" {
  name = "packer-ebs-builder-policy"
  user = aws_iam_user.packer.name

  policy = <<EOF
{
"Version": "2012-10-17",
"Statement": [
    {
        "Effect": "Allow",
        "Action": [
            "ec2:AttachVolume",
            "ec2:AuthorizeSecurityGroupIngress",
            "ec2:CopyImage",
            "ec2:CreateImage",
            "ec2:CreateKeypair",
            "ec2:CreateSecurityGroup",
            "ec2:CreateSnapshot",
            "ec2:CreateTags",
            "ec2:CreateVolume",
            "ec2:DeleteKeyPair",
            "ec2:DeleteSecurityGroup",
            "ec2:DeleteSnapshot",
            "ec2:DeleteVolume",
            "ec2:DeregisterImage",
            "ec2:DescribeImageAttribute",
            "ec2:DescribeImages",
            "ec2:DescribeInstances",
            "ec2:DescribeInstanceStatus",
            "ec2:DescribeRegions",
            "ec2:DescribeSecurityGroups",
            "ec2:DescribeSnapshots",
            "ec2:DescribeSubnets",
            "ec2:DescribeTags",
            "ec2:DescribeVolumes",
            "ec2:DetachVolume",
            "ec2:GetPasswordData",
            "ec2:ModifyImageAttribute",
            "ec2:ModifyInstanceAttribute",
            "ec2:ModifySnapshotAttribute",
            "ec2:RegisterImage",
            "ec2:RunInstances",
            "ec2:StopInstances",
            "ec2:TerminateInstances",
            "iam:PassRole",
            "iam:GetInstanceProfile"
        ],
        "Resource": "*"
        }
    ]
}
EOF
}

================
File: cts/packer/prod.backend.tfvars
================
key     = "360093697111/prod/packer/terraform.tfstate"
encrypt = "true"

================
File: cts/packer/prod.tfvars
================
username = "packer"
region   = "us-east-1"

================
File: cts/packer/variables.tf
================
variable "env" {}

variable "bu" {}

variable "region" {}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "username" {
  description = "The name for the IAM user"
  type        = string
}

================
File: cts/packer/versions.tf
================
terraform {
  required_version = ">= 1.2.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.22"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Component   = "github-actions"
      SourceCode  = "https://github.com/enverus-cts/cts.terraform/packer"
      Environment = var.env
      Product     = "nexus"
      Team        = "sre@enverus.com"
    }
  }
}

================
File: cts/rds/awx/.terraform-version
================
latest:^1.10

================
File: cts/rds/awx/dev.backend.tfvars
================
key = "360093697111/dev/rds/awx/terraform.tfstate"

================
File: cts/rds/awx/dev.tfvars
================
vault_path_awx_rds     = "enverus-cts/cts.terraform/rds/awx/dev-green/"
aws_region             = "us-east-1"
take_snapshot          = false
engine_version         = "15.8"
instance_class         = "db.m6g.large"
allocated_storage      = 50
db_snapshot_identifier = "sre-awx-dev-green-20250117"

================
File: cts/rds/awx/main.tf
================
## Data and locals

data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = ["cts-vpc-${var.env}"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc_id.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*| INSIDE | Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg"]
  }
}

data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}

locals {
  snapshot_date = formatdate("YYYYMMDDHH", timestamp())
}


# Resources

resource "aws_db_subnet_group" "awx_subnet_group_green" {
  name       = "${var.env}-awx-green"
  subnet_ids = data.aws_subnets.private_subnets.ids

  tags = {
    environment = var.env
    component   = "awx"
  }
}

resource "aws_security_group" "awx_db_sg_green" {
  name        = "awx-db-sg-green"
  description = "Allow default port Postgres"
  vpc_id      = data.aws_vpc.vpc_id.id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
      "100.0.0.0/8"
    ]
    security_groups = [data.aws_security_group.inside_sg.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_db_snapshot" "awx_green" {
  count                  = (var.take_snapshot ? 1 : 0)
  db_instance_identifier = "cts-${var.env}-awx-green"
  db_snapshot_identifier = "sre-awx-${var.env}-green-${local.snapshot_date}"
}

# Generate random string to use as db password.
resource "random_string" "postgres_password" {
  length  = 16
  special = true
  upper   = true
  lower   = true
  numeric = true
}

# Store the postgres db credentials/config in Vault
resource "vault_generic_secret" "postgres_green" {
  path = var.vault_path_awx_rds
  data_json = jsonencode({
    "database" = var.db_name
    "password" = random_string.postgres_password.result
    "username" = var.db_username
    "host"     = aws_db_instance.awx_db_green.address
    "port"     = var.db_port
    "sslmode"  = var.db_sslmode
    "type"     = var.db_type
  })
}

resource "aws_db_instance" "awx_db_green" {
  allocated_storage           = var.allocated_storage
  max_allocated_storage       = var.max_allocated_storage
  allow_major_version_upgrade = true
  apply_immediately           = true
  db_subnet_group_name        = aws_db_subnet_group.awx_subnet_group_green.name
  engine                      = "postgres"
  engine_version              = var.engine_version
  identifier                  = "cts-${var.env}-awx-green"
  instance_class              = var.instance_class
  db_name                     = var.db_name
  password                    = random_string.postgres_password.result
  username                    = var.db_username
  vpc_security_group_ids      = [aws_security_group.awx_db_sg_green.id]
  backup_retention_period     = 2
  backup_window               = "07:30-08:30"
  skip_final_snapshot         = false
  final_snapshot_identifier   = "sre-awx-${var.env}-green-final-${local.snapshot_date}"
  ca_cert_identifier          = "rds-ca-rsa2048-g1"
  storage_encrypted           = true
}

================
File: cts/rds/awx/prod.backend.tfvars
================
key = "316576613383/prod/rds/awx/terraform.tfstate"

================
File: cts/rds/awx/prod.tfvars
================
vault_path_awx_rds     = "enverus-cts/cts.terraform/rds/awx/prod-green/"
aws_region             = "us-east-1"
take_snapshot          = false
engine_version         = "15.8"
instance_class         = "db.m6g.large"
allocated_storage      = 500
db_snapshot_identifier = "sre-awx-prod-green-20250117"

================
File: cts/rds/awx/variables.tf
================
variable "aws_region" {
  description = "aws region"
  type        = string
}

variable "env" {
  description = "dev, preprod, prod"
  type        = string
}
variable "bu" {
  description = "business unit"
  type        = string
}

variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "vault_path_awx_rds" {
  description = "vault path for awx secrets"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "take_snapshot" {
  default = "false"
  type    = bool
}

variable "engine_version" {
  description = "Engine version of the db instance"
  type        = number
}

variable "instance_class" {
  description = "Instance class of the db"
  type        = string
}

variable "allocated_storage" {
  description = "allocated storage in gigabytes"
  type        = number
}

variable "max_allocated_storage" {
  description = "max allocated storage in gigabytes for autoscaling"
  default     = 500
  type        = number
}

variable "db_snapshot_identifier" {
  description = "name of snapshot at apply time"
  type        = string
}

variable "db_username" {
  description = "Name of DB user"
  type        = string
  default     = "awx_admin"
}

variable "db_name" {
  description = "Name of database"
  type        = string
  default     = "awx_green"
}

variable "db_port" {
  description = "Database port"
  type        = string
  default     = "5432"
}

variable "db_sslmode" {
  description = "Database sslmode"
  type        = string
  default     = "require"
}

variable "db_type" {
  description = "RDS database type"
  type        = string
  default     = "unmanaged"
}

================
File: cts/rds/awx/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0.1"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/rds/awx"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: cts/route53/cts/.terraform-version
================
latest:^1.10

================
File: cts/route53/cts/dev.backend.tfvars
================
key = "360093697111/dev/route53/terraform.tfstate"

================
File: cts/route53/cts/prod.backend.tfvars
================
key = "316576613383/prod/route53/terraform.tfstate"

================
File: cts/route53/cts/resolver.tf
================
data "aws_default_tags" "aws_default_tags" {}

module "route53_resolver" {
  source           = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.route53-resolvers?ref=v1.2.1"
  vpc_name         = "cts-vpc-${var.env}"
  subnet_name_tags = ["*INSIDE | Private Subnet"]
  env              = var.env
  enverus_domain_rules = {
    "enverus" = {
      "domain" = "enverus.com"
      "name"   = "DI-DNS-EN"
    },
    "drillinginfo" = {
      "domain" = "drillinginfo.com"
      "name"   = "DI-DNS"
    },
    "chi-gvsi" = {
      "domain" = "chi.gvsi.com"
      "name"   = "DI-DNS-chi-gvsi"
    },
    "oraclevcn" = {
      "domain" = "oraclevcn.com"
      "name"   = "Oraclevcn-Drillinginfo"
    },
    "azure-database" = {
      "domain" = "database.windows.net."
      "name"   = "Azure-Database-windows"
    }
  }
}

================
File: cts/route53/cts/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

================
File: cts/route53/cts/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "route53"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/route53"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: cts/route53/cts/zones.tf
================
resource "aws_route53_zone" "cts_env" {
  name = "${var.env}.cts.enverus.com"
}

================
File: cts/route53/enverus_com_subzones/.terraform-version
================
latest:^1.3

================
File: cts/route53/enverus_com_subzones/prod.backend.tfvars
================
key = "316576613383/prod/route53/enverus_com_subzones/terraform.tfstate"

================
File: cts/route53/enverus_com_subzones/prod.tfvars
================
assume_role_arn = "arn:aws:iam::155171951664:role/terraform" ## EA Legacy Prod

================
File: cts/route53/enverus_com_subzones/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: cts/route53/enverus_com_subzones/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "route53"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/route53/enverus_com_subzones"
      TerraformCreated = "true"
      Environment      = "prod"
    }
  }
}

================
File: cts/route53/enverus_com_subzones/zones.tf
================
locals {
  domains = toset([
    "int.enverus.com",
    "externaldns.eks.enverus.com",
  ])
}

data "aws_route53_zone" "route53_apex_domain" {
  name = "enverus.com"
}
# output "data_aws_route53_zone_route53_apex_domain" { value = data.aws_route53_zone.route53_apex_domain }

resource "aws_route53_zone" "aws_route53_zone" {
  for_each = local.domains
  name     = each.key
}
output "aws_route53_zone" { value = aws_route53_zone.aws_route53_zone }

resource "aws_route53_record" "ns" {
  for_each = local.domains

  zone_id = data.aws_route53_zone.route53_apex_domain.zone_id
  name    = each.key
  type    = "NS"
  ttl     = "86400"
  records = aws_route53_zone.aws_route53_zone[each.key].name_servers
}
output "aws_route53_record_ns" { value = aws_route53_record.ns }

================
File: cts/s3-buckets/policies/chef-validator.json.tpl
================
{
    "Version": "2008-10-17",
    "Id": "ReadPolicy",
    "Statement": [
        {
            "Sid": "ReadAccess",
            "Effect": "Allow",
            "Principal": {
                "AWS": [
                    "arn:aws:iam::${aid}:role/service-role",
                    "arn:aws:iam::${aid}:root"
                ]
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::enverus-${bu}-${env}-${name}/*"
        }
    ]
}

================
File: cts/s3-buckets/.terraform-version
================
latest:^1.3

================
File: cts/s3-buckets/buckets.tf
================
data "template_file" "policy" {
  template = templatefile("policies/chef-validator.json.tpl", {
    env  = var.env
    bu   = var.bu
    name = var.name
    aid  = data.aws_caller_identity.current.account_id
  })
}

data "aws_caller_identity" "current" {}

resource "aws_s3_bucket" "chef-validator" {
  bucket = "enverus-${var.bu}-${var.env}-${var.name}"
  policy = data.template_file.policy.rendered

  tags = {
    Name = "enverus-${var.bu}-${var.env}-${var.name}"
  }
}

================
File: cts/s3-buckets/dev.backend.tfvars
================
key = "360093697111/dev/s3/terraform.tfstate"

================
File: cts/s3-buckets/dev.tfvars
================
name = "chef-validator"

================
File: cts/s3-buckets/prod.backend.tfvars
================
key = "316576613383/prod/s3/terraform.tfstate"

================
File: cts/s3-buckets/prod.tfvars
================
name = "chef-validator"

================
File: cts/s3-buckets/variables.tf
================
variable "name" {
  description = "The name of the s3 bucket"
}

variable "bu" {
  description = "The business unit running this module"
}

variable "env" {
  description = "The environment running this module"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: cts/s3-buckets/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "s3"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/s3-buckets"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: cts/sre-hackathon/dev.backend.tfvars
================
key     = "360093697111/dev/sre-hackathon/terraform.tfstate"
encrypt = "true"
use_lockfile = true
dynamodb_table = null

================
File: cts/sre-hackathon/dev.tfvars
================
region    = "us-east-1"
dr-region = "us-west-2"
bucketname = "enverus-sre-hackathon"

================
File: cts/sre-hackathon/main.tf
================
data "aws_iam_policy_document" "access" {
  statement {
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }

    actions = [
      "s3:GetObject",
      "s3:ListBucket",
    ]

    resources = [
      module.hackathon-bucket.primaryS3Bucket.arn,
      "${module.hackathon-bucket.primaryS3Bucket.arn}/*",
    ]

    condition {
      test     = "ArnLike"
      variable = "aws:PrincipalArn"
      values   = ["arn:aws:iam::360093697111:role/sre-hackathon-*"]
    }
  }
}

module "hackathon-bucket" {
  source     = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket"
  bucketname = var.bucketname
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
  disable_bucket_versioning = true
  disable_bucket_replication = true
  s3_bucket_policy = data.aws_iam_policy_document.access.json
}

================
File: cts/sre-hackathon/variables.tf
================
variable "region" {}
variable "dr-region" {}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bucketname" {
  description = "The name of the bucket to create"
  type        = string
}

================
File: cts/sre-hackathon/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  alias  = "ue1"
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "sre"
      Environment      = var.env
      Team             = "tech-sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/sre-hackathon"
      TerraformCreated = "true"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = var.dr-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "sre"
      Environment      = var.env
      Team             = "tech-sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/auth/sre-hackathon"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/sre-windows-utility/.terraform-version
================
latest:^1.9

================
File: cts/sre-windows-utility/dev.backend.tfvars
================
key = "360093697111/dev/sre-windows-utility/terraform.tfstate"

================
File: cts/sre-windows-utility/dev.tfvars
================
ec2-region = "us-east-1"

================
File: cts/sre-windows-utility/main.tf
================
# Resource definitions for a windows server for running utilities like powershell with azure ad
data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = ["cts-vpc-dev"]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}

data "aws_subnets" "inside_private" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*INSIDE | Private Subnet"]
  }

  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

data "aws_security_group" "inside" {
  tags = {
    Name = "*-inside-sg"
  }
}

data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}

data "aws_ami" "Windows_Server" {
  most_recent = true

  filter {
    name   = "name"
    values = ["Windows_Server-2022-English-Full-Base-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["801119661308"] # amazon
}

resource "aws_security_group" "windows_rdp" {
  name        = "${var.instance_name}_windows_rdp"
  description = "Allow inbound remote desktop protocol traffic"
  vpc_id      = data.aws_vpc.main.id

  ingress {
    from_port       = 3389
    to_port         = 3389
    protocol        = "tcp"
    security_groups = [data.aws_security_group.inside.id]
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
  }

  tags = {
    Name = "${var.instance_name}_windows_rdp"
  }
}

resource "aws_instance" "windows" {
  ami           = data.aws_ami.Windows_Server.image_id
  instance_type = "m5a.xlarge"

  vpc_security_group_ids = [
    data.aws_security_group.inside.id,
    aws_security_group.windows_rdp.id
  ]

  subnet_id = tolist(data.aws_subnets.inside_private.ids)[0]

  key_name = "cm@drillinginfo.com"

  root_block_device {
    volume_size = 80
    volume_type = "gp3"
  }

  tags = {
    Name = var.instance_name
  }

  lifecycle {
    create_before_destroy = true
  }
}
output "aws_instance" { value = aws_instance.windows }

================
File: cts/sre-windows-utility/README.md
================
# SRE Windows Utility Machine

## Uses
* running powershell scripts to manage Azure AD Groups: https://git.drillinginfo.com/SRE/azureGroupCreationScripts
* other

================
File: cts/sre-windows-utility/variables.tf
================
variable "instance_name" {
  default     = "aws-ue1-sre-windows-utility"
  description = "Used to tag the instance and security groups that are created"
}

variable "assume_role_arn" {
}

variable "ec2-region" {
}

variable "env" {
}

================
File: cts/sre-windows-utility/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.ec2-region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.env
      SourceCode  = "https://github.com/enverus-cts/cts.terraform/tree/master/sre-windows-utility"
      Team        = "sre@enverus.com"
      Product     = "nexus"
    }
  }
}

================
File: cts/testing/atlantis/.terraform-version
================
latest:^1.0

================
File: cts/testing/atlantis/dev.backend.tfvars
================
key = "360093697111/dev/testing/atlantis/terraform.tfstate"

================
File: cts/testing/atlantis/dev.tfvars
================
bu = "testing"

================
File: cts/testing/atlantis/main.tf
================
data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = ["cts-vpc-dev"]
  }
}

output "aws_vpc" {
  value = data.aws_vpc.vpc_id
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    "use1-az3",
  ]
  state = "available"
}

data "aws_subnet_ids" "inside" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = ["*INSIDE*Private*"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

output "subnets" {
  value = data.aws_subnet_ids.inside.ids
}

================
File: cts/testing/atlantis/variables.tf
================
variable "region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {
  description = "Environment, eg 'dev'"
}

variable "bu" {
  description = "Domain, eg 'upstream'"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: cts/testing/atlantis/versions.tf
================
terraform {
  #  required_version = ">= 1.0"
  backend "s3" {}
  required_providers {
    aws = {
      source = "hashicorp/aws"
      #      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = var.bu
      Team         = "sre@enverus.com"
      SourceCode   = "https://github.com/enverus-cts/cts.terraform/testing/atlantis"
      Environment  = var.env
      Product      = "nexus"
    }
  }
}

================
File: cts/testing/consul-aws/.terraform-version
================
latest:^1.9

================
File: cts/testing/consul-aws/consul.tf
================
module "consul_servers" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.consul-cluster-aws.git?ref=v0.18.7"

  env                     = var.env
  bu                      = var.bu
  tagLocation             = var.region
  tagTeam                 = "sre@enverus.com"
  tagSourceCode           = "https://github.com/enverus-cts/cts.terraform/tree/master/testing/consul-aws"
  encryption_key          = var.encryption_key
  datacenter              = var.datacenter
  recursors               = var.recursors
  vmware_clusters_to_join = var.vmware_clusters_to_join
  domain                  = var.domain
  vpc_name_tag            = var.vpc_name_tag
  instance_type           = var.instance_type
  vo_routing_key          = "key-sre-dev-test"

  # SRE-15060 skipped because commented out
  # uncomment roles_list to run ansible callback
  #  roles_list = [
  #    {
  #      host_key      = "grafana-agent"
  #      template_name = "ansible_grafana_agent_all"
  #      extra_vars    = "\\\"business_unit\\\": \\\"${var.bu}\\\",\\\"environment_name\\\": \\\"${var.env}\\\""
  #    }
  #  ]
}
#output "consul_servers_aws_ue1" { value = module.consul_servers }

================
File: cts/testing/consul-aws/dev.backend.tfvars
================
key = "360093697111/dev/testing/consul-aws/terraform.tfstate"

================
File: cts/testing/consul-aws/dev.tfvars
================
region         = "us-east-1"
env            = "dev"
bu             = "testing"
datacenter     = "aws-ue1"
encryption_key = "EKWV7cDXxt6fZDq5dfLYKVmxCia8vMTBzyqSVK5Y4MM="
create_tag     = false
domain         = "dev"
vpc_name_tag   = "cts-vpc-dev"
instance_type  = "c5a.large"
vault_path_awx = "enverus-cts/cts.terraform/awx/dev/"

================
File: cts/testing/consul-aws/variables.tf
================
variable "region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "datacenter" {
  description = "Name of datacenter for consul"
}

variable "create_tag" {
  description = "create the vsphere tag?"
  default     = false
}

variable "encryption_key" {
  type = string
}

variable "recursors" {
  default = "10.52.8.26 10.52.8.36"
}

variable "consul_url" {
  description = "address of consul_url"
  type        = string
  default     = null
}

variable "vpc_name_tag" {
  description = "AWS vpc name tag"
  type        = string
}

variable "env" {
  description = "Environment, eg 'dev'"
}

variable "domain" {
  description = "Domain, eg 'dev'"
}

variable "bu" {
  description = "Domain, eg 'upstream'"
}

variable "vmware_clusters_to_join" {
  description = "space separated strings indication clusters to join, format: dc@region"
  default     = ""
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "vault_path_awx" {
  description = "path in vault to secret used for awx interactions"
  type        = string
}

variable "VAULT_ADDR" {
  description = "Vault Addr"
  type        = string
}

================
File: cts/testing/consul-aws/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    consul = {
      source  = "hashicorp/consul"
      version = "~> 2.12.0"
      # v2.13 is only compatible with consul 1.10 or newer
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "consul-testing"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/testing/consul-aws"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

================
File: cts/testing/di_es_regulatory/master/.terraform-version
================
latest:^1.2

================
File: cts/testing/di_es_regulatory/master/dev.backend.tfvars
================
key = "360093697111/dev/testing/di_es_regulatory/master/terraform.tfstate"

================
File: cts/testing/di_es_regulatory/master/dev.tfvars
================
vpc_name                       = "cts-vpc-dev"
iam_profile                    = "service-instance-profile"
vpc_environment                = "dev"
vo_routing_key                 = "key-DevUptime"
vault_path_awx                 = "cts-secrets/terraform/awx/dev"
chef-server-private-key-bucket = "enverus-cts-dev-chef-validator"
master_count_green             = "0"

================
File: cts/testing/di_es_regulatory/master/main.tf
================
data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name]
  }
}

data "aws_security_group" "inside_sg" {
  vpc_id = data.aws_vpc.main.id

  filter {
    name   = "tag:Name"
    values = ["*-inside-sg"]
  }
}

data "aws_subnet_ids" "private" {
  vpc_id = data.aws_vpc.main.id

  filter {
    name   = "tag:Name"
    values = ["*INSIDE | Private Subnet"]
  }
}

data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}

resource "aws_security_group" "elasticsearch" {
  name        = "allow_elasticsearch_ports"
  description = "Allow access to elasticsearch port range"
  vpc_id      = data.aws_vpc.main.id

  ingress {
    description     = "TLS from VPC"
    from_port       = 9200
    to_port         = 9400
    protocol        = "tcp"
    security_groups = [data.aws_security_group.inside_sg.id]
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
  }

  # full egress
  egress {
    from_port        = 0
    to_port          = 0
    protocol         = "-1"
    cidr_blocks      = ["0.0.0.0/0"]
    ipv6_cidr_blocks = ["::/0"]
  }

}

# GREEN CLUSTER
module "green-master-nodes" {
  source = "git::ssh://git@git.drillinginfo.com/SRE/tf_module_aws_autoscaling_group.git?ref=master"

  # ami search filters
  ami-filters = {
    name           = "drillinginfo/ubuntu2004/elasticsearch-ubuntu-20.04-amd64-*"
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lc params and userdata
  ec2-region         = "us-east-1"
  environment        = var.vpc_environment
  os                 = "ubuntu20"
  ec2-name           = "aws-ue1-${var.env}-di-es-reg-6x-mst-GRN-TEST"
  instance-type      = "c6i.large"
  subnet-ids         = data.aws_subnet_ids.private.ids
  security-group-ids = "${data.aws_security_group.inside_sg.id},${aws_security_group.elasticsearch.id}"
  keypair-name       = "cm@drillinginfo.com"
  iam-profile        = var.iam_profile
  ebs-optimized      = "true"

  root-block-device = [
    {
      volume_type           = "gp3"
      volume_size           = 50
      delete_on_termination = true
    },
  ]

  # asg params
  asg-name                  = "${var.env}-di-es-reg-6x-master-GRN-asg"
  desired-capacity          = var.master_count_green
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "0"
  suspended-processes       = ["AZRebalance"]

  # Chef
  chef-version                   = "12.21.14"
  chef-environment               = "${var.env}-elasticsearch-testing"
  chef-run-list                  = "\"role[linux]\", \"recipe[di_es_regulatory_new::master_aws_green]\", \"recipe[di_environment]\", \"recipe[di_es_regulatory_new::log4shell_mitigation]\""
  chef-server-private-key-bucket = var.chef-server-private-key-bucket

  # Tagging
  tagComponent    = "di-es-regulatory-6x"
  tagStack        = var.env
  tagAutospot     = "false"
  tagLocation     = "us-east-1"
  tagBusinessUnit = "ea"
  tagTeam         = "sre@enverus.com"
  tagSourceCode   = "https://git.drillinginfo.com/SRE/terraform/tree/master/elasticsearch-regulatory-master"
  tagEnv          = var.env
  tagProduct      = "Nexus"

  vault_path_awx = var.vault_path_awx
  roles_list = [
    {
      host_key      = "grafana-agent"
      template_name = "ansible_grafana_agent_all"
      extra_vars    = "\\\"business_unit\\\": \\\"ea\\\",\\\"environment_name\\\": \\\"${var.env}\\\""
    }
  ]

  vo_routing_key = var.vo_routing_key
}

================
File: cts/testing/di_es_regulatory/master/README.md
================
# Elasticsearch Test Cluster - Master Nodes

================
File: cts/testing/di_es_regulatory/master/variables.tf
================
variable "env" {
}

variable "bu" {
}

variable "vpc_name" {
}

variable "iam_profile" {
}

variable "master_count_green" {
  description = "The nunber of master nodes in the green cluster"
  default     = "3"
}

variable "vpc_environment" {
  description = "The vpc the node is in, used by the di asg module to lookup things in maps"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "vo_routing_key" {
  description = "Victorops (splunk) routing key for alerts"
  type        = string
}

variable "vault_path_awx" {
  description = "path in the vault to awx token"
}

variable "chef-server-private-key-bucket" {
  description = "Name of s3 bucket in the account that has the chef validator key"
}

================
File: cts/testing/di_es_regulatory/master/versions.tf
================
terraform {
  required_version = ">= 1.4"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/testing/di_es_regulatory/master"
      TerraformCreated = "true"
      Product          = "diweb"
    }
  }
}

================
File: cts/testing/di_es_regulatory/README.md
================
# Elasticsearch Test Cluster

In case we need to test new AMIs, terraform etc. for the DI Elasticsearch Regulatory Cluster (DIWeb), we can use this code to create it.

================
File: cts/testing/nomad-cluster/nomad-client-service/.terraform-version
================
latest:^1.9

================
File: cts/testing/nomad-cluster/nomad-client-service/dev.backend.tfvars
================
key = "360093697111/dev/testing/nomad-cluster/nomad-client-service/terraform.tfstate"

================
File: cts/testing/nomad-cluster/nomad-client-service/dev.tfvars
================
aws_region    = "us-east-1"
environment   = "dev"
os            = "ubuntu20"
ec2-name      = "aws-ue1-dev-TESTING-nomad-clt-svc"
ami           = "drillinginfo/ubuntu2004/nomad-client-ubuntu-20.04-amd64-*"
instance-type = "r6i.xlarge"
vpc_name_tag  = "cts-vpc-dev"
keypair-name  = "cm@drillinginfo.com"
iam-profile   = "service-instance-profile"
ebs-optimized = "true"
# asg params
asg-name                  = "dev-TESTING-nomad-client-service-asg"
desired-capacity          = "1"
health-check-grace-period = "60"
health-check-type         = "EC2"
min-size                  = "1"
recursors                 = ["10.25.8.2", "169.254.169.253"]

# Chef
chef-version                   = "12.21.12"
chef-environment               = "dev-docker"
chef-run-list                  = "\"recipe[linux_base::default_no_resolvconf_no_ddagent]\", \"recipe[di_environment]\""
chef-server-private-key-bucket = "enverus-cts-dev-chef-validator"

# Tagging
tagComponent    = "testing-nomad-client-service"
tagStack        = "dev"
tagAutospot     = "true"
tagTeam         = "sre@enverus.com"
tagEnv          = "dev"
tagLocation     = "us-east-1"
tagBusinessUnit = "testing"

nomad_type    = "test"
vault_address = "https://vault.dev.cts.enverus.com/"
datacenter    = "aws-ue1"
consul_token  = "EKWV7cDXxt6fZDq5dfLYKVmxCia8vMTBzyqSVK5Y4MM="
bu            = "testing"

vault_path_ecr_keys = "enverus-cts/aws-api-keys/ecr-login"

================
File: cts/testing/nomad-cluster/nomad-client-service/main.tf
================
locals {
  vpc_name_tag = split("-", var.vpc_name_tag)
}

module "nomad-client-service-aws" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.nomad-cluster.git?ref=v4.12.0"

  providers = {
    aws = aws.custom
  }

  # this often takes the latest ami - updated 20200812 to put a new ami into the launch config (consul downgrade)
  ami-filters = {
    name           = var.ami
    virtualization = "hvm"
    owner          = "070551638384"
  }

  aws_region     = var.aws_region
  environment    = var.environment
  os             = var.os
  ec2-name       = var.ec2-name
  instance-type  = var.instance-type
  vpc_name_tag   = var.vpc_name_tag
  keypair-name   = var.keypair-name
  iam-profile    = var.iam-profile
  ebs-optimized  = var.ebs-optimized
  recursors      = var.recursors
  vo_routing_key = var.vo_routing_key

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = var.desired-capacity
  health-check-grace-period = var.health-check-grace-period
  health-check-type         = var.health-check-type
  min-size                  = var.min-size

  # Chef
  chef-version                   = var.chef-version
  chef-environment               = var.chef-environment
  chef-run-list                  = var.chef-run-list
  chef-server-private-key-bucket = var.chef-server-private-key-bucket

  # Tagging
  tagComponent    = var.tagComponent
  tagStack        = var.tagStack
  tagBusinessUnit = var.tagBusinessUnit
  tagEnv          = var.tagEnv
  tagLocation     = var.tagLocation
  tagTeam         = var.tagTeam
  tagSourceCode   = "https://git.drillinginfo.com/SRE/terraform/tree/master/testing/nomad-cluster/nomad-client-service"
  tagAutospot     = var.tagAutospot
  tagProduct      = "nomad-client-service"

  nomad_type          = var.nomad_type
  vault_address       = var.VAULT_ADDR
  datacenter          = var.datacenter
  consul_token        = var.consul_token
  bu                  = var.bu
  vault_path_ecr_keys = var.vault_path_ecr_keys
}

================
File: cts/testing/nomad-cluster/nomad-client-service/variables.tf
================
variable "aws_region" {}
variable "environment" {}
variable "os" {}
variable "ami" {}

variable "ec2-name" {}
variable "instance-type" {}
variable "vpc_name_tag" {}
variable "keypair-name" {}
variable "iam-profile" {}
variable "ebs-optimized" {}
variable "asg-name" {}
variable "desired-capacity" {}
variable "health-check-grace-period" {}
variable "health-check-type" {}
variable "min-size" {}
variable "chef-version" {}
variable "chef-environment" {}
variable "chef-run-list" {}
variable "tagComponent" {}
variable "tagStack" {}
variable "tagBusinessUnit" {}
variable "tagEnv" {}
variable "tagLocation" {}
variable "tagTeam" {}
variable "tagAutospot" {}
variable "nomad_type" {}
variable "VAULT_ADDR" {}
variable "datacenter" {}
variable "consul_token" {}
variable "bu" {}
variable "recursors" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "vault_path_ecr_keys" {
  type        = string
  description = "Vault path to aws api keys for ecr login"
}

variable "chef-server-private-key-bucket" {
  type        = string
  description = "Name of s3 bucket to get chef validator key from"
}

================
File: cts/testing/nomad-cluster/nomad-client-service/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  alias  = "custom"
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "ea"
      component         = "nomad-client-service"
      team              = "sre"
      source_code       = "https://github.com/enverus-cts/cts.terraform/tree/master/testing/nomad-cluster/nomad-client-service"
      terraform_created = "true"
    }
  }
}

================
File: cts/testing/nomad-cluster/nomad-scheduler/.terraform-version
================
latest:^1.1

================
File: cts/testing/nomad-cluster/nomad-scheduler/dev.backend.tfvars
================
key = "360093697111/dev/testing/nomad-cluster/nomad-scheduler/terraform.tfstate"

================
File: cts/testing/nomad-cluster/nomad-scheduler/dev.tfvars
================
nomad_http_address = "http://10.24.27.246:4646"

================
File: cts/testing/nomad-cluster/nomad-scheduler/nomad-scheduler-job.tpl
================
job "nomad-scheduler" {

  datacenters = "${datacenter}"

  type = "service"

  priority = "90"

  update {
    stagger      = "30s"
    max_parallel = 1
  }

  constraint {
    attribute = "$${node.class}"
    value = "test"
  }

  group "nomad-scheduler" {

    restart {
      # The number of attempts to run the job within the specified interval.
      attempts = 5
      interval = "5m"

      # The "delay" parameter specifies the duration to wait before restarting
      # a task after it has failed.
      delay = "15s"

      # The "mode" parameter controls what happens when a task has restarted
      # "attempts" times within the interval. "delay" mode delays the next
      # restart until the next interval. "fail" mode does not restart the task
      # if "attempts" has been hit within the interval.
      mode = "fail"
    }

    count = 1

    ephemeral_disk {
      size = "50"
    }

    task "nomad-scheduler" {

      driver = "docker"

      config {
        image = "070551638384.dkr.ecr.us-east-1.amazonaws.com/nomad-scheduler"
        force_pull = true
      }

      logs {
        max_files = 3
        max_file_size = 10
      }

      resources {
        cpu    = "4000"
        memory = "4000"

        network {
          mbits = 10
          port "http" {}
        }
      }
    }
  }
}

================
File: cts/testing/nomad-cluster/nomad-scheduler/scheduler.tf
================
provider "nomad" {
  address = var.nomad_http_address
  region  = "aws-ue1"
}

data "template_file" "scheduler-job" {
  template = file("${path.module}/nomad-scheduler-job.tpl")

  vars = {
    datacenter = "aws-ue1"
  }
}

resource "nomad_job" "scheduler" {
  jobspec = data.template_file.scheduler-job.rendered
}

================
File: cts/testing/nomad-cluster/nomad-scheduler/variables.tf
================
variable "env" {
}

variable "bu" {
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "nomad_http_address" {
  description = "http address of nomad server to submit job"
  type        = string
}

================
File: cts/testing/nomad-cluster/nomad-scheduler/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    nomad = {
      source = "hashicorp/nomad"
    }
    template = {
      source = "hashicorp/template"
    }
  }
}

================
File: cts/testing/nomad-cluster/nomad-server/.terraform-version
================
latest:^1.1

================
File: cts/testing/nomad-cluster/nomad-server/dev.backend.tfvars
================
key = "360093697111/dev/testing/nomad-cluster/nomad-server/terraform.tfstate"

================
File: cts/testing/nomad-cluster/nomad-server/dev.tfvars
================
aws_region    = "us-east-1"
environment   = "dev"
os            = "ubuntu20"
ec2-name      = "aws-ue1-TESTING-nomad-svr"
ami           = "drillinginfo/ubuntu2004/nomad-server-aws-ubuntu-20.04-amd64-*"
vpc_name_tag  = "cts-vpc-dev"
instance-type = "m6i.large"
keypair-name  = "cm@drillinginfo.com"
iam-profile   = "service-instance-profile"
ebs-optimized = "true"
# asg params
asg-name                  = "dev-docker-testing-nomad-server-asg"
desired-capacity          = "3"
health-check-grace-period = "60"
health-check-type         = "EC2"
min-size                  = "3"
recursors                 = ["10.24.24.2", "169.254.169.253"]

# Chef
chef-version                   = "12.21.12"
chef-environment               = "dev-docker"
chef-run-list                  = "\"recipe[linux_base::default_no_ddagent]\", \"recipe[di_environment]\""
chef-server-private-key-bucket = "enverus-cts-dev-chef-validator"

# Tagging
tagComponent    = "testing-nomad-server"
tagStack        = "dev"
tagAutospot     = "false"
tagEnv          = "dev"
tagBusinessUnit = "testing"
tagLocation     = "us-east-1"
tagTeam         = "sre@enverus.com"

nomad_type    = "server"
vault_address = "https://vault.dev.cts.enverus.com/"
datacenter    = "aws-ue1"
consul_token  = "EKWV7cDXxt6fZDq5dfLYKVmxCia8vMTBzyqSVK5Y4MM="
bu            = "testing"

vault_path_ecr_keys = "enverus-cts/aws-api-keys/ecr-login"

================
File: cts/testing/nomad-cluster/nomad-server/main.tf
================
# data "vault_generic_secret" "vmware" {
#   path = "di-secrets/terraform/vsphere"
# }

module "nomad-server-aws" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.nomad-cluster.git?ref=v4.12.0"

  providers = {
    aws = aws.custom
  }

  ami-filters = {
    name           = var.ami
    virtualization = "hvm"
    owner          = "070551638384"
  }
  aws_region     = var.aws_region
  environment    = var.environment
  os             = var.os
  ec2-name       = var.ec2-name
  instance-type  = var.instance-type
  vpc_name_tag   = var.vpc_name_tag
  keypair-name   = var.keypair-name
  iam-profile    = var.iam-profile
  ebs-optimized  = var.ebs-optimized
  recursors      = var.recursors
  vo_routing_key = var.vo_routing_key

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = var.desired-capacity
  health-check-grace-period = var.health-check-grace-period
  health-check-type         = var.health-check-type
  min-size                  = var.min-size

  # Chef
  chef-version                   = var.chef-version
  chef-environment               = var.chef-environment
  chef-run-list                  = var.chef-run-list
  chef-server-private-key-bucket = var.chef-server-private-key-bucket

  # Tagging
  tagComponent    = var.tagComponent
  tagStack        = var.tagStack
  tagBusinessUnit = var.tagBusinessUnit
  tagEnv          = var.tagEnv
  tagLocation     = var.tagLocation
  tagTeam         = var.tagTeam
  tagSourceCode   = "https://github.com/enverus-cts/cts.terraform/tree/master/nomad-cluster/nomad-server"
  tagAutospot     = var.tagAutospot
  tagProduct      = "nomad-server"

  nomad_type          = var.nomad_type
  vault_address       = var.VAULT_ADDR
  datacenter          = var.datacenter
  consul_token        = var.consul_token
  bu                  = var.bu
  vault_path_ecr_keys = var.vault_path_ecr_keys
}

================
File: cts/testing/nomad-cluster/nomad-server/variables.tf
================
variable "aws_region" {}
variable "environment" {}
variable "os" {}
variable "ami" {}

variable "ec2-name" {}
variable "instance-type" {}
variable "vpc_name_tag" {}
variable "keypair-name" {}
variable "iam-profile" {}
variable "ebs-optimized" {}
variable "asg-name" {}
variable "desired-capacity" {}
variable "health-check-grace-period" {}
variable "health-check-type" {}
variable "min-size" {}
variable "chef-version" {}
variable "chef-environment" {}
variable "chef-run-list" {}
variable "tagComponent" {}
variable "tagStack" {}
variable "tagBusinessUnit" {}
variable "tagEnv" {}
variable "tagLocation" {}
variable "tagTeam" {}
variable "tagAutospot" {}
variable "nomad_type" {}
variable "VAULT_ADDR" {}
variable "datacenter" {}
variable "consul_token" {}
variable "bu" {}
variable "recursors" {}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "vault_path_ecr_keys" {
  type        = string
  description = "Vault path to aws api keys for ecr login"
}

variable "chef-server-private-key-bucket" {
  type        = string
  description = "Name of s3 bucket to get chef validator key from"
}

================
File: cts/testing/nomad-cluster/nomad-server/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  alias  = "custom"
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      Environment = var.environment
      SourceCode  = "https://github.com/enverus-cts/cts.terraform/tree/master/nomad-cluster/nomad-server"
      Team        = "sre@enverus.com"
      Product     = "nexus"
    }
  }
}

provider "vault" {}

================
File: cts/vault_azuread_sso_cts/.terraform-version
================
latest

================
File: cts/vault_azuread_sso_cts/dev.backend.tfvars
================
dynamodb_table = null
key            = "360093697111/dev/vault_azuread_sso_green/terraform.tfstate"
use_lockfile   = true

================
File: cts/vault_azuread_sso_cts/dev.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault.dev.cts.enverus.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_CTS_DEV_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_DEV_CTS_DEVS_RO = {
    policies = [
      "cts-dev-read",
    ]
  },
}
vault_path_oidc_client_secret               = "cts-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "enverus-cts/Azure_Service_Principal_Atlantis"
VAULT_ADDR_SOURCE                           = "https://vault.dev.cts.enverus.com"
VAULT_ADDR                                  = "https://vault.dev.cts.enverus.com"
vault_destination_root_token                = "enverus-cts/cts.terraform/vault/cts-dev-vault"

================
File: cts/vault_azuread_sso_cts/import.tf_
================
data "azuread_group" "vault_identity_group_alias_dev" {
  for_each = toset(keys(var.vault_identity_group_alias_dev))
  display_name = each.key
}
output "data_azuread_group" { value = data.azuread_group.vault_identity_group_alias_dev }

import {
  for_each = data.azuread_group.vault_identity_group_alias_dev

  id       = each.value.object_id
  to       = module.vault_azuread_sso.azuread_group.SEC_ENTITLE_HASHICORP_VAULT[each.key]
}

================
File: cts/vault_azuread_sso_cts/main.tf
================
data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

module "vault_azuread_sso" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-azuread-sso.git?ref=v0.2.0"

  oidc_client_id                 = var.oidc_client_id
  oidc_discovery_url             = var.oidc_discovery_url
  allowed_redirect_uris_prefix   = var.allowed_redirect_uris_prefix
  vault_identity_group_alias_sre = var.vault_identity_group_alias_sre
  vault_identity_group_alias_dev = var.vault_identity_group_alias_dev
  vault_path_oidc_client_secret  = var.vault_path_oidc_client_secret
}
output "vault_azuread_sso" { value = module.vault_azuread_sso }

================
File: cts/vault_azuread_sso_cts/prod.backend.tfvars
================
dynamodb_table = null
key            = "316576613383/prod/vault_azuread_sso_cts/terraform.tfstate"
use_lockfile   = true

================
File: cts/vault_azuread_sso_cts/prod.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault.prod.cts.enverus.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_CTS_PROD_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_DEVS_RO = {
    policies = [
      "cts-prod-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_ELM_RO = {
    policies = [
      "elm-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_ELM_RW = {
    policies = [
      "elm-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_REFINERY_RO = {
    policies = [
      "refinery-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_REFINERY_RW = {
    policies = [
      "refinery-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_PR_RW = {
    policies = [
      "pr-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_TR_RW = {
    policies = [
      "tr-sphere-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_PR_CEII_RW = {
    policies = [
      "pr-ceii-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_PR_MARGINALUNIT_RW = {
    policies = [
      "pr-marginalunit-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_BA_RW = {
    policies = [
      "ba-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_ARTIFACTORY_REPO_RW = {
    policies = [
      "artifactory-remote-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_RW = {
    policies = [
      "ea-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_MFG_ADMIN_RW = {
    policies = [
      "ea-mfg-admin-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_IAT_RW = {
    policies = [
      "iat-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_DSU_RO = {
    policies = [
      "dsu-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_DSU_RW = {
    policies = [
      "dsu-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_DIML_RO = {
    policies = [
      "diml-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_DIML_RW = {
    policies = [
      "diml-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_COS_DIRECTOR_RO = {
    policies = [
      "cos-director-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_COS_DIRECTOR_RW = {
    policies = [
      "cos-director-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_IRIS_SPARK_RO = {
    policies = [
      "iris-spark-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_IRIS_SPARK_RW = {
    policies = [
      "iris-spark-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_DA_DMS_RO = {
    policies = [
      "da-dms-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_DA_DMS_RW = {
    policies = [
      "da-dms-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_BA_OI_RW = {
    policies = [
      "payables-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_BA_OI_RO = {
    policies = [
      "payables-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_RIG_RO = {
    policies = [
      "ea-rig-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_RIG_RW = {
    policies = [
      "ea-rig-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_TEST_CREDENTIAL_RW = {
    policies = [
      "core-test-automation-credentials-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_ESG_RO = {
    policies = [
      "ea-esg-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_ESG_RW = {
    policies = [
      "ea-esg-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_COA_DATA_PIPELINE_RO = {
    policies = [
      "coa-data-pipeline-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_COA_DATA_PIPELINE_RW = {
    policies = [
      "coa-data-pipeline-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_CTS_COURTHOUSE_RW = {
    policies = [
      "courthouse-rw",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_DA_MCP_DEVAPI_RO = {
    policies = [
      "da-mcp-devapi-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_EA_DA_MCP_DEVAPI_RW = {
    policies = [
      "da-mcp-devapi-write",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_SEC_DEVSECOPSAPP_RO = {
    policies = [
      "sec-devsecopsapp-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_PROD_SEC_DEVSECOPSAPP_RW = {
    policies = [
      "sec-devsecopsapp-write",
    ]
  }
}
vault_path_oidc_client_secret               = "cts-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "enverus-cts/Azure_Service_Principal_Atlantis"
VAULT_ADDR_SOURCE                           = "https://vault.prod.cts.enverus.com"
VAULT_ADDR                                  = "https://vault.prod.cts.enverus.com"
vault_destination_root_token                = "enverus-cts/cts.terraform/vault/cts-prod-vault"

================
File: cts/vault_azuread_sso_cts/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "VAULT_ADDR_SOURCE" {
  description = "address of the source vault"
  type        = string
}

variable "vault_destination_root_token" {
  description = "vault path in source vault for the destination root token"
  type        = string
}

variable "vault_path_azure_service_principal_atlantis" {
  description = "The vault path to AzureAD Service Principal secret"
  type        = string
}

variable "vault_path_oidc_client_secret" {
  description = "The vault path to AzureAD OIDC secret"
  type        = string
}

variable "oidc_client_id" {
  description = "The client id for credentials to query the Azure APIs. Currently read permissions to query compute resources are required."
  type        = string
}

variable "oidc_discovery_url" {
  description = "The OIDC Discovery URL, without any .well-known component (base"
  type        = string
}

variable "allowed_redirect_uris_prefix" {
  description = "The list of allowed values for redirect_uri during OIDC logins. Required for OIDC roles"
  type        = list(string)
}

variable "vault_identity_group_alias_sre" {
  description = "Azure ID of the group alias to create."
  type        = string
  default     = null
}

variable "vault_identity_group_alias_dev" {
  description = "list of Azure IDs of the group alias to create."
  type        = any
  default     = {}
}

================
File: cts/vault_azuread_sso_cts/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

provider "vault" {
  alias   = "source"
  address = var.VAULT_ADDR_SOURCE
}

data "vault_generic_secret" "vault_destination" {
  provider = vault.source
  path     = var.vault_destination_root_token
}

provider "vault" {
  address = var.VAULT_ADDR
  token   = data.vault_generic_secret.vault_destination.data["ROOT_TOKEN"]
}

================
File: cts/vault_cts/.terraform-version
================
latest:^1.7

================
File: cts/vault_cts/data.tf
================
data "aws_route53_zone" "selected" {
  name = "${var.env}.cts.enverus.com"
}

data "aws_default_tags" "aws_default_tags" {}

================
File: cts/vault_cts/dev.backend.tfvars
================
key = "360093697111/dev/vault_2/terraform.tfstate"

================
File: cts/vault_cts/dev.tfvars
================
#keys
consul_token = "ohrDXjezwaIRmcf1sa5kXpDpjKjVS59LX3s8ufupUJE="
#module componements
datacenter    = "aws-ue1"
os            = "ubuntu20"
vpc_name_tag  = "cts-vpc-dev"
instance_type = "c6i.large"
ec2-name      = "aws-ue1-cts-dev-vault2"
asg-name      = "ue1-dev-cts-vault2-asg"
elb-name      = "ue1-dev-cts-vault2-lb"
dns-name      = "vault.dev.cts.enverus.com"
#Chef
chef-environment = "cts-dev-docker"
#Tagging
tagComponent            = "vault"
tagLocation             = "us-east-1"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "cts_dev"
vault_path              = "vault2/"
bucket_prefix           = true

================
File: cts/vault_cts/main.tf
================
module "aws-asg-cts-vault-server" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault.git?ref=v1.6.1"

  generate_certs = 1
  cert_type      = "AMAZON_ISSUED"
  cert_domain    = "*.${var.env}.${var.bu}.enverus.com"
  datacenter     = var.datacenter
  consul_token   = var.consul_token
  bu             = var.bu

  organization_name     = "Enverus"
  ca_common_name        = var.dns-name
  common_name           = var.dns-name
  dns_names             = ["vault.service.consul, ${var.dns-name}, localhost"]
  ip_addresses          = ["127.0.0.1"]
  validity_period_hours = "87658"
  vpc_name_tag          = var.vpc_name_tag
  inside_subnet_filter  = var.inside_subnet_filter
  vo_routing_key        = var.vo_routing_key
  vault_path            = var.vault_path
  bucket_prefix         = var.bucket_prefix
  # ami search filters
  ami-filters = {
    name           = var.image
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lc params and userdata
  environment             = var.env
  bucket_hook_environment = var.bucket_hook_environment
  os                      = var.os
  ec2-name                = var.ec2-name
  instance-type           = var.instance_type
  keypair-name            = var.keypair-name
  iam-profile             = "service-instance-profile"
  ebs-optimized           = "true"

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = "2"
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "2"
  suspended-processes       = ["AZRebalance"]
  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
      playbook_file = "install-alloy.yml",
      git_host      = "cloud",
      additional_args = [
        "--extra-vars \"alloy_environment_name=${var.env} alloy_business_unit=${var.bu}\"",
        "-C main"
      ],
    }
  ]

  # Chef
  chef-version     = "12.21.14"
  chef-environment = var.chef-environment
  chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\""

  # Tagging
  tagComponent  = var.tagComponent
  tagStack      = var.env
  tagLocation   = var.tagLocation
  tagProduct    = "nexus"
  tagAutospot   = "false"
  tagTeam       = data.aws_default_tags.aws_default_tags.tags.Team
  tagSourceCode = data.aws_default_tags.aws_default_tags.tags.SourceCode

  #elb dns stuff

  elb-name                  = var.elb-name
  internal                  = true
  cross_zone_load_balancing = true
  idle_timeout              = "60"
  lb_port                   = "443"
  vault_api_port            = "8200"
  create_dns_entry          = 1
  hosted_zone_id            = data.aws_route53_zone.selected.zone_id
  domain_name               = var.dns-name
}

================
File: cts/vault_cts/prod.backend.tfvars
================
key = "316576613383/prod/vault_cts/terraform.tfstate"

================
File: cts/vault_cts/prod.tfvars
================
#keys
consul_token = "Y1fB1emKjtmr5FLwYa1yFZu54yXlrjww5G6VPmkwX3s="
#module componements
datacenter    = "aws-ue1"
os            = "ubuntu20"
vpc_name_tag  = "cts-vpc-prod"
instance_type = "c6i.large"
ec2-name      = "aws-ue1-cts-prod-vault2"
asg-name      = "ue1-prod-cts-vault2-asg"
elb-name      = "ue1-prod-cts-vault2-lb"
dns-name      = "vault.prod.cts.enverus.com"
#Chef
chef-environment = "cts-prod-docker"
#Tagging
tagComponent            = "vault"
tagLocation             = "us-east-1"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "cts_prod"
vault_path              = "ctsvault/"
bucket_prefix           = true

================
File: cts/vault_cts/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "datacenter" {
  description = "the name of the dc, in our case could be 'aws-ue1'"
  type        = string
}

variable "os" {
  description = "used to configure scripts"
  type        = string
}

variable "bu" {
  description = "the business unit"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "consul_token" {
  description = "key to connect to consul"
  type        = string
}

variable "vpc_name_tag" {
  description = "Value of Name tag applied to target VPC, eg 'dev-VPC'"
  type        = string
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "ec2-name" {
  description = "used for naming the instances"
  type        = string
}

variable "asg-name" {
  description = "used for naming autoscaling group"
  type        = string
}

variable "elb-name" {
  description = "used for naming load balancer"
  type        = string
}

variable "dns-name" {
  description = "used for naming domain name"
  type        = string
}

variable "chef-environment" {
  description = "chef environment into which the node should bootstrap"
  type        = string
}

variable "tagComponent" {
  description = "used to set component tag"
  type        = string
}

variable "tagLocation" {
  type        = string
  description = "Location, eg, aws-ue1"
}

variable "keypair-name" {
  default     = "cm@drillinginfo.com"
  description = "keypair for ssh"
}

variable "inside_subnet_filter" {
}

variable "image" {
  description = "vault server image"
  type        = string
}

variable "bucket_hook_environment" {
  description = "string value for asg module"
  type        = string
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

variable "vault_path" {
  type        = string
  description = "Vault path in consul"
}

variable "bucket_prefix" {
  type        = bool
  description = "A prefix for the s3 backup bucket"
}

================
File: cts/vault_cts/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.43"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/vault"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: cts/vault_mounts/.terraform-version
================
latest:^1.8

================
File: cts/vault_mounts/dev.backend.tfvars
================
key = "360093697111/dev/vault_mounts/terraform.tfstate"

================
File: cts/vault_mounts/dev.tfvars
================
VAULT_ADDR        = "https://vault.dev.cts.enverus.com"
list_vault_mounts = ["enverus-cts"]
#to update to cts.dev vault you must run this locally as the atlantis workflow for cts-dev-vault connects to cts-prod vault.

================
File: cts/vault_mounts/main.tf
================
resource "vault_mount" "mounts" {
  for_each = var.list_vault_mounts

  path = each.key
  type = "kv-v2"
}

================
File: cts/vault_mounts/prod.backend.tfvars
================
key = "316576613383/prod/vault_mounts/terraform.tfstate"

================
File: cts/vault_mounts/prod.tfvars
================
VAULT_ADDR        = "https://vault.prod.cts.enverus.com"
list_vault_mounts = ["enverus-cts", "enverus-ea", "enverus-it", "enverus-tr", "enverus-ba", "enverus-pr"]

================
File: cts/vault_mounts/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_mounts" {
  description = "a list of vault mounts"
  type        = set(any)
}

================
File: cts/vault_mounts/versions.tf
================
terraform {
  required_version = ">= 1.8.1, < 1.8.2"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/vault_policies_and_roles/.terraform-version
================
latest

================
File: cts/vault_policies_and_roles/dev.backend.tfvars
================
dynamodb_table = null
key            = "360093697111/dev/vault_policies_and_roles/ue1/terraform.tfstate"
use_lockfile   = true

================
File: cts/vault_policies_and_roles/dev.tfvars
================
secrets_mountpoint = "enverus-cts"
VAULT_ADDR         = "https://vault.dev.cts.enverus.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  terraform-read-policy = [
    {
      path         = "*"
      capabilities = ["read"]
      description  = "Allow terraform to read all secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/role/databricks*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage databricks approles"
    },
    {
      path         = "auth/approle/role/elm-read*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage elm (legacy databricks) approle"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "atlantis access to everything"
    },
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "Allow revoking tokens that should no longer exist. This allows revoking tokens for dead tasks."
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["read", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list", "sudo"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACLs broadly across Vault."
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    },
    {
      path         = "*/metadata/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform metadata"
    },
    {
      path         = "*/metadata/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform metadata"
    }
  ]
  cts-dev-read = [
    {
      path         = "cts-secrets*"
      capabilities = ["list"]
      description  = "access to cts-secrets"
    },
    {
      path         = "it-secrets*"
      capabilities = ["list"]
      description  = "access to it-secrets"
    },
    {
      path         = "cts-secrets/terraform/*"
      capabilities = ["deny"]
      description  = "deny to terraform"
    },
    {
      path         = "it-secrets/terraform/*"
      capabilities = ["deny"]
      description  = "deny to terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: cts/vault_policies_and_roles/main.tf
================
resource "vault_auth_backend" "userpass" {
  type = "userpass"
}

data "vault_generic_secret" "atlantis_userpass" {
  path = var.atlantis_userpass
}

resource "vault_generic_endpoint" "atlantis" {
  depends_on           = [vault_auth_backend.userpass]
  path                 = "auth/userpass/users/atlantis"
  ignore_absent_fields = true

  data_json = jsonencode({
    "policies" : ["atlantis-token", "default"],
    "password" : data.vault_generic_secret.atlantis_userpass.data["PASSWORD"]
  })
}

module "vault_policies_and_roles" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-policies-and-roles.git?ref=v1.1.0"

  list_vault_policies = var.list_vault_policies
  secrets_mountpoint  = var.secrets_mountpoint
  bu                  = var.bu
  env                 = var.env
}
output "vault_policies_and_roles" { value = module.vault_policies_and_roles }

================
File: cts/vault_policies_and_roles/prod.backend.tfvars
================
dynamodb_table = null
key            = "316576613383/prod/vault_policies_and_roles/ue1/terraform.tfstate"
use_lockfile   = true

================
File: cts/vault_policies_and_roles/prod.tfvars
================
secrets_mountpoint = "enverus-cts"
VAULT_ADDR         = "https://vault.prod.cts.enverus.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  terraform-read-policy = [
    {
      path         = "*"
      capabilities = ["read"]
      description  = "Allow terraform to read all secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/role/databricks*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage databricks approles"
    },
    {
      path         = "auth/approle/role/elm-read*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage elm (legacy databricks) approle"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "Allow revoking tokens that should no longer exist. This allows revoking tokens for dead tasks."
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "atlantis access to everything"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["read", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list", "sudo"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACLs broadly across Vault."
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    },
    {
      path         = "*/metadata/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform metadata"
    },
    {
      path         = "*/metadata/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform metadata"
    }
  ]
  cts-prod-read = [
    {
      path         = "cts-secrets*"
      capabilities = ["list"]
      description  = "access to cts-secrets"
    },
    {
      path         = "it-secrets*"
      capabilities = ["list"]
      description  = "access to it-secrets"
    },
    {
      path         = "cts-secrets/terraform/*"
      capabilities = ["deny"]
      description  = "deny to terraform"
    },
    {
      path         = "it-secrets/terraform/*"
      capabilities = ["deny"]
      description  = "deny to terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "cts-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "cts-secrets/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-ba*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "enverus-ba/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-cts*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "enverus-cts/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "enverus-ea/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-pr*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "enverus-pr/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "pr-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "pr-secrets/data/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/*"
      capabilities = ["read", "list"]
      description  = "access to refinery secrets"
    },
    {
      path         = "enverus-pr*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-pr/data/*"
      capabilities = ["read", "list"]
      description  = "access to refinery secrets"
    },
    {
      path         = "cts-secrets/data/terraform/*"
      capabilities = ["deny"]
      description  = "explicitly deny terraform/* from elm-read policy"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-write = [
    {
      path         = "cts-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "cts-secrets/data/elm/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "cts-secrets/data/terraform/data_infrastructure/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "allow read/update to terraform/data_infrastructure"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  refinery-read = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/refinery/*"
      capabilities = ["read", "list"]
      description  = "access to refinery secrets"
    },
    {
      path         = "enverus-ea/data/terraform/*"
      capabilities = ["deny"]
      description  = "explicitly deny terraform/* from refinery-read policy"
    },
    {
      path         = "enverus-ea/data/terraform/refinery/*"
      capabilities = ["read", "list"]
      description  = "allow read to terraform/refinery"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  refinery-write = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/refinery/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to refinery secrets"
    },
    {
      path         = "enverus-ea/data/terraform/refinery/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "allow read/update to terraform/refinery"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  pr-write = [
    {
      path         = "enverus-pr*"
      capabilities = ["list"]
      description  = "access to enverus-pr secrets"
    },
    {
      path         = "enverus-pr/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to PR secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    },
    {
      path         = "enverus-pr/data/ceii/*"
      capabilities = ["deny"]
      description  = "deny access to the ceii folder level."
    }
  ]
  tr-sphere-write = [
    {
      path         = "enverus-tr/*"
      capabilities = ["list"]
      description  = "access to enverus-tr secrets"
    },
    {
      path         = "enverus-tr/data/sphere/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to TR sphere secrets"
    },
    {
      path         = "enverus-tr/metadata/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-tr secrets"
    },
  ]
  pr-ceii-write = [
    {
      path         = "enverus-pr*"
      capabilities = ["list"]
      description  = "access to enverus-pr secrets for ceii account"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    },
    {
      path         = "enverus-pr/data/ceii/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to the ceii folder level."
    }
  ]
  pr-marginalunit-write = [
    {
      path         = "enverus-pr*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-pr/data/pr-marginalunit/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to pr-marginalunit secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  ba-write = [
    {
      path         = "enverus-ba*"
      capabilities = ["list"]
      description  = "access to enverus-ba secrets"
    },
    {
      path         = "enverus-ba/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to BA secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  artifactory-remote-write = [
    {
      path         = "enverus-cts*"
      capabilities = ["list"]
      description  = "access to artifactory remote repository secrets"
    },
    {
      path         = "enverus-cts/data/artifactory-credentials/remote-repositories/*"
      capabilities = ["read", "update", "list"]
      description  = "access to artifactory remote repository secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  ea-write = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to EA secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  ea-mfg-admin-write = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to view existence of all enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/eadata-mfg/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "administrate enverus-ea/eadata-mfg secrets for well/land/etc. teams"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata secret access"
    },
    {
      path         = "enverus-ea/metadata/eadata-mfg/*"
      capabilities = ["list", "read", "delete"]
      description  = "metadata secret access"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  iat-write = [
    {
      path         = "enverus-it/*"
      capabilities = ["list"]
      description  = "access to enverus-it secrets"
    },
    {
      path         = "enverus-it/metadata/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-it secrets"
    },
    {
      path         = "enverus-it/data/Azure_Service_Principal_Atlantis"
      capabilities = ["read", "update", "list"]
      description  = "access to enverus-it secrets for ITA team/Atlantis identity"
    },
    {
      path         = "enverus-it/data/azure/hci/*"
      capabilities = ["read", "update", "list"]
      description  = "access to enverus-it secrets for ITA team/hci related secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    },
    {
      path         = "auth/token/*"
      capabilities = ["list", "read", "create", "update"]
      description  = "allow child token create"
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  dsu-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/dsu"
      capabilities = ["list", "read"]
      description  = "access to DSU secrets"
    },
    {
      path         = "enverus-ea/data/dsu/*"
      capabilities = ["list", "read"]
      description  = "access to DSU secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DSU secrets"
    }
  ]
  dsu-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/dsu"
      capabilities = ["list", "read"]
      description  = "access to DSU secrets"
    },
    {
      path         = "enverus-ea/data/dsu/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to DSU secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DSU secrets"
    }
  ]
  diml-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/diml"
      capabilities = ["list", "read"]
      description  = "access to DIML secrets"
    },
    {
      path         = "enverus-ea/data/diml/*"
      capabilities = ["list", "read"]
      description  = "access to DIML secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DIML secrets"
    }
  ]
  diml-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/diml"
      capabilities = ["list", "read"]
      description  = "access to DIML secrets"
    },
    {
      path         = "enverus-ea/data/diml/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to DIML secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DIML secrets"
    }
  ]
  cos-director-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/cos-director*"
      capabilities = ["list", "read"]
      description  = "access to COS Director secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to COS Director secrets"
    }
  ]
  cos-director-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/cos-director"
      capabilities = ["list", "read"]
      description  = "access to COS Director secrets"
    },
    {
      path         = "enverus-ea/data/cos-director/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to COS Director secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to COS Director secrets"
    }
  ]
  iris-spark-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/iris-spark*"
      capabilities = ["list", "read"]
      description  = "access to IRIS Spark secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to IRIS Spark secrets"
    }
  ]
  iris-spark-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/iris-spark"
      capabilities = ["create", "list", "read"]
      description  = "access to IRIS Spark secrets"
    },
    {
      path         = "enverus-ea/data/iris-spark/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to IRIS Spark secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to IRIS Spark secrets"
    }
  ]
  coa-data-pipeline-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/coa-data-pipeline*"
      capabilities = ["list", "read"]
      description  = "access to COA Data Pipeline secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to COA Data Pipeline secrets"
    }
  ]
  coa-data-pipeline-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/coa-data-pipeline"
      capabilities = ["create", "list", "read"]
      description  = "access to COA Data Pipeline secrets"
    },
    {
      path         = "enverus-ea/data/coa-data-pipeline/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to COA Data Pipeline secrets"
    },
    {
      path         = "enverus-ea/metadata/coa-data-pipeline/*"
      capabilities = ["read", "list", "delete"]
      description  = "metadata access to COA Data Pipeline secrets"
    }
  ]
  da-dms-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/da-dms*"
      capabilities = ["list", "read"]
      description  = "access to DA DSM secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DA DMS secrets"
    }
  ]
  da-dms-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/da-dms"
      capabilities = ["list", "read"]
      description  = "access to DA DMS secrets"
    },
    {
      path         = "enverus-ea/data/da-dms/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to DA DMS secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DA DMS secrets"
    }
  ]
  payables-write = [
    {
      path         = "enverus-ba/*"
      capabilities = ["list"]
      description  = "access to enverus-ba secrets"
    },
    {
      path         = "enverus-ba/data/payables"
      capabilities = ["read", "list", "create", "update", "delete"]
      description  = "access to payables secrets"
    },
    {
      path         = "enverus-ba/data/payables/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to payables secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    },
    {
      path         = "enverus-ba/metadata/payables/*"
      capabilities = ["list", "read", "delete", "update"]
      description  = "metadata access to secrets"
    }
  ]
  payables-read = [
    {
      path         = "enverus-ba/*"
      capabilities = ["list"]
      description  = "access to enverus-ba secrets"
    },
    {
      path         = "enverus-ba/data/payables/*"
      capabilities = ["list", "read"]
      description  = "access to read oi secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    },
    {
      path         = "enverus-ba/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to secrets"
    }
  ]
  ea-rig-read = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/rig/*"
      capabilities = ["list", "read"]
      description  = "access to rig secrets"
    },
    {
      path         = "enverus-ea/metadata/rig/*"
      capabilities = ["list", "read"]
      description  = "metadata access to rig secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs"
    }
  ]
  ea-rig-write = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/rig/*"
      capabilities = ["list", "read", "create", "update", "delete"]
      description  = "access to rig secrets"
    },
    {
      path         = "enverus-ea/metadata/rig/*"
      capabilities = ["list", "read"]
      description  = "metadata access to rig secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs"
    }
  ]
  core-test-automation-credentials-write = [
    {
      path         = "enverus-cts/*"
      capabilities = ["list"]
      description  = "access to artifactory remote repository secrets"
    },
    {
      path         = "enverus-cts/data/automation-test"
      capabilities = ["create", "read", "list"]
      description  = "create automation test credential groups/projects"
    },
    {
      path         = "enverus-cts/data/automation-test/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "create automation test credential groups/projects"
    },
    {
      path         = "enverus-cts/metadata/automation-test/*"
      capabilities = ["read", "list", "delete"]
      description  = "Managing automation test credential metadata"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  ea-esg-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/esg*"
      capabilities = ["list", "read"]
      description  = "access to esg secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to secrets"
    }
  ]
  ea-esg-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/esg*"
      capabilities = ["create", "list", "read"]
      description  = "access to esg secrets"
    },
    {
      path         = "enverus-ea/data/esg/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to esg secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to secrets"
    }
  ]
  courthouse-rw = [
    {
      path         = "enverus-ea*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/courthouse*"
      capabilities = ["create", "list", "read"]
      description  = "access to courthouse secrets"
    },
    {
      path         = "enverus-ea/data/courthouse/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to courthouse secrets"
    },
    {
      path         = "enverus-ea/data/terraform/courthouse/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "allow read/update to terraform/courthouse"
    },
    {
      path         = "enverus-ea/metadata/courthouse/*"
      capabilities = ["list", "read", "delete", "update"]
      description  = "metadata access to courthouse secrets"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  da-mcp-devapi-read = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/da-mcp-devapi*"
      capabilities = ["list", "read"]
      description  = "access to DA mcp-devapi secrets"
    },
    {
      path         = "enverus-ea/metadata/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DA mcp-devapi secrets"
    }
  ]
  da-mcp-devapi-write = [
    {
      path         = "enverus-ea/*"
      capabilities = ["list"]
      description  = "access to enverus-ea secrets"
    },
    {
      path         = "enverus-ea/data/da-mcp-devapi"
      capabilities = ["list", "read", "create"]
      description  = "access to DA mcp-devapi secrets"
    },
    {
      path         = "enverus-ea/data/da-mcp-devapi/*"
      capabilities = ["create", "update", "delete", "list", "read"]
      description  = "write access to DA mcp-devapi secrets"
    },
    {
      path         = "enverus-ea/metadata/da-mcp-devapi/*"
      capabilities = ["list", "read"]
      description  = "metadata access to DA mcp-devapi secrets"
    }
  ]
  sec-devsecopsapp-read = [
    {
      path         = "enverus-it/*"
      capabilities = ["list"]
      description  = "access to enverus-it secrets"
    },
    {
      path         = "enverus-it/data/sec.devsecops/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-it/sec.devsecops"
    },
    {
      path         = "enverus-it/data/sec.devsecops/actions/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-it/sec.devsecops/actions"
    },
    {
      path         = "enverus-it/data/sec.devsecops/insightsdb/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-it/sec.devsecops.insightsdb"
    },
    {
      path         = "enverus-it/data/sec.devsecops/workflows/*"
      capabilities = ["list", "read"]
      description  = "access to enverus-it/sec.devsecops.workflows"
    },
    {
      path         = "enverus-it/metadata/sec.devsecops/*"
      capabilities = ["list", "read"]
      description  = "metadata access to enverus-it/sec.devsecops"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "read-only access to ACL policies."
    }
  ]
  sec-devsecopsapp-write = [
    {
      path         = "enverus-it/*"
      capabilities = ["list"]
      description  = "access to enverus-it secrets"
    },
    {
      path         = "enverus-it/data/sec.devsecops/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to enverus-it/sec.devsecops"
    },
    {
      path         = "enverus-it/data/sec.devsecops/actions/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to enverus-it/sec.devsecops/actions"
    },
    {
      path         = "enverus-it/data/sec.devsecops/insightsdb/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to enverus-it/sec.devsecops/insightsdb"
    },
    {
      path         = "enverus-it/data/sec.devsecops/workflows/*"
      capabilities = ["read", "update", "delete", "list"]
      description  = "access to enverus-it/sec.devsecops/workflows"
    },
    {
      path         = "enverus-it/metadata/sec.devsecops/*"
      capabilities = ["list", "read"]
      description  = "metadata access to enverus-it/sec.devsecops"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "read-only access to ACL policies."
    }
  ]
}

================
File: cts/vault_policies_and_roles/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_policies" {
  description = "a list of vault policies"
  type = map(list(object(
    {
      path         = string
      capabilities = list(string)
      description  = string
  })))
}

variable "atlantis_userpass" {
  description = "vault path for atlantis user/pass"
  default     = "enverus-cts/cts.terraform/atlantis/userpass"
  type        = string
}

variable "secrets_mountpoint" {
  description = "Mountpoint of Secret path - used for atlantis"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Env"
  type        = string
}

================
File: cts/vault_policies_and_roles/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/vault_secrets/.terraform-version
================
latest:^1.8

================
File: cts/vault_secrets/main.tf
================
resource "vault_generic_secret" "fontawesome_secrets" {
  path         = "enverus-cts/artifactory-credentials/remote-repositories/fontawesome"
  disable_read = true
  data_json    = <<EOT
{
  "token": ""
}
EOT
  lifecycle {
    ignore_changes = [data_json]
  }
}

================
File: cts/vault_secrets/prod.backend.tfvars
================
key = "316576613383/prod/vault_secrets/terraform.tfstate"

================
File: cts/vault_secrets/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

================
File: cts/vault_secrets/versions.tf
================
terraform {
  required_version = ">= 1.8.1, < 1.8.2"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/vault_token/.terraform-version
================
latest:^1.8

================
File: cts/vault_token/main.tf
================
## this token is to be stored in vaults that require access to cts-prod vault
# see: https://enverus.atlassian.net/wiki/spaces/SRE/pages/35994337355/Renew+Vault+token+in+cts-prod-vault+to+allow+PR+workflow+to+write+to+both+vaults
# SRE-15058

resource "vault_token" "atlantis-rw-token" {
  display_name = "cts-prod-atlantis-rw-token"
  policies     = ["atlantis-rw"]
  no_parent    = true
  ttl          = "2160h"
}

resource "vault_generic_secret" "atlantis-rw-token" {
  path = var.secret_mountpoint
  data_json = jsonencode(
    {
      "TOKEN" = vault_token.atlantis-rw-token.client_token
    }
  )

  delete_all_versions = true
}

================
File: cts/vault_token/prod.backend.tfvars
================
key = "316576613383/prod/vault_token/terraform.tfstate"

================
File: cts/vault_token/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "secret_mountpoint" {
  description = "Mountpoint of Secret path"
  type        = string
  default     = "enverus-cts/atlantis/temp-token"
}

================
File: cts/vault_token/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "rtb-003a90c86289f7d62_10.135.0.0/16"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-003a90c86289f7d62"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "rtb-f36e5d96_10.25.96.0/21"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-f36e5d96"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "rtb-0bb150e5184602179_10.135.0.0/16"
resource "aws_route" "r5_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0bb150e5184602179"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "pcx-02031e7eefce8d289"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = jsonencode(449228620267)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-09308d3c8f8df0c29"
  tags = {
    Name = "OGue1_prod_To_SREue1_prod"
    Side = "Accepter"
  }
  tags_all = {
    Name = "OGue1_prod_To_SREue1_prod"
    Side = "Accepter"
  }
  vpc_id = "vpc-bcc69dd9"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-02031e7eefce8d289"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.peer
  auto_accept = null
  tags = {
    Name = "OGue1_prod_To_SREue1_prod"
    Side = "Accepter"
  }
  tags_all = {
    Name = "OGue1_prod_To_SREue1_prod"
    Side = "Accepter"
  }
  vpc_peering_connection_id = "pcx-02031e7eefce8d289"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-0ae49399e3caca931_10.135.0.0/16"
resource "aws_route" "r2_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0ae49399e3caca931"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "rtb-0c648d23cda80ebc1_10.135.0.0/16"
resource "aws_route" "r6_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0c648d23cda80ebc1"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "rtb-0f0573617a5d88e9e_10.135.0.0/16"
resource "aws_route" "r3_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f0573617a5d88e9e"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

# __generated__ by Terraform from "pcx-02031e7eefce8d289"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = jsonencode(155171951664)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-bcc69dd9"
  tags = {
    Name = "SREue1_prodOGue1_prod"
    Side = "Requester"
  }
  tags_all = {
    Name = "SREue1_prodOGue1_prod"
    Side = "Requester"
  }
  vpc_id = "vpc-09308d3c8f8df0c29"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-0f07e62bb228879aa_10.135.0.0/16"
resource "aws_route" "r4_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f07e62bb228879aa"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-02031e7eefce8d289"
}

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/155171951664/pcx-02031e7eefce8d289/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/dev.tfvars
================
## pcx-02031e7eefce8d289	155171951664	EA-Prod-Legacy	us-east-1	vpc-bcc69dd9	449228620267	CTS-Networking	us-east-1	vpc-09308d3c8f8df0c29

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::449228620267:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::155171951664:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-02031e7eefce8d289"
aws_vpc_peering_connection_id_accepter  = "pcx-02031e7eefce8d289"

aws_route_r1_requester = "rtb-003a90c86289f7d62_10.135.0.0/16"
aws_route_r2_requester = "rtb-0ae49399e3caca931_10.135.0.0/16"
aws_route_r3_requester = "rtb-0f0573617a5d88e9e_10.135.0.0/16"
aws_route_r4_requester = "rtb-0f07e62bb228879aa_10.135.0.0/16"
aws_route_r5_requester = "rtb-0bb150e5184602179_10.135.0.0/16"
aws_route_r6_requester = "rtb-0c648d23cda80ebc1_10.135.0.0/16"

aws_route_r1_accepter = "rtb-f36e5d96_10.25.96.0/21"

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

variable "aws_route_r2_requester" {
  type = string
}

import {
  to = aws_route.r2_requester
  id = var.aws_route_r2_requester
}

variable "aws_route_r3_requester" {
  type = string
}

import {
  to = aws_route.r3_requester
  id = var.aws_route_r3_requester
}

variable "aws_route_r4_requester" {
  type = string
}

import {
  to = aws_route.r4_requester
  id = var.aws_route_r4_requester
}

variable "aws_route_r5_requester" {
  type = string
}

import {
  to = aws_route.r5_requester
  id = var.aws_route_r5_requester
}

variable "aws_route_r6_requester" {
  type = string
}

import {
  to = aws_route.r6_requester
  id = var.aws_route_r6_requester
}

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-02031e7eefce8d289/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "pcx-05b06763d8a6a1eaa"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags = {
    Name = "to-dev-vpc-us-east-1"
  }
  tags_all = {
    Name = "to-dev-vpc-us-east-1"
  }
  vpc_id = "vpc-0727408d09da1d8c0"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-0206a15b6352132de_10.25.8.0/21"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0206a15b6352132de"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-002ce06e17ce997e1_10.25.8.0/21"
resource "aws_route" "r3_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-002ce06e17ce997e1"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-027206d3574f5a0e9_10.25.8.0/21"
resource "aws_route" "r2_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-027206d3574f5a0e9"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "pcx-05b06763d8a6a1eaa"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags = {
    Name = "eu-central-1-to-us-east-1"
  }
  tags_all = {
    Name = "eu-central-1-to-us-east-1"
  }
  vpc_id = "vpc-0727408d09da1d8c0"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-05b06763d8a6a1eaa"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.peer
  auto_accept = null
  tags = {
    Name = "eu-central-1-to-us-east-1"
  }
  tags_all = {
    Name = "eu-central-1-to-us-east-1"
  }
  vpc_peering_connection_id = "pcx-05b06763d8a6a1eaa"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-fc12f184_10.175.8.0/21"
resource "aws_route" "r6_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-fc12f184"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-bed28bc3_10.175.8.0/21"
resource "aws_route" "r3_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-bed28bc3"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-b0df86cd_10.175.8.0/21"
resource "aws_route" "r2_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-b0df86cd"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-26d48d5b_10.175.8.0/21"
resource "aws_route" "r4_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-26d48d5b"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-5aca9327_10.175.8.0/21"
resource "aws_route" "r5_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5aca9327"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

# __generated__ by Terraform from "rtb-5c0dee24_10.175.8.0/21"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.175.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5c0dee24"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-05b06763d8a6a1eaa"
}

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

variable "aws_route_r2_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r2_accepter
  id = var.aws_route_r2_accepter
}

variable "aws_route_r3_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r3_accepter
  id = var.aws_route_r3_accepter
}

variable "aws_route_r4_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r4_accepter
  id = var.aws_route_r4_accepter
}

variable "aws_route_r5_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r5_accepter
  id = var.aws_route_r5_accepter
}

variable "aws_route_r6_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r6_accepter
  id = var.aws_route_r6_accepter
}

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/070551638384/pcx-05b06763d8a6a1eaa/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/dev.tfvars
================
## pcx-05b06763d8a6a1eaa	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5	070551638384	EA-Dev-Legacy	eu-central-1	vpc-0727408d09da1d8c0

region          = "eu-central-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::070551638384:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::070551638384:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-05b06763d8a6a1eaa"
aws_vpc_peering_connection_id_accepter  = "pcx-05b06763d8a6a1eaa"

aws_route_r1_requester = "rtb-0206a15b6352132de_10.25.8.0/21"
aws_route_r2_requester = "rtb-027206d3574f5a0e9_10.25.8.0/21"
aws_route_r3_requester = "rtb-002ce06e17ce997e1_10.25.8.0/21"

aws_route_r1_accepter = "rtb-5c0dee24_10.175.8.0/21"
aws_route_r2_accepter = "rtb-b0df86cd_10.175.8.0/21"
aws_route_r3_accepter = "rtb-bed28bc3_10.175.8.0/21"
aws_route_r4_accepter = "rtb-26d48d5b_10.175.8.0/21"
aws_route_r5_accepter = "rtb-5aca9327_10.175.8.0/21"
aws_route_r6_accepter = "rtb-fc12f184_10.175.8.0/21"

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

variable "aws_route_r2_requester" {
  type = string
}

import {
  to = aws_route.r2_requester
  id = var.aws_route_r2_requester
}

variable "aws_route_r3_requester" {
  type = string
}

import {
  to = aws_route.r3_requester
  id = var.aws_route_r3_requester
}

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-05b06763d8a6a1eaa/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "rtb-0f902ccd02c7388bb_10.135.0.0/16"
resource "aws_route" "r2_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f902ccd02c7388bb"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-07247a9287ae0491f"
}

# __generated__ by Terraform from "rtb-0e2b14442622f81b7_10.135.0.0/16"
resource "aws_route" "r3_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0e2b14442622f81b7"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-07247a9287ae0491f"
}

# __generated__ by Terraform from "rtb-0752f1eca2332b1a0_10.135.0.0/16"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0752f1eca2332b1a0"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-07247a9287ae0491f"
}

# __generated__ by Terraform from "pcx-07247a9287ae0491f"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = jsonencode(155171951664)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-bcc69dd9"
  tags          = {}
  tags_all      = {}
  vpc_id        = "vpc-04b882501d6475316"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-07247a9287ae0491f"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider                  = aws.peer
  auto_accept               = null
  tags                      = {}
  tags_all                  = {}
  vpc_peering_connection_id = "pcx-07247a9287ae0491f"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-07247a9287ae0491f"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = jsonencode(534978349550)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-04b882501d6475316"
  tags = {
    Name = "PLS"
  }
  tags_all = {
    Name = "PLS"
  }
  vpc_id = "vpc-bcc69dd9"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

variable "aws_route_r2_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r2_accepter
  id = var.aws_route_r2_accepter
}

variable "aws_route_r3_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r3_accepter
  id = var.aws_route_r3_accepter
}

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/534978349550/pcx-07247a9287ae0491f/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/dev.tfvars
================
## pcx-07247a9287ae0491f	534978349550	EA-PLS	us-east-1	vpc-04b882501d6475316	155171951664	EA-Prod-Legacy	us-east-1	vpc-bcc69dd9

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::155171951664:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::534978349550:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-07247a9287ae0491f"
aws_vpc_peering_connection_id_accepter  = "pcx-07247a9287ae0491f"

aws_route_r1_accepter = "rtb-0752f1eca2332b1a0_10.135.0.0/16"
aws_route_r2_accepter = "rtb-0f902ccd02c7388bb_10.135.0.0/16"
aws_route_r3_accepter = "rtb-0e2b14442622f81b7_10.135.0.0/16"

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

# variable "aws_route_r1_requester" {
#   type = string
# }

# import {
#   to = aws_route.r1_requester
#   id = var.aws_route_r1_requester
# }

# variable "aws_route_r2_requester" {
#   type = string
# }

# import {
#   to = aws_route.r2_requester
#   id = var.aws_route_r2_requester
# }

# variable "aws_route_r3_requester" {
#   type = string
# }

# import {
#   to = aws_route.r3_requester
#   id = var.aws_route_r3_requester
# }

# variable "aws_route_r4_requester" {
#   type = string
# }

# import {
#   to = aws_route.r4_requester
#   id = var.aws_route_r4_requester
# }

# variable "aws_route_r5_requester" {
#   type = string
# }

# import {
#   to = aws_route.r5_requester
#   id = var.aws_route_r5_requester
# }

# variable "aws_route_r6_requester" {
#   type = string
# }

# import {
#   to = aws_route.r6_requester
#   id = var.aws_route_r6_requester
# }

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-07247a9287ae0491f/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "pcx-08ad6f18e7be5b5c5"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags = {
    Name = "DG-DataHub VPC <> DI Upstream Dev"
  }
  tags_all = {
    Name = "DG-DataHub VPC <> DI Upstream Dev"
  }
  vpc_id = "vpc-15a77773"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-5f21c626_10.25.8.0/21"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5f21c626"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-08ad6f18e7be5b5c5"
}

# __generated__ by Terraform from "pcx-08ad6f18e7be5b5c5"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = jsonencode(718046695701)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-15a77773"
  tags = {
    Name = "DGDevtoUpstreamDev"
  }
  tags_all = {
    Name = "DGDevtoUpstreamDev"
  }
  vpc_id = "vpc-cce405b5"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-08ad6f18e7be5b5c5"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.peer
  auto_accept = null
  tags = {
    Name = "DGDevtoUpstreamDev"
  }
  tags_all = {
    Name = "DGDevtoUpstreamDev"
  }
  vpc_peering_connection_id = "pcx-08ad6f18e7be5b5c5"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

# variable "aws_route_r1_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r1_accepter
#   id = var.aws_route_r1_accepter
# }

# variable "aws_route_r2_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r2_accepter
#   id = var.aws_route_r2_accepter
# }

# variable "aws_route_r3_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r3_accepter
#   id = var.aws_route_r3_accepter
# }

# variable "aws_route_r4_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r4_accepter
#   id = var.aws_route_r4_accepter
# }

# variable "aws_route_r5_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r5_accepter
#   id = var.aws_route_r5_accepter
# }

# variable "aws_route_r6_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r6_accepter
#   id = var.aws_route_r6_accepter
# }

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/070551638384/pcx-08ad6f18e7be5b5c5/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/dev.tfvars
================
## pcx-08ad6f18e7be5b5c5	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5	718046695701	TR-DG	eu-west-1	vpc-15a77773

region          = "eu-west-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::718046695701:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::070551638384:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-08ad6f18e7be5b5c5"
aws_vpc_peering_connection_id_accepter  = "pcx-08ad6f18e7be5b5c5"

aws_route_r1_requester = "rtb-5f21c626_10.25.8.0/21"
# aws_route_r2_requester = "rtb-027206d3574f5a0e9_10.25.8.0/21"
# aws_route_r3_requester = "rtb-002ce06e17ce997e1_10.25.8.0/21"

# aws_route_r1_accepter = "rtb-5c0dee24_10.175.8.0/21"
# aws_route_r2_accepter = "rtb-b0df86cd_10.175.8.0/21"
# aws_route_r3_accepter = "rtb-bed28bc3_10.175.8.0/21"
# aws_route_r4_accepter = "rtb-26d48d5b_10.175.8.0/21"
# aws_route_r5_accepter = "rtb-5aca9327_10.175.8.0/21"
# aws_route_r6_accepter = "rtb-fc12f184_10.175.8.0/21"

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

# variable "aws_route_r2_requester" {
#   type = string
# }

# import {
#   to = aws_route.r2_requester
#   id = var.aws_route_r2_requester
# }

# variable "aws_route_r3_requester" {
#   type = string
# }

# import {
#   to = aws_route.r3_requester
#   id = var.aws_route_r3_requester
# }

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-08ad6f18e7be5b5c5/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "rtb-5aca9327_10.25.96.0/21"
resource "aws_route" "r5_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5aca9327"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "rtb-fc12f184_10.25.96.0/21"
resource "aws_route" "r6_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-fc12f184"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "rtb-b0df86cd_10.25.96.0/21"
resource "aws_route" "r2_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-b0df86cd"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "rtb-5c0dee24_10.25.96.0/21"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5c0dee24"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "rtb-0bb150e5184602179_10.25.8.0/21"
resource "aws_route" "r5_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0bb150e5184602179"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

# __generated__ by Terraform from "rtb-0f0573617a5d88e9e_10.25.8.0/21"
resource "aws_route" "r3_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f0573617a5d88e9e"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

# __generated__ by Terraform from "rtb-26d48d5b_10.25.96.0/21"
resource "aws_route" "r4_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-26d48d5b"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "pcx-0c5ec45fa78af0411"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = jsonencode(449228620267)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-09308d3c8f8df0c29"
  tags = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  tags_all = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  vpc_id = "vpc-cce405b5"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-bed28bc3_10.25.96.0/21"
resource "aws_route" "r3_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.96.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-bed28bc3"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-00568843bd7032a59"
}

# __generated__ by Terraform from "pcx-0c5ec45fa78af0411"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.peer
  auto_accept = null
  tags = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  tags_all = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  vpc_peering_connection_id = "pcx-0c5ec45fa78af0411"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-003a90c86289f7d62_10.25.8.0/21"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-003a90c86289f7d62"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

# __generated__ by Terraform from "rtb-0ae49399e3caca931_10.25.8.0/21"
resource "aws_route" "r2_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0ae49399e3caca931"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

# __generated__ by Terraform from "rtb-0f0573617a5d88e9e_10.25.8.0/21"
resource "aws_route" "r4_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f0573617a5d88e9e"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

# __generated__ by Terraform from "pcx-0c5ec45fa78af0411"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  tags_all = {
    Name = "SREue1_dev_to_OGue1_dev"
  }
  vpc_id = "vpc-09308d3c8f8df0c29"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-0f07e62bb228879aa_10.25.8.0/21"
resource "aws_route" "r6_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0f07e62bb228879aa"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0c5ec45fa78af0411"
}

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

variable "aws_route_r2_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r2_accepter
  id = var.aws_route_r2_accepter
}

variable "aws_route_r3_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r3_accepter
  id = var.aws_route_r3_accepter
}

variable "aws_route_r4_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r4_accepter
  id = var.aws_route_r4_accepter
}

variable "aws_route_r5_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r5_accepter
  id = var.aws_route_r5_accepter
}

variable "aws_route_r6_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r6_accepter
  id = var.aws_route_r6_accepter
}

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/070551638384/pcx-0c5ec45fa78af0411/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/dev.tfvars
================
## pcx-0c5ec45fa78af0411	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5	449228620267	CTS-Networking	us-east-1	vpc-09308d3c8f8df0c29

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::449228620267:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::070551638384:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-0c5ec45fa78af0411"
aws_vpc_peering_connection_id_accepter  = "pcx-0c5ec45fa78af0411"

aws_route_r1_requester = "rtb-003a90c86289f7d62_10.25.8.0/21"
aws_route_r2_requester = "rtb-0ae49399e3caca931_10.25.8.0/21"
aws_route_r3_requester = "rtb-0f0573617a5d88e9e_10.25.8.0/21"
aws_route_r4_requester = "rtb-0f0573617a5d88e9e_10.25.8.0/21"
aws_route_r5_requester = "rtb-0bb150e5184602179_10.25.8.0/21"
aws_route_r6_requester = "rtb-0f07e62bb228879aa_10.25.8.0/21"

aws_route_r1_accepter = "rtb-5c0dee24_10.25.96.0/21"
aws_route_r2_accepter = "rtb-b0df86cd_10.25.96.0/21"
aws_route_r3_accepter = "rtb-bed28bc3_10.25.96.0/21"
aws_route_r4_accepter = "rtb-26d48d5b_10.25.96.0/21"
aws_route_r5_accepter = "rtb-5aca9327_10.25.96.0/21"
aws_route_r6_accepter = "rtb-fc12f184_10.25.96.0/21"

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

variable "aws_route_r2_requester" {
  type = string
}

import {
  to = aws_route.r2_requester
  id = var.aws_route_r2_requester
}

variable "aws_route_r3_requester" {
  type = string
}

import {
  to = aws_route.r3_requester
  id = var.aws_route_r3_requester
}

variable "aws_route_r4_requester" {
  type = string
}

import {
  to = aws_route.r4_requester
  id = var.aws_route_r4_requester
}

variable "aws_route_r5_requester" {
  type = string
}

import {
  to = aws_route.r5_requester
  id = var.aws_route_r5_requester
}

variable "aws_route_r6_requester" {
  type = string
}

import {
  to = aws_route.r6_requester
  id = var.aws_route_r6_requester
}

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-0c5ec45fa78af0411/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/0generated.tf
================
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.ea
  auto_accept   = null
  peer_owner_id = jsonencode(534978349550)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-04b882501d6475316"
  tags = {
    Name = "PLSProdtoDIDev"
    Side = "Accepter"
  }
  tags_all = {
    Name = "PLSProdtoDIDev"
    Side = "Accepter"
  }
  vpc_id = "vpc-cce405b5"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.pls
  auto_accept = true
  tags = {
    Name = "PLSProdtoDIDev"
    Side = "Accepter"
  }
  tags_all = {
    Name = "PLSProdtoDIDev"
    Side = "Accepter"
  }
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-0f902ccd02c7388bb_10.25.8.0/21"
resource "aws_route" "r1_requester" {
  provider                  = aws.pls
  destination_cidr_block    = "10.25.8.0/21"
  route_table_id            = "rtb-0f902ccd02c7388bb"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

# __generated__ by Terraform from "rtb-0752f1eca2332b1a0_10.25.8.0/21"
resource "aws_route" "r2_requester" {
  provider                  = aws.pls
  destination_cidr_block    = "10.25.8.0/21"
  route_table_id            = "rtb-0752f1eca2332b1a0"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

# __generated__ by Terraform from "rtb-0e2b14442622f81b7_10.25.8.0/21"
resource "aws_route" "r3_requester" {
  provider                  = aws.pls
  destination_cidr_block    = "10.25.8.0/21"
  route_table_id            = "rtb-0e2b14442622f81b7"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r1_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-5c0dee24"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r2_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-fc12f184"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r3_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-b0df86cd"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r4_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-5aca9327"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r5_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-26d48d5b"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "r6_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-bed28bc3"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

resource "aws_route" "public_accepter" {
  provider                  = aws.ea
  destination_cidr_block    = "172.16.100.0/24"
  route_table_id            = "rtb-9e12f1e6"
  vpc_peering_connection_id = aws_vpc_peering_connection.accepter.id #"pcx-0d89179c6f96fcc0d"
}

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/accepter.tf
================
# import {
#   provider = aws.pls

#   to = aws_vpc_peering_connection_accepter.accepter
#   id = "pcx-0a970a9dc0b43183b"
# }

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_accepter.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

# variable "aws_route_r1_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r1_accepter
#   id = var.aws_route_r1_accepter
# }

# variable "aws_route_r2_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r2_accepter
#   id = var.aws_route_r2_accepter
# }

# variable "aws_route_r3_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r3_accepter
#   id = var.aws_route_r3_accepter
# }

# variable "aws_route_r4_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r4_accepter
#   id = var.aws_route_r4_accepter
# }

# variable "aws_route_r5_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r5_accepter
#   id = var.aws_route_r5_accepter
# }

# variable "aws_route_r6_accepter" {
#   type = string
# }

# import {
#   provider = aws.peer

#   to = aws_route.r6_accepter
#   id = var.aws_route_r6_accepter
# }

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/070551638384/pcx-0d89179c6f96fcc0d/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/dev.tfvars
================
## pcx-0d89179c6f96fcc0d	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5	534978349550	EA-PLS	us-east-1	vpc-04b882501d6475316

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::534978349550:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::070551638384:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-0d89179c6f96fcc0d"
aws_vpc_peering_connection_id_accepter  = "pcx-0d89179c6f96fcc0d"

aws_route_r1_requester = "rtb-0f902ccd02c7388bb_10.25.8.0/21"
aws_route_r2_requester = "rtb-0752f1eca2332b1a0_10.25.8.0/21"
aws_route_r3_requester = "rtb-0e2b14442622f81b7_10.25.8.0/21"

# aws_route_r1_accepter = "rtb-5c0dee24_10.175.8.0/21"
# aws_route_r2_accepter = "rtb-b0df86cd_10.175.8.0/21"
# aws_route_r3_accepter = "rtb-bed28bc3_10.175.8.0/21"
# aws_route_r4_accepter = "rtb-26d48d5b_10.175.8.0/21"
# aws_route_r5_accepter = "rtb-5aca9327_10.175.8.0/21"
# aws_route_r6_accepter = "rtb-fc12f184_10.175.8.0/21"

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/requester.tf
================
# import {


#   to = aws_vpc_peering_connection.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

# variable "aws_route_r1_requester" {
#   type = string
# }

# import {
#   to = aws_route.r1_requester
#   id = var.aws_route_r1_requester
# }

# variable "aws_route_r2_requester" {
#   type = string
# }

# import {
#   to = aws_route.r2_requester
#   id = var.aws_route_r2_requester
# }

# variable "aws_route_r3_requester" {
#   type = string
# }

# import {
#   to = aws_route.r3_requester
#   id = var.aws_route_r3_requester
# }

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-0d89179c6f96fcc0d/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  alias  = "pls"
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "ea"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/0generated.tf
================
#destroy

# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "rtb-0b525561693be2dcd_10.25.8.0/21"
resource "aws_route" "r4_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0b525561693be2dcd"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-fc12f184_10.25.84.0/22"
resource "aws_route" "r6_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-fc12f184"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-5c0dee24_10.25.84.0/22"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5c0dee24"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "pcx-0fb92a6cb59559c65"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags = {
    Name = "CDSDevtoDIDev"
  }
  tags_all = {
    Name = "CDSDevtoDIDev"
  }
  vpc_id = "vpc-0f79ba6136ac65e1e"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-0fb92a6cb59559c65"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = jsonencode(281213658332)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-0f79ba6136ac65e1e"
  tags = {
    Name = "CDSDevtoDIDev"
  }
  tags_all = {
    Name = "CDSDevtoDIDev"
  }
  vpc_id = "vpc-cce405b5"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-0fb92a6cb59559c65"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider    = aws.peer
  auto_accept = null
  tags = {
    Name = "CDSDevtoDIDev"
  }
  tags_all = {
    Name = "CDSDevtoDIDev"
  }
  vpc_peering_connection_id = "pcx-0fb92a6cb59559c65"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-058fe181d0fa1929c_10.25.8.0/21"
resource "aws_route" "r6_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-058fe181d0fa1929c"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-06fed5a7aaa5cafea_10.25.8.0/21"
resource "aws_route" "r3_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-06fed5a7aaa5cafea"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-05802f8144da44b04_10.25.8.0/21"
resource "aws_route" "r2_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-05802f8144da44b04"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-26d48d5b_10.25.84.0/22"
resource "aws_route" "r4_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-26d48d5b"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-0547ce74d2bae7d77_10.25.8.0/21"
resource "aws_route" "r5_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0547ce74d2bae7d77"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-bed28bc3_10.25.84.0/22"
resource "aws_route" "r3_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-bed28bc3"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-5aca9327_10.25.84.0/22"
resource "aws_route" "r5_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5aca9327"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-b0df86cd_10.25.84.0/22"
resource "aws_route" "r2_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.84.0/22"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-b0df86cd"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

# __generated__ by Terraform from "rtb-0c52c063e725eecf6_10.25.8.0/21"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-0c52c063e725eecf6"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-0fb92a6cb59559c65"
}

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

variable "aws_route_r2_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r2_accepter
  id = var.aws_route_r2_accepter
}

variable "aws_route_r3_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r3_accepter
  id = var.aws_route_r3_accepter
}

variable "aws_route_r4_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r4_accepter
  id = var.aws_route_r4_accepter
}

variable "aws_route_r5_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r5_accepter
  id = var.aws_route_r5_accepter
}

variable "aws_route_r6_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r6_accepter
  id = var.aws_route_r6_accepter
}

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/070551638384/pcx-0fb92a6cb59559c65/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/dev.tfvars
================
## pcx-0fb92a6cb59559c65	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5	281213658332	TR-Legacy-Dev	us-east-1	vpc-0f79ba6136ac65e1e

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::281213658332:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::070551638384:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-0fb92a6cb59559c65"
aws_vpc_peering_connection_id_accepter  = "pcx-0fb92a6cb59559c65"

aws_route_r1_requester = "rtb-0c52c063e725eecf6_10.25.8.0/21"
aws_route_r2_requester = "rtb-05802f8144da44b04_10.25.8.0/21"
aws_route_r3_requester = "rtb-06fed5a7aaa5cafea_10.25.8.0/21"
aws_route_r4_requester = "rtb-0b525561693be2dcd_10.25.8.0/21"
aws_route_r5_requester = "rtb-0547ce74d2bae7d77_10.25.8.0/21"
aws_route_r6_requester = "rtb-058fe181d0fa1929c_10.25.8.0/21"

aws_route_r1_accepter = "rtb-5c0dee24_10.25.84.0/22"
aws_route_r2_accepter = "rtb-b0df86cd_10.25.84.0/22"
aws_route_r3_accepter = "rtb-bed28bc3_10.25.84.0/22"
aws_route_r4_accepter = "rtb-26d48d5b_10.25.84.0/22"
aws_route_r5_accepter = "rtb-5aca9327_10.25.84.0/22"
aws_route_r6_accepter = "rtb-fc12f184_10.25.84.0/22"

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

variable "aws_route_r2_requester" {
  type = string
}

import {
  to = aws_route.r2_requester
  id = var.aws_route_r2_requester
}

variable "aws_route_r3_requester" {
  type = string
}

import {
  to = aws_route.r3_requester
  id = var.aws_route_r3_requester
}

variable "aws_route_r4_requester" {
  type = string
}

import {
  to = aws_route.r4_requester
  id = var.aws_route_r4_requester
}

variable "aws_route_r5_requester" {
  type = string
}

import {
  to = aws_route.r5_requester
  id = var.aws_route_r5_requester
}

variable "aws_route_r6_requester" {
  type = string
}

import {
  to = aws_route.r6_requester
  id = var.aws_route_r6_requester
}

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-0fb92a6cb59559c65/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/destroy/pcx-d0e587b9/.terraform-version
================
latest:^1.9

================
File: cts/vpc/destroy/pcx-d0e587b9/0generated.tf
================
# __generated__ by Terraform
# Please review these resources and move them into your main configuration files.

# __generated__ by Terraform from "pcx-d0e587b9"
resource "aws_vpc_peering_connection" "requester" {
  auto_accept   = null
  peer_owner_id = jsonencode(155171951664)
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-bcc69dd9"
  tags = {
    Application = "arn:aws:cloudformation:us-east-1:070551638384:stack/vpc-dev-DevVpc-JJWY66DGQMDK/76968aa0-304a-11e7-b853-50d5cad95262"
    Component   = "vpc"
    Name        = "dev-VPCPeering"
    Stack       = "dev"
  }
  tags_all = {
    Application = "arn:aws:cloudformation:us-east-1:070551638384:stack/vpc-dev-DevVpc-JJWY66DGQMDK/76968aa0-304a-11e7-b853-50d5cad95262"
    Component   = "vpc"
    Name        = "dev-VPCPeering"
    Stack       = "dev"
  }
  vpc_id = "vpc-cce405b5"
  requester {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-bed28bc3_10.135.0.0/16"
resource "aws_route" "r3_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-bed28bc3"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "rtb-26d48d5b_10.135.0.0/16"
resource "aws_route" "r4_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-26d48d5b"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "rtb-5c0dee24_10.135.0.0/16"
resource "aws_route" "r1_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5c0dee24"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "rtb-5aca9327_10.135.0.0/16"
resource "aws_route" "r5_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-5aca9327"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "rtb-b0df86cd_10.135.0.0/16"
resource "aws_route" "r2_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-b0df86cd"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "rtb-fc12f184_10.135.0.0/16"
resource "aws_route" "r6_requester" {
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.135.0.0/16"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-fc12f184"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

# __generated__ by Terraform from "pcx-d0e587b9"
resource "aws_vpc_peering_connection_accepter" "accepter" {
  provider                  = aws.peer
  auto_accept               = null
  tags                      = {}
  tags_all                  = {}
  vpc_peering_connection_id = "pcx-d0e587b9"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "pcx-d0e587b9"
resource "aws_vpc_peering_connection" "accepter" {
  provider      = aws.peer
  auto_accept   = null
  peer_owner_id = "070551638384"
  peer_region   = "us-east-1"
  peer_vpc_id   = "vpc-cce405b5"
  tags          = {}
  tags_all      = {}
  vpc_id        = "vpc-bcc69dd9"
  accepter {
    allow_remote_vpc_dns_resolution = false
  }
}

# __generated__ by Terraform from "rtb-f36e5d96_10.25.8.0/21"
resource "aws_route" "r1_accepter" {
  provider                    = aws.peer
  carrier_gateway_id          = null
  core_network_arn            = null
  destination_cidr_block      = "10.25.8.0/21"
  destination_ipv6_cidr_block = null
  destination_prefix_list_id  = null
  egress_only_gateway_id      = null
  gateway_id                  = null
  local_gateway_id            = null
  nat_gateway_id              = null
  network_interface_id        = null
  route_table_id              = "rtb-f36e5d96"
  transit_gateway_id          = null
  vpc_endpoint_id             = null
  vpc_peering_connection_id   = "pcx-d0e587b9"
}

================
File: cts/vpc/destroy/pcx-d0e587b9/accepter.tf
================
import {
  provider = aws.peer

  to = aws_vpc_peering_connection.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

import {
  provider = aws.peer

  to = aws_vpc_peering_connection_accepter.accepter
  id = var.aws_vpc_peering_connection_id_accepter
}

# import {
#   provider = aws.peer

#   to = aws_vpc_peering_connection_options.accepter
#   id = var.aws_vpc_peering_connection_id_accepter
# }

variable "aws_route_r1_accepter" {
  type = string
}

import {
  provider = aws.peer

  to = aws_route.r1_accepter
  id = var.aws_route_r1_accepter
}

================
File: cts/vpc/destroy/pcx-d0e587b9/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/peering/155171951664/pcx-d0e587b9/terraform.tfstate"

================
File: cts/vpc/destroy/pcx-d0e587b9/dev.tfvars
================
## pcx-d0e587b9	155171951664	EA-Prod-Legacy	us-east-1	vpc-bcc69dd9	070551638384	EA-Dev-Legacy	us-east-1	vpc-cce405b5

region          = "us-east-1"
region_accepter = "us-east-1"

assume_role_arn          = "arn:aws:iam::070551638384:role/terraform"
assume_role_arn_accepter = "arn:aws:iam::155171951664:role/terraform"

aws_vpc_peering_connection_id_requester = "pcx-d0e587b9"
aws_vpc_peering_connection_id_accepter  = "pcx-d0e587b9"

aws_route_r1_requester = "rtb-5c0dee24_10.135.0.0/16"
aws_route_r2_requester = "rtb-b0df86cd_10.135.0.0/16"
aws_route_r3_requester = "rtb-bed28bc3_10.135.0.0/16"
aws_route_r4_requester = "rtb-26d48d5b_10.135.0.0/16"
aws_route_r5_requester = "rtb-5aca9327_10.135.0.0/16"
aws_route_r6_requester = "rtb-fc12f184_10.135.0.0/16"

aws_route_r1_accepter = "rtb-f36e5d96_10.25.8.0/21"

================
File: cts/vpc/destroy/pcx-d0e587b9/requester.tf
================
import {


  to = aws_vpc_peering_connection.requester
  id = var.aws_vpc_peering_connection_id_requester
}







# import {


#   to = aws_vpc_peering_connection_options.requester
#   id = var.aws_vpc_peering_connection_id_requester
# }

variable "aws_route_r1_requester" {
  type = string
}

import {
  to = aws_route.r1_requester
  id = var.aws_route_r1_requester
}

variable "aws_route_r2_requester" {
  type = string
}

import {
  to = aws_route.r2_requester
  id = var.aws_route_r2_requester
}

variable "aws_route_r3_requester" {
  type = string
}

import {
  to = aws_route.r3_requester
  id = var.aws_route_r3_requester
}

variable "aws_route_r4_requester" {
  type = string
}

import {
  to = aws_route.r4_requester
  id = var.aws_route_r4_requester
}

variable "aws_route_r5_requester" {
  type = string
}

import {
  to = aws_route.r5_requester
  id = var.aws_route_r5_requester
}

variable "aws_route_r6_requester" {
  type = string
}

import {
  to = aws_route.r6_requester
  id = var.aws_route_r6_requester
}

================
File: cts/vpc/destroy/pcx-d0e587b9/variables.tf
================
variable "assume_role_arn" {
  type = string
}

variable "assume_role_arn_accepter" {
  type = string
}

variable "region" {
  type = string
}

variable "region_accepter" {
  type = string
}

variable "aws_vpc_peering_connection_id_requester" {
  type = string
}

variable "aws_vpc_peering_connection_id_accepter" {
  type = string
}

================
File: cts/vpc/destroy/pcx-d0e587b9/versions.tf
================
terraform {
  required_version = ">= 1.9"
  backend "s3" {}
  # backend "local" {
  #   path = "terraform.tfstate"
  # }
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

provider "aws" {
  alias = "peer"

  region = var.region_accepter
  assume_role {
    role_arn = var.assume_role_arn_accepter
  }
}

================
File: cts/vpc/eu-north-1/.terraform-version
================
latest:^1.5

================
File: cts/vpc/eu-north-1/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/eu-north-1/terraform.tfstate"

================
File: cts/vpc/eu-north-1/dev.tfvars
================
region                               = "eu-north-1"
tag_name                             = "cts-vpc-dev"
vpc_cidr_block                       = "10.24.160.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/eu-north-1/main.tf
================
# Create a vpc using the vpc module

module "cts-vpc" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_environment                      = var.env
  tag_name                             = var.tag_name
  vpc_cidr_block                       = var.vpc_cidr_block
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}
output "vpc" { value = module.cts-vpc }

================
File: cts/vpc/eu-north-1/prod.backend.tfvars
================
key = "316576613383/vpc/eu-north-1/terraform.tfstate"

================
File: cts/vpc/eu-north-1/prod.tfvars
================
region                               = "eu-north-1"
tag_name                             = "cts-vpc-prod"
vpc_cidr_block                       = "10.24.40.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/eu-north-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the CloudWAN VPC attachment.  Disabled by default"
  type        = bool
  default     = false
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: cts/vpc/eu-north-1/versions.tf
================
terraform {
  required_version = ">= 1.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/vpc/eu-west-1/.terraform-version
================
latest:^1.5

================
File: cts/vpc/eu-west-1/dev.backend.tfvars
================
# 360093697111 is aws cts-dev account id
key = "360093697111/vpc/eu-west-1/terraform.tfstate"

================
File: cts/vpc/eu-west-1/dev.tfvars
================
region                               = "eu-west-1"
tag_name                             = "cts-vpc-dev"
vpc_cidr_block                       = "10.24.168.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/eu-west-1/main.tf
================
# Create a vpc using the vpc module

module "cts-vpc" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_environment                      = var.env
  tag_name                             = var.tag_name
  vpc_cidr_block                       = var.vpc_cidr_block
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}

output "vpc" { value = module.cts-vpc }

================
File: cts/vpc/eu-west-1/prod.backend.tfvars
================
key = "316576613383/vpc/eu-west-1/terraform.tfstate"

================
File: cts/vpc/eu-west-1/prod.tfvars
================
region                               = "eu-west-1"
tag_name                             = "cts-vpc-prod"
vpc_cidr_block                       = "10.24.32.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/eu-west-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the CloudWAN VPC attachment.  Disabled by default"
  type        = bool
  default     = false
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: cts/vpc/eu-west-1/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/vpc/us-east-1/.terraform-version
================
latest:^1.5

================
File: cts/vpc/us-east-1/dev.backend.tfvars
================
key = "360093697111/dev/vpc/us-east-1/terraform.tfstate"

================
File: cts/vpc/us-east-1/dev.tfvars
================
region                               = "us-east-1"
tag_name                             = "cts-vpc-dev"
vpc_cidr_block                       = "10.24.24.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: cts/vpc/us-east-1/main.tf
================
# Create a vpc using the vpc module

module "cts-vpc" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  vpc_cidr_block                       = var.vpc_cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_ue1_az3                       = var.enable_ue1_az3
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}

output "vpc" { value = module.cts-vpc }

================
File: cts/vpc/us-east-1/prod.backend.tfvars
================
key = "316576613383/vpc/terraform.tfstate"

================
File: cts/vpc/us-east-1/prod.tfvars
================
region                               = "us-east-1"
tag_name                             = "cts-vpc-prod"
vpc_cidr_block                       = "10.25.232.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: cts/vpc/us-east-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the CloudWAN VPC attachment.  Disabled by default"
  type        = bool
  default     = false
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# If you have resources in AZ3 currently, enable this variable to use us-east-1-az3. Otherwise the subnet and its resources will be destroyed.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: cts/vpc/us-east-1/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/vpc/us-west-2/.terraform-version
================
latest:^1.5

================
File: cts/vpc/us-west-2/dev.backend.tfvars
================
key = "360093697111/dev/vpc/us-west-2/terraform.tfstate"

================
File: cts/vpc/us-west-2/dev.tfvars
================
region                               = "us-west-2"
tag_name                             = "cts-vpc-dev"
vpc_cidr_block                       = "10.24.56.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/us-west-2/main.tf
================
# Create a vpc using the vpc module

module "cts-vpc" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_environment                      = var.env
  tag_name                             = var.tag_name
  vpc_cidr_block                       = var.vpc_cidr_block
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}
output "vpc" { value = module.cts-vpc }

================
File: cts/vpc/us-west-2/prod.backend.tfvars
================
key = "316576613383/vpc/us-west-2/terraform.tfstate"

================
File: cts/vpc/us-west-2/prod.tfvars
================
region                               = "us-west-2"
tag_name                             = "cts-vpc-prod"
vpc_cidr_block                       = "10.24.48.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: cts/vpc/us-west-2/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  type        = string
  description = "AWS region for provider"
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the CloudWAN VPC attachment.  Disabled by default"
  type        = bool
  default     = false
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: cts/vpc/us-west-2/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.6"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: cts/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_route53_record.consul-server-lb": [
      "aws_lb.consul-server-lb"
    ],
    "aws_lb_listener.consul-listener": [
      "aws_lb.consul-server-lb",
      "aws_lb_target_group.consul-tg"
    ],
    "aws_autoscaling_attachment.consul": [
      "aws_lb_target_group.consul-tg"
    ],
    "vault_generic_secret.atlantis-rw-token": [
      "vault_token.atlantis-rw-token"
    ],
    "artifactory_virtual_maven_repository.maven": [
      "artifactory_remote_maven_repository.maven-google-remote",
      "artifactory_local_maven_repository.maven-snapshot-local",
      "artifactory_local_maven_repository.maven-release-local",
      "artifactory_remote_maven_repository.maven-repo1-remote"
    ],
    "artifactory_virtual_npm_repository.npm": [
      "artifactory_remote_npm_repository.npm-fontawesome-remote"
    ],
    "aws_instance.windows": [
      "aws_security_group.windows_rdp"
    ],
    "aws_iam_access_key.gei": [
      "aws_iam_user.gei"
    ],
    "aws_iam_user_policy.gei": [
      "aws_iam_user.gei"
    ],
    "aws_lb.chef-infra-server": [
      "aws_security_group.chef_infra_lb_sg"
    ],
    "aws_lb_listener.chef-infra-server": [
      "aws_lb_target_group.chef-infra-server",
      "aws_lb.chef-infra-server"
    ],
    "aws_lb_listener.chef-infra-server-http": [
      "aws_lb_target_group.chef-infra-server",
      "aws_lb.chef-infra-server"
    ],
    "aws_route53_record.chef-infra-server": [
      "aws_lb.chef-infra-server"
    ],
    "aws_iam_role_policy_attachment.chef_infra_server_service_role": [
      "aws_iam_role.chef_infra_server_service_role",
      "aws_iam_policy.chef_infra_server_service_role"
    ],
    "aws_iam_role_policy_attachment.ssm": [
      "aws_iam_role.chef_infra_server_service_role"
    ],
    "aws_iam_instance_profile.ec2_instance_profile": [
      "aws_iam_role.chef_infra_server_service_role"
    ],
    "vault_generic_endpoint.atlantis": [
      "vault_auth_backend.userpass"
    ],
    "aws_iam_access_key.packer": [
      "aws_iam_user.packer"
    ],
    "aws_route53_record.ns": [
      "aws_route53_zone.aws_route53_zone"
    ],
    "aws_acm_certificate_validation.cert_validation": [
      "aws_acm_certificate.cts"
    ],
    "vault_generic_secret.postgres_green": [
      "aws_db_instance.awx_db_green",
      "random_string.postgres_password"
    ],
    "aws_db_instance.awx_db_green": [
      "aws_security_group.awx_db_sg_green",
      "aws_db_subnet_group.awx_subnet_group_green",
      "random_string.postgres_password"
    ],
    "aws_route.public_accepter": [
      "aws_vpc_peering_connection.accepter"
    ],
    "aws_cloudwatch_event_target.bottlerocket_check_target": [
      "aws_cloudwatch_event_rule.daily_bottlerocket_check",
      "aws_lambda_function.bottlerocket_version_checker"
    ],
    "aws_lambda_permission.allow_cloudwatch": [
      "aws_cloudwatch_event_rule.daily_bottlerocket_check",
      "aws_lambda_function.bottlerocket_version_checker"
    ],
    "aws_iam_role_policy_attachment.lambda_basic_execution": [
      "aws_iam_role.lambda_role"
    ],
    "aws_iam_role_policy_attachment.lambda_ssm_access": [
      "aws_iam_policy.lambda_policy",
      "aws_iam_role.lambda_role"
    ],
    "aws_ram_principal_association.dev_alpha_bottlerocket_ssm_share_principal": [
      "aws_ram_resource_share.dev_alpha_bottlerocket_ssm_share"
    ],
    "aws_ram_principal_association.alpha_bottlerocket_ssm_share_principal": [
      "aws_ram_resource_share.alpha_bottlerocket_ssm_share"
    ],
    "aws_ram_principal_association.development_bottlerocket_ssm_share_principal": [
      "aws_ram_resource_share.development_bottlerocket_ssm_share"
    ],
    "aws_ram_principal_association.production_bottlerocket_ssm_share_principal": [
      "aws_ram_resource_share.production_bottlerocket_ssm_share"
    ],
    "aws_cloudwatch_event_rule.daily_nodegroup_check": [
      "random_integer.nightly_lambda"
    ],
    "aws_cloudwatch_event_target.nodegroup_check_target": [
      "aws_cloudwatch_event_rule.daily_nodegroup_check",
      "aws_lambda_function.nodegroup_update"
    ],
    "aws_s3_bucket_ownership_controls.ownership": [
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_s3_bucket_acl.lambda_bucket_acl": [
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_s3_bucket_policy.allow_access_oidc": [
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_secretsmanager_secret_version.secret_version": [
      "aws_secretsmanager_secret.secret_name"
    ],
    "aws_secretsmanager_secret_policy.secret_policy": [
      "aws_secretsmanager_secret.secret_name"
    ],
    "aws_apigatewayv2_integration.repo-requirement-manager": [
      "aws_apigatewayv2_api.lambda",
      "aws_lambda_function.repo-settings-management"
    ],
    "aws_apigatewayv2_route.repo-requirement-manager": [
      "aws_apigatewayv2_api.lambda",
      "aws_apigatewayv2_integration.repo-requirement-manager"
    ],
    "aws_cloudwatch_log_group.api_gw": [
      "aws_apigatewayv2_api.lambda"
    ],
    "aws_lambda_permission.api_gw": [
      "aws_apigatewayv2_api.lambda",
      "aws_lambda_function.repo-settings-management"
    ],
    "aws_iam_role.oidc_s3_update_role": [
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_iam_role_policy.resource_policy": [
      "aws_iam_role.oidc_s3_update_role"
    ],
    "aws_lambda_function.repo-settings-management": [
      "aws_iam_role.lambda_exec",
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_lambda_function.timed-repo-settings-management": [
      "aws_iam_role.lambda_exec",
      "aws_s3_bucket.lambda_bucket"
    ],
    "aws_cloudwatch_log_group.repo-settings-management": [
      "aws_lambda_function.repo-settings-management"
    ],
    "aws_cloudwatch_log_group.timed-repo-settings-management": [
      "aws_lambda_function.timed-repo-settings-management"
    ],
    "aws_iam_role_policy_attachment.lambda_policy": [
      "aws_iam_role.lambda_exec"
    ],
    "aws_lambda_permission.oidc-account-access": [
      "aws_lambda_function.repo-settings-management",
      "aws_iam_role.oidc_s3_update_role"
    ],
    "aws_lambda_permission.timed-oidc-account-access": [
      "aws_lambda_function.timed-repo-settings-management",
      "aws_iam_role.oidc_s3_update_role"
    ],
    "aws_cloudwatch_event_target.bulk_updates": [
      "aws_lambda_function.timed-repo-settings-management",
      "aws_cloudwatch_event_rule.bulk_updates"
    ],
    "aws_lambda_permission.allow_cloudwatch_to_lambda": [
      "aws_lambda_function.timed-repo-settings-management",
      "aws_cloudwatch_event_rule.bulk_updates"
    ],
    "aws_iam_role_policy_attachment.policy-attach": [
      "aws_iam_role.resource_role",
      "aws_iam_policy.aws_iam_policy_read_secret"
    ],
    "vault_aws_auth_backend_role.ci_builder_role": [
      "vault_auth_backend.aws"
    ],
    "aws_iam_role_policy.github_actions_runner_ecr_policy": [
      "aws_iam_role.github_actions_oidc_ecr_role"
    ],
    "aws_iam_role_policy.github_actions_runner_packer_policy": [
      "aws_iam_role.github_actions_oidc_packer_role"
    ],
    "azuread_service_principal.sre_azure_stack_hci_sp": [
      "azuread_application.sre_azure_stack_hci_application"
    ],
    "time_rotating.sre_azure_stack_hci_rotation_2": [
      "time_rotating.sre_azure_stack_hci_rotation_1"
    ],
    "azuread_application_password.sre_azure_stack_hci_password_1": [
      "time_rotating.sre_azure_stack_hci_rotation_1",
      "azuread_application.sre_azure_stack_hci_application"
    ],
    "azuread_application_password.sre_azure_stack_hci_password_2": [
      "time_rotating.sre_azure_stack_hci_rotation_2"
    ],
    "azuread_application_password.sre_azure_stack_jenkins_password_1": [
      "time_rotating.sre_azure_stack_hci_rotation_1",
      "azuread_application.sre_azure_stack_hci_application"
    ],
    "azuread_application_password.sre_azure_stack_jenkins_password_2": [
      "time_rotating.sre_azure_stack_hci_rotation_2"
    ],
    "vault_generic_secret.vault_secret_sre_azure_stack_hci": [
      "time_rotating.sre_azure_stack_hci_rotation_2",
      "azuread_application_password.sre_azure_stack_hci_password_1",
      "time_rotating.sre_azure_stack_hci_rotation_1",
      "azuread_application_password.sre_azure_stack_hci_password_2",
      "azuread_application.sre_azure_stack_hci_application"
    ],
    "vault_generic_secret.vault_secret_sre_azure_stack_jenkins": [
      "azuread_application_password.sre_azure_stack_jenkins_password_1",
      "time_rotating.sre_azure_stack_hci_rotation_2",
      "azuread_application_password.sre_azure_stack_jenkins_password_2",
      "time_rotating.sre_azure_stack_hci_rotation_1",
      "azuread_application.sre_azure_stack_hci_application"
    ],
    "azuread_service_principal.hci_awx_service_principal": [
      "azuread_application.hci_awx_service_principal"
    ],
    "azurerm_role_assignment.azurerm_role_assignments_hci_awx_service_principal": [
      "azuread_service_principal.hci_awx_service_principal"
    ],
    "azuread_application_password.hci_awx_service_principal": [
      "time_rotating.time_rotating_sp",
      "azuread_application.hci_awx_service_principal"
    ],
    "vault_generic_secret.vault_secret_awx_service_principal": [
      "azuread_application.hci_awx_service_principal",
      "azuread_application_password.hci_awx_service_principal"
    ],
    "aws_iam_role_policy_attachment.tf-permissions": [
      "aws_iam_role.role",
      "aws_iam_policy.tf-permissions"
    ],
    "aws_iam_role_policy_attachment.terraform_attach": [
      "aws_iam_role.role"
    ],
    "aws_iam_instance_profile.ssm_profile": [
      "aws_iam_role.ssm_role"
    ],
    "aws_iam_role_policy_attachment.ssm_attachment": [
      "aws_iam_role.ssm_role"
    ],
    "aws_iam_role_policy_attachment.helix_agent_attachment": [
      "aws_iam_policy.helix_agent_policy",
      "aws_iam_role.ssm_role"
    ],
    "aws_iam_access_key.iam_access_key": [
      "aws_iam_user.iam_user"
    ],
    "aws_iam_user_policy_attachment.iam_user_policy_attachment": [
      "aws_iam_policy.iam_policy",
      "aws_iam_user.iam_user"
    ],
    "grafana_service_account_token.tr_contact_points": [
      "grafana_service_account.tr_contact_points"
    ],
    "grafana_cloud_access_policy_token.prism": [
      "grafana_cloud_access_policy.prism"
    ],
    "grafana_cloud_access_policy_token.open_invoice": [
      "grafana_cloud_access_policy.open_invoice"
    ],
    "azuread_application_identifier_uri.azuread_application_identifier_uri": [
      "azuread_application.github_sso",
      "azuread_service_principal.github_sso_sp"
    ],
    "azuread_service_principal.github_sso_sp": [
      "azuread_application.github_sso"
    ],
    "azuread_service_principal_token_signing_certificate.azuread_service_principal_token_signing_certificate": [
      "azuread_service_principal.github_sso_sp"
    ],
    "azuread_service_principal_claims_mapping_policy_assignment.saml_nameid_fix": [
      "azuread_claims_mapping_policy.saml_nameid_fix",
      "azuread_service_principal.github_sso_sp"
    ],
    "azuread_app_role_assignment.Team_AzureRole": [
      "azuread_service_principal.github_sso_sp"
    ],
    "aws_route53_record.cdn_alias": [
      "aws_cloudfront_distribution.cdn_distribution"
    ],
    "aws_route53_record.api_alias": [
      "aws_cloudfront_distribution.api_distribution"
    ],
    "aws_route53_record.dataplane_alias": [
      "aws_cloudfront_distribution.dataplane_distribution"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy",
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ]
  },
  "dependents": {
    "aws_lb.consul-server-lb": [
      "aws_route53_record.consul-server-lb",
      "aws_lb_listener.consul-listener"
    ],
    "aws_lb_target_group.consul-tg": [
      "aws_lb_listener.consul-listener",
      "aws_autoscaling_attachment.consul"
    ],
    "vault_token.atlantis-rw-token": [
      "vault_generic_secret.atlantis-rw-token"
    ],
    "artifactory_remote_maven_repository.maven-google-remote": [
      "artifactory_virtual_maven_repository.maven"
    ],
    "artifactory_local_maven_repository.maven-snapshot-local": [
      "artifactory_virtual_maven_repository.maven"
    ],
    "artifactory_local_maven_repository.maven-release-local": [
      "artifactory_virtual_maven_repository.maven"
    ],
    "artifactory_remote_maven_repository.maven-repo1-remote": [
      "artifactory_virtual_maven_repository.maven"
    ],
    "artifactory_remote_npm_repository.npm-fontawesome-remote": [
      "artifactory_virtual_npm_repository.npm"
    ],
    "aws_security_group.windows_rdp": [
      "aws_instance.windows"
    ],
    "aws_iam_user.gei": [
      "aws_iam_access_key.gei",
      "aws_iam_user_policy.gei"
    ],
    "aws_security_group.chef_infra_lb_sg": [
      "aws_lb.chef-infra-server"
    ],
    "aws_lb_target_group.chef-infra-server": [
      "aws_lb_listener.chef-infra-server",
      "aws_lb_listener.chef-infra-server-http"
    ],
    "aws_lb.chef-infra-server": [
      "aws_lb_listener.chef-infra-server",
      "aws_lb_listener.chef-infra-server-http",
      "aws_route53_record.chef-infra-server"
    ],
    "aws_iam_role.chef_infra_server_service_role": [
      "aws_iam_role_policy_attachment.chef_infra_server_service_role",
      "aws_iam_role_policy_attachment.ssm",
      "aws_iam_instance_profile.ec2_instance_profile"
    ],
    "aws_iam_policy.chef_infra_server_service_role": [
      "aws_iam_role_policy_attachment.chef_infra_server_service_role"
    ],
    "vault_auth_backend.userpass": [
      "vault_generic_endpoint.atlantis"
    ],
    "aws_iam_user.packer": [
      "aws_iam_access_key.packer"
    ],
    "aws_route53_zone.aws_route53_zone": [
      "aws_route53_record.ns"
    ],
    "aws_acm_certificate.cts": [
      "aws_acm_certificate_validation.cert_validation"
    ],
    "aws_db_instance.awx_db_green": [
      "vault_generic_secret.postgres_green"
    ],
    "random_string.postgres_password": [
      "vault_generic_secret.postgres_green",
      "aws_db_instance.awx_db_green"
    ],
    "aws_security_group.awx_db_sg_green": [
      "aws_db_instance.awx_db_green"
    ],
    "aws_db_subnet_group.awx_subnet_group_green": [
      "aws_db_instance.awx_db_green"
    ],
    "aws_vpc_peering_connection.accepter": [
      "aws_route.public_accepter"
    ],
    "aws_cloudwatch_event_rule.daily_bottlerocket_check": [
      "aws_cloudwatch_event_target.bottlerocket_check_target",
      "aws_lambda_permission.allow_cloudwatch"
    ],
    "aws_lambda_function.bottlerocket_version_checker": [
      "aws_cloudwatch_event_target.bottlerocket_check_target",
      "aws_lambda_permission.allow_cloudwatch"
    ],
    "aws_iam_role.lambda_role": [
      "aws_iam_role_policy_attachment.lambda_basic_execution",
      "aws_iam_role_policy_attachment.lambda_ssm_access"
    ],
    "aws_iam_policy.lambda_policy": [
      "aws_iam_role_policy_attachment.lambda_ssm_access"
    ],
    "aws_ram_resource_share.dev_alpha_bottlerocket_ssm_share": [
      "aws_ram_principal_association.dev_alpha_bottlerocket_ssm_share_principal"
    ],
    "aws_ram_resource_share.alpha_bottlerocket_ssm_share": [
      "aws_ram_principal_association.alpha_bottlerocket_ssm_share_principal"
    ],
    "aws_ram_resource_share.development_bottlerocket_ssm_share": [
      "aws_ram_principal_association.development_bottlerocket_ssm_share_principal"
    ],
    "aws_ram_resource_share.production_bottlerocket_ssm_share": [
      "aws_ram_principal_association.production_bottlerocket_ssm_share_principal"
    ],
    "random_integer.nightly_lambda": [
      "aws_cloudwatch_event_rule.daily_nodegroup_check"
    ],
    "aws_cloudwatch_event_rule.daily_nodegroup_check": [
      "aws_cloudwatch_event_target.nodegroup_check_target"
    ],
    "aws_lambda_function.nodegroup_update": [
      "aws_cloudwatch_event_target.nodegroup_check_target"
    ],
    "aws_s3_bucket.lambda_bucket": [
      "aws_s3_bucket_ownership_controls.ownership",
      "aws_s3_bucket_acl.lambda_bucket_acl",
      "aws_s3_bucket_policy.allow_access_oidc",
      "aws_iam_role.oidc_s3_update_role",
      "aws_lambda_function.repo-settings-management",
      "aws_lambda_function.timed-repo-settings-management"
    ],
    "aws_secretsmanager_secret.secret_name": [
      "aws_secretsmanager_secret_version.secret_version",
      "aws_secretsmanager_secret_policy.secret_policy"
    ],
    "aws_apigatewayv2_api.lambda": [
      "aws_apigatewayv2_integration.repo-requirement-manager",
      "aws_apigatewayv2_route.repo-requirement-manager",
      "aws_cloudwatch_log_group.api_gw",
      "aws_lambda_permission.api_gw"
    ],
    "aws_lambda_function.repo-settings-management": [
      "aws_apigatewayv2_integration.repo-requirement-manager",
      "aws_lambda_permission.api_gw",
      "aws_cloudwatch_log_group.repo-settings-management",
      "aws_lambda_permission.oidc-account-access"
    ],
    "aws_apigatewayv2_integration.repo-requirement-manager": [
      "aws_apigatewayv2_route.repo-requirement-manager"
    ],
    "aws_iam_role.oidc_s3_update_role": [
      "aws_iam_role_policy.resource_policy",
      "aws_lambda_permission.oidc-account-access",
      "aws_lambda_permission.timed-oidc-account-access"
    ],
    "aws_iam_role.lambda_exec": [
      "aws_lambda_function.repo-settings-management",
      "aws_lambda_function.timed-repo-settings-management",
      "aws_iam_role_policy_attachment.lambda_policy"
    ],
    "aws_lambda_function.timed-repo-settings-management": [
      "aws_cloudwatch_log_group.timed-repo-settings-management",
      "aws_lambda_permission.timed-oidc-account-access",
      "aws_cloudwatch_event_target.bulk_updates",
      "aws_lambda_permission.allow_cloudwatch_to_lambda"
    ],
    "aws_cloudwatch_event_rule.bulk_updates": [
      "aws_cloudwatch_event_target.bulk_updates",
      "aws_lambda_permission.allow_cloudwatch_to_lambda"
    ],
    "aws_iam_role.resource_role": [
      "aws_iam_role_policy_attachment.policy-attach"
    ],
    "aws_iam_policy.aws_iam_policy_read_secret": [
      "aws_iam_role_policy_attachment.policy-attach"
    ],
    "vault_auth_backend.aws": [
      "vault_aws_auth_backend_role.ci_builder_role"
    ],
    "aws_iam_role.github_actions_oidc_ecr_role": [
      "aws_iam_role_policy.github_actions_runner_ecr_policy"
    ],
    "aws_iam_role.github_actions_oidc_packer_role": [
      "aws_iam_role_policy.github_actions_runner_packer_policy"
    ],
    "azuread_application.sre_azure_stack_hci_application": [
      "azuread_service_principal.sre_azure_stack_hci_sp",
      "azuread_application_password.sre_azure_stack_hci_password_1",
      "azuread_application_password.sre_azure_stack_jenkins_password_1",
      "vault_generic_secret.vault_secret_sre_azure_stack_hci",
      "vault_generic_secret.vault_secret_sre_azure_stack_jenkins"
    ],
    "time_rotating.sre_azure_stack_hci_rotation_1": [
      "time_rotating.sre_azure_stack_hci_rotation_2",
      "azuread_application_password.sre_azure_stack_hci_password_1",
      "azuread_application_password.sre_azure_stack_jenkins_password_1",
      "vault_generic_secret.vault_secret_sre_azure_stack_hci",
      "vault_generic_secret.vault_secret_sre_azure_stack_jenkins"
    ],
    "time_rotating.sre_azure_stack_hci_rotation_2": [
      "azuread_application_password.sre_azure_stack_hci_password_2",
      "azuread_application_password.sre_azure_stack_jenkins_password_2",
      "vault_generic_secret.vault_secret_sre_azure_stack_hci",
      "vault_generic_secret.vault_secret_sre_azure_stack_jenkins"
    ],
    "azuread_application_password.sre_azure_stack_hci_password_1": [
      "vault_generic_secret.vault_secret_sre_azure_stack_hci"
    ],
    "azuread_application_password.sre_azure_stack_hci_password_2": [
      "vault_generic_secret.vault_secret_sre_azure_stack_hci"
    ],
    "azuread_application_password.sre_azure_stack_jenkins_password_1": [
      "vault_generic_secret.vault_secret_sre_azure_stack_jenkins"
    ],
    "azuread_application_password.sre_azure_stack_jenkins_password_2": [
      "vault_generic_secret.vault_secret_sre_azure_stack_jenkins"
    ],
    "azuread_application.hci_awx_service_principal": [
      "azuread_service_principal.hci_awx_service_principal",
      "azuread_application_password.hci_awx_service_principal",
      "vault_generic_secret.vault_secret_awx_service_principal"
    ],
    "azuread_service_principal.hci_awx_service_principal": [
      "azurerm_role_assignment.azurerm_role_assignments_hci_awx_service_principal"
    ],
    "time_rotating.time_rotating_sp": [
      "azuread_application_password.hci_awx_service_principal"
    ],
    "azuread_application_password.hci_awx_service_principal": [
      "vault_generic_secret.vault_secret_awx_service_principal"
    ],
    "aws_iam_role.role": [
      "aws_iam_role_policy_attachment.tf-permissions",
      "aws_iam_role_policy_attachment.terraform_attach"
    ],
    "aws_iam_policy.tf-permissions": [
      "aws_iam_role_policy_attachment.tf-permissions"
    ],
    "aws_iam_role.ssm_role": [
      "aws_iam_instance_profile.ssm_profile",
      "aws_iam_role_policy_attachment.ssm_attachment",
      "aws_iam_role_policy_attachment.helix_agent_attachment"
    ],
    "aws_iam_policy.helix_agent_policy": [
      "aws_iam_role_policy_attachment.helix_agent_attachment"
    ],
    "aws_iam_user.iam_user": [
      "aws_iam_access_key.iam_access_key",
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.iam_policy": [
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "grafana_service_account.tr_contact_points": [
      "grafana_service_account_token.tr_contact_points"
    ],
    "grafana_cloud_access_policy.prism": [
      "grafana_cloud_access_policy_token.prism"
    ],
    "grafana_cloud_access_policy.open_invoice": [
      "grafana_cloud_access_policy_token.open_invoice"
    ],
    "azuread_application.github_sso": [
      "azuread_application_identifier_uri.azuread_application_identifier_uri",
      "azuread_service_principal.github_sso_sp"
    ],
    "azuread_service_principal.github_sso_sp": [
      "azuread_application_identifier_uri.azuread_application_identifier_uri",
      "azuread_service_principal_token_signing_certificate.azuread_service_principal_token_signing_certificate",
      "azuread_service_principal_claims_mapping_policy_assignment.saml_nameid_fix",
      "azuread_app_role_assignment.Team_AzureRole"
    ],
    "azuread_claims_mapping_policy.saml_nameid_fix": [
      "azuread_service_principal_claims_mapping_policy_assignment.saml_nameid_fix"
    ],
    "aws_cloudfront_distribution.cdn_distribution": [
      "aws_route53_record.cdn_alias"
    ],
    "aws_cloudfront_distribution.api_distribution": [
      "aws_route53_record.api_alias"
    ],
    "aws_cloudfront_distribution.dataplane_distribution": [
      "aws_route53_record.dataplane_alias"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ]
  },
  "cross_repo_references": [
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_shared_genai_dev_infra",
    "external.vault_identity_group_alias_dev",
    "external.grafana_folder.grafana_folder_cts_accounts",
    "external.assume_role_arn",
    "external.aws_vpc.vpc_id",
    "external.vpc_cidr_block",
    "external.aws_route_r3_accepter",
    "external.dataplane_subdomain",
    "external.encryption_key",
    "external.env",
    "external.tag_name",
    "external.user_secret_name",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_prod",
    "external.azuread_user.dave",
    "external.spot_price",
    "external.health",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_prod",
    "external.artifactory_url",
    "external.azuread_users.owners",
    "external.azuread_application_published_app_ids.well_known",
    "external.aws_route53_zone.enverus_com",
    "external.ami_name_filter",
    "external.aws_iam_policy_document.full_control",
    "external.db_sslmode",
    "external.azuread_client_config.current",
    "external.aws_iam_policy_document.assume_role",
    "external.multi",
    "external.aws_route_r3_requester",
    "external.region",
    "external.atlantis_userpass",
    "external.repo_settings_manager_organization",
    "external.username_secret_name",
    "external.vmware_clusters_to_join",
    "external.aws_route53_zone.enverus",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_tr_prod_infra",
    "external.desired_capacity",
    "external.aws_iam_policy_document.github_actions_oidc_trust_relationship",
    "external.list_vault_mounts",
    "external.aws_subnets.inside_private",
    "external.cdn_subdomain",
    "external.template_file.oidc_lambda_maintenance_trust_policy",
    "external.vo_routing_key",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_prod",
    "external.vault_generic_secret.redgate_sqlserver_credentials",
    "external.region_accepter",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_prod",
    "external.business_unit",
    "external.iam_profile",
    "external.aws_iam_policy_document.access",
    "external.cloud_wan_core_network_id",
    "external.username",
    "external.db_port",
    "external.cloudwatch_logs_endpoint_type",
    "external.instance",
    "external.tagAutospot",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_llandman_prod",
    "external.engine_version",
    "external.ecr_name",
    "external.instance_class",
    "external.aws_tag_stack",
    "external.take_snapshot",
    "external.aws_iam_policy_document.replica",
    "external.vpc",
    "external.azuread_application_template.github_cloud_org_app_template",
    "external.vault_generic_secret.vault_destination",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_dev",
    "external.aws_cloudfront_cache_policy.cachingdisabled",
    "external.vault_generic_secret.Azure_Service_Principal_Atlantis",
    "external.vault_path_redgate_sqlserver_credentials",
    "external.vault_path_artifactory_credentials",
    "external.datacenter",
    "external.aws_route53_zone.selected",
    "external.business",
    "external.aws_route_r5_requester",
    "external.ecr_endpoint_type",
    "external.os",
    "external.ext_rs_api_enverus_acm",
    "external.consul_token",
    "external.template_file.oidc_lambda_maintenance_role_policies",
    "external.aws_iam_policy_document.github_actions_oidc_packer_policy",
    "external.bu",
    "external.secrets_manager_enverus_acr",
    "external.aws_iam_openid_connect_provider.gh_oidc",
    "external.vault_generic_secret.grafana",
    "external.enable",
    "external.password_secret_name",
    "external.kubecost_bucket",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_pythonsdk_s3_dev",
    "external.vpc_name",
    "external.tagBusinessUnit",
    "external.aws_iam_policy_document.helix_agent_policy",
    "external.vault_path_awx",
    "external.dr",
    "external.asg",
    "external.aws_subnets.private",
    "external.vault_generic_secret.docker_hub_token",
    "external.aws_iam_policy_document.github_actions_runner_s3_tools_access",
    "external.VAULT_ADDR_SOURCE",
    "external.vault_generic_secret.aws",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_llandman_dev",
    "external.iam",
    "external.token_secret_name",
    "external.vault_generic_secret.azure_token",
    "external.db_name",
    "external.ebs",
    "external.get_caller_identity.current",
    "external.vpc_name_tag",
    "external.oidc_client_id",
    "external.template_file.policy",
    "external.aws_route_r4_requester",
    "external.business_unit_tag",
    "external.aws_vpc_peering_connection_id_accepter",
    "external.github_sso_azuread_group_names",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_ecr",
    "external.aws_caller_identity.current",
    "external.vpc_environment",
    "external.allow_list_github_organizations",
    "external.aws_iam_policy_document.iam_policy_document",
    "external.enable_ue1_az3",
    "external.chef",
    "external.keypair",
    "external.aws_acm_certificate.cert",
    "external.instance_type",
    "external.resource_groups",
    "external.max_allocated_storage",
    "external.aws_iam_policy_document.source",
    "external.aws_iam_policy_document.github_actions_oidc_packer_trust_relationship",
    "external.ext_rs_dp_enverus_acm",
    "external.aws_subnets.private_subnets",
    "external.db_username",
    "external.vault_generic_secret.github_pat",
    "external.archive_file.lambda_zip",
    "external.bucket_prefix",
    "external.consul_servers",
    "external.secrets_manager_docker",
    "external.vmware",
    "external.recursors",
    "external.aws",
    "external.azuread_group.Team_AzureRole",
    "external.aws_security_group.inside",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_directaccess_preprod",
    "external.tagLocation",
    "external.sqlserver_username",
    "external.assume_role_arn_accepter",
    "external.tagTeam",
    "external.enable_centralized_endpoints_profile",
    "external.dns",
    "external.sqlserver_password",
    "external.aws_route_r2_accepter",
    "external.aws_iam_policy_document.policy_document",
    "external.aws_route_r2_requester",
    "external.aws_ec2_managed_prefix_list.main",
    "external.aws_route53_zone.route53_apex_domain",
    "external.aws_iam_openid_connect_provider.gh_oidc_provider",
    "external.vault_generic_secret.hci",
    "external.vault_path_oidc_client_secret",
    "external.bucket_hook_environment",
    "external.aws_tag_env",
    "external.aws_ec2_ebs_optimized",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_nv_infra",
    "external.allocated_storage",
    "external.ec2",
    "external.environment",
    "external.aws_organizations_organization.org",
    "external.vault_path",
    "external.user_provided_ansible_pull_playbook_list",
    "external.min_capacity",
    "external.tag_cloud_wan_segment",
    "external.tagComponent",
    "external.instance_name",
    "external.aws_tag_autospot",
    "external.grafana_cloud_stack.current",
    "external.vault_path_grafana_api_key",
    "external.nomad_type",
    "external.repo_settings_manager_repository",
    "external.secret_manager_secrets",
    "external.tagStack",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_packer",
    "external.vault_destination_root_token",
    "external.aws_route_r6_accepter",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_cdr_exporter_prod",
    "external.desired",
    "external.aws_ec2_managed_prefix_list.vpn_prefix_list",
    "external.template_file.bucket_policy_template",
    "external.db_type",
    "external.aws_subnet_ids.private",
    "external.min",
    "external.aws_subnets.inside",
    "external.nomad_http_address",
    "external.encryption",
    "external.aws_route53_zone.cts",
    "external.master_count_green",
    "external.aws_vpc.main",
    "external.vault_path_ecr_keys",
    "external.aws_route_r1_accepter",
    "external.aws_iam_policy_document.github_actions_oidc_ecr_policy",
    "external.configBackend",
    "external.domain",
    "external.aws_subnet_ids.inside",
    "external.tls_certificate.github",
    "external.azure_stack_hci_application",
    "external.aws_default_tags.aws_default_tags",
    "external.subnet",
    "external.aws_region",
    "external.vault_generic_secret.atlantis_userpass",
    "external.aws_availability_zones.good_zone_ids",
    "external.aws_config_sns",
    "external.operating_system",
    "external.aws_route_r5_accepter",
    "external.aws_tag_location",
    "external.elb",
    "external.azuread_group.SRE_Team_AzureRole",
    "external.artifactory_user",
    "external.ext_rs_cdn_enverus_acm",
    "external.aws_tag_component",
    "external.aws_default_tags.current",
    "external.vault_generic_secret.grafana_api",
    "external.api_subdomain",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_dev",
    "external.dataplane_origin_account_name",
    "external.artifactory_token",
    "external.aws_security_group.inside_sg",
    "external.aws_route_r4_accepter",
    "external.secret_mountpoint",
    "external.name",
    "external.template_file.oidc_assume_role_policy_template",
    "external.list_vault_policies",
    "external.azuread_service_principal.Atlantis_Group_Manager_Service_Principal",
    "external.aws_route_r6_requester",
    "external.azuread_application.HCIApplication",
    "external.kms_exclusion_list",
    "external.aws_iam_policy_document.runner_imdsv2_policy",
    "external.resource_type_exclusion_list",
    "external.vault_generic_secret.terraform_access_policy_token",
    "external.VAULT_ADDR",
    "external.bucket_name",
    "external.vault_path_azure_service_principal_atlantis",
    "external.aws_cloudfront_cache_policy.cachingoptimized",
    "external.ami",
    "external.aws_cloudfront_response_headers_policy.cors_with_preflight",
    "external.aws_ami.Windows_Server",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_cdr_exporter_dev",
    "external.tagEnv",
    "external.vault_path_github_pat",
    "external.ssh_key_pair",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_refinery_preprod",
    "external.secrets_mountpoint",
    "external.aws_organizations_organization.main",
    "external.inside_subnet_filter",
    "external.aws_vpc_peering_connection_id_requester",
    "external.vault_generic_secret.org_pems",
    "external.aws_iam_policy_document.instance_assume_role_policy",
    "external.vault_generic_secret.artifactory_credentials",
    "external.enable_cloud_wan_vpc_attachment",
    "external.allowed_redirect_uris_prefix",
    "external.aws_ec2_instance_type",
    "external.vault_path_awx_rds",
    "external.aws_iam_policy_document.gh_actions_runner_assume_role_oidc_mv_conn_matlabsdk_s3_dev",
    "external.vault_identity_group_alias_sre",
    "external.initial_version",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_tr_dev_infra",
    "external.oidc_discovery_url",
    "external.vault_path_aws_keys",
    "external.bucketname",
    "external.aws_iam_policy_document.github_actions_runner_assume_role_oidc_shared_genai_prod_infra",
    "external.enable_cgnat_subnet",
    "external.aws_tag_team",
    "external.vault_path_fontawesome_registry",
    "external.aws_route_r1_requester",
    "external.image",
    "external.runner_tools_bucket_name"
  ],
  "outputs": [
    "consul_servers",
    "ecr",
    "artifactory_virtual_npm_repository",
    "vault_azuread_sso",
    "aws_instance",
    "vault_policies_and_roles",
    "ecr",
    "data_aws_route53_zone_route53_apex_domain",
    "aws_route53_zone",
    "aws_route53_record_ns",
    "good_zone_ids",
    "vpc",
    "vpc",
    "vpc",
    "vpc",
    "lambda_function_name",
    "lambda_function_arn",
    "cloudwatch_rule_name",
    "alpha_version_parameter",
    "development_version_parameter",
    "production_version_parameter",
    "good_zone_ids",
    "private_subnets",
    "data_tls_certificate_github",
    "aws_iam_openid_connect_provider_gh_oidc_provider",
    "aws_iam_role_github_actions_oidc_ecr_role",
    "aws_iam_role_policy_github_actions_runner_ecr_policy",
    "aws_iam_role_github_actions_oidc_packer_role",
    "aws_iam_role_policy_github_actions_runner_packer_policy",
    "policy_arn",
    "aws_iam_role",
    "aws_iam_role_arn",
    "aws_vpc",
    "subnets",
    "consul_servers_aws_ue1",
    "grafana_folder_cts_accounts",
    "grafana_dashboard_accounts_service",
    "fileset",
    "azuread_group_adgroup",
    "github_cloud_org_app_template",
    "azuread_application",
    "azuread_application_identifier_uri",
    "azuread_service_principal_github_sso_sp",
    "azuread_service_principal_token_signing_certificate",
    "azuread_claims_mapping_policy",
    "azuread_service_principal_claims_mapping_policy_assignment",
    "azuread_app_role_assignment_Team_AzureRole",
    "application_template_id",
    "application_categories",
    "app_display_name",
    "app_publisher",
    "app_supported_provisioning_types",
    "app_single_sign_on_modes",
    "github_cloud_org_app_template",
    "azuread_application",
    "github_cloud_org_app_template",
    "azuread_application",
    "azuread_application_identifier_uri",
    "azuread_service_principal_github_sso_sp",
    "azuread_service_principal_token_signing_certificate",
    "azuread_claims_mapping_policy",
    "azuread_service_principal_claims_mapping_policy_assignment",
    "azuread_app_role_assignment_Team_AzureRole",
    "cdn_distribution",
    "api_distribution",
    "dataplane_distribution",
    "data_aws_cloudfront_cache_policy_cachingoptimized",
    "data_aws_cloudfront_cache_policy_cachingdisabled",
    "data_aws_cloudfront_response_headers_policy_cors_with_preflight",
    "ext_rs_cdn_enverus_acm",
    "ext_rs_api_enverus_acm",
    "ext_rs_dp_enverus_acm"
  ],
  "metadata": {
    "total_resources": 153,
    "resources_with_dependencies": 89,
    "resources_that_are_dependencies": 79,
    "cross_repo_refs_count": 271,
    "outputs_count": 72,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: cts/.gitignore
================
.terraform
terraform.tfsta*
jjb-macros-latest.yaml
jjb-templates-latest.yaml
.terraform.lock.hcl
.idea/
.DS_Store
/.vs/*
.vscode/
*.iml

================
File: cts/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.99.0
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"

================
File: cts/atlantis.yaml
================
version: 3
automerge: false
projects:
  ############# acm #######################
  - name: acm-dev
    dir: acm/cts_enverus_com
    workflow: dev
    terraform_version: v1.7.5
  - name: acm-prod
    dir: acm/cts_enverus_com
    workflow: prod
    terraform_version: v1.7.5
  ############# aws config ################
  - name: aws-config-dev
    dir: config
    workflow: dev
  - name: aws-config-prod
    dir: config
    workflow: prod
  ############ s3 buckets #################
  - name: s3-buckets-dev
    dir: s3-buckets
    workflow: dev
    terraform_version: v1.7.5
  - name: s3-buckets-prod
    dir: s3-buckets
    workflow: prod
    terraform_version: v1.7.5

  ############ iam #################
  - name: iam-roles-argo-cd-sts-dev
    dir: iam/roles/argo-cd-sts
    workflow: dev
    terraform_version: v1.7.5
  - name: iam-roles-argo-cd-sts-prod
    dir: iam/roles/argo-cd-sts
    workflow: prod
    terraform_version: v1.7.5
  - name: iam-roles-tf-atlantis-test-dev
    dir: iam/roles/tf-atlantis-test
    workflow: dev
    terraform_version: v1.7.4
  - name: iam-roles-ssm-agent-dev
    dir: iam/roles/ssm-agent
    workflow: dev
    terraform_version: v1.7.5
  - name: iam-roles-tf-ssm-agent-prod
    dir: iam/roles/ssm-agent
    workflow: prod
    terraform_version: v1.7.5
  - name: iam-hci-sp
    dir: iam/hci
    workflow: cts-prod-vault

  ############  cts vpc   #################
  - name: vpc-dev-us-east-1
    dir: vpc/us-east-1
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-dev-west-2
    dir: vpc/us-west-2
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-dev-eu-west-1
    dir: vpc/eu-west-1
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-dev-eu-north-1
    dir: vpc/eu-north-1
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-us-east-1
    dir: vpc/us-east-1
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-us-west-2
    dir: vpc/us-west-2
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-eu-west-1
    dir: vpc/eu-west-1
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-eu-north-1
    dir: vpc/eu-north-1
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############ Consul ########################
  - name: consul-cluster-dev
    dir: consul-cluster
    workflow: cts-dev-prod-vault
  - name: consul-cluster-prod
    dir: consul-cluster
    workflow: cts-prod-vault
  ##### centralized tf state storage ########
  - name: central-terraform-state-storage-bucket-prod
    dir: central-terraform-state-storage-bucket
    workflow: cts-prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############# route53 #######################
  - name: route53-dev
    dir: route53/cts
    workflow: dev
  - name: route53-prod
    dir: route53/cts
    workflow: prod
  - name: route53-enverus_com_subzones-prod
    dir: route53/enverus_com_subzones
    workflow: prod
    terraform_version: v1.7.5
  ############ vault ########################
  - name: vault-cts-cluster-dev
    dir: vault_cts
    workflow: dev-vault
  - name: vault-cts-cluster-prod
    dir: vault_cts
    workflow: prod-vault
  ############# vault azure ad sso ##########
  - name: vault-azuread-sso-cts-dev
    dir: vault_azuread_sso_cts
    workflow: cts-dev-dev-vault
  - name: vault-azuread-sso-cts-prod
    dir: vault_azuread_sso_cts
    workflow: cts-prod-vault
  ############## vault polices ##############
  - name: vault-policies-and-roles-dev
    dir: vault_policies_and_roles
    workflow: cts-dev-dev-vault
  - name: vault-policies-and-roles-prod
    dir: vault_policies_and_roles
    workflow: cts-prod-vault
  ############# vault mounts ################
  - name: vault-mounts-dev
    dir: vault_mounts
    workflow: cts-dev-dev-vault
  - name: vault-mounts-prod
    dir: vault_mounts
    workflow: cts-prod-vault
  ############# vault secrets ################
  - name: vault-secrets-prod
    dir: vault_secrets
    workflow: cts-prod-vault
  ############# vault token ################
  - name: vault-token-prod
    dir: vault_token
    workflow: cts-prod-vault
  ############## testing - consul + nomad testing infra ##############
  # - name: testing-consul-aws-dev
  #   dir: testing/consul-aws
  #   workflow: cts-dev-dev-vault
  #   terraform_version: v1.7.5
  # - name: testing-nomad-cluster-nomad-server-dev
  #   dir: testing/nomad-cluster/nomad-server
  #   workflow: cts-dev-dev-vault
  #   terraform_version: v1.7.5
  # - name: testing-nomad-cluster-nomad-client-dev
  #   dir: testing/nomad-cluster/nomad-client
  #   workflow: cts-dev-dev-vault
  #   terraform_version: v1.7.5
  # - name: testing-nomad-cluster-nomad-scheduler-dev
  #   dir: testing/nomad-cluster/nomad-scheduler
  #   workflow: cts-dev-dev-vault
  #   terraform_version: v1.7.5
  ##### grafana #######
  - name: grafana-datasources-dev
    dir: grafana/datasources
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  - name: grafana-datasources-prod
    dir: grafana/datasources
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  - name: grafana-service-accounts-prod
    dir: grafana/service-accounts
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  - name: grafana-access-policies-prism-prod
    dir: grafana/access-policies/prism
    workflow: cts-prod-vault
  - name: grafana-access-policies-open-invoice-prod
    dir: grafana/access-policies/open-invoice
    workflow: cts-prod-vault
  ############## lambda ##############
  ####################################################################
  - name: repo-settings-manager-dev
    dir: lambda/github-bots/repo-settings-manager
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  ####################################################################
  - name: repo-settings-manager-prod
    dir: lambda/github-bots/repo-settings-manager
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ####################################################################
  - name: bottlerocketos-dev
    dir: lambda/bottlerocket-parameter
    workflow: cts-dev-prod-vault
  - name: bottlerocketos-prod
    dir: lambda/bottlerocket-parameter
    workflow: cts-prod-vault
  ############## ecr ##############
  - name: ecr-prod
    dir: ecr
    workflow: cts-prod-vault
  - name: ecr-pull-through-cache-prod
    dir: ecr-pull-through-cache
    workflow: cts-prod-vault
  ############ AWS IDP GitHub OIDC #############
  - name: github-oidc-aws-idp-dev
    dir: github/oidc/idp
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  - name: github-oidc-aws-idp-prod
    dir: github/oidc/idp
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ############ GITHUB OIDC SRE Roles #############
  - name: github-oidc-sre-roles-dev
    dir: github/oidc/sre-roles
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  - name: github-oidc-sre-roles-prod
    dir: github/oidc/sre-roles
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ############ GITHUB OIDC Packer Role #############
  - name: github-oidc-packer-role-dev
    dir: github/oidc/custom-roles/packer
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  - name: github-oidc-packer-role-prod
    dir: github/oidc/custom-roles/packer
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ##### github actions self-hosted runner infra #######
  - name: github-runners-prod
    dir: github/runners
    workflow: cts-prod-vault
    autoplan:
      when_modified: ["*.tf*", "templates/runner-configs/*.yaml"]
  ##### github actions self-hosted s3 tools bucket #######
  - name: s3-github-runner-tool-bucket
    dir: github/s3
    workflow: cts-prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ##### github actions self-hosted runner policy #######
  - name: iam-policies-github-action-runner
    dir: iam/policies/github-action-runner
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ############ github/secrets-manager ##############
  - name: github-secrets-manager-dev
    dir: github/secrets-manager
    workflow: cts-dev-prod-vault
    terraform_version: v1.7.5
  ###################### AWX RDS ###################
  - name: awx-rds-dev
    dir: rds/awx
    workflow: cts-dev-prod-vault
  - name: awx-rds-prod
    dir: rds/awx
    workflow: cts-prod-vault
  ############ artifactory - https://drillinginfo.jfrog.io/ ###############
  - name: artifactory-prod
    dir: artifactory
    workflow: cts-prod-vault
  ############ end of artifactory #########################################
  ############ github org secrets  ########################################
  - name: github-organization-secrets-artifactory-prod
    dir: github-organization-secrets/artifactory
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  - name: github-organization-secrets-redgate-sqlcompare-prod
    dir: github-organization-secrets/redgate-sqlcompare
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ############ end of github org secrets  #################################

  ############ github enterprise importer ##############
  - name: github-enterprise-importer-dev
    dir: github-enterprise-importer
    workflow: cts-dev-dev-vault
    terraform_version: v1.7.5
  ############ end of github enterprise importer #############
  ############ Packer IAM User #############
  - name: packer-prod
    dir: packer
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  ##############################################################
  ############ github.com sso applications  ####################
  - name: github-sso-drillinginfo-prod
    dir: github-sso/drillinginfo
    workflow: cts-prod-vault
    terraform_version: v1.7.5
  - name: github-sso-bid-out-prod
    dir: github-sso/bid-out
    workflow: cts-prod-vault
  - name: github-sso-pearlstreettechnologies-prod
    dir: github-sso/pearlstreettechnologies
    workflow: cts-prod-vault
  - name: github-sso-business-analytics-prod
    dir: github-sso/business-analytics
    workflow: cts-prod-vault
  ##############################################################
  ############ github.com sso azuread groups  ####################
  - name: github-sso-azuread-groups-prod
    dir: github-sso/azuread-groups
    workflow: cts-prod-vault
  ##############################################################
  ############ chef infra server  ####################
  - name: chef-infra-server-prod
    dir: chef-infra-server
    workflow: cts-prod-vault
    terraform_version: v1.8.1
  ##############################################################
  - name: kubecost-s3-dev
    dir: kubecost
    workflow: cts-dev-prod-vault
  - name: kubecost-s3-prod
    dir: kubecost
    workflow: cts-prod-vault
  ##############################################################
  - name: auth0-backup
    dir: auth/auth0-backup
    workflow: cts-prod-vault
  ##################sre-windows-utility#########################
  - name: sre-windows-utility-dev
    dir: sre-windows-utility
    workflow: dev
  ##################sre-hackathon#########################
  - name: sre-hackathon
    dir: sre-hackathon
    workflow: dev
  ############ cloudfront (rudderstack) #############
  - name: cloudfront-rudderstack-dev
    dir: cloudfront/rudderstack
    workflow: dev
  - name: cloudfront-rudderstack-prod
    dir: cloudfront/rudderstack
    workflow: prod
  ############ end of projects #################################
  ##############################################################

  ##############################################################
  ############ temporary projects to delete vpc peers #################################
  # - name: pcx-05b06763d8a6a1eaa
  #   dir: vpc/destroy/pcx-05b06763d8a6a1eaa
  #   workflow: dev
  # - name: pcx-08ad6f18e7be5b5c5
  #   dir: vpc/destroy/pcx-08ad6f18e7be5b5c5
  #   workflow: dev
  # - name: pcx-0c5ec45fa78af0411
  #   dir: vpc/destroy/pcx-0c5ec45fa78af0411
  #   workflow: dev
  # - name: pcx-0d89179c6f96fcc0d
  #   dir: vpc/destroy/pcx-0d89179c6f96fcc0d
  #   workflow: dev
  # - name: pcx-0fb92a6cb59559c65
  #   dir: vpc/destroy/pcx-0fb92a6cb59559c65
  #   workflow: dev
  # - name: pcx-02031e7eefce8d289
  #   dir: vpc/destroy/pcx-02031e7eefce8d289
  #   workflow: dev
  # - name: pcx-d0e587b9
  #   dir: vpc/destroy/pcx-d0e587b9
  #   workflow: dev
  # - name: pcx-07247a9287ae0491f
  #   dir: vpc/destroy/pcx-07247a9287ae0491f
  #   workflow: dev

  ##############################################################

================
File: cts/global-dev-backend.tfvars
================
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::360093697111:role/terraform" }

================
File: cts/global-dev.tfvars
================
bu              = "cts"
env             = "dev"
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"
assume_role_arn = "arn:aws:iam::360093697111:role/terraform"
vo_routing_key  = "key-DevUptime"
region          = "us-east-1"
aws_region      = "us-east-1"

================
File: cts/global-prod-backend.tfvars
================
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::316576613383:role/terraform" }

================
File: cts/global-prod.tfvars
================
bu              = "cts"
env             = "prod"
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"
assume_role_arn = "arn:aws:iam::316576613383:role/terraform"
vo_routing_key  = "key-ProdUptime"
region          = "us-east-1"
aws_region      = "us-east-1"

================
File: cts/README.md
================
# cts-terraform
CTS Terrafrorm repo

================
File: cts/temp_test_graph.py
================
#!/usr/bin/env python3
"""
Super simple Terraform dependency test - KISS approach
Change the directory path below and run it
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Tuple

# ======= CHANGE THIS PATH TO YOUR DIRECTORY =======
TEST_DIRECTORY = "."
# ==================================================

def detect_cross_repo_references(content: str) -> List[str]:
    """Detect cross-repository references like data.terraform_remote_state"""
    cross_repo_refs = []
    
    # Patterns for cross-repo references
    patterns = [
        # data.terraform_remote_state.vpc.outputs.vpc_id
        r'data\.terraform_remote_state\.(\w+)\.outputs\.[\w\[\].*]+',
        # var references that might come from other repos
        r'var\.(\w+)(?:\.[\w\[\].*]+)?',
        # module references from other repos
        r'module\.(\w+)\.[\w\[\].*]+',
        # External data sources
        r'data\.(\w+)\.(\w+)\.[\w\[\].*]+',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, content, re.MULTILINE)
        for match in matches:
            if isinstance(match, tuple):
                ref = f"external.{'.'.join(match)}"
            else:
                ref = f"external.{match}"
            cross_repo_refs.append(ref)
    
    return list(set(cross_repo_refs))

def extract_outputs(content: str) -> List[str]:
    """Extract output definitions from Terraform content"""
    outputs = []
    
    # Pattern to match output blocks
    output_pattern = r'output\s+"([^"]+)"\s*\{'
    matches = re.findall(output_pattern, content)
    
    return matches

def main():
    print(" Enhanced Terraform Cross-Repo Test")
    print(f"Testing directory: {TEST_DIRECTORY}")
    print("="*50)
    
    # Get repo name from directory
    if TEST_DIRECTORY == ".":
        repo_name = Path.cwd().name
    else:
        repo_name = Path(TEST_DIRECTORY).name
        if repo_name == "repos":
            repo_name = Path.cwd().name
    
    print(f" Repository name: {repo_name}")
    
    # Find all .tf files
    try:
        test_path = Path(TEST_DIRECTORY)
        tf_files = list(test_path.glob("**/*.tf"))  # Recursive search
        print(f"Found {len(tf_files)} .tf files:")
        for tf_file in tf_files:
            print(f"   {tf_file.relative_to(test_path)}")
    except Exception as e:
        print(f" Directory error: {e}")
        print("Change the TEST_DIRECTORY path at the top of this script")
        return None, None, [], []
    
    # Read all files into one big content string
    all_content = ""
    for tf_file in tf_files:
        try:
            with open(tf_file, 'r') as f:
                content = f.read()
                all_content += f"\n# === {tf_file.relative_to(test_path)} ===\n" + content
        except Exception as e:
            print(f" Error reading {tf_file}: {e}")
            continue
    
    # Find all resources across all files
    print(f"\n Finding resources across all files...")
    resources = {}
    pattern = r'resource\s+"([^"]+)"\s+"([^"]+)"\s*\{'
    matches = re.findall(pattern, all_content)
    
    for resource_type, resource_name in matches:
        full_name = f"{resource_type}.{resource_name}"
        resources[full_name] = True
        print(f"  Found: {full_name}")
    
    print(f"\nTotal resources: {len(resources)}")
    
    # Detect cross-repo references and outputs
    print(f"\n Detecting cross-repository references...")
    cross_repo_refs = detect_cross_repo_references(all_content)
    outputs = extract_outputs(all_content)
    
    print(f"Cross-repo references found: {len(cross_repo_refs)}")
    for ref in cross_repo_refs:
        print(f"   {ref}")
    
    print(f"\nOutputs defined: {len(outputs)}")
    for output in outputs:
        print(f"   {output}")
    
    # Find dependencies across all files
    print(f"\n Finding dependencies (including cross-file)...")
    dependencies = {}
    
    for resource in resources:
        deps = []
        resource_type, resource_name = resource.split('.', 1)
        
        # Find the resource block for this specific resource
        resource_block_pattern = rf'resource\s+"{re.escape(resource_type)}"\s+"{re.escape(resource_name)}"\s*\{{([^{{}}]*(?:\{{[^{{}}]*\}}[^{{}}]*)*)\}}'
        resource_match = re.search(resource_block_pattern, all_content, re.DOTALL)
        
        if resource_match:
            resource_content = resource_match.group(1)
            
            # Look for references to other resources within this resource block
            for other_resource in resources:
                if other_resource == resource:
                    continue
                
                
                # Patterns to match Terraform resource references
                reference_patterns = [
                    # Direct resource references: aws_vpc.vpc.id, aws_subnet.private[*].id
                    rf'\b{re.escape(other_resource)}\.[\w\[\].*]+',
                    # Resource references in interpolations: ${aws_vpc.vpc.id}
                    rf'\$\{{\s*{re.escape(other_resource)}\.[\w\[\].*]+\s*\}}',
                    # for_each and count references: aws_route53_zone.endpoint_phz[each.key]
                    rf'\b{re.escape(other_resource)}\[[\w\[\].*"\']+\]\.[\w\[\].*]+',
                    # depends_on explicit dependencies
                    rf'depends_on\s*=\s*\[[\s\S]*?{re.escape(other_resource)}[\s\S]*?\]'
                ]
                
                # Check if this resource references the other resource
                for pattern in reference_patterns:
                    if re.search(pattern, resource_content):
                        deps.append(other_resource)
                        break
        
        if deps:
            dependencies[resource] = list(set(deps))  # Remove duplicates
    
    # Show results
    print(f"\n Results:")
    if not dependencies:
        print("No dependencies found")
    else:
        for resource, deps in dependencies.items():
            print(f"\n{resource} depends on:")
            for dep in deps:
                print(f"   {dep}")
    
    # Show reverse (what depends on what) - this shows cross-file impact
    print(f"\n Impact Analysis (including cross-file dependencies):")
    dependents = {}
    for resource, deps in dependencies.items():
        for dep in deps:
            if dep not in dependents:
                dependents[dep] = []
            dependents[dep].append(resource)
    
    for resource, deps in dependents.items():
        print(f"\n{resource} is used by:")
        for dep in deps:
            print(f"   {dep}")
    
    # Show most critical resources
    if dependents:
        print(f"\n Most Critical Resources:")
        critical = sorted(dependents.items(), key=lambda x: len(x[1]), reverse=True)
        for resource, deps in critical[:5]:
            print(f"   {resource}: used by {len(deps)} resources")
    
    # Save dependency graph to JSON with cross-repo data
    save_dependency_graph(dependencies, dependents, cross_repo_refs, outputs, repo_name)
    
    # Return data for question-based analysis
    return dependencies, dependents, cross_repo_refs, outputs

def save_dependency_graph(dependencies: Dict, dependents: Dict, cross_repo_refs: List[str], outputs: List[str], repo_name: str, filename: str = None):
    """Save the dependency graph to a JSON file with cross-repo data"""
    if filename is None:
        # Ensure we use a valid filename by cleaning the repo name
        clean_repo_name = repo_name.replace('-', '_').replace(' ', '_').replace('.', '_')
        filename = f"{clean_repo_name}_dependency_graph.json"
    
    graph_data = {
        "repo_name": repo_name,
        "dependencies": dependencies,
        "dependents": dependents,
        "cross_repo_references": cross_repo_refs,
        "outputs": outputs,
        "metadata": {
            "total_resources": len(set(list(dependencies.keys()) + list(dependents.keys()))),
            "resources_with_dependencies": len(dependencies),
            "resources_that_are_dependencies": len(dependents),
            "cross_repo_refs_count": len(cross_repo_refs),
            "outputs_count": len(outputs),
            "generated_from": TEST_DIRECTORY,
            "repo_name": repo_name
        }
    }
    
    with open(filename, 'w') as f:
        json.dump(graph_data, f, indent=2)
    
    print(f"\n Saved dependency graph to: {filename}")

def load_dependency_graph(filename: str = "dependency_graph.json") -> tuple:
    """Load dependency graph from JSON file"""
    try:
        with open(filename, 'r') as f:
            graph_data = json.load(f)
        
        dependencies = graph_data["dependencies"]
        dependents = graph_data["dependents"]
        
        return dependencies, dependents
        
    except FileNotFoundError:
        print(f"Dependency graph file not found: {filename}")
        print("Run 'python test_graph.py' first to generate the graph")
        return None, None
    except json.JSONDecodeError as e:
        print(f"Error reading dependency graph: {e}")
        return None, None

def build_dependency_context(dependencies: Dict, dependents: Dict, target_resource: str) -> str:
    """Build context about a resource and its dependencies for LLM analysis"""
    context_parts = []
    
    # Add information about what the target resource depends on
    if target_resource in dependencies:
        deps = dependencies[target_resource]
        context_parts.append(f"The resource '{target_resource}' depends on:")
        for dep in deps:
            context_parts.append(f"  - {dep}")
    else:
        context_parts.append(f"The resource '{target_resource}' has no dependencies.")
    
    # Add information about what depends on the target resource
    if target_resource in dependents:
        dependents_list = dependents[target_resource]
        context_parts.append(f"\nResources that depend on '{target_resource}':")
        for dependent in dependents_list:
            context_parts.append(f"  - {dependent}")
    else:
        context_parts.append(f"\nNo resources depend on '{target_resource}'.")
    
    # Add broader context about the dependency chain
    context_parts.append(f"\nDependency Analysis:")
    context_parts.append(f"- Total resources in the infrastructure: {len(set(list(dependencies.keys()) + list(dependents.keys())))}")
    context_parts.append(f"- Resources with dependencies: {len(dependencies)}")
    context_parts.append(f"- Resources that are dependencies for others: {len(dependents)}")
    
    return "\n".join(context_parts)

def find_relevant_resource(question: str, dependencies: Dict, dependents: Dict) -> str:
    """Find the most relevant resource based on the user's question"""
    question_lower = question.lower()
    all_resources = list(set(list(dependencies.keys()) + list(dependents.keys())))
    
    # Direct resource name matches
    for resource in all_resources:
        resource_parts = resource.split('.')
        resource_type = resource_parts[0] if len(resource_parts) > 0 else ""
        resource_name = resource_parts[1] if len(resource_parts) > 1 else ""
        
        # Check if question mentions the resource type or name
        if resource_type.replace('aws_', '') in question_lower:
            return resource
        if resource_name in question_lower:
            return resource
    
    # Keyword mapping for common terms
    keyword_mappings = {
        'vpc': 'aws_vpc',
        'route53': 'aws_route53',
        'endpoint': 'aws_vpc_endpoint',
        'security group': 'aws_security_group',
        'internet gateway': 'aws_internet_gateway',
        'nat gateway': 'aws_nat_gateway',
        'subnet': 'aws_subnet',
        'profile': 'aws_route53profiles_profile'
    }
    
    for keyword, resource_prefix in keyword_mappings.items():
        if keyword in question_lower:
            matching_resources = [r for r in all_resources if r.startswith(resource_prefix)]
            if matching_resources:
                return matching_resources[0]  # Return first match
    
    # If no specific match, return most critical resource
    if dependents:
        critical = sorted(dependents.items(), key=lambda x: len(x[1]), reverse=True)
        return critical[0][0]
    
    return all_resources[0] if all_resources else None

def generate_llm_prompt(question: str, dependencies: Dict, dependents: Dict) -> str:
    """Generate LLM prompt with entire dependency graph"""
    
    # Build complete dependency context
    dependency_text = "COMPLETE DEPENDENCY GRAPH:\n\n"
    
    # Add all dependencies
    dependency_text += "DEPENDENCIES (what each resource depends on):\n"
    for resource, deps in dependencies.items():
        dependency_text += f"\n{resource} depends on:\n"
        for dep in deps:
            dependency_text += f"   {dep}\n"
    
    dependency_text += "\n\n"
    
    # Add all dependents 
    dependency_text += "DEPENDENTS (what depends on each resource):\n"
    for resource, deps in dependents.items():
        dependency_text += f"\n{resource} is used by:\n"
        for dep in deps:
            dependency_text += f"   {dep}\n"
    
    # Create comprehensive prompt
    llm_prompt = f"""
You are a Terraform infrastructure expert. A user has asked: "{question}"

{dependency_text}

INFRASTRUCTURE SUMMARY:
- Total resources: {len(set(list(dependencies.keys()) + list(dependents.keys())))}
- Resources with dependencies: {len(dependencies)}
- Resources that are dependencies for others: {len(dependents)}

USER QUESTION: {question}

Based on the complete dependency graph above, please analyze and respond to the user's question directly and concisely.
"""
    
    return llm_prompt

def question_based_analysis(dependencies: Dict, dependents: Dict, user_question: str):
    """Analyze based on user question and show LLM prompt"""
    
    print("="*80)
    print(" QUESTION-BASED DEPENDENCY ANALYSIS")
    print("="*80)
    print(f"User Question: {user_question}")
    print("-" * 40)
    
    # Generate the LLM prompt
    llm_prompt = generate_llm_prompt(user_question, dependencies, dependents)
    
    print("PROMPT FOR LLM:")
    print("-" * 40)
    print(llm_prompt)
    print("-" * 40)
    print("\n Copy this prompt and send it to your LLM for analysis.")
    
    return llm_prompt

def analyze_resource_impact(dependencies: Dict, dependents: Dict):
    """Interactive resource impact analyzer"""
    print("\n Resource Impact Analyzer")
    print("="*50)
    
    # Show available resources
    all_resources = sorted(set(list(dependencies.keys()) + list(dependents.keys())))
    print(f"Available resources ({len(all_resources)}):")
    for i, resource in enumerate(all_resources, 1):
        deps_count = len(dependencies.get(resource, []))
        dependents_count = len(dependents.get(resource, []))
        print(f"  {i:2d}. {resource} (depends on: {deps_count}, used by: {dependents_count})")
    
    while True:
        print(f"\nEnter resource name or number (1-{len(all_resources)}) to analyze impact:")
        print("Type 'quit' to exit")
        
        user_input = input(">>> ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            break
        
        target_resource = None
        
        # Check if input is a number
        try:
            resource_index = int(user_input) - 1
            if 0 <= resource_index < len(all_resources):
                target_resource = all_resources[resource_index]
        except ValueError:
            # Check if input matches a resource name
            matching_resources = [r for r in all_resources if user_input.lower() in r.lower()]
            if len(matching_resources) == 1:
                target_resource = matching_resources[0]
            elif len(matching_resources) > 1:
                print(f"Multiple matches found: {matching_resources}")
                continue
            else:
                print(f"Resource '{user_input}' not found.")
                continue
        
        if target_resource:
            print(f"\n Analyzing impact of deleting: {target_resource}")
            print("="*60)
            
            try:
                question_based_analysis(dependencies, dependents, f"What happens if I delete {target_resource}?")
                print("\n" + "="*60)
                print(" NEXT STEPS:")
                print("1. Copy the prompt above")
                print("2. Send it to your LLM")
                print("3. Verify the LLM understands the dependency relationships")
                print("4. Check if the analysis makes sense for your infrastructure")
                
            except Exception as e:
                print(f" Error during analysis: {e}")
                # Fallback to basic dependency analysis
                dependency_context = build_dependency_context(dependencies, dependents, target_resource)
                print("Basic dependency analysis:")
                print(dependency_context)

def test_with_question(question: str):
    """Test the system with a specific question"""
    print(" Building dependency graph...")
    result = main()
    
    if len(result) == 4:
        dependencies, dependents, cross_repo_refs, outputs = result
    else:
        # Fallback for compatibility
        dependencies, dependents = result
        cross_repo_refs, outputs = [], []
    
    print(f"\n" + "="*80)
    print(" TESTING QUESTION-BASED ANALYSIS")
    print("="*80)
    
    question_based_analysis(dependencies, dependents, question)

if __name__ == "__main__":
    # Check if a question was provided as argument
    import sys
    
    if len(sys.argv) > 1:
        # Join all arguments as the question
        question = " ".join(sys.argv[1:])
        test_with_question(question)
    else:
        # Build the dependency graph and show usage
        result = main()
        
        if len(result) == 4:
            dependencies, dependents, cross_repo_refs, outputs = result
        else:
            # Fallback for compatibility
            dependencies, dependents = result
            cross_repo_refs, outputs = [], []
        
        print(f"\n" + "="*80)
        print(" ENHANCED CROSS-REPO LLM TESTING")
        print("="*80)
        print("Usage: python test_graph.py \"YOUR QUESTION HERE\"")
        print()
        print("Examples:")
        print('  python test_graph.py "What happens if I delete the route53 profile?"')
        print('  python test_graph.py "What would break if I remove VPC endpoints?"')
        print('  python test_graph.py "Can I safely modify the endpoint security group?"')
        print('  python test_graph.py "What happens if I delete the VPC?"')
        print('  python test_graph.py "What cross-repo dependencies exist?"')
        print("="*80)

================
File: ea/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: ea/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: ea/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: ea/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: ea/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: ea/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: ea/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: ea/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: ea/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: ea/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: ea/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: ea/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: ea/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: ea/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: ea/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 777c65f3f601e5e4f6a4ca67d6f359eec419a40c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406156 -0600	clone: from github.com:enverus-cts/sre.ea.terraform.git

================
File: ea/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 777c65f3f601e5e4f6a4ca67d6f359eec419a40c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406156 -0600	clone: from github.com:enverus-cts/sre.ea.terraform.git

================
File: ea/.git/logs/HEAD
================
0000000000000000000000000000000000000000 777c65f3f601e5e4f6a4ca67d6f359eec419a40c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406156 -0600	clone: from github.com:enverus-cts/sre.ea.terraform.git

================
File: ea/.git/refs/heads/main
================
777c65f3f601e5e4f6a4ca67d6f359eec419a40c

================
File: ea/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: ea/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.ea.terraform.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: ea/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: ea/.git/HEAD
================
ref: refs/heads/main

================
File: ea/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
615a6f5fb38247a3fa73f51a95b213663bf23f56 refs/remotes/origin/NEXUS-825
8b601d4601cabe4fb5c5824a50690a5c394903f6 refs/remotes/origin/NEXUS-940
e12439cf4593937a8620441edf73516f44196ac0 refs/remotes/origin/chore--add-pre-commit
77c18ab691169e98dae8c27886fa0ae67c7b94cd refs/remotes/origin/fix-vpc-name
777c65f3f601e5e4f6a4ca67d6f359eec419a40c refs/remotes/origin/main

================
File: ea/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: ea/.github/dependabot.yaml
================
version: 2
updates:
  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "terraform"
    directory: "/"
    schedule:
      interval: "daily"
    commit-message:
      prefix: "fix"
      prefix-development: "build"
      include: "scope"
    allow:
      - dependency-type: "production"
    reviewers:
      - "@enverus-cts/sre"

================
File: ea/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)
                 
        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: ea/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response) 
            return { "parameter": response,"errorMessage":"none" } 
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'
          
          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}
        
        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled' 
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added' 
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'    
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'  
          
          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter'] 
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']
                 
          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)   
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'    
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)           
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.' 

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')
          
          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id) 
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: ea/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: ea/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: ea/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
#trigger atlantis
module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: ea/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: ea/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: ea/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: ea/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=v2.0.4"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: ea/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: ea/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: ea/config/.terraform-version
================
latest:^1.8

================
File: ea/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: ea/config/dev.backend.tfvars
================
key = "392865356492/dev/aws_config/terraform.tfstate"

================
File: ea/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: ea/config/main.tf
================
##AWS Config
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: ea/config/outputs.tf
================


================
File: ea/config/prod.backend.tfvars
================
key = "855411325150/prod/aws_config/terraform.tfstate"

================
File: ea/config/prod.tfvars
================
environment             = "prod"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: ea/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}


variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: ea/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: ea/github-webhooks/atlantis/.terraform-version
================
latest

================
File: ea/github-webhooks/atlantis/dev.backend.tfvars
================
# 392865356492 == ea-dev 
key            = "392865356492/dev/github-webhooks/atlantis/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/github-webhooks/atlantis/dev.tfvars
================
url                       = "https://atlantis-github.enverus.com/events"
vault_path_github_token   = "enverus-cts/github-tokens/svc-git-sre@enverus/webhook-management"
vault_path_webhook_secret = "enverus-cts/atlantis/github.com-webhook-secret"
repos = [
  "awsdp-glue",
  "awsdp",
  "batch_image_converter",
  "cos-director",
  "data-science.esg-retool.terraform",
  "data-science.platform.terraform",
  "data.esg.terraform",
  "data.wmd.terraform",
  "dsu-uploader",
  "ea.data.mfg.terraform",
  "ea.prefect_v2_agent.terraform",
  "geodata-services",
  "prism.data.terraform",
  "prism.etl.terraform",
  "rigs.airflow.terraform",
]

================
File: ea/github-webhooks/atlantis/main.tf
================
# Get a github access token from vault to manage org webhooks
data "vault_generic_secret" "gh_token" {
  path = var.vault_path_github_token
}

# this secret is created by another terraform module in the cts networking
# terraform repo
data "vault_generic_secret" "webhook_secret" {
  path = var.vault_path_webhook_secret
}

# Create webhooks for repos
resource "github_repository_webhook" "enverus-ea" {
  for_each = toset(var.repos)

  repository = each.key

  configuration {
    url          = var.url
    content_type = "json"
    insecure_ssl = false
    secret       = data.vault_generic_secret.webhook_secret.data.github_secret
  }

  active = true

  events = [
    "issue_comment",
    "pull_request",
    "pull_request_review",
    "pull_request_review_comment",
    "push"
  ]
  provider = github.enverus-ea
}

================
File: ea/github-webhooks/atlantis/variables.tf
================
# for provider
variable "url" {
  description = "atlantis webhook url"
  type        = string
}

variable "vault_path_github_token" {
  description = "path in vault to github token for provider"
  type        = string
}

variable "vault_path_webhook_secret" {
  description = "path in vault to the shared secret used by webhooks and by atlantis"
  type        = string
}

variable "repos" {
  description = " a list or repos in the org to deploy webhooks to"
  type        = list(string)
}

variable "vault_addr" {
  description = "vault address"
  default     = "https://vault.prod.cts.enverus.com"
}

================
File: ea/github-webhooks/atlantis/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    github = {
      source  = "integrations/github"
      version = "~> 5.0"
    }
    random = {
      source  = "hashicorp/random"
      version = ">= 2.0"
    }
    vault = {
      source  = "hashicorp/vault"
      version = ">= 3.3"
    }
  }
}

provider "vault" {
  address = var.vault_addr
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-ea"
  alias = "enverus-ea"
}

================
File: ea/iam/bedrock-cross-account-invocation/.terraform-version
================
latest

================
File: ea/iam/bedrock-cross-account-invocation/dev.backend.tfvars
================
key            = "392865356492/dev/iam/bedrock-cross-account-invocation/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/iam/bedrock-cross-account-invocation/dev.tfvars
================
role_name     = "bedrock-cross-account-invocation-role"
principal_arn = "arn:aws:iam::891150701981:root" # Shared-GenAI-Dev

================
File: ea/iam/bedrock-cross-account-invocation/main.tf
================
# Create a role that can be assumed by another AWS account to invoke bedrock models

resource "aws_iam_role" "this" {
  name = var.role_name

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Principal = {
          AWS = var.principal_arn
        },
        Action = "sts:AssumeRole"
      }
    ]
  })
}

resource "aws_iam_role_policy" "this" {
  name = var.role_name
  role = aws_iam_role.this.id

  policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Sid = "AllowListing",
        Effect = "Allow",
        Action = [
          "bedrock:ListFoundationModels",
          "bedrock:List*",
          "bedrock:Get*"
        ],
        Resource = "*"
      },
      {
        Sid = "AllowInvoking",
        Effect = "Allow",
        Action = [
          "bedrock:InvokeModel",
          "bedrock:InvokeModelWithResponseStream"
        ],
        Resource = "*"
      }
    ]
  })
}

================
File: ea/iam/bedrock-cross-account-invocation/prod.backend.tfvars
================
key            = "855411325150/prod/iam/bedrock-cross-account-invocation/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/iam/bedrock-cross-account-invocation/prod.tfvars
================
role_name     = "bedrock-cross-account-invocation-role"
principal_arn = "arn:aws:iam::126127704198:root" # Shared-GenAI-Prod

================
File: ea/iam/bedrock-cross-account-invocation/variables.tf
================
variable "assume_role_arn" {
  description = "The ARN of the role to assume, specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "role_name" {
  description = "The name of the role to create"
  type        = string
}

variable "principal_arn" {
  description = "The ARN of the principal that will assume the role"
  type        = string
}

================
File: ea/iam/bedrock-cross-account-invocation/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.45"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit = "ea"
      Component    = "bedrock"
      Team         = "sre@enverus.com"
      Environment  = var.env
      SourceCode   = "https://github.com/enverus-cts/sre.ea.terraform/tree/main/iam/bedrock-cross-account-invocation"
    }
  }
}

================
File: ea/prism-alerts/s3-bucket/dev.backend.tfvars
================
key = "392865356492/dev/prism-alerts/s3-bucket/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: ea/prism-alerts/s3-bucket/dev.tfvars
================
# Put dev-specific values here
bucket_name = "enverus-ea-prism-alerts-dev"

================
File: ea/prism-alerts/s3-bucket/main.tf
================
module "prism-alerts-s3-bucket" {
  source = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket.git"
  bucketname = var.bucket_name
  BucketOwnerPreferred = "BucketOwnerEnforced"
  EnableBackups = false

  providers = {
    aws.primary = aws.ue1
    aws.dr = aws.uw2
  }
}

================
File: ea/prism-alerts/s3-bucket/prod.backend.tfvars
================
key = "855411325150/prod/prism-alerts/s3-bucket/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: ea/prism-alerts/s3-bucket/prod.tfvars
================
# Put prod-specific values here
bucket_name = "enverus-ea-prism-alerts-prod"

================
File: ea/prism-alerts/s3-bucket/variables.tf
================
variable "bucket_name" {
  description = "Name to give the bucket.  Must be globally unique. https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html"
  type        = string
  default     = null
}

variable "env" {
  description = "environment, eg dev"
}

variable "bu" {
  description = "business unit, eg ea"
}

variable "region" {
  description = "aws region"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to (set in globals)"
}

================
File: ea/prism-alerts/s3-bucket/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.00"
    }
  }
}

provider "aws" {
  region = var.region
  alias  = "ue1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "prism-alerts"
      Team             = "Intelligent Alerting"
      SourceCode       = "https://github.com/enverus-cts/sre.ea.terraform/prism-alerts"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "foundations"
    }
  }
}

provider "aws" {
  region = var.region
  alias  = "uw2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "prism-alerts"
      Team             = "Intelligent Alerting"
      SourceCode       = "https://github.com/enverus-cts/sre.ea.terraform/prism-alerts"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "foundations"
    }
  }
}

================
File: ea/vpc/us-east-1/.terraform-version
================
latest

================
File: ea/vpc/us-east-1/dev.backend.tfvars
================
key            = "392865356492/dev/vpc/us-east-1/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/vpc/us-east-1/dev.tfvars
================
region                          = "us-east-1"
tag_name                        = "ea-vpc-dev"
vpc_cidr_block                  = "10.24.96.0/21"
enable_cgnat_subnet             = true
cloud_wan_core_network_id       = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment           = "nonprod"
enable_cloud_wan_vpc_attachment = true
consul_server_ip = [
  "10.25.11.104",
  "10.25.9.64",
  "10.25.15.15"
]
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: ea/vpc/us-east-1/main.tf
================
# Create a vpc using the vpc module

module "ea-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  tag_environment                      = var.env
  tag_name                             = var.tag_name
  vpc_cidr_block                       = var.vpc_cidr_block
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_ue1_az3                       = var.enable_ue1_az3
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}
output "vpc" { value = module.ea-vpc }

data "aws_default_tags" "aws_default_tags" {}

module "route53_resolver" {
  source           = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.route53-resolvers?ref=v1.2.1"
  vpc_name         = var.tag_name
  subnet_name_tags = ["*INSIDE | Private Subnet"]
  env              = var.env
  consul_server_ip = var.consul_server_ip
  enverus_domain_rules = {
    "enverus" = {
      "domain" = "enverus.com"
      "name"   = "DI-DNS-EN"
    },
    "drillinginfo" = {
      "domain" = "drillinginfo.com"
      "name"   = "DI-DNS"
    },
    "chi-gvsi" = {
      "domain" = "chi.gvsi.com"
      "name"   = "DI-DNS-chi-gvsi"
    },
    "oraclevcn" = {
      "domain" = "oraclevcn.com"
      "name"   = "Oraclevcn-Drillinginfo"
    },
    "azure-database" = {
      "domain" = "database.windows.net."
      "name"   = "Azure-Database-windows"
    },
    "transzapcom" = {
      "domain" = "transzap.com."
      "name"   = "OI-DNS"
    },
    "prod_aus" = {
      "domain" = "prod.aus"
      "name"   = "DI-DNS-prod-aus"
    }
  }
}

================
File: ea/vpc/us-east-1/prod.backend.tfvars
================
key            = "855411325150/vpc/us-east-1/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/vpc/us-east-1/prod.tfvars
================
region                          = "us-east-1"
tag_name                        = "ea-vpc-prod"
vpc_cidr_block                  = "10.24.112.0/21"
enable_cgnat_subnet             = true
cloud_wan_core_network_id       = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment           = "prod"
enable_cloud_wan_vpc_attachment = true
consul_server_ip = [
  "10.135.3.189",
  "10.135.6.181"
]
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: ea/vpc/us-east-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Enable vpc attachment to Cloud-WAN core network."
  type        = bool
}

variable "consul_server_ip" {
  description = "IP Address of a consul server to resolve .consul.service names"
  type        = list(string)
  default     = []

}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# If you have resources in AZ3 currently, enable this variable to use us-east-1-az3. Otherwise the subnet and its resources will be destroyed.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: ea/vpc/us-east-1/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.45"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ea"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/sre.ea.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: ea/vpc/us-west-2/.terraform-version
================
latest:^1.10

================
File: ea/vpc/us-west-2/dev.backend.tfvars
================
key            = "392865356492/dev/vpc/us-west-2/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/vpc/us-west-2/dev.tfvars
================
region                               = "us-west-2"
tag_name                             = "ea-vpc-dev"
vpc_cidr_block                       = "10.24.104.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: ea/vpc/us-west-2/main.tf
================
# Create a vpc using the vpc module

module "ea-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  tag_environment                      = var.env
  tag_name                             = var.tag_name
  vpc_cidr_block                       = var.vpc_cidr_block
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}
output "vpc" { value = module.ea-vpc }

data "aws_default_tags" "aws_default_tags" {}

module "route53_resolver" {
  source           = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.route53-resolvers?ref=v1.2.1"
  vpc_name         = var.tag_name
  subnet_name_tags = ["*INSIDE | Private Subnet"]
  env              = var.env
  enverus_domain_rules = {
    "enverus" = {
      "domain" = "enverus.com"
      "name"   = "DI-DNS-EN"
    },
    "drillinginfo" = {
      "domain" = "drillinginfo.com"
      "name"   = "DI-DNS"
    },
    "chi-gvsi" = {
      "domain" = "chi.gvsi.com"
      "name"   = "DI-DNS-chi-gvsi"
    },
    "oraclevcn" = {
      "domain" = "oraclevcn.com"
      "name"   = "Oraclevcn-Drillinginfo"
    },
    "azure-database" = {
      "domain" = "database.windows.net."
      "name"   = "Azure-Database-windows"
    },
    "transzapcom" = {
      "domain" = "transzap.com."
      "name"   = "OI-DNS"
    },
  }
}

================
File: ea/vpc/us-west-2/moved.tf
================
moved {
  from = module.cts-vpc
  to   = module.ea-vpc
}

================
File: ea/vpc/us-west-2/prod.backend.tfvars
================
key            = "855411325150/vpc/us-west-2/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: ea/vpc/us-west-2/prod.tfvars
================
region                               = "us-west-2"
tag_name                             = "ea-vpc-prod"
vpc_cidr_block                       = "10.24.120.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: ea/vpc/us-west-2/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Enable vpc attachment to Cloud-WAN core network."
  type        = bool
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: ea/vpc/us-west-2/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/sre.ea.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: ea/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy",
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ]
  },
  "dependents": {
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ]
  },
  "cross_repo_references": [
    "external.environment",
    "external.enable",
    "external.enable_cgnat_subnet",
    "external.configBackend",
    "external.vault_generic_secret.gh_token",
    "external.cloud_wan_core_network_id",
    "external.aws_default_tags.current",
    "external.vault_addr",
    "external.role_name",
    "external.vault_path_webhook_secret",
    "external.principal_arn",
    "external.region",
    "external.kms_exclusion_list",
    "external.url",
    "external.consul_server_ip",
    "external.multi",
    "external.vault_generic_secret.webhook_secret",
    "external.aws_config_sns",
    "external.vault_path_github_token",
    "external.enable_centralized_endpoints_profile",
    "external.vpc_cidr_block",
    "external.aws_caller_identity.current",
    "external.bu",
    "external.resource_type_exclusion_list",
    "external.tag_name",
    "external.cloudwatch_logs_endpoint_type",
    "external.enable_ue1_az3",
    "external.ecr_endpoint_type",
    "external.enable_cloud_wan_vpc_attachment",
    "external.repos",
    "external.bucket_name",
    "external.business_unit",
    "external.env",
    "external.tag_cloud_wan_segment",
    "external.assume_role_arn"
  ],
  "outputs": [
    "vpc",
    "vpc"
  ],
  "metadata": {
    "total_resources": 6,
    "resources_with_dependencies": 2,
    "resources_that_are_dependencies": 4,
    "cross_repo_refs_count": 35,
    "outputs_count": 2,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: ea/.gitignore
================
.terraform
terraform.tfsta*
jjb-macros-latest.yaml
jjb-templates-latest.yaml
.terraform.lock.hcl
.idea/
.DS_Store
/.vs/*
.vscode/

================
File: ea/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.97.4
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"

================
File: ea/atlantis.yaml
================
version: 3
automerge: false
projects:
  ############  cts vpc   #################
  - name: vpc-dev-us-east-1
    dir: vpc/us-east-1
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-dev-west-2
    dir: vpc/us-west-2
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-us-east-1
    dir: vpc/us-east-1
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod-us-west-2
    dir: vpc/us-west-2
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############# aws config ################
  - name: aws-config-dev
    dir: config
    workflow: dev
  - name: aws-config-prod
    dir: config
    workflow: prod
  ############# aws config ################
  - name: github-webhooks-atlantis-dev
    dir: github-webhooks/atlantis
    workflow: cts-dev-prod-vault
  ###### prism alerts s3 bucket ###########
  - name: prism-alerts-s3-dev
    dir: prism-alerts/s3-bucket
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: prism-alerts-s3-prod
    dir: prism-alerts/s3-bucket
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ### IAM role for bedrock ###
  - name: iam-bedrock-cross-account-invocation-dev
    dir: iam/bedrock-cross-account-invocation
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: iam-bedrock-cross-account-invocation-prod
    dir: iam/bedrock-cross-account-invocation
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]

================
File: ea/global-dev-backend.tfvars
================
assume_role             = { role_arn = "arn:aws:iam::392865356492:role/terraform" }
bucket                  = "enverus-centralized-terraform-state"
dynamodb_table          = "terraform-state-locking"
region                  = "us-east-1"
shared_credentials_file = "/secrets/vault_atlantis_ea_dev.env"

================
File: ea/global-dev.tfvars
================
bu              = "ea"
env             = "dev"
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"
assume_role_arn = "arn:aws:iam::392865356492:role/terraform"
vo_routing_key  = "key-DevUptime"
region          = "us-east-1"
aws_region      = "us-east-1"

================
File: ea/global-prod-backend.tfvars
================
assume_role             = { role_arn = "arn:aws:iam::855411325150:role/terraform" }
bucket                  = "enverus-centralized-terraform-state"
dynamodb_table          = "terraform-state-locking"
region                  = "us-east-1"
shared_credentials_file = "/secrets/vault_atlantis_ea_prod.env"

================
File: ea/global-prod.tfvars
================
bu              = "ea"
env             = "prod"
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"
assume_role_arn = "arn:aws:iam::855411325150:role/terraform"
vo_routing_key  = "key-ProdUptime"
region          = "us-east-1"
aws_region      = "us-east-1"

================
File: ea/README.md
================
# ea-terraform
Terraform repo for EA dev and prod

================
File: egress/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: egress/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: egress/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: egress/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: egress/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: egress/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: egress/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: egress/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: egress/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: egress/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: egress/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: egress/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: egress/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: egress/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: egress/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 f4e78316215a6f696d256dee4f5e04e8276f085c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406116 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc-egress.git

================
File: egress/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 f4e78316215a6f696d256dee4f5e04e8276f085c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406116 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc-egress.git

================
File: egress/.git/logs/HEAD
================
0000000000000000000000000000000000000000 f4e78316215a6f696d256dee4f5e04e8276f085c Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406116 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc-egress.git

================
File: egress/.git/refs/heads/main
================
f4e78316215a6f696d256dee4f5e04e8276f085c

================
File: egress/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: egress/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.tf-modules.aws-vpc-egress.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: egress/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: egress/.git/HEAD
================
ref: refs/heads/main

================
File: egress/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
738f14a4c638cf43c892477ca7c2ad020c44ce22 refs/remotes/origin/SRE-15022
bdee82542624990c7eb6d26f277c57519d0ea347 refs/remotes/origin/aztest
d2b7a5eba434ea93ac7fb3b623ab09a72b535b69 refs/remotes/origin/chore/sre-11688-add-release-action
78241359596e916a17013de524ac60f76e9e5110 refs/remotes/origin/chore/sre-12367-add-dependabot
183519fcefbc6cd76a33f5f4ecd3f7b14db8624d refs/remotes/origin/chore/sre-12522-improve-sem-rel
f6c70ccbb735d43e4f0dd84c2c946b9e680e6223 refs/remotes/origin/chore/sre-12541-add-ci-actions
3b9e7f8ab99af8c70d73de9956f848df252dfc6a refs/remotes/origin/dependabot/github_actions/actions/cache-4.2.4
bca4e61803444f4d736fa3f7ec70e50ad554dff0 refs/remotes/origin/dependabot/github_actions/actions/create-github-app-token-2.1.0
08852a6993f0f4a5ac2dcbb381c96aca4e1abcd2 refs/remotes/origin/dependabot/github_actions/dflook/terraform-fmt-2.2.2
f4e78316215a6f696d256dee4f5e04e8276f085c refs/remotes/origin/main
f15b35a96455318b39e7a496cf2265765cac3e7b refs/tags/v1.0.0
9726c0d23b630be158e6863158d56f37656d2a8e refs/tags/v1.1.0
cd0b40f78686834d6dbae8510de4ac9ee1f5b76f refs/tags/v1.2.0
9dcf8a4e3caf31faafab929a00b3ce9d2e77c7c1 refs/tags/v1.3.0
3a28947193b42fe7a0e4fd5e84e7c0552708cbff refs/tags/v1.4.0
a5565222ffe12a22d0740a27d7437b6c47dd8e96 refs/tags/v1.4.1
1515cac973b3b4a57b84d9d390d8aed6e37e64a3 refs/tags/v1.5.0
8c33ddbf01b8de22069e3f48d6cd7101991d0761 refs/tags/v1.5.1
62f92fc8d1f1cda87395a9119d42d0ab6b9ce1f8 refs/tags/v1.5.2

================
File: egress/.github/workflows/ci-release.yaml
================
name: Release

on:
  push:
    branches:
      - main
    paths-ignore:
      - "docs/**"
      - "examples/**"
      - ".tests/**"
      - ".github/**"

jobs:
  terraform:
    name: Release Terraform Module
    runs-on: enverus-ubuntu
    steps:

    - name: Checkout
      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2.5.3

    - name: Get changed files
      id: changed-files
      uses: tj-actions/changed-files@ed68ef82c095e0d48ec87eccea555d944a631a4c # v46.0.5
      with:
        files: |
          *.tf
          modules/**/*.tf
          charts/**/Chart.yaml
          charts/**/values.yaml
          charts/**/templates/**
          !.github/**
          !examples/**
          !.tests/**
          !docs/**

    - uses: enverus-cts/sre.actions.terraform-release@v0.2.0
      with:
        repoName: ${{ github.event.repository.name }}
        releaserGithubAppId: ${{ secrets.RELEASER_APP_ID }}
        releaserGithubAppPrivateKey: ${{ secrets.RELEASER_APP_PRIVATE_KEY_BASE64 }}

================
File: egress/.github/workflows/ci-terraform.yaml
================
---
name: feature-branch
on:
  workflow_dispatch:
  pull_request:
    branches:
      - main
      - release/**
    types: [opened, synchronize, reopened, labeled, unlabeled]
jobs:
  format:
    runs-on: enverus-ubuntu
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Terraform format
        uses: dflook/terraform-fmt@9a3b6ebe9cfc5ce4b34b86ffd234145adf074763 # v2.2.1

      - name: Reviewdog suggester
        # if: ${{ inputs.suggestions }}
        uses: reviewdog/action-suggester@4747dbc9f9e37adba0943e681cc20db466642158 # v0.20.3v1
        with:
          tool_name: "terraform fmt -recursive"
          cleanup: false
          filter_mode: diff_context

      - name: Status check
        shell: bash
        run: git diff --exit-code

  lint-find-dirs:
    runs-on: enverus-ubuntu
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - id: set-matrix
        run: |
          matrix=$(find ./ -name '*.tf' \
            -not -path '*/.terraform/*' \
            -exec dirname {} \; \
            | sort \
            | uniq \
            | jq --raw-input --slurp 'split("\n")| map(select(. != ""))')
          echo "matrix=$(echo $matrix)" >> $GITHUB_OUTPUT
    outputs:
      tfdirs_matrix: ${{ steps.set-matrix.outputs.matrix }}

  lint:
    runs-on: enverus-ubuntu
    needs: lint-find-dirs
    strategy:
      fail-fast: false
      matrix:
        tfdir: ${{ fromJson(needs.lint-find-dirs.outputs.tfdirs_matrix) }}
    env:
      TFLINT_PLUGIN_DIR: ${{ github.workspace }}/.tflint.d/plugins
      TFLINT_PLUGINS: aws
      TFLINT_CACHE_VER: 1 # Increment this to force a cache refresh
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Get github app pem key base64
        id: github-app-creds
        uses: enverus-cts/action-sre-vault-retrieve-secret@v1.0.1
        with:
          secret-path: "enverus-cts/github/enverus-cts/gh-app-action-workflow-rw"
          vault-server: "https://vault.prod.cts.enverus.com/"

      - name: Decode the GitHub App Private Key
        id: decode
        shell: bash
        run: |
          private_key=$(echo "${{ steps.github-app-creds.outputs.githubAppPrivateKeyB64 }}" | base64 -d | awk 'BEGIN {ORS="\\n"} {print}' | head -c -2) &> /dev/null
          echo "::add-mask::$private_key"
          echo "private-key=$private_key" >> "$GITHUB_OUTPUT"

      - name: Get token
        uses: actions/create-github-app-token@df432ceedc7162793a195dd1713ff69aefc7379e # v2.0.6
        id: app-token
        with:
          app-id: ${{ steps.github-app-creds.outputs.githubAppID }}
          private-key: ${{ steps.decode.outputs.private-key }}
          owner: "enverus-cts"

      - name: git insteadOf
        run: |
          git config --global url."https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/".insteadOf ssh://git@github.com/
          git config --global user.name "Enverus CI"
          git config --global user.email 'ci@enverus.com'
          git clone https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/enverus-cts/sre.tf-modules.aws-vpc-egress
        shell: bash

      - name: Setup Node.js
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4.4.0
        with:
          node-version: "18"

      - uses: hashicorp/setup-terraform@b9cd54a3c349d3f38e8881555d616ced269862dd # v3.1.2

      - run: terraform init
        working-directory: ${{ matrix.tfdir }}

      - name: cache tflint plugins
        id: cache-plugins
        uses: actions/cache@5a3ec84eff668545956fd18022155c47e93e2684 # v4.2.3
        with:
          path: ${{ env.TFLINT_PLUGIN_DIR }}
          key: tflint-plugins-${{ env.TFLINT_CACHE_VER }}

      - name: tflint
        uses: reviewdog/action-tflint@41b4770c9d9e50741c20e431986b33124a07ca52 # v1.24.2
        with:
          reporter: ${{ 'github-pr-review' || 'local' }}
          fail_on_error: true # Set to true when all tflint issues are fixed in all tf repo release branches
          tflint_rulesets: ${{ env.TFLINT_PLUGINS }}
          tflint_init: true
          tflint_version: "v0.49.0"
          working_directory: ${{ matrix.tfdir }}
          filter_mode: diff_context

  validate:
    runs-on: enverus-ubuntu
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          repository: ${{ github.event.pull_request.head.repo.full_name }}

      - name: Generate readme
        shell: bash
        run: |
          make gen

      - name: Check readme
        id: readme_diff
        shell: bash
        run: git diff --exit-code
        continue-on-error: true

      - name: Auto-update README.md for bot pull requests
        id: auto_commit
        if: |
          steps.readme_diff.outcome == 'failure'
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'gihub-actions[bot]@users.noreply.github.com'
          git commit -a -m "chore: auto-update README.md [skip-ci]"
          git push

================
File: egress/.github/workflows/pr-labeler.yaml
================
name: PR Labeler

on:
  pull_request:
    types: [opened]

jobs:
  pr-labeler:
    runs-on: enverus-ubuntu
    steps:
      - name: Appling automatically labels to the PRs
        uses: TimonVS/pr-labeler-action@v5.0.0
        with:
          configuration-path: .github/pr-labeler.yml
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

================
File: egress/.github/workflows/pr-lint.yaml
================
name: PR Lint

on:
  pull_request_target:
    types:
      - opened
      - edited
      - synchronize

jobs:
  main:
    name: Validate PR title
    runs-on: enverus-ubuntu
    steps:
      - uses: enverus-cts/sre.actions.pr-lint@v1.0.0
        with:
          githubToken: ${{ secrets.GITHUB_TOKEN }}

================
File: egress/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: egress/.github/dependabot.yaml
================
version: 2
updates:
  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "terraform"
    directory: "/"
    schedule:
      interval: "daily"
    commit-message:
      prefix: "fix"
      prefix-development: "build"
      include: "scope"
    allow:
      - dependency-type: "production"
    reviewers:
      - "@enverus-cts/sre"

================
File: egress/.github/pr-labeler.yaml
================
feature: ['feature/*', 'feat/*']
fix: 'fix/*'
bug: 'fix/*'
release: 'bc/*'

================
File: egress/examples/vpc/main.tf
================
# The values for `customer_gateway_bgp_asn`, `vpc_cidr_block` are completely made up for this example.

module "test-vpc" {
  aws_region                      = "us-east-1"
  source                          = "../../"
  tag_name                        = "vpc-test"
  tag_stack                       = "terraform-development"
  vpc_cidr_block                  = "172.19.16.0/21"
  enable_cloud_wan_vpc_attachment = true
  cloud_wan_core_network_id       = "core-network-00000000000000000"
  tag_cloud_wan_segment           = "dev"
}

================
File: egress/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_route53profiles_resource_association.phz_associations": [
      "aws_route53_record.endpoint_records",
      "aws_route53_zone.endpoint_phz",
      "aws_route53profiles_profile.centralized-endpoints-profile"
    ],
    "aws_route53profiles_resource_association.ssm_messages_phz_association": [
      "aws_route53_zone.ssm_messages_phz",
      "aws_route53_record.ssm_message_record",
      "aws_route53profiles_profile.centralized-endpoints-profile"
    ],
    "aws_route53profiles_resource_association.ecr_dkr_phz_association": [
      "aws_route53_record.wildcard_ecr_dkr_record",
      "aws_route53_zone.ecr_dkr_phz",
      "aws_route53profiles_profile.centralized-endpoints-profile"
    ],
    "aws_route53profiles_resource_association.cloudwatch_logs_phz_association": [
      "aws_route53_zone.cloudwatch_logs_phz",
      "aws_route53_record.cloudwatch_logs_record",
      "aws_route53profiles_profile.centralized-endpoints-profile"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.ssm_messages_phz": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.ecr_dkr_phz": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.cloudwatch_logs_phz": [
      "aws_vpc.vpc"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint.vpc_endpoints": [
      "aws_security_group.endpoint-sg",
      "aws_vpc.vpc",
      "aws_subnet.private"
    ],
    "aws_vpc_endpoint.ssm_messages_endpoint": [
      "aws_security_group.endpoint-sg",
      "aws_vpc.vpc",
      "aws_subnet.private"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_security_group.endpoint-sg",
      "aws_vpc.vpc",
      "aws_subnet.private"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_security_group.endpoint-sg",
      "aws_vpc.vpc",
      "aws_subnet.private"
    ],
    "aws_route.private_nat_gateway": [
      "aws_nat_gateway.nat_gateway",
      "aws_route_table.private"
    ],
    "aws_route.public_internet_gateway": [
      "aws_internet_gateway.internet_gateway",
      "aws_route_table.public"
    ],
    "aws_route_table_association.private": [
      "aws_subnet.private",
      "aws_route_table.private"
    ],
    "aws_route_table_association.public": [
      "aws_subnet.public",
      "aws_route_table.public"
    ],
    "aws_route.rfc-1918-public": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_route_table.public"
    ],
    "aws_route.rfc-1918-private": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_route_table.private"
    ],
    "aws_network_interface.network_interface": [
      "aws_nat_gateway.nat_gateway",
      "aws_subnet.public"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_subnet.public",
      "aws_internet_gateway.internet_gateway",
      "aws_eip.eip"
    ],
    "aws_security_group_rule.dmz_egress_default": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_http": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_https": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_icmp": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_egress_default": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_http": [
      "aws_security_group.dmz",
      "aws_security_group.inside"
    ],
    "aws_vpc_dhcp_options_association.dhcp_options_association": [
      "aws_vpc.vpc",
      "aws_vpc_dhcp_options.dhcp_options"
    ],
    "aws_route53_record.endpoint_records": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_route53_zone.endpoint_phz"
    ],
    "aws_route53_record.ssm_message_record": [
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_route53_zone.ssm_messages_phz"
    ],
    "aws_route53_record.wildcard_ecr_dkr_record": [
      "aws_route53_zone.ecr_dkr_phz",
      "aws_vpc_endpoint.ecr_dkr_endpoint"
    ],
    "aws_route53_record.cloudwatch_logs_record": [
      "aws_route53_zone.cloudwatch_logs_phz",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint"
    ]
  },
  "dependents": {
    "aws_route53_record.endpoint_records": [
      "aws_route53profiles_resource_association.phz_associations"
    ],
    "aws_route53_zone.endpoint_phz": [
      "aws_route53profiles_resource_association.phz_associations",
      "aws_route53_record.endpoint_records"
    ],
    "aws_route53profiles_profile.centralized-endpoints-profile": [
      "aws_route53profiles_resource_association.phz_associations",
      "aws_route53profiles_resource_association.ssm_messages_phz_association",
      "aws_route53profiles_resource_association.ecr_dkr_phz_association",
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association"
    ],
    "aws_route53_zone.ssm_messages_phz": [
      "aws_route53profiles_resource_association.ssm_messages_phz_association",
      "aws_route53_record.ssm_message_record"
    ],
    "aws_route53_record.ssm_message_record": [
      "aws_route53profiles_resource_association.ssm_messages_phz_association"
    ],
    "aws_route53_record.wildcard_ecr_dkr_record": [
      "aws_route53profiles_resource_association.ecr_dkr_phz_association"
    ],
    "aws_route53_zone.ecr_dkr_phz": [
      "aws_route53profiles_resource_association.ecr_dkr_phz_association",
      "aws_route53_record.wildcard_ecr_dkr_record"
    ],
    "aws_route53_zone.cloudwatch_logs_phz": [
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association",
      "aws_route53_record.cloudwatch_logs_record"
    ],
    "aws_route53_record.cloudwatch_logs_record": [
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association"
    ],
    "aws_vpc.vpc": [
      "aws_internet_gateway.internet_gateway",
      "aws_route53_zone.ssm_messages_phz",
      "aws_route53_zone.ecr_dkr_phz",
      "aws_route53_zone.cloudwatch_logs_phz",
      "aws_security_group.endpoint-sg",
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint"
    ],
    "aws_subnet.private": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_route_table_association.private"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_route.private_nat_gateway",
      "aws_network_interface.network_interface"
    ],
    "aws_route_table.private": [
      "aws_route.private_nat_gateway",
      "aws_route_table_association.private",
      "aws_route.rfc-1918-private"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_route.public_internet_gateway",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_route_table.public": [
      "aws_route.public_internet_gateway",
      "aws_route_table_association.public",
      "aws_route.rfc-1918-public"
    ],
    "aws_subnet.public": [
      "aws_route_table_association.public",
      "aws_network_interface.network_interface",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_networkmanager_vpc_attachment.vpc_attachment": [
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_eip.eip": [
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_security_group.dmz": [
      "aws_security_group_rule.dmz_egress_default",
      "aws_security_group_rule.dmz_ingress_http",
      "aws_security_group_rule.dmz_ingress_https",
      "aws_security_group_rule.dmz_ingress_icmp",
      "aws_security_group_rule.inside_ingress_http"
    ],
    "aws_security_group.inside": [
      "aws_security_group_rule.inside_egress_default",
      "aws_security_group_rule.inside_ingress_http"
    ],
    "aws_vpc_dhcp_options.dhcp_options": [
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ],
    "aws_vpc_endpoint.vpc_endpoints": [
      "aws_route53_record.endpoint_records"
    ],
    "aws_vpc_endpoint.ssm_messages_endpoint": [
      "aws_route53_record.ssm_message_record"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_route53_record.wildcard_ecr_dkr_record"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_route53_record.cloudwatch_logs_record"
    ]
  },
  "cross_repo_references": [
    "external.aws_region",
    "external.enabled_endpoints",
    "external.availability_zone_count",
    "external.enable_ecr_dkr_endpoint",
    "external.endpoint_timeout_create",
    "external.cloud_wan_core_network_id",
    "external.availabilty_zone_list",
    "external.tag_name",
    "external.tag_cloud_wan_segment",
    "external.dhcp_options_domain_name",
    "external.endpoint_config",
    "external.enable_ssm_messages_endpoint",
    "external.private_supernet",
    "external.eip_timeout_read",
    "external.dhcp_options_domain_name_servers",
    "external.endpoint_timeout_delete",
    "external.vpc_cidr_block",
    "external.eip_timeout_delete",
    "external.endpoint_timeout_update",
    "external.eip_timeout_update",
    "external.enable_cloudwatch_logs_endpoint",
    "external.security_group_rule_inside_cidr_blocks",
    "external.public_supernet"
  ],
  "outputs": [
    "aws_vpc_dhcp_options",
    "aws_vpc_dhcp_options_association",
    "aws_eip",
    "aws_internet_gateway",
    "aws_nat_gateway",
    "aws_network_interface",
    "aws_security_group_dmz",
    "aws_security_group_rule_dmz_egress_default",
    "aws_security_group_rule_dmz_ingress_http",
    "aws_security_group_rule_dmz_ingress_https",
    "aws_security_group_inside",
    "aws_security_group_rule_inside_egress_default",
    "aws_security_group_rule_inside_ingress_http",
    "aws_subnet_private",
    "aws_subnet_public",
    "aws_vpc",
    "vpc_id",
    "aws_networkmanager_vpc_attachment",
    "route53_profile_arn"
  ],
  "metadata": {
    "total_resources": 44,
    "resources_with_dependencies": 32,
    "resources_that_are_dependencies": 26,
    "cross_repo_refs_count": 23,
    "outputs_count": 19,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: egress/.gitignore
================
node_modules/
typescript

================
File: egress/.releaserc
================
{
  "branches": [
    "main"
  ],
  "plugins": [
    "@semantic-release/commit-analyzer",
    [
      "semantic-release-jira-notes",
      {
        "jiraHost": "drillinginfo.atlassian.net",
        "ticketPrefixes": [
          "SRE",
          "NEXUS"
        ],
        "preset": "conventionalcommits",
        "presetConfig": {
          "types": [
            {
              "type": "feat",
              "section": "Features"
            },
            {
              "type": "fix",
              "section": "Bug Fixes"
            },
            {
              "type": "revert",
              "section": "Reverts"
            },
            {
              "type": "chore",
              "section": "Miscellaneous Chores"
            }
          ]
        }
      }
    ],
    [
      "@semantic-release/github"
    ],
    [
      "@semantic-release/changelog",
      {
        "changelogFile": "CHANGELOG.md"
      }
    ],
    [
      "@semantic-release/git",
      {
        "assets": [
          "CHANGELOG.md"
        ]
      }
    ],
    [
      "semantic-release-ms-teams",
      {
        "webhookUrl": "https://drillinginfo.webhook.office.com/webhookb2/4a035bb2-7aab-4668-879e-6d7add60a35c@61f90f11-8d76-4b05-9b09-90af7d07328a/IncomingWebhook/6b77492907c740cb862c5f5af3d72eab/bdd3e6a1-7ee8-4ae1-a516-ceccd765cc86",
        "title": "A new version of sre.tf-modules.aws-vpc-egress has been released",
        "imageUrl": "https://blogs.vmware.com/cloudprovider/files/2019/04/og-image-8b3e4f7d-blog-aspect-ratio.png",
        "showContributors": true,
        "notifyInDryRun": false
      }
    ]
  ]
}

================
File: egress/.semver-output
================
[7:34:06 PM] [semantic-release]    Published release 1.5.2 on default channel

================
File: egress/.terraform-version
================
latest:^1.9

================
File: egress/CHANGELOG.md
================
## [1.5.2](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.5.1...v1.5.2) (2025-07-31)


### Bug Fixes

* Add missing depends_on attributes for resource associations in Route 53 profiles ([#24](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/24)) ([d767e19](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/d767e197134f54a1f53ee2b43d23389b8077864c))


### Miscellaneous Chores

* update  to 1.5.2 [skip ci] ([83de83e](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/83de83e547dec1dc25f07cf7b5d164e5910809c0))

## [1.5.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.5.0...v1.5.1) (2025-07-25)


### Bug Fixes

* **[SRE-15385](https://drillinginfo.atlassian.net/browse/SRE-15385):** Fix endpoint association with Route 53 profile issues. ([#23](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/23)) ([a3cc290](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/a3cc2903ffb4593739fb2dc0bd59a5e62d951b52))


### Miscellaneous Chores

* update  to 1.5.1 [skip ci] ([a74bc5d](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/a74bc5d9e79fa9e374de4c7b12db8f90ac61a2ea))

## [1.5.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.4.1...v1.5.0) (2025-07-24)


### Features

* **[SRE-15385](https://drillinginfo.atlassian.net/browse/SRE-15385):** Updated to use Route 53 profiles for centralized endpoint access. ([#22](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/22)) ([708c914](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/708c9141d645b372364dbf2388c751c5ab801325))


### Miscellaneous Chores

* update  to 1.5.0 [skip ci] ([588a1cd](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/588a1cd6df3d7c8b41c9118be20e64aa260f068c))

## [1.4.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.4.0...v1.4.1) (2025-07-14)


### Bug Fixes

* **[SRE-15165](https://drillinginfo.atlassian.net/browse/SRE-15165):** Removing S3 and DynamoDB endpoints from Egress VPC Module ([#20](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/20)) ([7bdf020](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/7bdf0200e77738084316b7ef1106cd461a4f2ebd))
* **[SRE-15165](https://drillinginfo.atlassian.net/browse/SRE-15165):** Removing S3 and DynamoDB Gateway endpoints ([#21](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/21)) ([580b93f](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/580b93fd9ec4b779523184ef937668de826dd5b4))


### Miscellaneous Chores

* **release:** 1.4.1 [skip ci] ([bda9876](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/bda98761b9ae3191b1d92903e5b9b734670a7b49)), closes [#20](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/20)
* update  to 1.4.1 [skip ci] ([d24bb5e](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/d24bb5e42c36a52bc9d1a224802223fdb845c923))
* update  to 1.4.1 [skip ci] ([3cc37e4](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/3cc37e4915d875452bdc9a33e84d54406d7308c6))

## [1.4.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.4.0...v1.4.1) (2025-07-14)


### Bug Fixes

* **[SRE-15165](https://drillinginfo.atlassian.net/browse/SRE-15165):** Removing S3 and DynamoDB endpoints from Egress VPC Module ([#20](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/20)) ([7bdf020](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/7bdf0200e77738084316b7ef1106cd461a4f2ebd))


### Miscellaneous Chores

* update  to 1.4.1 [skip ci] ([3cc37e4](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/3cc37e4915d875452bdc9a33e84d54406d7308c6))

## [1.4.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/compare/v1.3.0...v1.4.0) (2025-07-10)


### Features

* **[SRE-15155](https://drillinginfo.atlassian.net/browse/SRE-15155):** Setting up branch for CloudWAN testing ([#18](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/18)) ([f9fd675](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/f9fd675c27cf385211f4ab68640868fd98ae386d))


### Miscellaneous Chores

* **deps:** bump dflook/terraform-fmt from 1.48.0 to 2.0.0 ([#16](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/16)) ([dbd20e9](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/dbd20e9c9806aaa251b84f967be1773bee9204a2))
* **deps:** bump dflook/terraform-fmt from 2.0.0 to 2.0.1 ([#17](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/17)) ([123e4cd](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/123e4cd05ec3d3a9749fecb9f2b47144030da50e))
* **deps:** bump dflook/terraform-fmt from 2.0.1 to 2.1.0 ([#19](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/19)) ([22e42f2](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/22e42f226eec6936326e978064dac3a3503bbc44))
* **[SRE-14757](https://drillinginfo.atlassian.net/browse/SRE-14757):** add codeowners ([#9](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/9)) ([6c90936](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/6c90936bc8b9544946a939bf8861cac10e4b7b66))
* **[SRE-14757](https://drillinginfo.atlassian.net/browse/SRE-14757):** update actions and possibly dependabot ([#10](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/10)) ([613a63e](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/613a63e6ff846d6c5e316f3bf58224d2b45b2877))
* update  to 1.4.0 [skip ci] ([a041bdf](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/a041bdf4ee6a3e80283ce7044a80eabe03747e04))
* update action versions in CI workflows ([#15](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/issues/15)) ([ade4633](https://github.com/enverus-cts/sre.tf-modules.aws-vpc-egress/commit/ade463327ea9674d0290f4d84c19f956dabf9bf4))

## Unreleased

* Enable DNS Hostnames

## 1.1.0 (2019-06-10)

* Remove Customer Gateway and VPW resources


## 1.0.0 (2019-06-05)

* Remove Transit Gateway resources (Created with Aviatrix)


## 0.0.4 (2019-06-04)

* Use dynamic routing for VPN connections
* Set default BGP ASN for Customer Gateways


## 0.0.3 (2019-04-25)

* Use boolean comparison where applicable
* Separate examples for vpc with(out) attaching to a transit gateway
* Remove provider block from module


## 0.0.2 (2019-04-09)

* Add VPN security group
* Add missing `aws_security_group_rule` resources for the INSIDE security group
* Add variables for CIDR blocks used in security group rule resources
* Remove variables for the description argument of the `aws_security_group` resource
* Add variables `customer_gateway_bgp_asn` and `customer_gateway_ip_address`
* Add data source `aws_ec2_transit_gateway` conditionally for variable `attach_transit_gateway`
* Add a route, conditionally, on each private route table for the transit gateway
* Add transit gateway attachment (conditionally)
* Update the example to test transit gateway attachment


## 0.0.1 (2019-03-28)

* Initial Release

================
File: egress/clould-wan.tf
================
# Core Network policy attachment

resource "aws_networkmanager_vpc_attachment" "vpc_attachment" {
  subnet_arns     = aws_subnet.private[*].arn
  core_network_id = var.cloud_wan_core_network_id
  vpc_arn         = aws_vpc.vpc.arn

  tags = {
    cloud-wan = var.tag_cloud_wan_segment
    Name      = "Egress-${var.aws_region}"
  }
  depends_on = [aws_vpc.vpc]
}

================
File: egress/dhcp_options.tf
================
resource "aws_vpc_dhcp_options" "dhcp_options" {
  domain_name         = var.dhcp_options_domain_name
  domain_name_servers = var.dhcp_options_domain_name_servers

  tags = {
    Component = "dhcp-options"
    Name      = var.tag_name
  }
}

resource "aws_vpc_dhcp_options_association" "dhcp_options_association" {
  dhcp_options_id = aws_vpc_dhcp_options.dhcp_options.id
  vpc_id          = aws_vpc.vpc.id
}

================
File: egress/egress_dependency_graph.json
================
{
  "repo_name": "egress",
  "dependencies": {
    "aws_route53profiles_resource_association.phz_associations": [
      "aws_route53profiles_profile.centralized-endpoints-profile",
      "aws_route53_zone.endpoint_phz",
      "aws_route53_record.endpoint_records"
    ],
    "aws_route53profiles_resource_association.ssm_messages_phz_association": [
      "aws_route53_zone.ssm_messages_phz",
      "aws_route53profiles_profile.centralized-endpoints-profile",
      "aws_route53_record.ssm_message_record"
    ],
    "aws_route53profiles_resource_association.ecr_dkr_phz_association": [
      "aws_route53profiles_profile.centralized-endpoints-profile",
      "aws_route53_zone.ecr_dkr_phz",
      "aws_route53_record.wildcard_ecr_dkr_record"
    ],
    "aws_route53profiles_resource_association.cloudwatch_logs_phz_association": [
      "aws_route53profiles_profile.centralized-endpoints-profile",
      "aws_route53_zone.cloudwatch_logs_phz",
      "aws_route53_record.cloudwatch_logs_record"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.ssm_messages_phz": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.ecr_dkr_phz": [
      "aws_vpc.vpc"
    ],
    "aws_route53_zone.cloudwatch_logs_phz": [
      "aws_vpc.vpc"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint.vpc_endpoints": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_endpoint.ssm_messages_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_route.private_nat_gateway": [
      "aws_nat_gateway.nat_gateway",
      "aws_route_table.private"
    ],
    "aws_route.public_internet_gateway": [
      "aws_internet_gateway.internet_gateway",
      "aws_route_table.public"
    ],
    "aws_route_table_association.private": [
      "aws_subnet.private",
      "aws_route_table.private"
    ],
    "aws_route_table_association.public": [
      "aws_route_table.public",
      "aws_subnet.public"
    ],
    "aws_route.rfc-1918-public": [
      "aws_route_table.public",
      "aws_networkmanager_vpc_attachment.vpc_attachment"
    ],
    "aws_route.rfc-1918-private": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_route_table.private"
    ],
    "aws_network_interface.network_interface": [
      "aws_subnet.public",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_internet_gateway.internet_gateway",
      "aws_subnet.public",
      "aws_eip.eip"
    ],
    "aws_security_group_rule.dmz_egress_default": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_http": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_https": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_icmp": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_egress_default": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_http": [
      "aws_security_group.inside",
      "aws_security_group.dmz"
    ],
    "aws_vpc_dhcp_options_association.dhcp_options_association": [
      "aws_vpc.vpc",
      "aws_vpc_dhcp_options.dhcp_options"
    ],
    "aws_route53_record.endpoint_records": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_route53_zone.endpoint_phz"
    ],
    "aws_route53_record.ssm_message_record": [
      "aws_route53_zone.ssm_messages_phz",
      "aws_vpc_endpoint.ssm_messages_endpoint"
    ],
    "aws_route53_record.wildcard_ecr_dkr_record": [
      "aws_route53_zone.ecr_dkr_phz",
      "aws_vpc_endpoint.ecr_dkr_endpoint"
    ],
    "aws_route53_record.cloudwatch_logs_record": [
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_route53_zone.cloudwatch_logs_phz"
    ]
  },
  "dependents": {
    "aws_route53profiles_profile.centralized-endpoints-profile": [
      "aws_route53profiles_resource_association.phz_associations",
      "aws_route53profiles_resource_association.ssm_messages_phz_association",
      "aws_route53profiles_resource_association.ecr_dkr_phz_association",
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association"
    ],
    "aws_route53_zone.endpoint_phz": [
      "aws_route53profiles_resource_association.phz_associations",
      "aws_route53_record.endpoint_records"
    ],
    "aws_route53_record.endpoint_records": [
      "aws_route53profiles_resource_association.phz_associations"
    ],
    "aws_route53_zone.ssm_messages_phz": [
      "aws_route53profiles_resource_association.ssm_messages_phz_association",
      "aws_route53_record.ssm_message_record"
    ],
    "aws_route53_record.ssm_message_record": [
      "aws_route53profiles_resource_association.ssm_messages_phz_association"
    ],
    "aws_route53_zone.ecr_dkr_phz": [
      "aws_route53profiles_resource_association.ecr_dkr_phz_association",
      "aws_route53_record.wildcard_ecr_dkr_record"
    ],
    "aws_route53_record.wildcard_ecr_dkr_record": [
      "aws_route53profiles_resource_association.ecr_dkr_phz_association"
    ],
    "aws_route53_zone.cloudwatch_logs_phz": [
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association",
      "aws_route53_record.cloudwatch_logs_record"
    ],
    "aws_route53_record.cloudwatch_logs_record": [
      "aws_route53profiles_resource_association.cloudwatch_logs_phz_association"
    ],
    "aws_vpc.vpc": [
      "aws_internet_gateway.internet_gateway",
      "aws_route53_zone.ssm_messages_phz",
      "aws_route53_zone.ecr_dkr_phz",
      "aws_route53_zone.cloudwatch_logs_phz",
      "aws_security_group.endpoint-sg",
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ],
    "aws_subnet.private": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_route_table_association.private"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc_endpoint.vpc_endpoints",
      "aws_vpc_endpoint.ssm_messages_endpoint",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_route.private_nat_gateway",
      "aws_network_interface.network_interface"
    ],
    "aws_route_table.private": [
      "aws_route.private_nat_gateway",
      "aws_route_table_association.private",
      "aws_route.rfc-1918-private"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_route.public_internet_gateway",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_route_table.public": [
      "aws_route.public_internet_gateway",
      "aws_route_table_association.public",
      "aws_route.rfc-1918-public"
    ],
    "aws_subnet.public": [
      "aws_route_table_association.public",
      "aws_network_interface.network_interface",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_networkmanager_vpc_attachment.vpc_attachment": [
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_eip.eip": [
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_security_group.dmz": [
      "aws_security_group_rule.dmz_egress_default",
      "aws_security_group_rule.dmz_ingress_http",
      "aws_security_group_rule.dmz_ingress_https",
      "aws_security_group_rule.dmz_ingress_icmp",
      "aws_security_group_rule.inside_ingress_http"
    ],
    "aws_security_group.inside": [
      "aws_security_group_rule.inside_egress_default",
      "aws_security_group_rule.inside_ingress_http"
    ],
    "aws_vpc_dhcp_options.dhcp_options": [
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ],
    "aws_vpc_endpoint.vpc_endpoints": [
      "aws_route53_record.endpoint_records"
    ],
    "aws_vpc_endpoint.ssm_messages_endpoint": [
      "aws_route53_record.ssm_message_record"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_route53_record.wildcard_ecr_dkr_record"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_route53_record.cloudwatch_logs_record"
    ]
  },
  "cross_repo_references": [
    "external.vpc_cidr_block",
    "external.enable_cloudwatch_logs_endpoint",
    "external.endpoint_config",
    "external.enabled_endpoints",
    "external.enable_ecr_dkr_endpoint",
    "external.private_supernet",
    "external.public_supernet",
    "external.security_group_rule_inside_cidr_blocks",
    "external.availabilty_zone_list",
    "external.endpoint_timeout_update",
    "external.eip_timeout_delete",
    "external.dhcp_options_domain_name",
    "external.availability_zone_count",
    "external.tag_cloud_wan_segment",
    "external.tag_name",
    "external.dhcp_options_domain_name_servers",
    "external.eip_timeout_read",
    "external.endpoint_timeout_create",
    "external.enable_ssm_messages_endpoint",
    "external.aws_region",
    "external.eip_timeout_update",
    "external.cloud_wan_core_network_id",
    "external.endpoint_timeout_delete"
  ],
  "outputs": [
    "aws_vpc_dhcp_options",
    "aws_vpc_dhcp_options_association",
    "aws_eip",
    "aws_internet_gateway",
    "aws_nat_gateway",
    "aws_network_interface",
    "aws_security_group_dmz",
    "aws_security_group_rule_dmz_egress_default",
    "aws_security_group_rule_dmz_ingress_http",
    "aws_security_group_rule_dmz_ingress_https",
    "aws_security_group_inside",
    "aws_security_group_rule_inside_egress_default",
    "aws_security_group_rule_inside_ingress_http",
    "aws_subnet_private",
    "aws_subnet_public",
    "aws_vpc",
    "vpc_id",
    "aws_networkmanager_vpc_attachment",
    "route53_profile_arn"
  ],
  "metadata": {
    "total_resources": 44,
    "resources_with_dependencies": 32,
    "resources_that_are_dependencies": 26,
    "cross_repo_refs_count": 23,
    "outputs_count": 19,
    "generated_from": ".",
    "repo_name": "egress"
  }
}

================
File: egress/elastic_ips.tf
================
resource "aws_eip" "eip" {
  count  = var.availability_zone_count
  domain = "vpc"

  tags = {
    Component = "elastic-ip"
    Name      = var.tag_name
  }

  timeouts {
    delete = var.eip_timeout_delete
    read   = var.eip_timeout_read
    update = var.eip_timeout_update
  }
}

================
File: egress/endpoints.tf
================
# IMPORTANT: DO NOT CREATE S3 AND DYNAMODB GATEWAY ENDPOINTS.
# They do not work cross account. Any VPC that does not have these endpoints locally will fail to access S3 and DynamoDB if there is an endpoint for them in the Egress VPC.

# Security group to allow endpoint access
resource "aws_security_group" "endpoint-sg" {
  name        = "EndpointSecurityGroup"
  description = "Security group for VPC endpoints access"
  vpc_id      = aws_vpc.vpc.id

  ingress {
    description     = "Allow all inbound traffic from prefix list"
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.rfc-1918.id]
  }

  egress {
    description = "Allow all outbound traffic"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# Create VPC endpoints for all enabled services
resource "aws_vpc_endpoint" "vpc_endpoints" {
  for_each = toset(local.enabled_endpoints)

  service_name        = local.endpoint_service_names[each.key]
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = false
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = local.endpoint_display_names[each.key]
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

# SSM Messages Endpoint
resource "aws_vpc_endpoint" "ssm_messages_endpoint" {
  count               = var.enable_ssm_messages_endpoint ? 1 : 0
  service_name        = "com.amazonaws.${var.aws_region}.ssmmessages"
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = false
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = "SSM Messages Endpoint"
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

# ECR Docker Registry Endpoint
resource "aws_vpc_endpoint" "ecr_dkr_endpoint" {
  count               = var.enable_ecr_dkr_endpoint ? 1 : 0
  service_name        = "com.amazonaws.${var.aws_region}.ecr.dkr"
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = false
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = "ECR DKR Endpoint"
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

# CloudWatch Logs Endpoint
resource "aws_vpc_endpoint" "cloudwatch_logs_endpoint" {
  count               = var.enable_cloudwatch_logs_endpoint ? 1 : 0
  service_name        = "com.amazonaws.${var.aws_region}.logs"
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = false
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = "CloudWatch Logs Endpoint"
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

================
File: egress/internet_gateways.tf
================
resource "aws_internet_gateway" "internet_gateway" {
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "internet-gateway"
    Name      = var.tag_name
  }
}

================
File: egress/locals.tf
================
locals {
  private_subnet_cidrs = [
    for i in range(var.availability_zone_count) : cidrsubnet(var.private_supernet, 2, i)
  ]

  public_subnet_cidrs = [
    for i in range(var.availability_zone_count) : cidrsubnet(var.public_supernet, 2, i)
  ]

  # Use the passed-in endpoint list
  enabled_endpoints = var.enabled_endpoints

  # Build regional-specific mappings from passed config
  endpoint_domains = {
    for key in var.enabled_endpoints : key => "${var.endpoint_config[key].domain}.${var.aws_region}.amazonaws.com"
  }

  endpoint_record_names = {
    for key in var.enabled_endpoints : key => "${var.endpoint_config[key].record_name}.${var.aws_region}.amazonaws.com"
  }

  endpoint_service_names = {
    for key in var.enabled_endpoints : key => "com.amazonaws.${var.aws_region}.${var.endpoint_config[key].service_name}"
  }

  endpoint_display_names = {
    for key in var.enabled_endpoints : key => var.endpoint_config[key].display_name
  }
}

================
File: egress/Makefile
================
.PHONY: gen _gen-main _gen-examples _gen-modules

CURRENT_DIR     = $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
TF_EXAMPLES     = $(sort $(dir $(wildcard $(CURRENT_DIR)examples/*/)))
TF_MODULES      = $(sort $(dir $(wildcard $(CURRENT_DIR)modules/*/)))
TF_DOCS_VERSION = 0.16.0

# Adjust your delimiter here or overwrite via make arguments
DELIM_START = <!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
DELIM_CLOSE = <!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

gen:
	@echo "################################################################################"
	@echo "# Terraform-docs generate"
	@echo "################################################################################"
	@$(MAKE) _gen-main

_gen-main:
	@echo "------------------------------------------------------------"
	@echo "# Main module"
	@echo "------------------------------------------------------------"
	@if docker run --rm \
		-v $(CURRENT_DIR):/data \
		-e DELIM_START='$(DELIM_START)' \
		-e DELIM_CLOSE='$(DELIM_CLOSE)' \
		cytopia/terraform-docs:${TF_DOCS_VERSION} \
		terraform-docs-replace-012 md README.md; then \
		echo "OK"; \
	else \
		echo "Failed"; \
		exit 1; \
	fi

================
File: egress/nat_gateways.tf
================
resource "aws_nat_gateway" "nat_gateway" {
  depends_on    = [aws_internet_gateway.internet_gateway]
  count         = length(local.public_subnet_cidrs)
  allocation_id = element(aws_eip.eip.*.id, count.index)
  subnet_id     = element(aws_subnet.public.*.id, count.index)

  tags = {
    Component = "nat-gateway"
    Name      = var.tag_name
  }
}

================
File: egress/network_interfaces.tf
================
resource "aws_network_interface" "network_interface" {
  count       = length(local.public_subnet_cidrs)
  description = "NAT Gateway network Interface"

  #  description       = "Interface for NAT Gateway ${element(aws_nat_gateway.nat_gateway.*.id, count.index)}"
  subnet_id = element(aws_subnet.public.*.id, count.index)

  tags = {
    Component = "network-interface"
    Name      = var.tag_name
  }
}

================
File: egress/outputs.tf
================
#DHCP
output "aws_vpc_dhcp_options" {
  description = "VPC DHCP options"
  value       = aws_vpc_dhcp_options.dhcp_options
}

output "aws_vpc_dhcp_options_association" {
  description = "VPC DHCP Options association"
  value       = aws_vpc_dhcp_options_association.dhcp_options_association
}

#EIP
output "aws_eip" {
  description = "Elastic IP's used"
  value       = aws_eip.eip
}

#GATEWAYS
output "aws_internet_gateway" {
  description = "VPC Internet Gateway"
  value       = aws_internet_gateway.internet_gateway
}

output "aws_nat_gateway" {
  description = "VPC NAT Gateway"
  value       = aws_nat_gateway.nat_gateway
}

#NETWORK INTERFACE
output "aws_network_interface" {
  description = "VPC Network Interfaces"
  value       = aws_network_interface.network_interface
}

#SECURITY GROUPS
# output "aws_security_group_dmz" {
#   description = "DMZ Security Group"
#   value       = aws_security_group.dmz
# }

# output "aws_security_group_rule_dmz_egress_default" {
#   description = "DMZ egress default rule"
#   value       = aws_security_group_rule.dmz_egress_default
# }

# output "aws_security_group_rule_dmz_ingress_http" {
#   description = "Allow ingress HTTP from inside CIDR."
#   value       = aws_security_group_rule.dmz_ingress_http
# }

# output "aws_security_group_rule_dmz_ingress_https" {
#   description = "Allow ingress HTTPS from inside CIDR."
#   value       = aws_security_group_rule.dmz_ingress_https
# }

# output "aws_security_group_inside" {
#   description = "Inside Security Group"
#   value       = aws_security_group.inside
# }

# output "aws_security_group_rule_inside_egress_default" {
#   description = "Allow all egress traffic."
#   value       = aws_security_group_rule.inside_egress_default
# }

# output "aws_security_group_rule_inside_ingress_http" {
#   description = "Allow HTTP ingress from inside CIDR."
#   value       = aws_security_group_rule.inside_ingress_http
# }

#SUBNETS

output "aws_subnet_private" {
  description = "Private subnets"
  value       = aws_subnet.private
}

output "aws_subnet_public" {
  description = "Public Subnets"
  value       = aws_subnet.public
}

#VPC

output "aws_vpc" {
  description = "Created VPC"
  value       = aws_vpc.vpc
}

output "vpc_id" {
  description = "ID of created VPC."
  value       = aws_vpc.vpc.id
}

output "aws_networkmanager_vpc_attachment" {
  description = "CloudWan attachment"
  value       = aws_networkmanager_vpc_attachment.vpc_attachment
}

output "route53_profile_arn" {
  description = "ARN of the Route 53 profile for centralized endpoints"
  value       = aws_route53profiles_profile.centralized-endpoints-profile.arn
}

================
File: egress/package.json
================
{
  "devDependencies": {
    "@semantic-release/changelog": "^6.0.3",
    "@semantic-release/commit-analyzer": "^9.0.2",
    "@semantic-release/git": "^10.0.1",
    "@semantic-release/github": "^8.0.7",
    "conventional-changelog-conventionalcommits": "^7.0.2",
    "semantic-release": "^19.0.5",
    "semantic-release-jira-notes": "^3.0.0",
    "semantic-release-ms-teams": "^2.1.0"
  }
}

================
File: egress/prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "rfc-1918" {
  name = "All RFC-1918 CIDR-s - shared"
}

================
File: egress/README.md
================
# AWS VPC Terraform Module

<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.9.0 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | >= 4.32 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_aws"></a> [aws](#provider\_aws) | >= 4.32 |

## Modules

No modules.

## Resources

| Name | Type |
|------|------|
| [aws_eip.eip](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eip) | resource |
| [aws_internet_gateway.internet_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway) | resource |
| [aws_nat_gateway.nat_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/nat_gateway) | resource |
| [aws_network_interface.network_interface](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_interface) | resource |
| [aws_networkmanager_vpc_attachment.vpc_attachment](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/networkmanager_vpc_attachment) | resource |
| [aws_route.private_nat_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.public_internet_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.rfc-1918-private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.rfc-1918-public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route53_record.cloudwatch_logs_record](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record) | resource |
| [aws_route53_record.endpoint_records](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record) | resource |
| [aws_route53_record.ssm_message_record](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record) | resource |
| [aws_route53_record.wildcard_ecr_dkr_record](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record) | resource |
| [aws_route53_zone.cloudwatch_logs_phz](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_zone) | resource |
| [aws_route53_zone.ecr_dkr_phz](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_zone) | resource |
| [aws_route53_zone.endpoint_phz](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_zone) | resource |
| [aws_route53_zone.ssm_messages_phz](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_zone) | resource |
| [aws_route53profiles_profile.centralized-endpoints-profile](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_profile) | resource |
| [aws_route53profiles_resource_association.cloudwatch_logs_phz_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_resource_association) | resource |
| [aws_route53profiles_resource_association.ecr_dkr_phz_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_resource_association) | resource |
| [aws_route53profiles_resource_association.phz_associations](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_resource_association) | resource |
| [aws_route53profiles_resource_association.ssm_messages_phz_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_resource_association) | resource |
| [aws_route_table.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table) | resource |
| [aws_route_table.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table) | resource |
| [aws_route_table_association.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association) | resource |
| [aws_route_table_association.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association) | resource |
| [aws_security_group.endpoint-sg](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group) | resource |
| [aws_subnet.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_subnet.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_vpc.vpc](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc) | resource |
| [aws_vpc_dhcp_options.dhcp_options](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_dhcp_options) | resource |
| [aws_vpc_dhcp_options_association.dhcp_options_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_dhcp_options_association) | resource |
| [aws_vpc_endpoint.cloudwatch_logs_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.ecr_dkr_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.ssm_messages_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.vpc_endpoints](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_ec2_managed_prefix_list.rfc-1918](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_managed_prefix_list) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_availability_zone_count"></a> [availability\_zone\_count](#input\_availability\_zone\_count) | The number of AZs that should be broken out into subnets. This applies to both private and public subnets. | `number` | `null` | no |
| <a name="input_availabilty_zone_list"></a> [availabilty\_zone\_list](#input\_availabilty\_zone\_list) | List of the Availability Zones to place subnets into. 1 for 1 match. | `list(string)` | n/a | yes |
| <a name="input_aws_region"></a> [aws\_region](#input\_aws\_region) | The AWS region where the VPC will be created. | `string` | n/a | yes |
| <a name="input_cloud_wan_core_network_id"></a> [cloud\_wan\_core\_network\_id](#input\_cloud\_wan\_core\_network\_id) | Id of Cloud-WAN core network to attach to. | `string` | `null` | no |
| <a name="input_dhcp_options_domain_name"></a> [dhcp\_options\_domain\_name](#input\_dhcp\_options\_domain\_name) | The suffix domain name to use by default when resolving non Fully Qualified Domain Names. In other words, this is what ends up being the search value in the /etc/resolv.conf file. | `string` | `"compute.internal"` | no |
| <a name="input_dhcp_options_domain_name_servers"></a> [dhcp\_options\_domain\_name\_servers](#input\_dhcp\_options\_domain\_name\_servers) | List of name servers to configure in /etc/resolv.conf. | `list(string)` | <pre>[<br>  "AmazonProvidedDNS"<br>]</pre> | no |
| <a name="input_eip_timeout_delete"></a> [eip\_timeout\_delete](#input\_eip\_timeout\_delete) | How long to wait for an EIP to be deleted. | `string` | `"3m"` | no |
| <a name="input_eip_timeout_read"></a> [eip\_timeout\_read](#input\_eip\_timeout\_read) | How long to wait querying for information about EIPs. | `string` | `"15m"` | no |
| <a name="input_eip_timeout_update"></a> [eip\_timeout\_update](#input\_eip\_timeout\_update) | How long to wait for an EIP to be updated. | `string` | `"5m"` | no |
| <a name="input_enable_cloudwatch_logs_endpoint"></a> [enable\_cloudwatch\_logs\_endpoint](#input\_enable\_cloudwatch\_logs\_endpoint) | Boolean value to determine if CloudWatch Logs endpoint should be enabled. | `bool` | `true` | no |
| <a name="input_enable_ecr_dkr_endpoint"></a> [enable\_ecr\_dkr\_endpoint](#input\_enable\_ecr\_dkr\_endpoint) | Boolean value to determine if ECR DKR endpoint should be enabled. | `bool` | `true` | no |
| <a name="input_enable_ssm_messages_endpoint"></a> [enable\_ssm\_messages\_endpoint](#input\_enable\_ssm\_messages\_endpoint) | Boolean value to determine if SSM Messages endpoint should be enabled. | `bool` | `true` | no |
| <a name="input_enabled_endpoints"></a> [enabled\_endpoints](#input\_enabled\_endpoints) | List of endpoints to enable for Route53 profiles and VPC endpoints | `list(string)` | `[]` | no |
| <a name="input_endpoint_config"></a> [endpoint\_config](#input\_endpoint\_config) | Complete endpoint configuration map | <pre>map(object({<br>    domain       = string<br>    record_name  = string<br>    service_name = string<br>    display_name = string<br>  }))</pre> | `{}` | no |
| <a name="input_endpoint_timeout_create"></a> [endpoint\_timeout\_create](#input\_endpoint\_timeout\_create) | Used for creating a VPC endpoint. | `string` | `"10m"` | no |
| <a name="input_endpoint_timeout_delete"></a> [endpoint\_timeout\_delete](#input\_endpoint\_timeout\_delete) | Used for destroying VPC endpoints. | `string` | `"10m"` | no |
| <a name="input_endpoint_timeout_update"></a> [endpoint\_timeout\_update](#input\_endpoint\_timeout\_update) | Used for VPC endpoint modifications. | `string` | `"10m"` | no |
| <a name="input_private_supernet"></a> [private\_supernet](#input\_private\_supernet) | CIDR block for the private supernet | `string` | n/a | yes |
| <a name="input_public_supernet"></a> [public\_supernet](#input\_public\_supernet) | CIDR block for the public supernet | `string` | n/a | yes |
| <a name="input_security_group_rule_inside_cidr_blocks"></a> [security\_group\_rule\_inside\_cidr\_blocks](#input\_security\_group\_rule\_inside\_cidr\_blocks) | The list of CIDR blocks used for ingress rules for the INSIDE security group. | `list(string)` | <pre>[<br>  "10.0.0.0/8",<br>  "172.0.0.0/8",<br>  "192.168.0.0/16"<br>]</pre> | no |
| <a name="input_security_group_rule_vpn_cidr_blocks"></a> [security\_group\_rule\_vpn\_cidr\_blocks](#input\_security\_group\_rule\_vpn\_cidr\_blocks) | The list of CIDR blocks used for ingress and egress rules for the VPN security group. | `list(string)` | <pre>[<br>  "10.0.0.0/8",<br>  "172.0.0.0/8",<br>  "192.168.0.0/16"<br>]</pre> | no |
| <a name="input_tag_cloud_wan_segment"></a> [tag\_cloud\_wan\_segment](#input\_tag\_cloud\_wan\_segment) | Set which cloud-wan segment the VPC attachement will join. | `string` | `null` | no |
| <a name="input_tag_environment"></a> [tag\_environment](#input\_tag\_environment) | Set the 'Environment' tag on all VPC components that support tagging. | `string` | n/a | yes |
| <a name="input_tag_name"></a> [tag\_name](#input\_tag\_name) | The name of the VPC. Set the 'Name' tag for the VPC, and is used in all other VPC components that support tagging. | `string` | n/a | yes |
| <a name="input_vpc_cidr_block"></a> [vpc\_cidr\_block](#input\_vpc\_cidr\_block) | The CIDR block for the VPC. | `string` | n/a | yes |

## Outputs

| Name | Description |
|------|-------------|
| <a name="output_aws_eip"></a> [aws\_eip](#output\_aws\_eip) | Elastic IP's used |
| <a name="output_aws_internet_gateway"></a> [aws\_internet\_gateway](#output\_aws\_internet\_gateway) | VPC Internet Gateway |
| <a name="output_aws_nat_gateway"></a> [aws\_nat\_gateway](#output\_aws\_nat\_gateway) | VPC NAT Gateway |
| <a name="output_aws_network_interface"></a> [aws\_network\_interface](#output\_aws\_network\_interface) | VPC Network Interfaces |
| <a name="output_aws_networkmanager_vpc_attachment"></a> [aws\_networkmanager\_vpc\_attachment](#output\_aws\_networkmanager\_vpc\_attachment) | CloudWan attachment |
| <a name="output_aws_subnet_private"></a> [aws\_subnet\_private](#output\_aws\_subnet\_private) | Private subnets |
| <a name="output_aws_subnet_public"></a> [aws\_subnet\_public](#output\_aws\_subnet\_public) | Public Subnets |
| <a name="output_aws_vpc"></a> [aws\_vpc](#output\_aws\_vpc) | Created VPC |
| <a name="output_aws_vpc_dhcp_options"></a> [aws\_vpc\_dhcp\_options](#output\_aws\_vpc\_dhcp\_options) | VPC DHCP options |
| <a name="output_aws_vpc_dhcp_options_association"></a> [aws\_vpc\_dhcp\_options\_association](#output\_aws\_vpc\_dhcp\_options\_association) | VPC DHCP Options association |
| <a name="output_route53_profile_arn"></a> [route53\_profile\_arn](#output\_route53\_profile\_arn) | ARN of the Route 53 profile for centralized endpoints |
| <a name="output_vpc_id"></a> [vpc\_id](#output\_vpc\_id) | ID of created VPC. |

<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

================
File: egress/route_tables.tf
================
resource "aws_route_table" "private" {
  count  = length(local.private_subnet_cidrs)
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "route-table"
    Name      = "${var.tag_name} - AZ${count.index + 1} - Private Table"
  }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "route-table"
    Name      = "${var.tag_name} - AZ ALL - Public Table"
  }
}

resource "aws_route" "private_nat_gateway" {
  count                  = length(local.private_subnet_cidrs)
  destination_cidr_block = "0.0.0.0/0"
  nat_gateway_id         = element(aws_nat_gateway.nat_gateway.*.id, count.index)
  route_table_id         = element(aws_route_table.private.*.id, count.index)
}

resource "aws_route" "public_internet_gateway" {
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.internet_gateway.id
  route_table_id         = aws_route_table.public.id
}

resource "aws_route_table_association" "private" {
  count          = length(local.private_subnet_cidrs)
  route_table_id = element(aws_route_table.private.*.id, count.index)
  subnet_id      = element(aws_subnet.private.*.id, count.index)
}

resource "aws_route_table_association" "public" {
  count          = length(local.public_subnet_cidrs)
  route_table_id = aws_route_table.public.id
  subnet_id      = element(aws_subnet.public.*.id, count.index)
}

resource "aws_route" "rfc-1918-public" {
  route_table_id             = aws_route_table.public.id
  core_network_arn           = "arn:aws:networkmanager::449228620267:core-network/${var.cloud_wan_core_network_id}"
  destination_prefix_list_id = data.aws_ec2_managed_prefix_list.rfc-1918.id
  depends_on                 = [aws_networkmanager_vpc_attachment.vpc_attachment]
}

resource "aws_route" "rfc-1918-private" {

  count                      = length(local.private_subnet_cidrs)
  route_table_id             = element(aws_route_table.private.*.id, count.index)
  core_network_arn           = "arn:aws:networkmanager::449228620267:core-network/${var.cloud_wan_core_network_id}"
  destination_prefix_list_id = data.aws_ec2_managed_prefix_list.rfc-1918.id
  depends_on                 = [aws_networkmanager_vpc_attachment.vpc_attachment]
}

================
File: egress/route53_profiles.tf
================
resource "aws_route53profiles_profile" "centralized-endpoints-profile" {
  name = "centralized-endpoints-profile"
}

# Associate Private Hosted Zones with the Route 53 Profile (list-based)
resource "aws_route53profiles_resource_association" "phz_associations" {
  for_each = toset(local.enabled_endpoints)

  name         = "${each.key}-phz-association"
  profile_id   = aws_route53profiles_profile.centralized-endpoints-profile.id
  resource_arn = aws_route53_zone.endpoint_phz[each.key].arn

  depends_on = [
    aws_route53_record.endpoint_records
  ]
}

resource "aws_route53profiles_resource_association" "ssm_messages_phz_association" {
  count        = var.enable_ssm_messages_endpoint ? 1 : 0
  name         = "ssm-messages-phz-association"
  profile_id   = aws_route53profiles_profile.centralized-endpoints-profile.id
  resource_arn = aws_route53_zone.ssm_messages_phz[0].arn

  depends_on = [
    aws_route53_record.ssm_message_record
  ]
}

resource "aws_route53profiles_resource_association" "ecr_dkr_phz_association" {
  count        = var.enable_ecr_dkr_endpoint ? 1 : 0
  name         = "ecr-dkr-phz-association"
  profile_id   = aws_route53profiles_profile.centralized-endpoints-profile.id
  resource_arn = aws_route53_zone.ecr_dkr_phz[0].arn

  depends_on = [
    aws_route53_record.wildcard_ecr_dkr_record
  ]
}

resource "aws_route53profiles_resource_association" "cloudwatch_logs_phz_association" {
  count        = var.enable_cloudwatch_logs_endpoint ? 1 : 0
  name         = "cloudwatch-logs-phz-association"
  profile_id   = aws_route53profiles_profile.centralized-endpoints-profile.id
  resource_arn = aws_route53_zone.cloudwatch_logs_phz[0].arn

  depends_on = [
    aws_route53_record.cloudwatch_logs_record
  ]
}

================
File: egress/route53_records.tf
================
# Create records for all enabled endpoints
resource "aws_route53_record" "endpoint_records" {
  for_each = toset(local.enabled_endpoints)

  zone_id = aws_route53_zone.endpoint_phz[each.key].zone_id
  name    = local.endpoint_record_names[each.key]
  type    = "A"

  alias {
    name                   = aws_vpc_endpoint.vpc_endpoints[each.key].dns_entry[0].dns_name
    zone_id                = aws_vpc_endpoint.vpc_endpoints[each.key].dns_entry[0].hosted_zone_id
    evaluate_target_health = true
  }

  depends_on = [
    aws_vpc_endpoint.vpc_endpoints,
    aws_route53_zone.endpoint_phz
  ]
}


# Record for SSM Messages Endpoint in the Private Hosted Zone
resource "aws_route53_record" "ssm_message_record" {
  count   = var.enable_ssm_messages_endpoint ? 1 : 0
  zone_id = aws_route53_zone.ssm_messages_phz[0].zone_id
  name    = "ssmmessages.${var.aws_region}.amazonaws.com"
  type    = "A"

  alias {
    name                   = aws_vpc_endpoint.ssm_messages_endpoint[0].dns_entry[0].dns_name
    zone_id                = aws_vpc_endpoint.ssm_messages_endpoint[0].dns_entry[0].hosted_zone_id
    evaluate_target_health = true
  }

  depends_on = [
    aws_vpc_endpoint.ssm_messages_endpoint[0],
    aws_route53_zone.ssm_messages_phz[0]
  ]

}

# Record for ECR Docker Registry in the Private Hosted Zone
resource "aws_route53_record" "wildcard_ecr_dkr_record" {
  count   = var.enable_ecr_dkr_endpoint ? 1 : 0
  zone_id = aws_route53_zone.ecr_dkr_phz[0].zone_id
  name    = "*.dkr.ecr.${var.aws_region}.amazonaws.com"
  type    = "A"

  alias {
    name                   = aws_vpc_endpoint.ecr_dkr_endpoint[0].dns_entry[0].dns_name
    zone_id                = aws_vpc_endpoint.ecr_dkr_endpoint[0].dns_entry[0].hosted_zone_id
    evaluate_target_health = true
  }

  depends_on = [
    aws_vpc_endpoint.ecr_dkr_endpoint[0],
    aws_route53_zone.ecr_dkr_phz[0]
  ]
}

# Record for CloudWatch Logs Endpoint in the Private Hosted Zone
resource "aws_route53_record" "cloudwatch_logs_record" {
  count   = var.enable_cloudwatch_logs_endpoint ? 1 : 0
  zone_id = aws_route53_zone.cloudwatch_logs_phz[0].zone_id
  name    = "logs.${var.aws_region}.amazonaws.com"
  type    = "A"

  alias {
    name                   = aws_vpc_endpoint.cloudwatch_logs_endpoint[0].dns_entry[0].dns_name
    zone_id                = aws_vpc_endpoint.cloudwatch_logs_endpoint[0].dns_entry[0].hosted_zone_id
    evaluate_target_health = true
  }

  depends_on = [
    aws_vpc_endpoint.cloudwatch_logs_endpoint[0],
    aws_route53_zone.cloudwatch_logs_phz[0]
  ]
}

================
File: egress/route53_zones.tf
================
# Create PHZs for enabled endpoints
resource "aws_route53_zone" "endpoint_phz" {
  for_each = toset(local.enabled_endpoints)

  name = local.endpoint_domains[each.key]

  vpc {
    vpc_id = aws_vpc.vpc.id
  }

  lifecycle {
    ignore_changes = [vpc]
  }

  tags = {
    Name = "${each.key}-phz"
  }
}

# SSM Messages Endpoint PHZ
resource "aws_route53_zone" "ssm_messages_phz" {
  count = var.enable_ssm_messages_endpoint ? 1 : 0
  name  = "ssmmessages.${var.aws_region}.amazonaws.com"

  vpc {
    vpc_id = aws_vpc.vpc.id
  }

  lifecycle {
    ignore_changes = [vpc]
  }
}

# ECR Docker Registry Endpoint PHZ
resource "aws_route53_zone" "ecr_dkr_phz" {
  count = var.enable_ecr_dkr_endpoint ? 1 : 0
  name  = "dkr.ecr.${var.aws_region}.amazonaws.com"

  vpc {
    vpc_id = aws_vpc.vpc.id
  }

  lifecycle {
    ignore_changes = [vpc]
  }
}

# CloudWatch Logs Endpoint PHZ
resource "aws_route53_zone" "cloudwatch_logs_phz" {
  count = var.enable_cloudwatch_logs_endpoint ? 1 : 0
  name  = "logs.${var.aws_region}.amazonaws.com"

  vpc {
    vpc_id = aws_vpc.vpc.id
  }

  lifecycle {
    ignore_changes = [vpc]
  }
}

================
File: egress/security_groups.tf
================
# resource "aws_security_group" "dmz" {
#   description = "${var.tag_name} DMZ - Public - Internet Exposed - Security Group"
#   name_prefix = "${var.tag_name}-sg-dmz-"
#   vpc_id      = aws_vpc.vpc.id

#   tags = {
#     Component = "security-group"
#     Name      = "${var.tag_name}-dmz-sg"
#   }
# }

# resource "aws_security_group" "inside" {
#   description = "${var.tag_name} INSIDE - Private Subnet - Security Group"
#   name_prefix = "${var.tag_name}-sg-inside-"
#   vpc_id      = aws_vpc.vpc.id

#   tags = {
#     Component = "security-group"
#     Name      = "${var.tag_name}-inside-sg"
#   }
# }

# resource "aws_security_group_rule" "dmz_egress_default" {
#   cidr_blocks = [
#     "0.0.0.0/0",
#   ]

#   description       = "Allow all outbound traffic."
#   from_port         = 0
#   protocol          = "-1"
#   to_port           = 0
#   type              = "egress"
#   security_group_id = aws_security_group.dmz.id
# }

# resource "aws_security_group_rule" "dmz_ingress_http" {
#   cidr_blocks = [
#     "0.0.0.0/0",
#   ]

#   description       = "Allow inbound HTTP traffic from everywhere."
#   from_port         = 80
#   protocol          = "tcp"
#   to_port           = 80
#   type              = "ingress"
#   security_group_id = aws_security_group.dmz.id
# }

# resource "aws_security_group_rule" "dmz_ingress_https" {
#   description       = "Allow inbound HTTPS traffic from everywhere."
#   from_port         = 443
#   protocol          = "tcp"
#   to_port           = 443
#   type              = "ingress"
#   security_group_id = aws_security_group.dmz.id
#   cidr_blocks = [
#     "0.0.0.0/0",
#   ]
# }

# resource "aws_security_group_rule" "dmz_ingress_icmp" {
#   description       = "Allow inbound ICMP traffic."
#   from_port         = -1
#   protocol          = "icmp"
#   to_port           = -1
#   type              = "ingress"
#   security_group_id = aws_security_group.dmz.id
#   cidr_blocks       = var.security_group_rule_inside_cidr_blocks
# }

# resource "aws_security_group_rule" "inside_egress_default" {
#   description       = "Allow all outbound traffic."
#   from_port         = 0
#   protocol          = "-1"
#   to_port           = 0
#   type              = "egress"
#   security_group_id = aws_security_group.inside.id
#   cidr_blocks = [
#     "0.0.0.0/0",
#   ]
# }

# resource "aws_security_group_rule" "inside_ingress_http" {
#   description              = "Allow inbound HTTP traffic from the DMZ security group."
#   from_port                = 80
#   protocol                 = "tcp"
#   to_port                  = 80
#   type                     = "ingress"
#   security_group_id        = aws_security_group.inside.id
#   source_security_group_id = aws_security_group.dmz.id
# }

================
File: egress/subnets.tf
================
resource "aws_subnet" "private" {
  count                               = length(local.private_subnet_cidrs)
  availability_zone                   = var.availabilty_zone_list[count.index]
  cidr_block                          = local.private_subnet_cidrs[count.index]
  vpc_id                              = aws_vpc.vpc.id
  private_dns_hostname_type_on_launch = "resource-name"
  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ${count.index + 1} | INSIDE | Private Subnet"
  }
}

resource "aws_subnet" "public" {
  count                               = length(local.public_subnet_cidrs)
  availability_zone                   = var.availabilty_zone_list[count.index]
  cidr_block                          = local.public_subnet_cidrs[count.index]
  vpc_id                              = aws_vpc.vpc.id
  private_dns_hostname_type_on_launch = "resource-name"
  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ${count.index + 1} | DMZ | Public Subnet"
  }
}

================
File: egress/variables.tf
================
### DHCP Options ###

variable "dhcp_options_domain_name" {
  description = "The suffix domain name to use by default when resolving non Fully Qualified Domain Names. In other words, this is what ends up being the search value in the /etc/resolv.conf file."
  type        = string
  default     = "compute.internal"
  nullable    = false
}

variable "dhcp_options_domain_name_servers" {
  description = "List of name servers to configure in /etc/resolv.conf."
  type        = list(string)
  default = [
    "AmazonProvidedDNS",
  ]
  nullable = false
}

### Elastic IP ###

variable "eip_timeout_delete" {
  description = "How long to wait for an EIP to be deleted."
  type        = string
  default     = "3m"
  nullable    = false
}

variable "eip_timeout_read" {
  description = "How long to wait querying for information about EIPs."
  type        = string
  default     = "15m"
  nullable    = false
}

variable "eip_timeout_update" {
  default     = "5m"
  description = "How long to wait for an EIP to be updated."
  type        = string
}

### Endpoint ###

variable "aws_region" {
  description = "The AWS region where the VPC will be created."
  type        = string
}

variable "endpoint_timeout_create" {
  description = "Used for creating a VPC endpoint."
  type        = string
  default     = "10m"
  nullable    = false
}

variable "endpoint_timeout_delete" {
  description = "Used for destroying VPC endpoints."
  type        = string
  default     = "10m"
  nullable    = false
}

variable "endpoint_timeout_update" {
  description = "Used for VPC endpoint modifications."
  type        = string
  default     = "10m"
  nullable    = false
}

variable "enabled_endpoints" {
  description = "List of endpoints to enable for Route53 profiles and VPC endpoints"
  type        = list(string)
  default     = []
}

variable "endpoint_config" {
  description = "Complete endpoint configuration map"
  type = map(object({
    domain       = string
    record_name  = string
    service_name = string
    display_name = string
  }))
  default = {}
}

### Security Group ###

variable "security_group_rule_inside_cidr_blocks" {
  description = "The list of CIDR blocks used for ingress rules for the INSIDE security group."
  type        = list(string)
  default = [
    "10.0.0.0/8",
    "172.0.0.0/8",
    "192.168.0.0/16",
  ]
  nullable = false
}

variable "security_group_rule_vpn_cidr_blocks" {
  description = "The list of CIDR blocks used for ingress and egress rules for the VPN security group."
  type        = list(string)
  default = [
    "10.0.0.0/8",
    "172.0.0.0/8",
    "192.168.0.0/16",
  ]
  nullable = false
}

### Tags ###

variable "tag_name" {
  description = "The name of the VPC. Set the 'Name' tag for the VPC, and is used in all other VPC components that support tagging."
  type        = string
}

variable "tag_environment" {
  description = "Set the 'Environment' tag on all VPC components that support tagging."
  type        = string
}

### VPC ###

variable "vpc_cidr_block" {
  description = "The CIDR block for the VPC."
  type        = string
}

## Subnets ##

variable "availability_zone_count" {
  description = "The number of AZs that should be broken out into subnets. This applies to both private and public subnets."
  type        = number
  default     = null
}

variable "cloud_wan_core_network_id" {
  description = "Id of Cloud-WAN core network to attach to."
  type        = string
  default     = null
}

variable "tag_cloud_wan_segment" {
  description = "Set which cloud-wan segment the VPC attachement will join."
  type        = string
  default     = null
}

variable "private_supernet" {
  description = "CIDR block for the private supernet"
  type        = string
}

variable "public_supernet" {
  description = "CIDR block for the public supernet"
  type        = string
}

variable "availabilty_zone_list" {
  description = "List of the Availability Zones to place subnets into. 1 for 1 match."
  type        = list(string)
}

variable "enable_ecr_dkr_endpoint" {
  description = "Boolean value to determine if ECR DKR endpoint should be enabled."
  type        = bool
  default     = true
}

variable "enable_ssm_messages_endpoint" {
  description = "Boolean value to determine if SSM Messages endpoint should be enabled."
  type        = bool
  default     = true
}

variable "enable_cloudwatch_logs_endpoint" {
  description = "Boolean value to determine if CloudWatch Logs endpoint should be enabled."
  type        = bool
  default     = true
}

================
File: egress/versions.tf
================
terraform {
  required_version = ">= 1.9.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

================
File: egress/vpc.tf
================
resource "aws_vpc" "vpc" {
  cidr_block           = var.vpc_cidr_block
  enable_dns_hostnames = true

  tags = {
    Name = var.tag_name
  }
}

================
File: gen-ai/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: gen-ai/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: gen-ai/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: gen-ai/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: gen-ai/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: gen-ai/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: gen-ai/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: gen-ai/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: gen-ai/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: gen-ai/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: gen-ai/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: gen-ai/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: gen-ai/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: gen-ai/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: gen-ai/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 1b424b9cf7cbb4c59686acd8ab001748bf304bdd Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406177 -0600	clone: from github.com:enverus-cts/genai.terraform.git

================
File: gen-ai/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 1b424b9cf7cbb4c59686acd8ab001748bf304bdd Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406177 -0600	clone: from github.com:enverus-cts/genai.terraform.git

================
File: gen-ai/.git/logs/HEAD
================
0000000000000000000000000000000000000000 1b424b9cf7cbb4c59686acd8ab001748bf304bdd Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406177 -0600	clone: from github.com:enverus-cts/genai.terraform.git

================
File: gen-ai/.git/refs/heads/main
================
1b424b9cf7cbb4c59686acd8ab001748bf304bdd

================
File: gen-ai/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: gen-ai/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/genai.terraform.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: gen-ai/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: gen-ai/.git/HEAD
================
ref: refs/heads/main

================
File: gen-ai/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
0b07823103cd3dc5a716bb514c3edcf10a71bef2 refs/remotes/origin/SRE-12431
92dc3352f471afda24bbd23c8f7ca8976a3d1e92 refs/remotes/origin/feat/sre-12487-github-custom-role
1b424b9cf7cbb4c59686acd8ab001748bf304bdd refs/remotes/origin/main

================
File: gen-ai/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)

        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: gen-ai/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response)
            return { "parameter": response,"errorMessage":"none" }
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'

          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled'
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added'
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter']
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.'

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: gen-ai/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: gen-ai/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: gen-ai/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
#trigger atlantis
module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: gen-ai/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: gen-ai/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: gen-ai/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: gen-ai/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: gen-ai/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: gen-ai/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: gen-ai/config/.terraform-version
================
latest:^1.8

================
File: gen-ai/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: gen-ai/config/dev.backend.tfvars
================
key = "891150701981/dev/config/terraform.tfstate"

================
File: gen-ai/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = "2fd6188a-21f3-4014-9e13-012c32f135c3"

================
File: gen-ai/config/main.tf
================
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: gen-ai/config/prod.backend.tfvars
================
key = "126127704198/prod/aws_config/terraform.tfstate"

================
File: gen-ai/config/prod.tfvars
================
environment             = "prod"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: gen-ai/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}


variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: gen-ai/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/cts.terraform/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: gen-ai/iam/bedrock_knowledge_base_role.tf
================
resource "aws_iam_role" "AmazonBedrockExecutionRoleForKnowledgeBase_default" {
  name               = "AmazonBedrockExecutionRoleForKnowledgeBase_default"
  assume_role_policy = data.aws_iam_policy_document.AmazonBedrockExecutionRoleForKnowledgeBase_assume_role_policy.json
  inline_policy {
    name   = "AmazonBedrockExecutionRoleForKnowledgeBase_default"
    policy = data.aws_iam_policy_document.AmazonBedrockExecutionRoleForKnowledgeBase_default.json
  }
}

data "aws_iam_policy_document" "AmazonBedrockExecutionRoleForKnowledgeBase_assume_role_policy" {
  statement {
    effect = "Allow"
    principals {
      type        = "Service"
      identifiers = ["bedrock.amazonaws.com"]
    }
    actions = ["sts:AssumeRole"]
    condition {
      test     = "StringEquals"
      variable = "aws:SourceAccount"
      values   = [data.aws_caller_identity.current.account_id]
    }
    condition {
      test     = "ArnLike"
      variable = "AWS:SourceArn"
      values   = ["arn:aws:bedrock:*:${data.aws_caller_identity.current.account_id}:knowledge-base/*"]
    }
  }
}

data "aws_iam_policy_document" "AmazonBedrockExecutionRoleForKnowledgeBase_default" {
  statement {
    sid    = "BedrockFoundationAccess"
    effect = "Allow"
    actions = [
      "bedrock:ListFoundationModels",
      "bedrock:ListCustomModels"
    ]
    resources = [
      "*"
    ]
  }
  statement {
    sid    = "BedrockInvokeAccess"
    effect = "Allow"
    actions = [
      "bedrock:InvokeModel"
    ]

    resources = [
      "arn:aws:bedrock:*::foundation-model/*"
    ]
  }
  statement {
    sid    = "BucketAccess"
    effect = "Allow"
    actions = [
      "s3:GetObject",
      "s3:ListBucket"
    ]
    resources = [
      "arn:aws:s3:::*",
      "arn:aws:s3:::*/*"
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:PrincipalAccount"
      values   = [data.aws_caller_identity.current.account_id]
    }
  }
  statement {
    sid    = "AOSSApiAccess"
    effect = "Allow"
    actions = [
      "aoss:APIAccessAll"
    ]
    resources = [
      "arn:aws:aoss:*:${data.aws_caller_identity.current.account_id}:collection/*"
    ]
  }
  statement {
    sid    = 5
    effect = "Allow"
    actions = [
      "rds:DescribeDBClusters",
      "rds-data:BatchExecuteStatement",
      "rds-data:ExecuteStatement"
    ]
    resources = [
      "arn:aws:rds:*:${data.aws_caller_identity.current.account_id}:cluster:*"
    ]
  }
}

================
File: gen-ai/iam/bedrockrole_assume_role.tf
================
data "aws_iam_policy_document" "bedrock_assume_role_policy" {
  statement {
    actions = ["sts:AssumeRole"]

    principals {
      type        = "AWS"
      identifiers = [data.aws_caller_identity.current.account_id]
    }
  }
}

data "aws_iam_policy_document" "bedrock_inline_policy" {
  statement {
    sid    = "MarketPlaceSubscriptions"
    effect = "Allow"
    actions = [
      "aws-marketplace:Subscribe"
    ]
    resources = [
      "*"
    ]
    condition {
      test     = "ForAnyValue:StringEquals"
      variable = "aws-marketplace:ProductId"
      values = [
        "1d288c71-65f9-489a-a3e2-9c7f4f6e6a85",
        "cc0bdd50-279a-40d8-829c-4009b77a1fcc",
        "c468b48a-84df-43a4-8c46-8870630108a7",
        "99d90be8-b43e-49b7-91e4-752f3866c8c7",
        "b0eb9475-3a2c-43d1-94d3-56756fd43737",
        "d0123e8d-50d6-4dba-8a26-3fed4899f388",
        "a61c46fe-1747-41aa-9af0-2e0ae8a9ce05",
        "216b69fd-07d5-4c7b-866b-936456d68311",
        "b7568428-a1ab-46d8-bab3-37def50f6f6a",
        "38e55671-c3fe-4a44-9783-3584906e7cad",
        "prod-ariujvyzvd2qy",
        "prod-2c2yc2s3guhqy",
      ]
    }
  }
  statement {
    sid    = "MarketPlaceUnsubscribe"
    effect = "Allow"
    actions = [
      "aws-marketplace:Unsubscribe",
      "aws-marketplace:ViewSubscriptions"
    ]
    resources = ["*"]
  }
  statement {
    sid    = "OpensearchPermissions"
    effect = "Allow"
    actions = [
      "aoss:*"
    ]
    resources = ["*"]
  }
  statement {
    sid    = "CreateServiceLinkedRole"
    effect = "Allow"
    actions = [
      "iam:CreateServiceLinkedRole",
    ]
    resources = ["*"]

  }
}

resource "aws_iam_role" "bedrock_assume_role" {
  name               = "bedrock_assume_role"
  assume_role_policy = data.aws_iam_policy_document.bedrock_assume_role_policy.json
  managed_policy_arns = [
    "arn:aws:iam::aws:policy/AmazonBedrockFullAccess",
    "arn:aws:iam::aws:policy/AmazonS3FullAccess",
    "arn:aws:iam::aws:policy/AmazonOpenSearchServiceFullAccess"
  ]
  inline_policy {
    name   = "bedrock_inline_policy"
    policy = data.aws_iam_policy_document.bedrock_inline_policy.json
  }
}

================
File: gen-ai/iam/data.tf
================
data "aws_caller_identity" "current" {}

================
File: gen-ai/iam/dev.backend.tfvars
================
key = "891150701981/iam/terraform.tfstate"

================
File: gen-ai/iam/prod.backend.tfvars
================
key = "126127704198/iam/terraform.tfstate"

================
File: gen-ai/iam/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

================
File: gen-ai/iam/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "nv"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/nv.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/route53/.terraform-version
================
latest:^1.7

================
File: gen-ai/route53/dev.backend.tfvars
================
key = "891150701981/dev/route-53/terraform.tfstate"

================
File: gen-ai/route53/dns.excalidraw
================
{
  "type": "excalidraw",
  "version": 2,
  "source": "https://marketplace.visualstudio.com/items?itemName=pomdtr.excalidraw-editor",
  "elements": [
    {
      "id": "g-E1w3jwutLlYOjcrj1l_",
      "type": "rectangle",
      "x": 292.4175720214844,
      "y": 122.05961608886719,
      "width": 286.62258911132807,
      "height": 259.15193176269537,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "seed": 1695592049,
      "version": 194,
      "versionNonce": 747865873,
      "isDeleted": false,
      "boundElements": [
        {
          "id": "ou71yCfdOCKgeA-7s95WL",
          "type": "arrow"
        }
      ],
      "updated": 1712859269561,
      "link": null,
      "locked": false
    },
    {
      "id": "iVlOBwm8tiNC_Vir0lzpP",
      "type": "text",
      "x": 333.5521545410156,
      "y": 142.50750732421875,
      "width": 165.2598419189453,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 1708088465,
      "version": 97,
      "versionNonce": 446778513,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859051682,
      "link": null,
      "locked": false,
      "text": "genai.enverus.com",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "containerId": null,
      "originalText": "genai.enverus.com",
      "lineHeight": 1.25
    },
    {
      "id": "tznRS6e_Mh_ifD7-EbJU0",
      "type": "rectangle",
      "x": 257.1744384765625,
      "y": 51.34868242416832,
      "width": 412.6585693359375,
      "height": 763.135124206543,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "seed": 390187295,
      "version": 140,
      "versionNonce": 807103615,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859290170,
      "link": null,
      "locked": false
    },
    {
      "id": "kvXQI2c5Bp6gmTmN-f58h",
      "type": "text",
      "x": 438,
      "y": 65.48148729477379,
      "width": 133.09991455078125,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 859942367,
      "version": 2,
      "versionNonce": 933185905,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859070518,
      "link": null,
      "locked": false,
      "text": "126127704198",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "containerId": null,
      "originalText": "126127704198",
      "lineHeight": 1.25
    },
    {
      "type": "rectangle",
      "version": 173,
      "versionNonce": 2001598577,
      "isDeleted": false,
      "id": "qLJk6NP-T2KT4WsCKJtVv",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 707.8455810546875,
      "y": 50.604438802342145,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 412.6585693359375,
      "height": 580.3794174194336,
      "seed": 456094175,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1712859097764,
      "link": null,
      "locked": false
    },
    {
      "id": "OROaCdeXO3yxVueqZvqNv",
      "type": "text",
      "x": 842.7130126953125,
      "y": 79.31085588608238,
      "width": 127.27992248535156,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 662156977,
      "version": 23,
      "versionNonce": 1103573937,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859096184,
      "link": null,
      "locked": false,
      "text": "891150701981",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "containerId": null,
      "originalText": "891150701981",
      "lineHeight": 1.25
    },
    {
      "id": "x-oPaPVDwS5AnIfDFd4mv",
      "type": "rectangle",
      "x": 323.29425048828125,
      "y": 184.82523729477379,
      "width": 226.5542602539062,
      "height": 37.61300659179687,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "seed": 1098062431,
      "version": 123,
      "versionNonce": 987478865,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859142682,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 180,
      "versionNonce": 1040803807,
      "isDeleted": false,
      "id": "RvF85znhwfhN_ddGMSnlG",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 324.67034912109375,
      "y": 251.31499864731285,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 226.0122680664063,
      "height": 37.04919433593751,
      "seed": 752853169,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "type": "text",
          "id": "1fXCfGCtcPpcc3gl_aJ7s"
        },
        {
          "id": "OknXf0ggT3sBPx6FDNxsR",
          "type": "arrow"
        }
      ],
      "updated": 1712859167925,
      "link": null,
      "locked": false
    },
    {
      "id": "1fXCfGCtcPpcc3gl_aJ7s",
      "type": "text",
      "x": 335.9165802001953,
      "y": 257.3395958152816,
      "width": 203.51980590820312,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 1392392415,
      "version": 22,
      "versionNonce": 2126636497,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859150643,
      "link": null,
      "locked": false,
      "text": "dev.genai.enverus.com",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "center",
      "verticalAlign": "middle",
      "baseline": 18,
      "containerId": "RvF85znhwfhN_ddGMSnlG",
      "originalText": "dev.genai.enverus.com",
      "lineHeight": 1.25
    },
    {
      "id": "62SvBRJY4llWX7QSyWucI",
      "type": "text",
      "x": 325.53741455078125,
      "y": 188.79191209946129,
      "width": 211.6597900390625,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 2117039807,
      "version": 74,
      "versionNonce": 1031646193,
      "isDeleted": false,
      "boundElements": [
        {
          "id": "ou71yCfdOCKgeA-7s95WL",
          "type": "arrow"
        }
      ],
      "updated": 1712859279700,
      "link": null,
      "locked": false,
      "text": "prod.genai.enverus.com",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "containerId": null,
      "originalText": "prod.genai.enverus.com",
      "lineHeight": 1.25
    },
    {
      "id": "ou71yCfdOCKgeA-7s95WL",
      "type": "arrow",
      "x": 321.32159423828125,
      "y": 210.18894579086754,
      "width": 82.6258544921875,
      "height": 228.85598754882812,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "seed": 1889602527,
      "version": 646,
      "versionNonce": 1598588305,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859280405,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          -34.965911865234375,
          206.6363525390625
        ],
        [
          47.659942626953125,
          228.85598754882812
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": {
        "elementId": "62SvBRJY4llWX7QSyWucI",
        "focus": 1.0055132417590438,
        "gap": 4.2158203125
      },
      "endBinding": {
        "elementId": "sd7glHSVGOn8mnPRg6Aav",
        "focus": -0.08502682877003957,
        "gap": 4.234588623046875
      },
      "startArrowhead": null,
      "endArrowhead": "arrow"
    },
    {
      "id": "OknXf0ggT3sBPx6FDNxsR",
      "type": "arrow",
      "x": 551.9140625,
      "y": 270.58042528305504,
      "width": 220.8160400390625,
      "height": 92.08209228515625,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "seed": 631729873,
      "version": 43,
      "versionNonce": 634158783,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859213266,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          220.8160400390625,
          -92.08209228515625
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": {
        "elementId": "RvF85znhwfhN_ddGMSnlG",
        "focus": 0.7369308838297008,
        "gap": 1.2314453125
      },
      "endBinding": {
        "elementId": "9HDSzVbWQYsnE9q2b_q7g",
        "focus": 0.6025252114022274,
        "gap": 2.1683349609375
      },
      "startArrowhead": null,
      "endArrowhead": "arrow"
    },
    {
      "id": "sd7glHSVGOn8mnPRg6Aav",
      "type": "rectangle",
      "x": 373.21612548828125,
      "y": 393.4450187889144,
      "width": 285.1824951171875,
      "height": 150.8234252929687,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "seed": 560927743,
      "version": 126,
      "versionNonce": 2127943967,
      "isDeleted": false,
      "boundElements": [
        {
          "id": "ou71yCfdOCKgeA-7s95WL",
          "type": "arrow"
        }
      ],
      "updated": 1712859267423,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 182,
      "versionNonce": 1287263729,
      "isDeleted": false,
      "id": "PpcjiPqcQG8Nouz-zlNNQ",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 408.3008728027344,
      "y": 405.62464525375816,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 211.6597900390625,
      "height": 25,
      "seed": 1783680927,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1712859298505,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "prod.genai.enverus.com",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "prod.genai.enverus.com",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 348,
      "versionNonce": 1803477905,
      "isDeleted": false,
      "id": "rDuVzhsanMCltdCHmfC7A",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 385.5993957519531,
      "y": 470.61187364731285,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 266.733154296875,
      "height": 38.72293090820312,
      "seed": 2050328735,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "type": "text",
          "id": "4PWS95SjgFK53XGkXKFQb"
        }
      ],
      "updated": 1712859264638,
      "link": null,
      "locked": false
    },
    {
      "id": "4PWS95SjgFK53XGkXKFQb",
      "type": "text",
      "x": 397.88609313964844,
      "y": 477.4733391014144,
      "width": 242.15975952148438,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "seed": 271572881,
      "version": 83,
      "versionNonce": 702433649,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859264638,
      "link": null,
      "locked": false,
      "text": "int.prod.genai.enverus.com",
      "fontSize": 20,
      "fontFamily": 1,
      "textAlign": "center",
      "verticalAlign": "middle",
      "baseline": 18,
      "containerId": "rDuVzhsanMCltdCHmfC7A",
      "originalText": "int.prod.genai.enverus.com",
      "lineHeight": 1.25
    },
    {
      "type": "rectangle",
      "version": 175,
      "versionNonce": 309087967,
      "isDeleted": false,
      "id": "9HDSzVbWQYsnE9q2b_q7g",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 774.8984375,
      "y": 123.98533250961765,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 285.1824951171875,
      "height": 150.8234252929687,
      "seed": 779141489,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "id": "OknXf0ggT3sBPx6FDNxsR",
          "type": "arrow"
        }
      ],
      "updated": 1712859213266,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 227,
      "versionNonce": 1475969553,
      "isDeleted": false,
      "id": "v1tV52CHNkWtznWjhkkey",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 801.2164306640625,
      "y": 133.9077568260239,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 203.51980590820312,
      "height": 25,
      "seed": 1385786193,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1712859216231,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "dev.genai.enverus.com",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "dev.genai.enverus.com",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 376,
      "versionNonce": 91451793,
      "isDeleted": false,
      "id": "QrBdrWh3KjYe6tU7p2FDD",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 781.9957580566406,
      "y": 189.71674730453952,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 266.733154296875,
      "height": 38.72293090820312,
      "seed": 600955185,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "type": "text",
          "id": "x8kcF_r271cuaiTlUus9r"
        }
      ],
      "updated": 1712859216995,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 114,
      "versionNonce": 2078232785,
      "isDeleted": false,
      "id": "x8kcF_r271cuaiTlUus9r",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 798.3524475097656,
      "y": 196.5782127586411,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 234.019775390625,
      "height": 25,
      "seed": 1937869585,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1712859219245,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "int.dev.genai.enverus.com",
      "textAlign": "center",
      "verticalAlign": "middle",
      "containerId": "QrBdrWh3KjYe6tU7p2FDD",
      "originalText": "int.dev.genai.enverus.com",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 248,
      "versionNonce": 1564253905,
      "isDeleted": false,
      "id": "gLx5qsTUuqc-XS_MWYzzE",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 323.764404296875,
      "y": 313.4217949119613,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 226.0122680664063,
      "height": 37.04919433593751,
      "seed": 2090101137,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "type": "text",
          "id": "wmtPtrTbMWlXFKdnTQpu3"
        },
        {
          "id": "Ohs2FgjdPXWzWx-wByPxO",
          "type": "arrow"
        }
      ],
      "updated": 1712859286668,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 93,
      "versionNonce": 1854890303,
      "isDeleted": false,
      "id": "wmtPtrTbMWlXFKdnTQpu3",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 338.89063262939453,
      "y": 319.44639207993004,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 195.7598114013672,
      "height": 25,
      "seed": 1246957425,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1712859244225,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "int.genai.enverus.com",
      "textAlign": "center",
      "verticalAlign": "middle",
      "containerId": "gLx5qsTUuqc-XS_MWYzzE",
      "originalText": "int.genai.enverus.com",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "id": "Ohs2FgjdPXWzWx-wByPxO",
      "type": "arrow",
      "x": 325.64806145376957,
      "y": 351.4709892478988,
      "width": 5.569633286578551,
      "height": 252.45639659806437,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "seed": 1305722911,
      "version": 156,
      "versionNonce": 569435473,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1712859312169,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          5.569633286578551,
          252.45639659806437
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": {
        "elementId": "gLx5qsTUuqc-XS_MWYzzE",
        "focus": 0.9835859598878561,
        "gap": 1
      },
      "endBinding": {
        "elementId": "eRnBn-60KR8N7W8aHcMMW",
        "focus": -1.0161414824646153,
        "gap": 5.595781822151878
      },
      "startArrowhead": null,
      "endArrowhead": "arrow"
    },
    {
      "type": "rectangle",
      "version": 227,
      "versionNonce": 704412447,
      "isDeleted": false,
      "id": "eRnBn-60KR8N7W8aHcMMW",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 336.8134765625,
      "y": 601.2014997593169,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 285.1824951171875,
      "height": 150.8234252929687,
      "seed": 1855362737,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "id": "Ohs2FgjdPXWzWx-wByPxO",
          "type": "arrow"
        }
      ],
      "updated": 1712859308672,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 253,
      "versionNonce": 1584039089,
      "isDeleted": false,
      "id": "t0IyfxeeDbh73v8pO0KpY",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 373.61285400390625,
      "y": 615.1549909702544,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 195.7598114013672,
      "height": 25,
      "seed": 238030257,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1712859305263,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "int.genai.enverus.com",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "int.genai.enverus.com",
      "lineHeight": 1.25,
      "baseline": 18
    }
  ],
  "appState": {
    "gridSize": null,
    "viewBackgroundColor": "#ffffff"
  },
  "files": {}
}

================
File: gen-ai/route53/prod.backend.tfvars
================
key = "126127704198/prod/route-53/terraform.tfstate"

================
File: gen-ai/route53/prod.tfvars
================
genai_ns_records_prod = [
  "ns-669.awsdns-19.net.",
  "ns-439.awsdns-54.com.",
  "ns-1153.awsdns-16.org.",
  "ns-1706.awsdns-21.co.uk."
]

genai_ns_records_dev = [
  "ns-1083.awsdns-07.org.",
  "ns-209.awsdns-26.com.",
  "ns-1853.awsdns-39.co.uk.",
  "ns-606.awsdns-11.net."
]

================
File: gen-ai/route53/records.tf
================
# Because we are going cross-account, we need to create the NS records in the parent account
resource "aws_route53_record" "genai_dev" {
  count   = var.env == "prod" ? 1 : 0
  name    = "dev.genai.enverus.com"
  ttl     = 300
  type    = "NS"
  zone_id = aws_route53_zone.genai_prod[0].zone_id

  records = var.genai_ns_records_dev
}

resource "aws_route53_record" "genai_prod" {
  count   = var.env == "prod" ? 1 : 0
  name    = "prod.genai.enverus.com"
  ttl     = 300
  type    = "NS"
  zone_id = aws_route53_zone.genai_prod[0].zone_id

  records = var.genai_ns_records_prod
}

# This is all happening in the same account, so we can create the NS records in the same account but the zone a level up.
resource "aws_route53_record" "genai_int" {
  name    = "int.${var.env}.genai.enverus.com"
  ttl     = 300
  type    = "NS"
  zone_id = aws_route53_zone.genai_env.zone_id

  records = aws_route53_zone.genai_internal_env.name_servers
}

# This zone only exists in the prod account... so we need to create the NS records in the prod account
resource "aws_route53_record" "genai_internal_int" {
  count   = var.env == "prod" ? 1 : 0
  name    = "int.genai.enverus.com"
  ttl     = 300
  type    = "NS"
  zone_id = aws_route53_zone.genai_prod[0].zone_id

  records = aws_route53_zone.int_genai[0].name_servers
}

================
File: gen-ai/route53/resolver.tf
================
#Disabled for now because I don't think we need them, but in case we do.. here is the code.
# module "route53_resolver" {
#   source           = "git@github.com:enverus-cts/sre.tf-modules.route53-resolvers.git?ref=main"
#   vpc_name         = "genai-vpc-${var.env}"
#   subnet_name_tags = ["*INSIDE | Private Subnet"]
#   env              = var.env
#   enverus_domain_rules = {
#     "enverus" = {
#       "domain" = "enverus.com"
#       "name"   = "DI-DNS-EN"
#     },
#     "drillinginfo" = {
#       "domain" = "drillinginfo.com"
#       "name"   = "DI-DNS"
#     },
#     "azure-windows-databases" = {
#       "domain" = "database.windows.net"
#       "name"   = "Azure-Database-windows"
#     },
#     "oraclevcn" = {
#       "domain" = "oraclevcn.com"
#       "name"   = "Oraclevcn-Drillinginfo"
#     },
#   }
# }

================
File: gen-ai/route53/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "genai_ns_records_prod" {
  description = "ns records for genai prod zone delegated to shared genai prod account"
  type        = list(string)
  default     = [""]
}

variable "genai_ns_records_dev" {
  description = "ns records for genai dev zone delegated to shared genai dev account"
  type        = list(string)
  default     = [""]
}

================
File: gen-ai/route53/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "genai"
      Component        = "route53"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/genai.terraform/tree/main/route53"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: gen-ai/route53/zones.tf
================
resource "aws_route53_zone" "genai_prod" {
  count = var.env == "prod" ? 1 : 0
  name  = "genai.enverus.com"
}

resource "aws_route53_zone" "int_genai" {
  count = var.env == "prod" ? 1 : 0
  name  = "int.genai.enverus.com"
}

resource "aws_route53_zone" "genai_env" {
  name = "${var.env}.genai.enverus.com"
}

resource "aws_route53_zone" "genai_internal_env" {
  name = "int.${var.env}.genai.enverus.com"
}

================
File: gen-ai/s3/.terraform-version
================
latest

================
File: gen-ai/s3/dev.backend.tfvars
================
key            = "891150701981/s3/terraform.tfstate"
use_lockfile   = true
dynamodb_table = null

================
File: gen-ai/s3/main.tf
================
data "aws_caller_identity" "current" {
  provider = aws.ue1
}

module "s3_logging_buckets" {
  source                     = "git@github.com:enverus-cts/sre.tf-modules.s3-bucket"
  bucketprefix               = "enverus-genai-logging"
  disable_bucket_replication = true
  use_managed_aws_key        = true
  s3_bucket_policy           = data.aws_iam_policy_document.bucketPolicy.json
  providers = {
    aws.primary = aws.ue1
    aws.dr      = aws.uw2
  }
}

data "aws_iam_policy_document" "bucketPolicy" {
  provider = aws.ue1
  statement {
    sid = "AllowQLogging"

    actions = [
      "s3:PutObject"
    ]
    effect = "Allow"
    principals {
      type        = "Service"
      identifiers = ["q.amazonaws.com"]
    }
    resources = [
      module.s3_logging_buckets.primaryS3Bucket.arn,
      "${module.s3_logging_buckets.primaryS3Bucket.arn}/*"
    ]
    condition {
      test     = "StringEquals"
      variable = "aws:SourceOrgId"
      values   = ["o-lypgui0jlj"]
    }
    condition {
      test     = "ArnLike"
      variable = "aws:SourceArn"
      values   = ["arn:aws:codewhisperer:us-east-1:${data.aws_caller_identity.current.account_id}:*"]
    }
  }
}

================
File: gen-ai/s3/prod.backend.tfvars
================
key            = "126127704198/s3/terraform.tfstate"
use_lockfile   = true
dynamodb_table = null

================
File: gen-ai/s3/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

================
File: gen-ai/s3/versions.tf
================
terraform {
  required_version = ">= 1.11"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5"
    }
  }
}

provider "aws" {
  alias  = "ue1"
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "nv"
      Component        = "s3"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/nv.terraform/tree/main/s3"
      TerraformCreated = "true"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "nv"
      Component        = "s3"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/nv.terraform/tree/main/s3"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/vpc/eu-north-1/.terraform-version
================
latest:^1.7

================
File: gen-ai/vpc/eu-north-1/dev.backend.tfvars
================
key = "891150701981/vpc/eu-north-1/terraform.tfstate"

================
File: gen-ai/vpc/eu-north-1/dev.tfvars
================
region                               = "eu-north-1"
tag_name                             = "genai-vpc-dev"
vpc_cidr_block                       = "10.24.224.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "nonprod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/eu-north-1/main.tf
================
# Create a vpc using the vpc module

module "genai-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  vpc_cidr_block                       = var.vpc_cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}

output "vpc" { value = module.genai-vpc }

================
File: gen-ai/vpc/eu-north-1/prod.backend.tfvars
================
key = "126127704198/vpc/eu-north-1/terraform.tfstate"

================
File: gen-ai/vpc/eu-north-1/prod.tfvars
================
region                               = "eu-north-1"
tag_name                             = "genai-vpc-prod"
vpc_cidr_block                       = "10.24.228.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "prod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/eu-north-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The ID of the CloudWan Core Network"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the attachment of the VPC to the CloudWan Core Network"
  type        = bool
  default     = true
}

variable "tag_cloud_wan_segment" {
  description = "The CloudWan Segment to attach the VPC to"
  type        = string
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: gen-ai/vpc/eu-north-1/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/genai.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/vpc/eu-west-1/.terraform-version
================
latest:^1.7

================
File: gen-ai/vpc/eu-west-1/dev.backend.tfvars
================
key = "891150701981/vpc/eu-west-1/terraform.tfstate"

================
File: gen-ai/vpc/eu-west-1/dev.tfvars
================
region                               = "eu-west-1"
tag_name                             = "genai-vpc-dev"
vpc_cidr_block                       = "10.24.232.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "nonprod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/eu-west-1/main.tf
================
# Create a vpc using the vpc module

module "genai-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  vpc_cidr_block                       = var.vpc_cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}

output "vpc" { value = module.genai-vpc }

================
File: gen-ai/vpc/eu-west-1/prod.backend.tfvars
================
key = "126127704198/vpc/eu-west-1/terraform.tfstate"

================
File: gen-ai/vpc/eu-west-1/prod.tfvars
================
region                               = "eu-west-1"
tag_name                             = "genai-vpc-prod"
vpc_cidr_block                       = "10.24.236.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "prod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/eu-west-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The ID of the CloudWan Core Network"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the attachment of the VPC to the CloudWan Core Network"
  type        = bool
  default     = true
}

variable "tag_cloud_wan_segment" {
  description = "The CloudWan Segment to attach the VPC to"
  type        = string
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: gen-ai/vpc/eu-west-1/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/genai.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/vpc/us-east-1/.terraform-version
================
latest

================
File: gen-ai/vpc/us-east-1/data.tf
================
data "aws_subnets" "private" {
  filter {
    name   = "vpc-id"
    values = [module.genai-vpc.aws_vpc.id]
  }

  filter {
    name   = "tag:Name"
    values = ["*Private*"]
  }
}

data "aws_lb" "genai_service_alb" {
  count = var.env == "dev" ? 1 : 0
  name  = "genai-dev-ue1-mu-lb"
}

data "aws_lb" "genai_service_int_alb" {
  count = var.env == "dev" ? 1 : 0
  name  = "genai-dev-ue1-mu-int-lb"
}

data "aws_route53_zone" "int_dev_genai" {
  count        = var.env == "dev" ? 1 : 0
  name         = "int.${var.env}.genai.enverus.com"
  private_zone = false
}

data "aws_route53_zone" "dev_genai" {
  count        = var.env == "dev" ? 1 : 0
  name         = "dev.genai.enverus.com"
  private_zone = false
}

================
File: gen-ai/vpc/us-east-1/dev.backend.tfvars
================
key            = "891150701981/vpc/us-east-1/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: gen-ai/vpc/us-east-1/dev.tfvars
================
region                               = "us-east-1"
tag_name                             = "genai-vpc-dev"
vpc_cidr_block                       = "10.24.240.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "nonprod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: gen-ai/vpc/us-east-1/endpoints.tf
================
## Loadbalancers first:
resource "aws_lb_target_group" "genai_service_target_group" {
  count       = var.env == "dev" ? 1 : 0
  name        = "mobile-dmz-genai-service-tg"
  target_type = "alb"
  port        = 443
  protocol    = "TCP"
  vpc_id      = module.genai-vpc.aws_vpc.id
  health_check {
    protocol = "HTTPS"
    port     = "traffic-port"
    matcher  = "200-399,404"
    path     = "/"
  }
}


resource "aws_lb_target_group" "genai_service_int_target_group" {
  count       = var.env == "dev" ? 1 : 0
  name        = "mobile-dmz-genai-service-int-tg"
  target_type = "alb"
  port        = 443
  protocol    = "TCP"
  vpc_id      = module.genai-vpc.aws_vpc.id
  health_check {
    protocol = "HTTPS"
    port     = "traffic-port"
    matcher  = "200-399,404"
    path     = "/"
  }
}

resource "aws_lb" "genai_service_lb" {
  count                            = var.env == "dev" ? 1 : 0
  name                             = "mobile-dmz-genai-service-nlb"
  load_balancer_type               = "network"
  subnets                          = data.aws_subnets.private.ids
  internal                         = true
  enable_cross_zone_load_balancing = true
}

resource "aws_lb" "genai_service_int_lb" {
  count                            = var.env == "dev" ? 1 : 0
  name                             = "mobile-dmz-genai-service-int-nlb"
  load_balancer_type               = "network"
  subnets                          = data.aws_subnets.private.ids
  internal                         = true
  enable_cross_zone_load_balancing = true
}

resource "aws_lb_listener" "genai_service_lb_listener" {
  count             = var.env == "dev" ? 1 : 0
  load_balancer_arn = aws_lb.genai_service_lb[0].arn
  port              = "443"
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.genai_service_target_group[0].arn
  }
}

resource "aws_lb_listener" "genai_service_int_lb_listener" {
  count             = var.env == "dev" ? 1 : 0
  load_balancer_arn = aws_lb.genai_service_int_lb[0].arn
  port              = "443"
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.genai_service_int_target_group[0].arn
  }
}

resource "aws_lb_target_group_attachment" "genai_service_tg_attachment" {
  count            = var.env == "dev" ? 1 : 0
  target_group_arn = aws_lb_target_group.genai_service_target_group[0].arn
  target_id        = data.aws_lb.genai_service_alb[0].arn
}

resource "aws_lb_target_group_attachment" "genai_service_int_tg_attachment" {
  count            = var.env == "dev" ? 1 : 0
  target_group_arn = aws_lb_target_group.genai_service_int_target_group[0].arn
  target_id        = data.aws_lb.genai_service_int_alb[0].arn
}

#VPC Endpoint Services now
# we'll have to create the route53 record.  This is required for the private dns name registration.

resource "aws_vpc_endpoint_service" "genai_service_int_endpoint_service" {
  count                      = var.env == "dev" ? 1 : 0
  acceptance_required        = false
  network_load_balancer_arns = [aws_lb.genai_service_int_lb[0].arn]
  allowed_principals         = ["arn:aws:iam::812779367494:root"] #IT-Dev account. Location of the mobile-dmz.
  private_dns_name           = "service.int.dev.genai.enverus.com"

  tags = {
    Name   = "genai-service-int-endpoint-service"
    Target = "genai-service-int"
  }
}

resource "aws_route53_record" "genai_service_int_txt" {
  count   = var.env == "dev" ? 1 : 0
  zone_id = data.aws_route53_zone.int_dev_genai[0].zone_id
  name    = aws_vpc_endpoint_service.genai_service_int_endpoint_service[0].private_dns_name_configuration[0].name
  type    = "TXT"
  ttl     = "300"
  records = [aws_vpc_endpoint_service.genai_service_int_endpoint_service[0].private_dns_name_configuration[0].value]
}


resource "aws_vpc_endpoint_service" "genai_service_endpoint_service" {
  count                      = var.env == "dev" ? 1 : 0
  acceptance_required        = false
  network_load_balancer_arns = [aws_lb.genai_service_lb[0].arn]
  allowed_principals         = ["arn:aws:iam::812779367494:root"] #IT-Dev account. Location of the mobile-dmz.
  private_dns_name           = "service.dev.genai.enverus.com"

  tags = {
    Name   = "genai-service-endpoint-service"
    Target = "genai-service"
  }
}

resource "aws_route53_record" "genai_service_txt" {
  count   = var.env == "dev" ? 1 : 0
  zone_id = data.aws_route53_zone.dev_genai[0].zone_id
  name    = aws_vpc_endpoint_service.genai_service_endpoint_service[0].private_dns_name_configuration[0].name
  type    = "TXT"
  ttl     = "300"
  records = [aws_vpc_endpoint_service.genai_service_endpoint_service[0].private_dns_name_configuration[0].value]
}

================
File: gen-ai/vpc/us-east-1/main.tf
================
# Create a vpc using the vpc module

module "genai-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  vpc_cidr_block                       = var.vpc_cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
  enable_ue1_az3                       = var.enable_ue1_az3
}

output "vpc" { value = module.genai-vpc }

================
File: gen-ai/vpc/us-east-1/prod.backend.tfvars
================
key            = "126127704198/vpc/us-east-1/terraform.tfstate"
dynamodb_table = null
use_lockfile   = true

================
File: gen-ai/vpc/us-east-1/prod.tfvars
================
region                               = "us-east-1"
tag_name                             = "genai-vpc-prod"
vpc_cidr_block                       = "10.24.244.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "prod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: gen-ai/vpc/us-east-1/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The ID of the CloudWan Core Network"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the attachment of the VPC to the CloudWan Core Network"
  type        = bool
  default     = true
}

variable "tag_cloud_wan_segment" {
  description = "The CloudWan Segment to attach the VPC to"
  type        = string
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# If you have resources in AZ3 currently, enable this variable to use us-east-1-az3. Otherwise the subnet and its resources will be destroyed.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: gen-ai/vpc/us-east-1/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/genai.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/vpc/us-west-2/.terraform-version
================
latest:^1.7

================
File: gen-ai/vpc/us-west-2/dev.backend.tfvars
================
key = "891150701981/vpc/us-west-2/terraform.tfstate"

================
File: gen-ai/vpc/us-west-2/dev.tfvars
================
region                               = "us-west-2"
tag_name                             = "genai-vpc-dev"
vpc_cidr_block                       = "10.24.248.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "nonprod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/us-west-2/main.tf
================
# Create a vpc using the vpc module

module "genai-vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = var.region
  vpc_cidr_block                       = var.vpc_cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  tag_name                             = var.tag_name
  tag_environment                      = var.env
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
}

output "vpc" { value = module.genai-vpc }

================
File: gen-ai/vpc/us-west-2/prod.backend.tfvars
================
key = "126127704198/vpc/us-west-2/terraform.tfstate"

================
File: gen-ai/vpc/us-west-2/prod.tfvars
================
region                               = "us-west-2"
tag_name                             = "genai-vpc-prod"
vpc_cidr_block                       = "10.24.252.0/22"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
enable_cloud_wan_vpc_attachment      = true
tag_cloud_wan_segment                = "prod"
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true

================
File: gen-ai/vpc/us-west-2/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "vpc_cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = null
}

variable "region" {
  description = "AWS region for provider"
  type        = string
}

variable "cloud_wan_core_network_id" {
  description = "The ID of the CloudWan Core Network"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Boolean to enable the attachment of the VPC to the CloudWan Core Network"
  type        = bool
  default     = true
}

variable "tag_cloud_wan_segment" {
  description = "The CloudWan Segment to attach the VPC to"
  type        = string
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: gen-ai/vpc/us-west-2/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/genai.terraform/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: gen-ai/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_route53_record.genai_dev": [
      "aws_route53_zone.genai_prod"
    ],
    "aws_route53_record.genai_prod": [
      "aws_route53_zone.genai_prod"
    ],
    "aws_route53_record.genai_int": [
      "aws_route53_zone.genai_env",
      "aws_route53_zone.genai_internal_env"
    ],
    "aws_route53_record.genai_internal_int": [
      "aws_route53_zone.genai_prod",
      "aws_route53_zone.int_genai"
    ],
    "aws_lb_listener.genai_service_lb_listener": [
      "aws_lb_target_group.genai_service_target_group",
      "aws_lb.genai_service_lb"
    ],
    "aws_lb_listener.genai_service_int_lb_listener": [
      "aws_lb_target_group.genai_service_int_target_group",
      "aws_lb.genai_service_int_lb"
    ],
    "aws_lb_target_group_attachment.genai_service_tg_attachment": [
      "aws_lb_target_group.genai_service_target_group"
    ],
    "aws_lb_target_group_attachment.genai_service_int_tg_attachment": [
      "aws_lb_target_group.genai_service_int_target_group"
    ],
    "aws_vpc_endpoint_service.genai_service_int_endpoint_service": [
      "aws_lb.genai_service_int_lb"
    ],
    "aws_route53_record.genai_service_int_txt": [
      "aws_vpc_endpoint_service.genai_service_int_endpoint_service"
    ],
    "aws_vpc_endpoint_service.genai_service_endpoint_service": [
      "aws_lb.genai_service_lb"
    ],
    "aws_route53_record.genai_service_txt": [
      "aws_vpc_endpoint_service.genai_service_endpoint_service"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy",
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy",
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role"
    ]
  },
  "dependents": {
    "aws_route53_zone.genai_prod": [
      "aws_route53_record.genai_dev",
      "aws_route53_record.genai_prod",
      "aws_route53_record.genai_internal_int"
    ],
    "aws_route53_zone.genai_env": [
      "aws_route53_record.genai_int"
    ],
    "aws_route53_zone.genai_internal_env": [
      "aws_route53_record.genai_int"
    ],
    "aws_route53_zone.int_genai": [
      "aws_route53_record.genai_internal_int"
    ],
    "aws_lb_target_group.genai_service_target_group": [
      "aws_lb_listener.genai_service_lb_listener",
      "aws_lb_target_group_attachment.genai_service_tg_attachment"
    ],
    "aws_lb.genai_service_lb": [
      "aws_lb_listener.genai_service_lb_listener",
      "aws_vpc_endpoint_service.genai_service_endpoint_service"
    ],
    "aws_lb_target_group.genai_service_int_target_group": [
      "aws_lb_listener.genai_service_int_lb_listener",
      "aws_lb_target_group_attachment.genai_service_int_tg_attachment"
    ],
    "aws_lb.genai_service_int_lb": [
      "aws_lb_listener.genai_service_int_lb_listener",
      "aws_vpc_endpoint_service.genai_service_int_endpoint_service"
    ],
    "aws_vpc_endpoint_service.genai_service_int_endpoint_service": [
      "aws_route53_record.genai_service_int_txt"
    ],
    "aws_vpc_endpoint_service.genai_service_endpoint_service": [
      "aws_route53_record.genai_service_txt"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ]
  },
  "cross_repo_references": [
    "external.ecr_endpoint_type",
    "external.enable_ue1_az3",
    "external.aws_iam_policy_document.bucketPolicy",
    "external.vpc_cidr_block",
    "external.aws_caller_identity.current",
    "external.business_unit",
    "external.aws_config_sns",
    "external.region",
    "external.resource_type_exclusion_list",
    "external.env",
    "external.aws_subnets.private",
    "external.cloudwatch_logs_endpoint_type",
    "external.environment",
    "external.aws_iam_policy_document.bedrock_assume_role_policy",
    "external.cloud_wan_core_network_id",
    "external.aws_iam_policy_document.AmazonBedrockExecutionRoleForKnowledgeBase_assume_role_policy",
    "external.aws_default_tags.current",
    "external.aws_iam_policy_document.bedrock_inline_policy",
    "external.s3_logging_buckets",
    "external.enable_cloud_wan_vpc_attachment",
    "external.tag_cloud_wan_segment",
    "external.tag_name",
    "external.aws_iam_policy_document.AmazonBedrockExecutionRoleForKnowledgeBase_default",
    "external.bu",
    "external.configBackend",
    "external.enable_cgnat_subnet",
    "external.enable",
    "external.genai_ns_records_prod",
    "external.multi",
    "external.assume_role_arn",
    "external.enable_centralized_endpoints_profile",
    "external.kms_exclusion_list",
    "external.genai_ns_records_dev"
  ],
  "outputs": [
    "vpc",
    "vpc",
    "vpc",
    "vpc"
  ],
  "metadata": {
    "total_resources": 26,
    "resources_with_dependencies": 14,
    "resources_that_are_dependencies": 14,
    "cross_repo_refs_count": 33,
    "outputs_count": 4,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: gen-ai/.gitignore
================
# Local .terraform directories
**/.terraform/*

# .tfstate files
*.tfstate
*.tfstate.*

# Crash log files
crash.log
crash.*.log

# Include override files you do wish to add to version control using negated pattern
# !example_override.tf

# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan
# example: *tfplan*

# Ignore CLI configuration files
.terraformrc
terraform.rc

================
File: gen-ai/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.88.2
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"
      # - id: terraform_tfsec
      #   files: ^examples/ # only scan `examples/*` which are the implementation
      #   args:
      #     - --args=--config-file=__GIT_WORKING_DIR__/tfsec.yaml
      #     - --args=--concise-output

================
File: gen-ai/atlantis.yaml
================
version: 3

projects:
  ####### VPC #######
  - name: ue1-prod-vpc
    dir: vpc/us-east-1
    workflow: prod-vault
  - name: ue1-dev-vpc
    dir: vpc/us-east-1
    workflow: dev-vault
  - name: uw2-prod-vpc
    dir: vpc/us-west-2
    workflow: prod-vault
  - name: uw2-dev-vpc
    dir: vpc/us-west-2
    workflow: dev-vault
  - name: en1-prod-vpc
    dir: vpc/eu-north-1
    workflow: prod-vault
  - name: en1-dev-vpc
    dir: vpc/eu-north-1
    workflow: dev-vault
  - name: ew1-prod-vpc
    dir: vpc/eu-west-1
    workflow: prod-vault
  - name: ew1-dev-vpc
    dir: vpc/eu-west-1
    workflow: dev-vault
  ####### config #######
  - name: prod-config
    dir: config
    workflow: prod
  - name: dev-config
    dir: config
    workflow: dev
  ####### Route53 ########
  - name: dev-route53
    dir: route53
    workflow: dev
  - name: prod-route53
    dir: route53
    workflow: prod
  ####### IAM ########
  - name: dev-iam
    dir: iam
    workflow: dev
  - name: prod-iam
    dir: iam
    workflow: prod
  ####### S3 ########
  - name: dev-s3
    dir: s3
    workflow: dev
  - name: prod-s3
    dir: s3
    workflow: prod

================
File: gen-ai/global-dev-backend.tfvars
================
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::891150701981:role/terraform" }

================
File: gen-ai/global-dev.tfvars
================
bu              = "ea"                                       # business uni
env             = "dev"                                      # environment
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"       # use prod cts unless working with legacy accounts
assume_role_arn = "arn:aws:iam::891150701981:role/terraform" # update account id
region          = "us-east-1"                                # region

================
File: gen-ai/global-prod-backend.tfvars
================
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::126127704198:role/terraform" }

================
File: gen-ai/global-prod.tfvars
================
bu              = "ea"                                       # business uni
env             = "prod"                                     # environment
VAULT_ADDR      = "https://vault.prod.cts.enverus.com"       # use prod cts unless working with legacy accounts
assume_role_arn = "arn:aws:iam::126127704198:role/terraform" # update account id
region          = "us-east-1"                                # region

================
File: gen-ai/README.md
================
# genai.terraform
Infrastructure repo for the GenAI Prod and Dev Accounts

================
File: networking/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: networking/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: networking/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: networking/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: networking/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: networking/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: networking/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: networking/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: networking/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: networking/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: networking/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: networking/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: networking/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: networking/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: networking/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 c521331e05d6f70333a159217af57c58e3f86f87 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406105 -0600	clone: from github.com:enverus-cts/sre.terraform.cts-networking.git

================
File: networking/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 c521331e05d6f70333a159217af57c58e3f86f87 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406105 -0600	clone: from github.com:enverus-cts/sre.terraform.cts-networking.git

================
File: networking/.git/logs/HEAD
================
0000000000000000000000000000000000000000 c521331e05d6f70333a159217af57c58e3f86f87 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406105 -0600	clone: from github.com:enverus-cts/sre.terraform.cts-networking.git

================
File: networking/.git/refs/heads/main
================
c521331e05d6f70333a159217af57c58e3f86f87

================
File: networking/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: networking/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.terraform.cts-networking.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: networking/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: networking/.git/HEAD
================
ref: refs/heads/main

================
File: networking/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
1c8dc2898cbf1c4fc01e96b938b0dca324c69f2e refs/remotes/origin/NEXUS-605_Update_AWX_Template_Names_to_standard
1e674f1c69717164219ffbf0bcee7eb3484e8d19 refs/remotes/origin/SRE-11251
7c663ae3f90590797ab8199042f05004811999f2 refs/remotes/origin/SRE-12023
384be4c24a1c40512cfb0f2ff0cd0b1d1b7c6531 refs/remotes/origin/SRE-12431
b6a0744cca302c43788d29a988849919af3bd985 refs/remotes/origin/SRE-13395-central-mpl-2
ead224b054a8dd1cef14a3e5aaa6273583d95d90 refs/remotes/origin/SRE-14302
57fc4bc75432128a1b3dec9008d977f251ac9fed refs/remotes/origin/SRE-14760-set-up-change-feed-for-cts-networking-into-a-teams-channel2
399136ad1f1796d09a2ef1969359053e23751b7c refs/remotes/origin/SRE-15022
d30d1188214c1c87eb6200d53db87a039334dcc3 refs/remotes/origin/chore/sre-15038-update-actions
65d648d78747c61b63e0ec6087a4137c09b46874 refs/remotes/origin/feat/SRE-11564_direct_connect
c65659419a7a2e7add6e73d5d787389fc1449374 refs/remotes/origin/feat/sre-12648-add-sre-dev-attch
04b63075598f889b899f9e19b512d8522e006ae4 refs/remotes/origin/feat/sre-12690-ba-cwan
82fdb5f4d6f9c96327ee94fa3c8ab1ad21330f80 refs/remotes/origin/macneib-patch-1
c521331e05d6f70333a159217af57c58e3f86f87 refs/remotes/origin/main

================
File: networking/.github/workflows/teams-notification.yaml
================
name: Notify Teams Channel on PR Opened

on:
  pull_request:
    types: [opened]

jobs:
  notify:
    runs-on: enverus-ubuntu

    steps:
    - name: Send notification to Microsoft Teams cts-networking-changes channel
      uses: dchourasia/ms-teams-notification@1b2ee458772fbff74ca32505563efed4e663e405 # 1.0
      with:
        github-token: ${{ github.token }}
        webhook-uri: ${{ secrets.MS_TEAMS_WEBHOOK_URL_CTS_NETWORKING_CHANGES }}
        show-on-exit: false
        custom-facts: |
          - name: PR Title
            value: ${{ github.event.pull_request.title }}
          - name: PR Description
            value: ${{ github.event.pull_request.body }}
          - name: Pull Request URL
            value: ${{ github.event.pull_request.html_url }}
        custom-actions: |
          - text: View PR
            url: ${{ github.event.pull_request.html_url }}

================
File: networking/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: networking/.github/dependabot.yaml
================
version: 2
updates:
  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"

================
File: networking/acm/.terraform-version
================
latest:^0.12

================
File: networking/acm/cert.tf
================
data "aws_route53_zone" "enverus" {
  name         = "dev.sre.enverus.com"
  private_zone = false
}

resource "aws_acm_certificate" "enverus" {
  domain_name       = "*.dev.sre.enverus.com"
  validation_method = "DNS"

  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_route53_record" "enverus_cert" {
  for_each = {
    for dvo in aws_acm_certificate.enverus.domain_validation_options : dvo.domain_name => {
      name   = dvo.resource_record_name
      record = dvo.resource_record_value
      type   = dvo.resource_record_type
    }
  }

  allow_overwrite = true
  name            = each.value.name
  records         = [each.value.record]
  ttl             = 60
  type            = each.value.type
  zone_id         = data.aws_route53_zone.enverus.zone_id
}

resource "aws_acm_certificate_validation" "enverus" {
  certificate_arn         = aws_acm_certificate.enverus.arn
  validation_record_fqdns = [for record in aws_route53_record.enverus_cert : record.fqdn]
}

================
File: networking/acm/dev.backend.tfvars
================
key = "dev/acm/terraform.tfstate"

================
File: networking/acm/main.tf
================
terraform {
  backend "s3" {}
  required_version = "~> 0.12.31"
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: networking/acm/variables.tf
================
variable "env" {}
variable "aws_region" {}
variable "assume_role_arn" {}

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/.terraform-version
================
latest:^1.4

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/dev.backend.tfvars
================
key = "dev/atlantis-github-webhook-infra/github-org-webhooks/terraform.state"

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/dev.tfvars
================
url = "https://atlantis-github.enverus.com/events"

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/main.tf
================
# Get a github access token from vault to manage org webhooks
data "vault_generic_secret" "gh_token" {
  path = "enverus-cts/github-tokens/svc-git-sre@enverus/webhook-management"
}

# Create and store in vault a shared secret
resource "random_password" "shared_secret" {
  length  = 32
  special = false
}

resource "vault_generic_secret" "shared_secret" {
  path = "enverus-cts/atlantis/github.com-webhook-secret"

  data_json = jsonencode(
    {
      "github_secret" = random_password.shared_secret.result
    }
  )
}

# Create webhook for enverus-cts
resource "github_organization_webhook" "enverus-cts" {
  configuration {
    url          = var.url
    content_type = "json"
    insecure_ssl = false
    secret       = random_password.shared_secret.result
  }

  active = true

  events = [
    "issue_comment",
    "pull_request",
    "pull_request_review",
    "pull_request_review_comment",
    "push"
  ]
  provider = github.enverus-cts

}

# Create webhook for enverus-pr
resource "github_organization_webhook" "enverus-pr" {
  configuration {
    url          = var.url
    content_type = "json"
    insecure_ssl = false
    secret       = random_password.shared_secret.result
  }

  active = true

  events = [
    "issue_comment",
    "pull_request",
    "pull_request_review",
    "pull_request_review_comment",
    "push"
  ]

  provider = github.enverus-pr
}

# Create webhook for enverus-it
resource "github_organization_webhook" "enverus-it" {
  configuration {
    url          = var.url
    content_type = "json"
    insecure_ssl = false
    secret       = random_password.shared_secret.result
  }

  active = true

  events = [
    "issue_comment",
    "pull_request",
    "pull_request_review",
    "pull_request_review_comment",
    "push"
  ]

  provider = github.enverus-it
}

# Create webhook for enverus-ba
# resource "github_organization_webhook" "enverus-ba" {
#   configuration {
#     url          = var.url
#     content_type = "json"
#     insecure_ssl = false
#     secret       = random_password.shared_secret.result
#   }

#   active = true

#   events = [
#     "issue_comment",
#     "pull_request",
#     "pull_request_review",
#     "pull_request_review_comment",
#     "push"
#   ]

#   provider = github.enverus-ba
# }

# Create webhook for enverus-tr
resource "github_organization_webhook" "enverus-tr" {
  configuration {
    url          = var.url
    content_type = "json"
    insecure_ssl = false
    secret       = random_password.shared_secret.result
  }

  active = true

  events = [
    "issue_comment",
    "pull_request",
    "pull_request_review",
    "pull_request_review_comment",
    "push"
  ]

  provider = github.enverus-tr
}

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/variables.tf
================
# for provider
variable "url" {
  description = "webhook url"
  type        = string
}

variable "vault_addr" {
  description = "vault address"
  default     = "https://vault.prod.cts.enverus.com"
}

================
File: networking/atlantis-github-webhook-infra/github-org-webhooks/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    github = {
      source  = "integrations/github"
      version = "~> 6.0"
    }
    random = {
      source  = "hashicorp/random"
      version = ">= 2.0"
    }
    vault = {
      source  = "hashicorp/vault"
      version = ">= 3.3"
    }
  }
}


provider "vault" {
  address = var.vault_addr
}

# Need a provider for each org that needs a webhook
provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-cts"
  alias = "enverus-cts"
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-pr"
  alias = "enverus-pr"
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-it"
  alias = "enverus-it"
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-nv"
  alias = "enverus-nv"
}

# Need a provider for each org that needs a webhook
provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-ea"
  alias = "enverus-ea"
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-ba"
  alias = "enverus-ba"
}

provider "github" {
  token = data.vault_generic_secret.gh_token.data["token"]
  owner = "enverus-tr"
  alias = "enverus-tr"
}

================
File: networking/atlantis-github-webhook-infra/.gitignore
================
terraform.tfvars
terraform.tfstate
.terraform

================
File: networking/atlantis-github-webhook-infra/.terraform-version
================
latest:^1.4

================
File: networking/atlantis-github-webhook-infra/dev.backend.tfvars
================
key = "dev/atlantis-github-webhook-infra/terraform.state"

================
File: networking/atlantis-github-webhook-infra/dev.tfvars
================
name     = "atlantis-github"
vpc_name = "sre-vpc-dev"

# DNS
route53_zone_name            = "dev.sre.enverus.com"
route53_record_name          = "atlantis-github.dev.sre.enverus.com"
edge_proxy_lb_name           = "dev-edge-lb"
internal_route53_record_name = "atlantis-github-internal.dev.sre.enverus.com"

# Tags
tags = {
  Name = "atlantis"
}

# Access
alb_ingress_cidr_blocks = []
allow_github_webhooks   = true

================
File: networking/atlantis-github-webhook-infra/main.tf
================
# create ALB, security groups, ACM cert, and route53 for atlantis webhook relay.
locals {

  # Include only one group of secrets - for github, gitlab or bitbucket
  has_secrets = var.atlantis_github_user_token != ""

  # webhook
  secret_webhook_key = local.has_secrets
  # determine if the alb has authentication enabled, otherwise forward the traffic unauthenticated
  alb_authenication_method = length(keys(var.alb_authenticate_oidc)) > 0 ? "authenticate-oidc" : length(keys(var.alb_authenticate_cognito)) > 0 ? "authenticate-cognito" : "forward"

  tags = merge(
    {
      "Name" = var.name
    },
    var.tags,
  )

  # Chunk these into groups of 5, the limit for IPs in an AWS lb listener
  whitelist_unauthenticated_cidr_block_chunks = chunklist(
    sort(compact(concat(var.allow_github_webhooks ? var.github_webhooks_cidr_blocks : [], var.whitelist_unauthenticated_cidr_blocks))),
    5
  )

}

data "aws_partition" "current" {}

data "aws_region" "current" {}

data "aws_route53_zone" "this" {
  name         = var.route53_zone_name
  private_zone = var.route53_private_zone
}

data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = ["${var.vpc_name}"]
  }
}
data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "public" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["${var.vpc_name}*DMZ*Public Subnet"]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}

################################################################################
# ALB
################################################################################
module "alb" {
  source  = "terraform-aws-modules/alb/aws"
  version = "v6.5.0"

  name     = var.name
  internal = var.internal

  vpc_id          = data.aws_vpc.vpc_id.id
  subnets         = data.aws_subnets.public.ids
  security_groups = flatten([module.alb_https_sg.security_group_id, module.alb_http_sg.security_group_id, var.security_group_ids])

  access_logs = {
    enabled = var.alb_logging_enabled
    bucket  = var.alb_log_bucket_name
    prefix  = var.alb_log_location_prefix
  }

  enable_deletion_protection = var.alb_enable_deletion_protection

  drop_invalid_header_fields = var.alb_drop_invalid_header_fields

  listener_ssl_policy_default = var.alb_listener_ssl_policy_default
  https_listeners = [
    {
      target_group_index   = 0
      port                 = 443
      protocol             = "HTTPS"
      certificate_arn      = var.certificate_arn == "" ? module.acm.acm_certificate_arn : var.certificate_arn
      action_type          = local.alb_authenication_method
      authenticate_oidc    = var.alb_authenticate_oidc
      authenticate_cognito = var.alb_authenticate_cognito
    },
  ]

  http_tcp_listeners = [
    {
      port        = 80
      protocol    = "HTTP"
      action_type = "redirect"
      redirect = {
        port        = 443
        protocol    = "HTTPS"
        status_code = "HTTP_301"
      }
    },
  ]

  target_groups = [
    {
      name                 = var.name
      backend_protocol     = "HTTP"
      backend_port         = var.atlantis_port
      target_type          = "ip"
      deregistration_delay = 10
      health_check = {
        path = "/healthz"
      }
    },
  ]

  tags = local.tags
}

# Forward action for certain CIDR blocks to bypass authentication (eg. GitHub webhooks)
resource "aws_lb_listener_rule" "unauthenticated_access_for_cidr_blocks" {
  count = var.allow_unauthenticated_access ? length(local.whitelist_unauthenticated_cidr_block_chunks) : 0

  listener_arn = module.alb.https_listener_arns[0]
  priority     = var.allow_unauthenticated_access_priority + count.index

  action {
    type             = "forward"
    target_group_arn = module.alb.target_group_arns[0]
  }

  condition {
    source_ip {
      values = local.whitelist_unauthenticated_cidr_block_chunks[count.index]
    }
  }
}

# Forward action for certain URL paths to bypass authentication (eg. GitHub webhooks)
resource "aws_lb_listener_rule" "unauthenticated_access_for_webhook" {
  count = var.allow_unauthenticated_access && var.allow_github_webhooks ? 1 : 0

  listener_arn = module.alb.https_listener_arns[0]
  priority     = var.allow_unauthenticated_webhook_access_priority

  action {
    type             = "forward"
    target_group_arn = module.alb.target_group_arns[0]
  }

  condition {
    path_pattern {
      values = ["/events"]
    }
  }
}

################################################################################
# Security groups
################################################################################
module "alb_https_sg" {
  source  = "terraform-aws-modules/security-group/aws//modules/https-443"
  version = "v4.3.0"

  name        = "${var.name}-alb-https"
  vpc_id      = data.aws_vpc.vpc_id.id
  description = "Security group with HTTPS ports open for specific IPv4 CIDR block (or everybody), egress ports are all world open"

  ingress_cidr_blocks = sort(compact(concat(var.allow_github_webhooks ? var.github_webhooks_cidr_blocks : [], var.alb_ingress_cidr_blocks)))

  tags = merge(local.tags, var.alb_https_security_group_tags)
}

module "alb_http_sg" {
  source  = "terraform-aws-modules/security-group/aws//modules/http-80"
  version = "v4.3.0"

  name        = "${var.name}-alb-http"
  vpc_id      = data.aws_vpc.vpc_id.id
  description = "Security group with HTTP ports open for specific IPv4 CIDR block (or everybody), egress ports are all world open"

  ingress_cidr_blocks = sort(compact(concat(var.allow_github_webhooks ? var.github_webhooks_cidr_blocks : [], var.alb_ingress_cidr_blocks)))

  tags = merge(local.tags, var.alb_http_security_group_tags)
}

module "atlantis_sg" {
  source  = "terraform-aws-modules/security-group/aws"
  version = "v4.3.0"

  name        = var.name
  vpc_id      = data.aws_vpc.vpc_id.id
  description = "Security group with open port for Atlantis (${var.atlantis_port}) from ALB, egress ports are all world open"

  ingress_with_source_security_group_id = [
    {
      from_port                = var.atlantis_port
      to_port                  = var.atlantis_port
      protocol                 = "tcp"
      description              = "Atlantis"
      source_security_group_id = module.alb_https_sg.security_group_id
    },
  ]

  egress_rules = ["all-all"]

  tags = merge(local.tags, var.atlantis_security_group_tags)
}


################################################################################
# ACM (SSL certificate)
################################################################################
module "acm" {
  source  = "terraform-aws-modules/acm/aws"
  version = "v3.2.0"

  create_certificate = var.certificate_arn == ""

  domain_name = var.acm_certificate_domain_name == "" ? join(".", [var.name, var.route53_zone_name]) : var.acm_certificate_domain_name

  zone_id = var.certificate_arn == "" ? element(concat(data.aws_route53_zone.this.*.id, [""]), 0) : ""

  tags = local.tags
}

################################################################################
# Route53 records
################################################################################
# Create a record for external access to ALB
resource "aws_route53_record" "atlantis" {
  count = var.create_route53_record ? 1 : 0

  zone_id = data.aws_route53_zone.this.zone_id
  name    = var.route53_record_name != null ? var.route53_record_name : var.name
  type    = "A"

  alias {
    name                   = module.alb.lb_dns_name
    zone_id                = module.alb.lb_zone_id
    evaluate_target_health = true
  }
}

# Create a record for internal access to the ALB via edge proxy
data "aws_lb" "edge" {
  name = var.edge_proxy_lb_name
}

resource "aws_route53_record" "internal" {
  count = var.create_route53_record ? 1 : 0

  zone_id = data.aws_route53_zone.this.zone_id
  name    = var.internal_route53_record_name
  type    = "A"

  alias {
    name                   = data.aws_lb.edge.dns_name
    zone_id                = data.aws_lb.edge.zone_id
    evaluate_target_health = true
  }
}

################################################################################
# Cloudwatch logs
################################################################################
resource "aws_cloudwatch_log_group" "atlantis" {
  name              = var.name
  retention_in_days = var.cloudwatch_log_retention_in_days
  kms_key_id        = var.cloudwatch_logs_kms_key_id

  tags = local.tags
}

================
File: networking/atlantis-github-webhook-infra/outputs.tf
================
# ALB
output "alb_dns_name" {
  description = "Dns name of alb"
  value       = module.alb.lb_dns_name
}

output "alb_zone_id" {
  description = "Zone ID of alb"
  value       = module.alb.lb_zone_id
}

output "alb_arn" {
  description = "ARN of alb"
  value       = module.alb.lb_arn
}

output "alb_security_group_id" {
  description = "Security group of alb"
  value       = module.alb_https_sg.security_group_id
}

output "alb_http_listeners_id" {
  description = "Ids of alb http listeners"
  value       = module.alb.http_tcp_listener_ids
}

output "alb_http_listeners_arn" {
  description = "ARNs of alb http listeners"
  value       = module.alb.http_tcp_listener_arns
}

output "alb_https_listeners_id" {
  description = "Ids of alb https listeners"
  value       = module.alb.https_listener_ids
}

output "alb_https_listeners_arn" {
  description = "ARN of alb https listeners"
  value       = module.alb.https_listener_arns
}

================
File: networking/atlantis-github-webhook-infra/README.md
================
# AWS Terraform module which connects Atlantis to Github Webhooks

[Atlantis](https://www.runatlantis.io/) is tool which provides unified workflow for collaborating on Terraform through GitHub, GitLab and Bitbucket Cloud.

This repository contains Terraform infrastructure code which creates AWS resources required to connect [Atlantis](https://www.runatlantis.io/) on AWS to github webhooks, including:

- SSL certificate using Amazon Certificate Manager (ACM)
- Application Load Balancer (ALB)
- Domain name using AWS Route53 which points to ALB
- Github webhooks

Github repositories have to be configured to post events to Atlantis webhook URL.

### Before using Atlantis and the code in this repository please make sure that you have read and understood the security implications described in [the official Atlantis documentation](https://www.runatlantis.io/docs/security.html).

================
File: networking/atlantis-github-webhook-infra/terraform.tfvars.sample
================
vpc_id = "vpc-1651acf1"
private_subnets = ["10.10.1.0/24", "10.10.2.0/24"]

# DNS
route53_zone_name = "example.com"


# Specify one of the following block.
# For Github
atlantis_github_user = ""
atlantis_github_user_token = ""



# Tags
tags = {
  Name = "atlantis"
}

================
File: networking/atlantis-github-webhook-infra/variables.tf
================
variable "name" {
  description = "Name to use on all resources created (VPC, ALB, etc)"
  type        = string
  default     = "atlantis"
}

variable "security_group_ids" {
  description = "List of one or more security groups to be added to the load balancer"
  type        = list(string)
  default     = []
}

variable "tags" {
  description = "A map of tags to use on all resources"
  type        = map(string)
  default     = {}
}

variable "alb_https_security_group_tags" {
  description = "Additional tags to put on the https security group"
  type        = map(string)
  default     = {}
}

variable "alb_http_security_group_tags" {
  description = "Additional tags to put on the http security group"
  type        = map(string)
  default     = {}
}

variable "atlantis_security_group_tags" {
  description = "Additional tags to put on the atlantis security group"
  type        = map(string)
  default     = {}
}

variable "region" {
  description = "AWS region"
  default     = "us-east-1"
}

variable "internal" {
  description = "Whether the load balancer is internal or external"
  type        = bool
  default     = false
}


# ALB
variable "alb_ingress_cidr_blocks" {
  description = "List of IPv4 CIDR ranges to use on all ingress rules of the ALB."
  type        = list(string)
  default     = ["0.0.0.0/0"]
}

variable "alb_log_bucket_name" {
  description = "S3 bucket (externally created) for storing load balancer access logs. Required if alb_logging_enabled is true."
  type        = string
  default     = ""
}

variable "alb_log_location_prefix" {
  description = "S3 prefix within the log_bucket_name under which logs are stored."
  type        = string
  default     = ""
}

variable "alb_logging_enabled" {
  description = "Controls if the ALB will log requests to S3."
  type        = bool
  default     = false
}

variable "alb_authenticate_oidc" {
  description = "Map of Authenticate OIDC parameters to protect ALB (eg, using Auth0). See https://www.terraform.io/docs/providers/aws/r/lb_listener.html#authenticate-oidc-action"
  type        = any
  default     = {}
}

variable "alb_authenticate_cognito" {
  description = "Map of AWS Cognito authentication parameters to protect ALB (eg, using SAML). See https://www.terraform.io/docs/providers/aws/r/lb_listener.html#authenticate-cognito-action"
  type        = any
  default     = {}
}

variable "alb_enable_deletion_protection" {
  description = "If true, deletion of the load balancer will be disabled via the AWS API. This will prevent Terraform from deleting the load balancer. Defaults to false."
  type        = bool
  default     = null
}

variable "alb_drop_invalid_header_fields" {
  description = "Indicates whether invalid header fields are dropped in application load balancers. Defaults to false."
  type        = bool
  default     = null
}

variable "allow_unauthenticated_access" {
  description = "Whether to create ALB listener rule to allow unauthenticated access for certain CIDR blocks (eg. allow GitHub webhooks to bypass OIDC authentication)"
  type        = bool
  default     = false
}

variable "allow_unauthenticated_access_priority" {
  description = "ALB listener rule priority for allow unauthenticated access rule"
  type        = number
  default     = 10
}

variable "allow_unauthenticated_webhook_access_priority" {
  description = "ALB listener rule priority for allow unauthenticated webhook access rule"
  type        = number
  default     = 15
}

variable "allow_github_webhooks" {
  description = "Whether to allow access for GitHub webhooks"
  type        = bool
  default     = false
}

variable "github_webhooks_cidr_blocks" {
  description = "List of CIDR blocks used by GitHub webhooks" # This is hardcoded to avoid dependency on github provider. Source: https://api.github.com/meta
  type        = list(string)
  default     = ["140.82.112.0/20", "185.199.108.0/22", "192.30.252.0/22", "143.55.64.0/20"]
}

variable "whitelist_unauthenticated_cidr_blocks" {
  description = "List of allowed CIDR blocks to bypass authentication"
  type        = list(string)
  default     = []
}

variable "alb_listener_ssl_policy_default" {
  description = "The security policy if using HTTPS externally on the load balancer. [See](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html)."
  type        = string
  default     = "ELBSecurityPolicy-TLS13-1-2-Res-2021-06"
}


# ACM
variable "certificate_arn" {
  description = "ARN of certificate issued by AWS ACM. If empty, a new ACM certificate will be created and validated using Route53 DNS"
  type        = string
  default     = ""
}

variable "acm_certificate_domain_name" {
  description = "Route53 domain name to use for ACM certificate. Route53 zone for this domain should be created in advance. Specify if it is different from value in `route53_zone_name`"
  type        = string
  default     = ""
}

# Route53
variable "route53_zone_name" {
  description = "Route53 zone name to create ACM certificate in and main A-record, without trailing dot"
  type        = string
  default     = ""
}

variable "route53_record_name" {
  description = "Name of Route53 record to create ACM certificate in and main A-record. If null is specified, var.name is used instead. Provide empty string to point root domain name to ALB."
  type        = string
  default     = null
}

variable "route53_private_zone" {
  description = "Enable to use a private Route53 zone"
  type        = bool
  default     = false
}

variable "create_route53_record" {
  description = "Whether to create Route53 record for Atlantis"
  type        = bool
  default     = true
}

# Github
variable "atlantis_github_user" {
  description = "GitHub username that is running the Atlantis command"
  type        = string
  default     = ""
}

variable "atlantis_github_user_token" {
  description = "GitHub token of the user that is running the Atlantis command"
  type        = string
  default     = ""
}

variable "atlantis_github_webhook_secret" {
  description = "GitHub webhook secret of an app that is running the Atlantis command"
  type        = string
  default     = ""
}

variable "atlantis_port" {
  description = "Local port Atlantis should be running on. Default value is most likely fine."
  type        = number
  default     = 4141
}

# Cloudwatch
variable "cloudwatch_log_retention_in_days" {
  description = "Retention period of Atlantis CloudWatch logs"
  type        = number
  default     = 7
}

variable "cloudwatch_logs_kms_key_id" {
  description = "The ARN of the KMS Key to use when encrypting log data."
  type        = string
  default     = null
}

# for provider
variable "assume_role_arn" {
  description = "ARN of a role to assume to do terraform"
  type        = string
}

# for data source
variable "vpc_name" {
  description = "Name of vpc to get data from"
  type        = string
}

variable "internal_route53_record_name" {
  description = "DNS name for internal access to atlantis"
  type        = string
}

variable "edge_proxy_lb_name" {
  description = "edge proxy lb name - used in data source"
  type        = string
}

================
File: networking/atlantis-github-webhook-infra/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    random = {
      source  = "hashicorp/random"
      version = ">= 2.0"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: networking/cloud-wan/.terraform-version
================
latest

================
File: networking/cloud-wan/cloudwan-policy.tf
================
# AWS Cloud WAN Core Network Policy
data "aws_networkmanager_core_network_policy_document" "initial_nw_policy" {
  core_network_configuration {
    vpn_ecmp_support = false
    asn_ranges       = ["64517-64521"]
    # inside_cidr_blocks =
    edge_locations {
      location = var.aws_regions.ue1
      asn      = 64517
    }
    edge_locations {
      location = var.aws_regions.uw2
      asn      = 64518
    }
    edge_locations {
      location = var.aws_regions.ew1
      asn      = 64519
    }
    edge_locations {
      location = var.aws_regions.en1
      asn      = 64520
    }
  }

  segments {
    name = "prod"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  segments {
    name = "nonprod"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  segments {
    name = "shared"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  # Hardcode VPC's that need attachment to a segment that =/= their environment tag at a lower rule number.
  # 100 - 499 = Hardcoded vpc attachments.
  # 500 - 1000 = tag based attachments.
  attachment_policies {
    description     = "Production cloudwan connections."
    rule_number     = 500
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "prod"
    }
    action {
      association_method = "constant"
      segment            = "prod"
    }
  }

  attachment_policies {
    description     = "Non-production cloudwan connections."
    rule_number     = 600
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "nonprod"
    }
    action {
      association_method = "constant"
      segment            = "nonprod"
    }
  }

  attachment_policies {
    description     = "Shared cloudwan connections.  Mostly SRE run systems."
    rule_number     = 700
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "shared"
    }
    action {
      association_method = "constant"
      segment            = "shared"
    }
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "prod"
    share_with = ["*"]
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "nonprod"
    share_with = ["*"]
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "shared"
    share_with = ["*"]
  }

}

data "aws_networkmanager_core_network_policy_document" "core_nw_policy" {
  core_network_configuration {
    vpn_ecmp_support = false
    asn_ranges       = ["64517-64521"]
    # inside_cidr_blocks =
    edge_locations {
      location = var.aws_regions.ue1
      asn      = 64517
    }
    edge_locations {
      location = var.aws_regions.uw2
      asn      = 64518
    }
    edge_locations {
      location = var.aws_regions.ew1
      asn      = 64519
    }
    edge_locations {
      location = var.aws_regions.en1
      asn      = 64520
    }
  }

  segments {
    name = "prod"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  segments {
    name = "nonprod"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  segments {
    name = "shared"
    edge_locations = [
      var.aws_regions.ue1,
      var.aws_regions.uw2,
      var.aws_regions.en1,
      var.aws_regions.ew1,
    ]
    require_attachment_acceptance = false
    isolate_attachments           = false
  }

  # Hardcode VPC's that need attachment to a segment that =/= their environment tag at a lower rule number.
  # 100 - 499 = Hardcoded vpc attachments.
  # 500 - 1000 = tag based attachments.
  attachment_policies {
    description     = "Production cloudwan connections."
    rule_number     = 500
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "prod"
    }
    action {
      association_method = "constant"
      segment            = "prod"
    }
  }

  attachment_policies {
    description     = "Non-production cloudwan connections."
    rule_number     = 600
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "nonprod"
    }
    action {
      association_method = "constant"
      segment            = "nonprod"
    }
  }

  attachment_policies {
    description     = "Shared cloudwan connections.  Mostly SRE run systems."
    rule_number     = 700
    condition_logic = "or"

    conditions {
      type     = "tag-value"
      key      = "cloud-wan"
      operator = "equals"
      value    = "shared"
    }
    action {
      association_method = "constant"
      segment            = "shared"
    }
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "prod"
    share_with = ["*"]
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "nonprod"
    share_with = ["*"]
  }

  segment_actions {
    action     = "share"
    mode       = "attachment-route"
    segment    = "shared"
    share_with = ["*"]
  }

  segment_actions {
    action                  = "create-route"
    segment                 = "prod"
    description             = "Default routes to egress VPC's"
    destination_cidr_blocks = ["0.0.0.0/0"]
    destinations = [
      module.cts-ue1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-uw2-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-en1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-ew1-egress-vpc.aws_networkmanager_vpc_attachment.id,
    ]
  }

  segment_actions {
    action                  = "create-route"
    segment                 = "nonprod"
    description             = "Default routes to egress VPC's"
    destination_cidr_blocks = ["0.0.0.0/0"]
    destinations = [
      module.cts-ue1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-uw2-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-en1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-ew1-egress-vpc.aws_networkmanager_vpc_attachment.id,
    ]
  }

  segment_actions {
    action                  = "create-route"
    segment                 = "shared"
    description             = "Default routes to egress VPC's"
    destination_cidr_blocks = ["0.0.0.0/0"]
    destinations = [
      module.cts-ue1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-uw2-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-en1-egress-vpc.aws_networkmanager_vpc_attachment.id,
      module.cts-ew1-egress-vpc.aws_networkmanager_vpc_attachment.id,
    ]
  }
}

================
File: networking/cloud-wan/data.tf
================
data "aws_caller_identity" "current" {
  provider = aws.uw2
}

================
File: networking/cloud-wan/design.excalidraw
================
{
  "type": "excalidraw",
  "version": 2,
  "source": "https://marketplace.visualstudio.com/items?itemName=pomdtr.excalidraw-editor",
  "elements": [
    {
      "type": "rectangle",
      "version": 46,
      "versionNonce": 1213421047,
      "isDeleted": false,
      "id": "YWRDhIt6IbAC1TRA82FPv",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 278.953125,
      "y": 94.21875,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 444.127197265625,
      "height": 593.446044921875,
      "seed": 921505623,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698956989929,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 160,
      "versionNonce": 312892055,
      "isDeleted": false,
      "id": "uRFcQdKGSNah7hkfORk6z",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 734.236328125,
      "y": 91.43218994140625,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 457.050537109375,
      "height": 599.9036254882812,
      "seed": 1837334295,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957002614,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 206,
      "versionNonce": 683651223,
      "isDeleted": false,
      "id": "_zBNqZqgm2ByQKCxIJ6QU",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1199.21337890625,
      "y": 88.835693359375,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 457.050537109375,
      "height": 599.9036254882812,
      "seed": 520375097,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957011214,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 233,
      "versionNonce": 381619385,
      "isDeleted": false,
      "id": "J1Akkpbynnyy99ztBhTqb",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1666.78564453125,
      "y": 84.12802124023438,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 457.050537109375,
      "height": 599.9036254882812,
      "seed": 1143615447,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957016662,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 20,
      "versionNonce": 239070576,
      "isDeleted": false,
      "id": "fjkRznncnzFc8i6Qa6UaF",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 414,
      "y": 108,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 83.43998718261719,
      "height": 25,
      "seed": 219757401,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329375,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "    UW2",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "    UW2",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 10,
      "versionNonce": 1746133392,
      "isDeleted": false,
      "id": "7NFFAmyAywsGpMI0mSHhg",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 942,
      "y": 115,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 33.17999267578125,
      "height": 25,
      "seed": 1309337945,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329376,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "UE1",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "UE1",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 12,
      "versionNonce": 1019264880,
      "isDeleted": false,
      "id": "f3duf7HPJ_Y-fH6QEHkY0",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1401,
      "y": 127,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 31.779983520507812,
      "height": 25,
      "seed": 1096449911,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329377,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EN1",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EN1",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 43,
      "versionNonce": 2084646800,
      "isDeleted": false,
      "id": "WMNIecwYQ6aP8CaXdHc8C",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1864.6964285714284,
      "y": 123.23660714285717,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 42.639984130859375,
      "height": 25,
      "seed": 249190519,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329378,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EW2",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EW2",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 163,
      "versionNonce": 1207232586,
      "isDeleted": false,
      "id": "tw9ZSB7Ra9LelZJ0HEiOv",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 25.16169084821422,
      "y": 187.5757620675223,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 2092.2121233258927,
      "height": 113.41775948660722,
      "seed": 895561239,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [
        {
          "id": "9Pd9arqNSnrOawjNH5mUN",
          "type": "arrow"
        }
      ],
      "updated": 1700251678887,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 15,
      "versionNonce": 1196904816,
      "isDeleted": false,
      "id": "kjSE-o1fXqJyKhwDvJdkF",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 101.71428571428572,
      "y": 226.07177734375003,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 99.59992980957031,
      "height": 25,
      "seed": 1005634649,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329378,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "CLoudWAN",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "CLoudWAN",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 239,
      "versionNonce": 784067737,
      "isDeleted": false,
      "id": "QbVA81TXa4wctyXTBFZGe",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 486.5657087053571,
      "y": 374.01288713727695,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 150.6689453125,
      "height": 102.75129045758922,
      "seed": 1350949145,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957253936,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 81,
      "versionNonce": 1391544375,
      "isDeleted": false,
      "id": "FGfs1IF9QULTsbRRR7-gg",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1237.4753069196427,
      "y": 388.70099748883933,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 150.6689453125,
      "height": 102.75129045758922,
      "seed": 1776636407,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957108665,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 123,
      "versionNonce": 103989753,
      "isDeleted": false,
      "id": "jf7OfgfA9rO5Vr7kbSUqk",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1696.2197265625,
      "y": 386.19358607700894,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 150.6689453125,
      "height": 102.75129045758922,
      "seed": 531177593,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957111199,
      "link": null,
      "locked": false
    },
    {
      "type": "rectangle",
      "version": 138,
      "versionNonce": 1068861367,
      "isDeleted": false,
      "id": "xb98jU5XTQFeEbsMOIhWi",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 767.3668387276784,
      "y": 379.30201939174117,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 150.6689453125,
      "height": 102.75129045758922,
      "seed": 1821139737,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957114910,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 181,
      "versionNonce": 2039790992,
      "isDeleted": false,
      "id": "K3XtNCO3b8mScYVhOygZJ",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 513.0169503348214,
      "y": 403.4120396205358,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 101.19990539550781,
      "height": 25,
      "seed": 1409379801,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329379,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EgressVPC",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EgressVPC",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 98,
      "versionNonce": 625714032,
      "isDeleted": false,
      "id": "Y2Ldnpjp_iRttxeTdXBNJ",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1264.4270368303569,
      "y": 411.1053466796875,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 101.19990539550781,
      "height": 25,
      "seed": 256519417,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329379,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EgressVPC",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EgressVPC",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 140,
      "versionNonce": 1632013200,
      "isDeleted": false,
      "id": "HHflAjlNszlgRv1aI5rkY",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1723.1714564732142,
      "y": 408.5979352678571,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 101.19990539550781,
      "height": 25,
      "seed": 1666318231,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329380,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EgressVPC",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EgressVPC",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "text",
      "version": 16,
      "versionNonce": 619033968,
      "isDeleted": false,
      "id": "M0mnMbcyBpvvH45NL9GUB",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 793.1428571428571,
      "y": 407.50034877232144,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 101.19990539550781,
      "height": 25,
      "seed": 1398949367,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329381,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "EgressVPC",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "EgressVPC",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 40,
      "versionNonce": 1659853719,
      "isDeleted": false,
      "id": "t8juYuHq9v_Vv8jNXO3qN",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 298.34375,
      "y": 369.21909877232144,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 150.02301897321422,
      "height": 104.79544503348211,
      "seed": 106025911,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1698957259822,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 10,
      "versionNonce": 1301191056,
      "isDeleted": false,
      "id": "KiUx6-6rXnL3QMkf_2BDf",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 330.2857142857142,
      "y": 406.07177734375,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 46.77998352050781,
      "height": 25,
      "seed": 2069930455,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329382,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "TGW",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "TGW",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 198,
      "versionNonce": 1069993558,
      "isDeleted": false,
      "id": "aZx1S0Y9bdlZixq9DiR7O",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 32.12909226190493,
      "y": 533.7831333705358,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 2080.347202845982,
      "height": 127.66714913504461,
      "seed": 837655415,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1700251597853,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 36,
      "versionNonce": 191727472,
      "isDeleted": false,
      "id": "-dwO-Qk2psKjDZrmJckcW",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 84.57142857142856,
      "y": 594.6432059151786,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 186.47987365722656,
      "height": 25,
      "seed": 752904663,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329382,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "Direct Connect GW",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "Direct Connect GW",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 113,
      "versionNonce": 304492246,
      "isDeleted": false,
      "id": "paPPvWFoBGbisjWq-fEMY",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 444.8902271815708,
      "y": 133.3002624511719,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 215.99633789062509,
      "height": 49.289581298828125,
      "seed": 1245108374,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1700251676166,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 74,
      "versionNonce": 1369761680,
      "isDeleted": false,
      "id": "KMRjm9go0RV4qeUlot6ba",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 459.5420216151647,
      "y": 147.8971862792969,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 202.13987731933594,
      "height": 25,
      "seed": 1017214614,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329383,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "VPC 10.24.240.0/22",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "VPC 10.24.240.0/22",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "arrow",
      "version": 44,
      "versionNonce": 2144176342,
      "isDeleted": false,
      "id": "9Pd9arqNSnrOawjNH5mUN",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 500.93612561907094,
      "y": 168.89990234375003,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 6.386474609375,
      "height": 74.121337890625,
      "seed": 1781341514,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [],
      "updated": 1700250986525,
      "link": null,
      "locked": false,
      "startBinding": {
        "elementId": "tw9ZSB7Ra9LelZJ0HEiOv",
        "focus": 0.5488403616940372,
        "gap": 18.675859723772277
      },
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          -6.386474609375,
          74.121337890625
        ]
      ]
    },
    {
      "type": "rectangle",
      "version": 81,
      "versionNonce": 1898791626,
      "isDeleted": false,
      "id": "bMZuze-IwDv16BhYoHp43",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 534.7642506190709,
      "y": 803.165283203125,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 532.0367431640625,
      "height": 196.71612548828125,
      "seed": 1540908746,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1700251027757,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 20,
      "versionNonce": 892017008,
      "isDeleted": false,
      "id": "UR8m2Q_m5EqHdW_0X-gxz",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 656.5455006190709,
      "y": 895.462158203125,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 77.49992370605469,
      "height": 25,
      "seed": 2040436810,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329384,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "On-Prem",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "On-Prem",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "arrow",
      "version": 41,
      "versionNonce": 2031548118,
      "isDeleted": false,
      "id": "m5YUj5_kAm1mhGh4otMSN",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 393.63925061907094,
      "y": 274.4744873046875,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 0.13623046875,
      "height": 120.2432861328125,
      "seed": 889150346,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [],
      "updated": 1700251051609,
      "link": null,
      "locked": false,
      "startBinding": null,
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          0.13623046875,
          120.2432861328125
        ]
      ]
    },
    {
      "type": "arrow",
      "version": 32,
      "versionNonce": 1542343370,
      "isDeleted": false,
      "id": "h2CZ94UbYZHNqS299TN2h",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 393.20175061907094,
      "y": 457.8807373046875,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 32.1763916015625,
      "height": 145.3570556640625,
      "seed": 2147331094,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [],
      "updated": 1700251053926,
      "link": null,
      "locked": false,
      "startBinding": null,
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          32.1763916015625,
          145.3570556640625
        ]
      ]
    },
    {
      "type": "arrow",
      "version": 43,
      "versionNonce": 1628062806,
      "isDeleted": false,
      "id": "xhDjHc5W2dRkDVAY9NAH0",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 789.2642506190709,
      "y": 986.7728271484375,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 8.1226806640625,
      "height": 192.91766357421875,
      "seed": 1018188938,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [
        {
          "type": "text",
          "id": "Drgbn2icAdWBY-vr0JzFk"
        }
      ],
      "updated": 1700251698038,
      "link": null,
      "locked": false,
      "startBinding": null,
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": "arrow",
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          8.1226806640625,
          192.91766357421875
        ]
      ]
    },
    {
      "type": "text",
      "version": 19,
      "versionNonce": 462816726,
      "isDeleted": false,
      "id": "Drgbn2icAdWBY-vr0JzFk",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 734.1256245204381,
      "y": 1070.7316589355469,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 118.39993286132812,
      "height": 25,
      "seed": 1454166922,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1700251148332,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "10.24.0.0/16",
      "textAlign": "center",
      "verticalAlign": "middle",
      "containerId": "xhDjHc5W2dRkDVAY9NAH0",
      "originalText": "10.24.0.0/16",
      "lineHeight": 1.25,
      "baseline": 19
    },
    {
      "type": "rectangle",
      "version": 76,
      "versionNonce": 398282646,
      "isDeleted": false,
      "id": "c4oQ0c650THmpVg8TRO8r",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 616.0611256190709,
      "y": 1161.4307861328125,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 442.40283203125,
      "height": 186.84539794921875,
      "seed": 1197600214,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1700251094109,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 18,
      "versionNonce": 1505850768,
      "isDeleted": false,
      "id": "K4KtPkGd_GtFTm1wPjlIm",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 733.9361256190709,
      "y": 1267.1651611328125,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 127.01991271972656,
      "height": 25,
      "seed": 1221779990,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329384,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "Aviatrix AWS",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "Aviatrix AWS",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "rectangle",
      "version": 75,
      "versionNonce": 654600813,
      "isDeleted": false,
      "id": "DBm7jwk8QQtd_oi41FjYH",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 750.2798756190709,
      "y": 1459.2115478515625,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 282.88525390625,
      "height": 120.09967041015625,
      "seed": 16369866,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 3
      },
      "boundElements": [],
      "updated": 1705091692252,
      "link": null,
      "locked": false
    },
    {
      "type": "text",
      "version": 29,
      "versionNonce": 895904624,
      "isDeleted": false,
      "id": "gfyTnRUCgdWF1fLXjOeKh",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 796.9361256190709,
      "y": 1503.1646728515625,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 127.21992492675781,
      "height": 25,
      "seed": 1346102346,
      "groupIds": [],
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1709322329385,
      "link": null,
      "locked": false,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "10.24.0.0/24",
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "10.24.0.0/24",
      "lineHeight": 1.25,
      "baseline": 18
    },
    {
      "type": "arrow",
      "version": 20,
      "versionNonce": 1530413770,
      "isDeleted": false,
      "id": "24ybTUi699MypXleZNbFE",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 473.22779228573785,
      "y": 630.9523518880209,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 138.26721191406256,
      "height": 220.78328450520837,
      "seed": 1615096598,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [],
      "updated": 1700251701069,
      "link": null,
      "locked": false,
      "startBinding": null,
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": "arrow",
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          138.26721191406256,
          220.78328450520837
        ]
      ]
    },
    {
      "type": "arrow",
      "version": 39,
      "versionNonce": 500974038,
      "isDeleted": false,
      "id": "v_GQuwNmmJZdJPknkzJn_",
      "fillStyle": "hachure",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 878.8007089524044,
      "y": 1479.0433756510415,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "width": 3.07373046875,
      "height": 162.8765869140625,
      "seed": 1000443606,
      "groupIds": [],
      "frameId": null,
      "roundness": {
        "type": 2
      },
      "boundElements": [],
      "updated": 1700251692872,
      "link": null,
      "locked": false,
      "startBinding": null,
      "endBinding": null,
      "lastCommittedPoint": null,
      "startArrowhead": "arrow",
      "endArrowhead": "arrow",
      "points": [
        [
          0,
          0
        ],
        [
          3.07373046875,
          -162.8765869140625
        ]
      ]
    }
  ],
  "appState": {
    "gridSize": null,
    "viewBackgroundColor": "#ffffff"
  },
  "files": {}
}

================
File: networking/cloud-wan/dev.backend.tfvars
================
key    = "449228620267/dev/cloud-wan/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: networking/cloud-wan/dev.tfvars
================
environment   = "dev"
business_unit = "cts"
source_code   = "https://github.com/enverus-cts/sre.terraform.cts-networking"
team          = "sre@enverus.com"
egress_vpc_cidr_block = {
  ue1 = "10.24.204.0/23"
  uw2 = "10.24.206.0/23"
  en1 = "10.24.200.0/23"
  ew1 = "10.24.202.0/23"
}

egress_vpc_name = {
  ue1 = "cts-dev-networking-vpc-egress-ue1"
  uw2 = "cts-dev-networking-vpc-egress-uw2"
  en1 = "cts-dev-networking-vpc-egress-en1"
  ew1 = "cts-dev-networking-vpc-egress-ew1"
}
# Direct Connect VI: ID | BGP ASN|BGP authentication key |Your router peer IP | Amazon router peer IP | AWS logical device
#dxpeer-ffwi7wlp	ipv4	64601	0xFwlcs6DaYsnEYea4FTw7oi	10.255.59.37/30	10.255.59.38/30	PEH51-2ymbeumgcmhl1

direct_connect_gateway_id = "ae061ea3-0bc4-47d1-bbc9-803dd22b9151"

tgw_allowed_prefixes = ["10.135.0.0/16", "10.24.0.0/16", "10.25.0.0/16"]

================
File: networking/cloud-wan/flowlogs.tf
================
#VPC Flow Logs
resource "aws_flow_log" "ue1_vpc_flow_log" {
  provider             = aws.ue1
  log_destination      = "arn:aws:s3:::enverus-central-logs"
  log_destination_type = "s3"
  traffic_type         = "ALL"
  vpc_id               = module.cts-ue1-egress-vpc.aws_vpc.id
  destination_options {
    per_hour_partition = true
    file_format        = "parquet"
  }
  tags = {
    Name = "VPC Flow Log to central"
  }
}

resource "aws_flow_log" "uw2_vpc_flow_log" {
  provider             = aws.uw2
  log_destination      = "arn:aws:s3:::enverus-central-logs"
  log_destination_type = "s3"
  traffic_type         = "ALL"
  vpc_id               = module.cts-uw2-egress-vpc.aws_vpc.id
  destination_options {
    per_hour_partition = true
    file_format        = "parquet"
  }
  tags = {
    Name = "VPC Flow Log to central"
  }
}

resource "aws_flow_log" "en1_vpc_flow_log" {
  provider             = aws.en1
  log_destination      = "arn:aws:s3:::enverus-central-logs"
  log_destination_type = "s3"
  traffic_type         = "ALL"
  vpc_id               = module.cts-en1-egress-vpc.aws_vpc.id
  destination_options {
    per_hour_partition = true
    file_format        = "parquet"
  }
  tags = {
    Name = "VPC Flow Log to central"
  }
}

resource "aws_flow_log" "uw1_vpc_flow_log" {
  provider             = aws.ew1
  log_destination      = "arn:aws:s3:::enverus-central-logs"
  log_destination_type = "s3"
  traffic_type         = "ALL"
  vpc_id               = module.cts-ew1-egress-vpc.aws_vpc.id
  destination_options {
    per_hour_partition = true
    file_format        = "parquet"
  }
  tags = {
    Name = "VPC Flow Log to central"
  }
}

================
File: networking/cloud-wan/locals.tf
================
locals {
  # Endpoint configuration for us-east-1
  endpoint_config_ue1 = {
    kinesis = {
      domain       = "kinesis"
      record_name  = "kinesis"
      service_name = "kinesis-streams"
      display_name = "Kinesis Endpoint"
    }
    sqs = {
      domain       = "sqs"
      record_name  = "sqs"
      service_name = "sqs"
      display_name = "SQS Endpoint"
    }
    elb = {
      domain       = "elasticloadbalancing"
      record_name  = "elasticloadbalancing"
      service_name = "elasticloadbalancing"
      display_name = "ELB Endpoint"
    }
    sns = {
      domain       = "sns"
      record_name  = "sns"
      service_name = "sns"
      display_name = "SNS Endpoint"
    }
    athena = {
      domain       = "athena"
      record_name  = "athena"
      service_name = "athena"
      display_name = "Athena Endpoint"
    }
  }

  # Endpoint configuration for other regions
  endpoint_config_uw2 = {}
  endpoint_config_ew1 = {}
  endpoint_config_en1 = {}

  # Which endpoints to enable per region
  region_endpoint_config = {
    ue1 = keys(local.endpoint_config_ue1)
    uw2 = keys(local.endpoint_config_uw2)
    ew1 = keys(local.endpoint_config_ew1)
    en1 = keys(local.endpoint_config_en1)
  }
}

================
File: networking/cloud-wan/main.tf
================
# GLOBAL NETWORK
resource "aws_networkmanager_global_network" "global_network" {
  provider = aws.ue1

  description = "Cloud WAN - Global ${title(var.env)} Network"

  tags = {
    Name = "Enverus Global ${title(var.env)} AWS Network"
  }
}

# CORE NETWORK
resource "aws_networkmanager_core_network" "core_network" {
  provider = aws.uw2

  description       = "Cloud WAN - ${title(var.env)} Core Network"
  global_network_id = aws_networkmanager_global_network.global_network.id

  create_base_policy  = false
  base_policy_regions = values({ for k, v in var.aws_regions : k => v })

  tags = {
    Name = "Core Network - ${var.project_identifier}"
  }
}

# CORE NETWORK POLICY ATTACHMENT
resource "aws_networkmanager_core_network_policy_attachment" "initial_policy_attachment" {
  provider = aws.uw2
  lifecycle {
    ignore_changes = all
  }
  core_network_id = aws_networkmanager_core_network.core_network.id
  policy_document = data.aws_networkmanager_core_network_policy_document.initial_nw_policy.json
}

resource "aws_networkmanager_core_network_policy_attachment" "policy_attachment" {
  provider   = aws.uw2
  depends_on = [module.cts-en1-egress-vpc, module.cts-ew1-egress-vpc, module.cts-ue1-egress-vpc, module.cts-uw2-egress-vpc]

  core_network_id = aws_networkmanager_core_network.core_network.id
  policy_document = data.aws_networkmanager_core_network_policy_document.core_nw_policy.json
}

resource "aws_networkmanager_dx_gateway_attachment" "dx_gateway_attachment" {
  provider                   = aws.uw2
  core_network_id            = aws_networkmanager_core_network.core_network.id
  direct_connect_gateway_arn = "arn:aws:directconnect::${data.aws_caller_identity.current.account_id}:dx-gateway/${var.direct_connect_gateway_id}"
  edge_locations             = [var.aws_regions.ue1, var.aws_regions.uw2, var.aws_regions.en1, var.aws_regions.ew1]
  tags = {
    "cloud-wan" = "shared"
    "Name"      = "DX Gateway Attachment"
  }
}

================
File: networking/cloud-wan/outputs.tf
================
output "cts-ue1-egress-vpc" {
  value = module.cts-ue1-egress-vpc.vpc_id
}

output "cts-uw2-egress-vpc" {
  value = module.cts-uw2-egress-vpc.vpc_id
}

output "cts-en1-egress-vpc" {
  value = module.cts-en1-egress-vpc.vpc_id
}

output "cts-ew1-egress-vpc" {
  value = module.cts-ew1-egress-vpc.vpc_id
}

output "global-network" {
  value = aws_networkmanager_global_network.global_network.arn
}

output "core-network" {
  value = aws_networkmanager_core_network.core_network.arn
}

================
File: networking/cloud-wan/prod.backend.tfvars
================
key    = "449228620267/prod/cloud-wan/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: networking/cloud-wan/prod.tfvars
================
environment   = "prod"
business_unit = "cts"
source_code   = "https://github.com/enverus-cts/sre.terraform.cts-networking"
team          = "sre@enverus.com"
egress_vpc_cidr_block = {
  ue1 = "10.24.196.0/23"
  uw2 = "10.24.198.0/23"
  en1 = "10.24.192.0/23"
  ew1 = "10.24.194.0/23"
}

egress_vpc_name = {
  ue1 = "cts-prod-networking-vpc-egress-ue1"
  uw2 = "cts-prod-networking-vpc-egress-uw2"
  en1 = "cts-prod-networking-vpc-egress-en1"
  ew1 = "cts-prod-networking-vpc-egress-ew1"
}

direct_connect_gateway_id = "b36127ab-d3e1-4a95-9fbf-5ad6f294377c"
uw2_tgw_allow_prefixed    = [""]

ue1_tgw_allowed_prefixes = [
  "10.135.0.0/16",
  "10.24.0.0/16",
  "10.25.0.0/16"
]

================
File: networking/cloud-wan/resource-sharing.tf
================
data "aws_organizations_organization" "parent_organization" {
  provider = aws.uw2
}

output "account_ids" {
  description = "Account arn for the organization"
  value       = data.aws_organizations_organization.parent_organization.arn
}

resource "aws_ram_resource_share" "core_network" {
  provider                  = aws.ue1
  name                      = "Cloud WAN - Core ${title(var.env)} Network Share"
  allow_external_principals = false
  tags = {
    BusinessUnit     = var.bu
    Environment      = var.env
    TerraformCreated = "true"
    SourceCode       = var.source_code
    Team             = var.team
  }
}

resource "aws_ram_principal_association" "core_network" {
  provider           = aws.ue1
  principal          = data.aws_organizations_organization.parent_organization.arn
  resource_share_arn = aws_ram_resource_share.core_network.arn
}

resource "aws_ram_resource_association" "core_network" {
  provider           = aws.ue1
  resource_arn       = aws_networkmanager_core_network.core_network.arn
  resource_share_arn = aws_ram_resource_share.core_network.arn
  depends_on = [
    aws_networkmanager_core_network.core_network
  ]
}

# Route 53 Centralized Endpoint Profile Sharing
resource "aws_ram_resource_share" "route53_endpoint_profile_ue1" {
  name                      = "Route 53 Profile - Centralized Endpoints"
  allow_external_principals = false
  region                    = "us-east-1"

  tags = {
    BusinessUnit     = var.bu
    Environment      = var.env
    TerraformCreated = "true"
    SourceCode       = var.source_code
    Team             = var.team
  }
}

resource "aws_ram_resource_share" "route53_endpoint_profile_uw2" {
  name                      = "Route 53 Profile - Centralized Endpoints"
  allow_external_principals = false
  region                    = "us-west-2"

  tags = {
    BusinessUnit     = var.bu
    Environment      = var.env
    TerraformCreated = "true"
    SourceCode       = var.source_code
    Team             = var.team
  }
}

resource "aws_ram_resource_share" "route53_endpoint_profile_en1" {
  name                      = "Route 53 Profile - Centralized Endpoints"
  allow_external_principals = false
  region                    = "eu-north-1"

  tags = {
    BusinessUnit     = var.bu
    Environment      = var.env
    TerraformCreated = "true"
    SourceCode       = var.source_code
    Team             = var.team
  }
}

resource "aws_ram_resource_share" "route53_endpoint_profile_ew1" {
  name                      = "Route 53 Profile - Centralized Endpoints"
  allow_external_principals = false
  region                    = "eu-west-1"

  tags = {
    BusinessUnit     = var.bu
    Environment      = var.env
    TerraformCreated = "true"
    SourceCode       = var.source_code
    Team             = var.team
  }
}

# Resource Associations for "aws_ram_resource_share" for Route 53 Profiles
resource "aws_ram_resource_association" "route53_endpoint_profile_association_ue1" {
  region             = "us-east-1"
  resource_arn       = module.cts-ue1-egress-vpc.route53_profile_arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_ue1.arn
  depends_on = [
    module.cts-ue1-egress-vpc
  ]
}

resource "aws_ram_resource_association" "route53_endpoint_profile_association_uw2" {
  region             = "us-west-2"
  resource_arn       = module.cts-uw2-egress-vpc.route53_profile_arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_uw2.arn
  depends_on = [
    module.cts-uw2-egress-vpc
  ]
}

resource "aws_ram_resource_association" "route53_endpoint_profile_association_en1" {
  region             = "eu-north-1"
  resource_arn       = module.cts-en1-egress-vpc.route53_profile_arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_en1.arn
  depends_on = [
    module.cts-en1-egress-vpc
  ]
}

resource "aws_ram_resource_association" "route53_endpoint_profile_association_ew1" {
  region             = "eu-west-1"
  resource_arn       = module.cts-ew1-egress-vpc.route53_profile_arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_ew1.arn
  depends_on = [
    module.cts-ew1-egress-vpc
  ]
}

# Resources being shared out with the organization
resource "aws_ram_principal_association" "route53_profile_ue1" {
  provider           = aws.ue1
  principal          = data.aws_organizations_organization.parent_organization.arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_ue1.arn

  depends_on = [
    aws_ram_resource_association.route53_endpoint_profile_association_ue1
  ]
}

resource "aws_ram_principal_association" "route53_profile_uw2" {
  provider           = aws.uw2
  principal          = data.aws_organizations_organization.parent_organization.arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_uw2.arn

  depends_on = [
    aws_ram_resource_association.route53_endpoint_profile_association_uw2
  ]
}

resource "aws_ram_principal_association" "route53_profile_en1" {
  provider           = aws.en1
  principal          = data.aws_organizations_organization.parent_organization.arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_en1.arn

  depends_on = [
    aws_ram_resource_association.route53_endpoint_profile_association_en1
  ]
}

resource "aws_ram_principal_association" "route53_profile_ew1" {
  provider           = aws.ew1
  principal          = data.aws_organizations_organization.parent_organization.arn
  resource_share_arn = aws_ram_resource_share.route53_endpoint_profile_ew1.arn

  depends_on = [
    aws_ram_resource_association.route53_endpoint_profile_association_ew1
  ]
}

================
File: networking/cloud-wan/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
  default     = "dev"
}

variable "bu" {
  description = "Business Unit"
  type        = string
  default     = "cts"
}

variable "source_code" {
  description = "Repository where code exists"
  type        = string
}

variable "team" {
  description = "Contact info for team that owns this resrouce"
  type        = string
}

# Project identifier
variable "project_identifier" {
  type        = string
  description = "Project Identifier."

  default = "Enverus"
}

# AWS Regions to use
variable "aws_regions" {
  type        = map(string)
  description = "AWS regions to spin up resources."

  default = {
    ue1 = "us-east-1"
    uw2 = "us-west-2"
    ew1 = "eu-west-1"
    en1 = "eu-north-1"
  }
}

# Transit Gateway ASNs
# to add ASN, contact the netops team (netops.@enverus.com).
# https://netbox.drillinginfo.com/ipam/asns
variable "transit_gateway_asn" {
  type        = map(number)
  description = "Transit Gateway ASNs."

  default = {
    ue1 = 64517
    uw2 = 64518
    ew1 = 64519
    en1 = 64520
  }
}

variable "egress_vpc_cidr_block" {
  type        = map(string)
  description = "VPC cidr blocks."

  default = {
  }
}

variable "egress_vpc_name" {
  type        = map(string)
  description = "VPC cidr blocks."

  default = {

  }
}

variable "direct_connect_gateway_id" {
  type        = string
  description = "ID of the Direct Connect gateway"
}

variable "ue1_tgw_allowed_prefixes" {
  type        = list(string)
  description = "Prefixes allowed to propagate through the US-East-1 TGW to the Direct Connect Gateway"
  default     = [""]
}

variable "uw2_tgw_allowed_prefixes" {
  type        = list(string)
  description = "Prefixes allowed to propagate through the US-West-2 TGW to the Direct Connect Gateway"
  default     = [""]
}

================
File: networking/cloud-wan/versions.tf
================
terraform {
  required_version = ">= 1.4.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "> 6.0"
    }
  }
}

# Provider definition for all 4 Regions
provider "aws" {
  region = var.aws_regions.ue1
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = var.source_code
      Team             = var.team
    }
  }
}

provider "aws" {
  region = var.aws_regions.ue1
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "ue1"
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = var.source_code
      Team             = var.team
    }
  }
}

provider "aws" {
  region = var.aws_regions.uw2
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "uw2"
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = var.source_code
      Team             = var.team
    }
  }
}

# Provider definition for Ireland Region
provider "aws" {
  region = var.aws_regions.ew1
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "ew1"
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = var.source_code
      Team             = var.team
    }
  }
}

# Provider definition for Stockholm Region
provider "aws" {
  region = var.aws_regions.en1
  assume_role {
    role_arn = var.assume_role_arn
  }
  alias = "en1"
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = var.source_code
      Team             = var.team
    }
  }
}

================
File: networking/cloud-wan/vpc.tf
================
# Egress VPC
module "cts-ue1-egress-vpc" {
  depends_on = [aws_networkmanager_core_network_policy_attachment.initial_policy_attachment]
  source     = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc-egress?ref=v1.5.2"
  providers = {
    aws = aws.ue1
  }

  private_supernet                = cidrsubnet(var.egress_vpc_cidr_block.ue1, 1, 0)
  public_supernet                 = cidrsubnet(var.egress_vpc_cidr_block.ue1, 1, 1)
  availabilty_zone_list           = ["us-east-1a", "us-east-1b", "us-east-1d", "us-east-1e"]
  aws_region                      = var.aws_regions.ue1
  vpc_cidr_block                  = var.egress_vpc_cidr_block.ue1
  availability_zone_count         = 4
  tag_name                        = var.egress_vpc_name.ue1
  tag_environment                 = var.env
  cloud_wan_core_network_id       = aws_networkmanager_core_network.core_network.id
  tag_cloud_wan_segment           = "shared"
  enable_ecr_dkr_endpoint         = true
  enable_ssm_messages_endpoint    = false
  enable_cloudwatch_logs_endpoint = true

  # Pass both the enabled endpoints and the full configuration
  enabled_endpoints = local.region_endpoint_config.ue1
  endpoint_config   = local.endpoint_config_ue1
}
output "vpc_ue1" { value = module.cts-ue1-egress-vpc }

module "cts-uw2-egress-vpc" {
  depends_on = [aws_networkmanager_core_network_policy_attachment.initial_policy_attachment]
  source     = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc-egress?ref=v1.5.2"
  providers = {
    aws = aws.uw2
  }

  private_supernet                = cidrsubnet(var.egress_vpc_cidr_block.uw2, 1, 0)
  public_supernet                 = cidrsubnet(var.egress_vpc_cidr_block.uw2, 1, 1)
  availabilty_zone_list           = ["us-west-2a", "us-west-2b", "us-west-2c", "us-west-2d"]
  aws_region                      = var.aws_regions.uw2
  vpc_cidr_block                  = var.egress_vpc_cidr_block.uw2
  availability_zone_count         = 4
  tag_name                        = var.egress_vpc_name.uw2
  tag_environment                 = var.env
  cloud_wan_core_network_id       = aws_networkmanager_core_network.core_network.id
  tag_cloud_wan_segment           = "shared"
  enable_ecr_dkr_endpoint         = true
  enable_ssm_messages_endpoint    = false
  enable_cloudwatch_logs_endpoint = true

  # Pass both the enabled endpoints and the full configuration
  enabled_endpoints = local.region_endpoint_config.uw2
  endpoint_config   = local.endpoint_config_uw2
}
output "vpc_uw2" { value = module.cts-uw2-egress-vpc }


module "cts-ew1-egress-vpc" {
  depends_on = [aws_networkmanager_core_network_policy_attachment.initial_policy_attachment]
  source     = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc-egress?ref=v1.5.2"
  providers = {
    aws = aws.ew1
  }

  private_supernet                = cidrsubnet(var.egress_vpc_cidr_block.ew1, 1, 0)
  public_supernet                 = cidrsubnet(var.egress_vpc_cidr_block.ew1, 1, 1)
  availabilty_zone_list           = ["eu-west-1a", "eu-west-1b", "eu-west-1c"]
  aws_region                      = var.aws_regions.ew1
  vpc_cidr_block                  = var.egress_vpc_cidr_block.ew1
  availability_zone_count         = 3
  tag_name                        = var.egress_vpc_name.ew1
  tag_environment                 = var.env
  cloud_wan_core_network_id       = aws_networkmanager_core_network.core_network.id
  tag_cloud_wan_segment           = "shared"
  enable_ecr_dkr_endpoint         = false
  enable_ssm_messages_endpoint    = false
  enable_cloudwatch_logs_endpoint = false

  enabled_endpoints = local.region_endpoint_config.ew1
  endpoint_config   = local.endpoint_config_ew1
}
output "vpc_ew1" { value = module.cts-ew1-egress-vpc }

module "cts-en1-egress-vpc" {
  depends_on = [aws_networkmanager_core_network_policy_attachment.initial_policy_attachment]
  source     = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc-egress?ref=v1.5.2"
  providers = {
    aws = aws.en1
  }

  private_supernet                = cidrsubnet(var.egress_vpc_cidr_block.en1, 1, 0)
  public_supernet                 = cidrsubnet(var.egress_vpc_cidr_block.en1, 1, 1)
  availabilty_zone_list           = ["eu-north-1a", "eu-north-1b", "eu-north-1c"]
  aws_region                      = var.aws_regions.en1
  vpc_cidr_block                  = var.egress_vpc_cidr_block.en1
  availability_zone_count         = 3
  tag_name                        = var.egress_vpc_name.en1
  tag_environment                 = var.env
  cloud_wan_core_network_id       = aws_networkmanager_core_network.core_network.id
  tag_cloud_wan_segment           = "shared"
  enable_ecr_dkr_endpoint         = false
  enable_ssm_messages_endpoint    = false
  enable_cloudwatch_logs_endpoint = false

  enabled_endpoints = local.region_endpoint_config.en1
  endpoint_config   = local.endpoint_config_en1
}
output "vpc_en1" { value = module.cts-en1-egress-vpc }

================
File: networking/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)
                 
        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: networking/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response) 
            return { "parameter": response,"errorMessage":"none" } 
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'
          
          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}
        
        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled' 
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added' 
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'    
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'  
          
          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter'] 
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']
                 
          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)   
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'    
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)           
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message 
          )
        
        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.' 

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):         
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')
          
          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id) 
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: networking/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: networking/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: networking/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
#trigger atlantis
module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: networking/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: networking/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.ssm.git//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: networking/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: networking/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-config.git//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: networking/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: networking/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: networking/config/.terraform-version
================
latest:^1.8

================
File: networking/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: networking/config/dev.backend.tfvars
================
#key = "449228620267/dev/aws_config/terraform.tfstate"
key = "dev/aws-config-aggregator/terraform.tfstate"

================
File: networking/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = "2fd6188a-21f3-4014-9e13-012c32f135c3"

================
File: networking/config/main.tf
================
##AWS Config
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: networking/config/outputs.tf
================


================
File: networking/config/README.md
================
This deploys the AWS config service with account level specification.

https://enverus.atlassian.net/wiki/spaces/SRE/pages/35816177677/AWS+Config has more info.

================
File: networking/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}

variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: networking/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/config"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: networking/consul-cluster/.terraform-version
================
latest:^1.5

================
File: networking/consul-cluster/data.tf
================
# Create network lb to handle TCP connections to edge proxy
data "aws_route53_zone" "sre" {
  name         = "${var.env}.sre.drillinginfo.com"
  private_zone = false
}

data "aws_vpc" "main" {
  filter {
    name   = "tag:Name"
    values = [var.vpc-name-tag]
  }
}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_subnets" "private_subnets" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.main.id]
  }
  filter {
    name   = "tag:Name"
    values = [var.subnet-name-tag]
  }
  filter {
    name   = "availability-zone-id"
    values = data.aws_availability_zones.good_zone_ids.zone_ids
  }
}
# output "private_subnets" { value = data.aws_subnets.private_subnets.ids }

================
File: networking/consul-cluster/dev.backend.tfvars
================
key = "dev/consul-cluster/terraform.tfstate"

================
File: networking/consul-cluster/dev.tfvars
================
env                  = "dev"
business-unit        = "sre"
encryption-key       = "ItWC9TmfeecGGr1f3KSxdg=="
aws_region           = "us-east-1"
datacenter           = "aws-ue1"
recursors            = "10.53.8.26 10.52.8.36"
aws-clusters-to-join = "aws-ue1@us-east-1"
vpc-name-tag         = "sre-vpc-dev"
subnet-name-tag      = "*| INSIDE | Private Subnet"
instance_type        = "c6a.large"
vault_path_awx       = "sre_tools_secrets/terraform/awx"

# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yaml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=cts\"",
      "-C main"
    ],
  }
]

================
File: networking/consul-cluster/main.tf
================
module "consul_servers" {
  source                  = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.consul-cluster-aws.git?ref=v0.17.2"
  env                     = var.env
  bu                      = var.business-unit
  tagLocation             = var.aws_region
  tagTeam                 = "SRE"
  tagSourceCode           = "https://github.com/enverus-cts/shared-terraform/tree/master/consul-cluster"
  encryption_key          = var.encryption-key
  datacenter              = var.datacenter
  recursors               = var.recursors
  aws_clusters_to_join    = var.aws-clusters-to-join
  vmware_clusters_to_join = var.vmware-clusters-to-join
  vpc_name_tag            = var.vpc-name-tag
  spot_price              = var.spot_price
  instance_type           = var.instance_type
  #ansible pull
  vo_routing_key                           = var.vo_routing_key
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

# output "consul_servers" { value = module.consul_servers }

resource "aws_route53_record" "consul-server-lb" {
  zone_id = data.aws_route53_zone.sre.zone_id
  name    = "consul-aws.${var.env}.sre.drillinginfo.com"
  type    = "A"

  alias {
    name                   = aws_lb.consul-server-lb.dns_name
    zone_id                = aws_lb.consul-server-lb.zone_id
    evaluate_target_health = true
  }
  allow_overwrite = true
}

resource "aws_lb" "consul-server-lb" {
  name                             = "${var.business-unit}-${var.env}-consul-lb"
  internal                         = true
  subnets                          = data.aws_subnets.private_subnets.ids
  load_balancer_type               = "network"
  enable_cross_zone_load_balancing = true

  tags = {
    Component = "consul"
    Name      = "${var.business-unit}-${var.env}-consul-lb"
  }
}

resource "aws_lb_target_group" "consul-tg" {
  name                 = "${var.business-unit}-${var.env}-consul-tg"
  port                 = 8500
  protocol             = "TCP"
  vpc_id               = data.aws_vpc.main.id
  deregistration_delay = 30

  health_check {
    path    = "/"
    matcher = "200-399"
  }
}

resource "aws_lb_listener" "consul-listener" {
  load_balancer_arn = aws_lb.consul-server-lb.arn
  port              = 80
  protocol          = "TCP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.consul-tg.arn
  }
}

resource "aws_autoscaling_attachment" "consul" {
  autoscaling_group_name = module.consul_servers.asg_name
  lb_target_group_arn    = aws_lb_target_group.consul-tg.arn
}

================
File: networking/consul-cluster/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {
  description = "Environment, eg 'dev'"
}

variable "business-unit" {
  description = "Business Unit of cluster, eg. 'cds'"
}

variable "encryption-key" {
  description = "Consul encrypt key used to secure comm. in the cluster (and separate clusters)"
}

variable "recursors" {
  description = "DNS recursors for consul"
}

variable "datacenter" {
  description = "Name of datacenter for consul"
}

variable "vpc-name-tag" {
  description = "Value of tag Name for vpc - used to identify vpc in data sources"
}

variable "subnet-name-tag" {
  description = "Value of tag Name for subnets - used to get private subnets"
}

variable "aws-clusters-to-join" {
  description = "space sep. strings indication clusters to join, format: dc@region"
  default     = ""
}

variable "vmware-clusters-to-join" {
  description = "space sep. strings indication clusters to join, format: di-chi@Chicago"
  default     = ""
}

variable "spot_price" {
  description = "The maximum hourly price to pay for EC2 Spot Instances."
  type        = number
  default     = null
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "assume_role_arn" {}
variable "vault_path_awx" {}
variable "VAULT_ADDR" {}

variable "vo_routing_key" {
  description = "Provide a Victor Ops Routing Key"
  type        = string
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
}

================
File: networking/consul-cluster/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
    consul = {
      source  = "hashicorp/consul"
      version = "~> 2.12.0"
      # v2.13 is only compatible with consul 1.10 or newer
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.business-unit
      Environment      = var.env
      Component        = "consul"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/shared-terraform/consul-cluster"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "consul" {
  address    = aws_route53_record.consul-server-lb.fqdn
  datacenter = var.datacenter
}

================
File: networking/direct-connect/_off_dev.backend.tfvars_off
================
key = "dev/direct-connect/terraform.tfstate"

================
File: networking/direct-connect/_off_dev.tfvars_off
================
aws_tag_business_unit = "cts"
aws_tag_component     = "Direct Connect"
aws_tag_team          = "tech-sre@enverus.com"
aws_tag_source_code   = "https://git.drillinginfo.com/SRE/shared-terraform/tree/master/direct-connect"
aws_tag_env           = "prod"
aws_tag_product       = "nexus"

================
File: networking/direct-connect/.terraform-version
================
latest:^1.6

================
File: networking/direct-connect/connection.tf
================
resource "aws_dx_connection" "ashburn_primary" {
  name      = "Ashburn - Primary"
  bandwidth = "10Gbps"
  location  = "EqDC2"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "ashburn_secondary" {
  name      = "Ashburn - Secondary"
  bandwidth = "10Gbps"
  location  = "EqDC2"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "chicago_primary" {
  name      = "Chicago - Primary"
  bandwidth = "10Gbps"
  location  = "EqDC2"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "reston_primary" {
  name      = "Reston - Primary"
  bandwidth = "10Gbps"
  location  = "CSVA1"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "seattle_westin_primary" {
  provider  = aws.uw2
  name      = "Seattle-Westin-Primary"
  bandwidth = "10Gbps"
  location  = "EqSe2-EQ"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "seattle_westin_secondary" {
  provider  = aws.uw2
  name      = "Seattle-Westin-Secondary"
  bandwidth = "10Gbps"
  location  = "EqSe2-EQ"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_connection" "cloudwan-sea1-zayo-portland-primary" {
  provider  = aws.uw2
  name      = "Seattle-Portland"
  bandwidth = "10Gbps"
  location  = "PEH51"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

================
File: networking/direct-connect/dev.backend.tfvars
================
key    = "449228620267/prod/direct-connect/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: networking/direct-connect/dev.tfvars
================
aws_tag_business_unit = "cts"
aws_tag_component     = "Direct Connect"
aws_tag_team          = "tech-sre@enverus.com"
aws_tag_source_code   = "https://git.drillinginfo.com/SRE/shared-terraform/tree/master/direct-connect"
aws_tag_env           = "prod"
aws_tag_product       = "nexus"

================
File: networking/direct-connect/gateway.tf
================
resource "aws_dx_gateway" "primary" {
  name            = "sre-dx-gw"
  amazon_side_asn = "64702"
}

resource "aws_dx_gateway" "cloudwan-directconnect-prod-gateway" {
  name            = "cloudwan-directconnect-prod-gateway"
  amazon_side_asn = "64999"
}

================
File: networking/direct-connect/outputs.tf
================
output "cloudwan-sea1-zayo-portland-primary" {
  value = aws_dx_connection.cloudwan-sea1-zayo-portland-primary
}

================
File: networking/direct-connect/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {}
variable "assume_role_arn" {}
variable "VAULT_ADDR" {}


#-------------------------------------------------------------------------------
#  Answer file for variables
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#  AWS
#-------------------------------------------------------------------------------

variable "aws_tag_business_unit" {
  description = "The business uit that is the proponent of the instance"
  type        = string
}

variable "aws_tag_component" {
  description = "The primary purpose of the resoruce"
  type        = string
}

variable "aws_tag_team" {
  description = "The team that owns the resource"
  type        = string
}

variable "aws_tag_source_code" {
  description = "The git repo where this resource is managed from"
  type        = string
}
variable "aws_tag_env" {
  description = "The environment tag"
  type        = string
}

variable "aws_tag_product" {
  description = "The service that is supported by this resource"
  type        = string
}

================
File: networking/direct-connect/versions.tf
================
terraform {
  backend "s3" {}
  required_version = ">= 1.6"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.8"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Environment      = "prod"
      TerraformCreated = "true"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/direct-connect"
      Team             = "sre@enverus.com"
    }
  }
}

# Note: aws_default tags will not be applied to Direct Connections or Direct Connection Interfaces.
# This might be occuring because the provider doesn't process tags for DX/DXIs.
# So each DX/DXI needs its own tags
provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Environment      = "prod"
      TerraformCreated = "true"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/direct-connect"
      Team             = "sre@enverus.com"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: networking/direct-connect/virtual-interfaces.tf
================
data "vault_generic_secret" "direct_connect" {
  path = "sre_tools_secrets/terraform/direct-connect"
}

# resource "aws_dx_transit_virtual_interface" "ashburn_primary" {
#   connection_id = aws_dx_connection.ashburn_primary.id

#   dx_gateway_id    = aws_dx_gateway.primary.id
#   name             = "sre-transit-vif-ashburn-primary"
#   vlan             = 4019
#   address_family   = "ipv4"
#   bgp_asn          = 64701
#   amazon_address   = "10.255.254.2/30"
#   bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
#   customer_address = "10.255.254.1/30"
#   tags = {
#     BusinessUnit     = var.aws_tag_business_unit
#     Component        = var.aws_tag_component
#     Team             = var.aws_tag_team
#     SourceCode       = var.aws_tag_source_code
#     Environment      = var.aws_tag_env
#     Product          = var.aws_tag_product
#     TerraformCreated = "true"
#   }
# }

# resource "aws_dx_transit_virtual_interface" "ashburn_secondary" {
#   connection_id    = aws_dx_connection.ashburn_secondary.id
#   dx_gateway_id    = aws_dx_gateway.primary.id
#   name             = "sre-transit-vif-ashburn-secondary"
#   vlan             = 4020
#   address_family   = "ipv4"
#   bgp_asn          = 64701
#   amazon_address   = "10.255.254.6/30"
#   bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
#   customer_address = "10.255.254.5/30"
#   tags = {
#     BusinessUnit     = var.aws_tag_business_unit
#     Component        = var.aws_tag_component
#     Team             = var.aws_tag_team
#     SourceCode       = var.aws_tag_source_code
#     Environment      = var.aws_tag_env
#     Product          = var.aws_tag_product
#     TerraformCreated = "true"
#   }
# }

resource "aws_dx_transit_virtual_interface" "ashburn_primary_cloudwan" {
  connection_id    = aws_dx_connection.ashburn_primary.id
  dx_gateway_id    = aws_dx_gateway.cloudwan-directconnect-prod-gateway.id
  name             = "cloudwan-vif-ashburn-primary"
  vlan             = 4025
  address_family   = "ipv4"
  bgp_asn          = 64701
  amazon_address   = "10.255.55.22/30"
  bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
  customer_address = "10.255.55.21/30"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_transit_virtual_interface" "ashburn_secondary_cloudwan" {
  connection_id    = aws_dx_connection.ashburn_secondary.id
  dx_gateway_id    = aws_dx_gateway.cloudwan-directconnect-prod-gateway.id
  name             = "cloudwan-vif-ashburn-secondary"
  vlan             = 4026
  address_family   = "ipv4"
  bgp_asn          = 64704
  amazon_address   = "10.255.55.26/30"
  bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
  customer_address = "10.255.55.25/30"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

# resource "aws_dx_transit_virtual_interface" "reston_primary" {
#   connection_id    = aws_dx_connection.reston_primary.id
#   dx_gateway_id    = aws_dx_gateway.primary.id
#   name             = "sre-transit-vif-reston-primary"
#   vlan             = 4021
#   address_family   = "ipv4"
#   bgp_asn          = 64701
#   amazon_address   = "10.255.254.10/30"
#   bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
#   customer_address = "10.255.254.9/30"
#   tags = {
#     BusinessUnit     = var.aws_tag_business_unit
#     Component        = var.aws_tag_component
#     Team             = var.aws_tag_team
#     SourceCode       = var.aws_tag_source_code
#     Environment      = var.aws_tag_env
#     Product          = var.aws_tag_product
#     TerraformCreated = "true"
#   }
# }

# resource "aws_dx_transit_virtual_interface" "chicago_primary" {
#   connection_id    = aws_dx_connection.chicago_primary.id
#   dx_gateway_id    = aws_dx_gateway.primary.id
#   name             = "sre-transit-vif-chicago-primary"
#   vlan             = 4010
#   address_family   = "ipv4"
#   bgp_asn          = 64801
#   amazon_address   = "10.255.250.2/30"
#   bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
#   customer_address = "10.255.250.1/30"
#   tags = {
#     BusinessUnit     = var.aws_tag_business_unit
#     Component        = var.aws_tag_component
#     Team             = var.aws_tag_team
#     SourceCode       = var.aws_tag_source_code
#     Environment      = var.aws_tag_env
#     Product          = var.aws_tag_product
#     TerraformCreated = "true"
#   }
# }


resource "aws_dx_transit_virtual_interface" "cloudwan-sea1-zayo-portland-primary" {
  provider = aws.uw2

  connection_id    = aws_dx_connection.cloudwan-sea1-zayo-portland-primary.id
  dx_gateway_id    = aws_dx_gateway.cloudwan-directconnect-prod-gateway.id
  name             = "cloudwan-sea1-zayo-portland-primary"
  vlan             = 4032
  address_family   = "ipv4"
  bgp_asn          = 64601
  amazon_address   = "10.255.59.38/30"
  bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
  customer_address = "10.255.59.37/30"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

resource "aws_dx_transit_virtual_interface" "cloudwan-reston-primary" {
  connection_id    = aws_dx_connection.reston_primary.id
  dx_gateway_id    = aws_dx_gateway.cloudwan-directconnect-prod-gateway.id
  name             = "cloudwan-reston-primary"
  vlan             = 4024
  address_family   = "ipv4"
  bgp_asn          = 64704
  amazon_address   = "10.255.55.18/30"
  bgp_auth_key     = data.vault_generic_secret.direct_connect.data["bgp_auth_key"]
  customer_address = "10.255.55.17/30"
  tags = {
    BusinessUnit     = var.aws_tag_business_unit
    Component        = var.aws_tag_component
    Team             = var.aws_tag_team
    SourceCode       = var.aws_tag_source_code
    Environment      = var.aws_tag_env
    Product          = var.aws_tag_product
    TerraformCreated = "true"
  }
}

================
File: networking/eks/lbc-crd/crds.yaml
================
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.5.0
  creationTimestamp: null
  name: ingressclassparams.elbv2.k8s.aws
spec:
  group: elbv2.k8s.aws
  names:
    kind: IngressClassParams
    listKind: IngressClassParamsList
    plural: ingressclassparams
    singular: ingressclassparams
  scope: Cluster
  versions:
  - additionalPrinterColumns:
    - description: The Ingress Group name
      jsonPath: .spec.group.name
      name: GROUP-NAME
      type: string
    - description: The AWS Load Balancer scheme
      jsonPath: .spec.scheme
      name: SCHEME
      type: string
    - description: The AWS Load Balancer ipAddressType
      jsonPath: .spec.ipAddressType
      name: IP-ADDRESS-TYPE
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: AGE
      type: date
    name: v1beta1
    schema:
      openAPIV3Schema:
        description: IngressClassParams is the Schema for the IngressClassParams API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: IngressClassParamsSpec defines the desired state of IngressClassParams
            properties:
              group:
                description: Group defines the IngressGroup for all Ingresses that belong to IngressClass with this IngressClassParams.
                properties:
                  name:
                    description: Name is the name of IngressGroup.
                    type: string
                required:
                - name
                type: object
              ipAddressType:
                description: IPAddressType defines the ip address type for all Ingresses that belong to IngressClass with this IngressClassParams.
                enum:
                - ipv4
                - dualstack
                type: string
              namespaceSelector:
                description: NamespaceSelector restrict the namespaces of Ingresses that are allowed to specify the IngressClass with this IngressClassParams. * if absent or present but empty, it selects all namespaces.
                properties:
                  matchExpressions:
                    description: matchExpressions is a list of label selector requirements. The requirements are ANDed.
                    items:
                      description: A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
                      properties:
                        key:
                          description: key is the label key that the selector applies to.
                          type: string
                        operator:
                          description: operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
                          type: string
                        values:
                          description: values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
                          items:
                            type: string
                          type: array
                      required:
                      - key
                      - operator
                      type: object
                    type: array
                  matchLabels:
                    additionalProperties:
                      type: string
                    description: matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
                    type: object
                type: object
              scheme:
                description: Scheme defines the scheme for all Ingresses that belong to IngressClass with this IngressClassParams.
                enum:
                - internal
                - internet-facing
                type: string
              tags:
                description: Tags defines list of Tags on AWS resources provisioned for Ingresses that belong to IngressClass with this IngressClassParams.
                items:
                  description: Tag defines a AWS Tag on resources.
                  properties:
                    key:
                      description: The key of the tag.
                      type: string
                    value:
                      description: The value of the tag.
                      type: string
                  required:
                  - key
                  - value
                  type: object
                type: array
            type: object
        type: object
    served: true
    storage: true
    subresources: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.5.0
  creationTimestamp: null
  name: targetgroupbindings.elbv2.k8s.aws
spec:
  group: elbv2.k8s.aws
  names:
    kind: TargetGroupBinding
    listKind: TargetGroupBindingList
    plural: targetgroupbindings
    singular: targetgroupbinding
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - description: The Kubernetes Service's name
      jsonPath: .spec.serviceRef.name
      name: SERVICE-NAME
      type: string
    - description: The Kubernetes Service's port
      jsonPath: .spec.serviceRef.port
      name: SERVICE-PORT
      type: string
    - description: The AWS TargetGroup's TargetType
      jsonPath: .spec.targetType
      name: TARGET-TYPE
      type: string
    - description: The AWS TargetGroup's Amazon Resource Name
      jsonPath: .spec.targetGroupARN
      name: ARN
      priority: 1
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: AGE
      type: date
    name: v1alpha1
    schema:
      openAPIV3Schema:
        description: TargetGroupBinding is the Schema for the TargetGroupBinding API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: TargetGroupBindingSpec defines the desired state of TargetGroupBinding
            properties:
              networking:
                description: networking provides the networking setup for ELBV2 LoadBalancer to access targets in TargetGroup.
                properties:
                  ingress:
                    description: List of ingress rules to allow ELBV2 LoadBalancer to access targets in TargetGroup.
                    items:
                      properties:
                        from:
                          description: List of peers which should be able to access the targets in TargetGroup. At least one NetworkingPeer should be specified.
                          items:
                            description: NetworkingPeer defines the source/destination peer for networking rules.
                            properties:
                              ipBlock:
                                description: IPBlock defines an IPBlock peer. If specified, none of the other fields can be set.
                                properties:
                                  cidr:
                                    description: CIDR is the network CIDR. Both IPV4 or IPV6 CIDR are accepted.
                                    type: string
                                required:
                                - cidr
                                type: object
                              securityGroup:
                                description: SecurityGroup defines a SecurityGroup peer. If specified, none of the other fields can be set.
                                properties:
                                  groupID:
                                    description: GroupID is the EC2 SecurityGroupID.
                                    type: string
                                required:
                                - groupID
                                type: object
                            type: object
                          type: array
                        ports:
                          description: List of ports which should be made accessible on the targets in TargetGroup. If ports is empty or unspecified, it defaults to all ports with TCP.
                          items:
                            properties:
                              port:
                                anyOf:
                                - type: integer
                                - type: string
                                description: The port which traffic must match. When NodePort endpoints(instance TargetType) is used, this must be a numerical port. When Port endpoints(ip TargetType) is used, this can be either numerical or named port on pods. if port is unspecified, it defaults to all ports.
                                x-kubernetes-int-or-string: true
                              protocol:
                                description: The protocol which traffic must match. If protocol is unspecified, it defaults to TCP.
                                enum:
                                - TCP
                                - UDP
                                type: string
                            type: object
                          type: array
                      required:
                      - from
                      - ports
                      type: object
                    type: array
                type: object
              serviceRef:
                description: serviceRef is a reference to a Kubernetes Service and ServicePort.
                properties:
                  name:
                    description: Name is the name of the Service.
                    type: string
                  port:
                    anyOf:
                    - type: integer
                    - type: string
                    description: Port is the port of the ServicePort.
                    x-kubernetes-int-or-string: true
                required:
                - name
                - port
                type: object
              targetGroupARN:
                description: targetGroupARN is the Amazon Resource Name (ARN) for the TargetGroup.
                type: string
              targetType:
                description: targetType is the TargetType of TargetGroup. If unspecified, it will be automatically inferred.
                enum:
                - instance
                - ip
                type: string
            required:
            - serviceRef
            - targetGroupARN
            type: object
          status:
            description: TargetGroupBindingStatus defines the observed state of TargetGroupBinding
            properties:
              observedGeneration:
                description: The generation observed by the TargetGroupBinding controller.
                format: int64
                type: integer
            type: object
        type: object
    served: true
    storage: false
    subresources:
      status: {}
  - additionalPrinterColumns:
    - description: The Kubernetes Service's name
      jsonPath: .spec.serviceRef.name
      name: SERVICE-NAME
      type: string
    - description: The Kubernetes Service's port
      jsonPath: .spec.serviceRef.port
      name: SERVICE-PORT
      type: string
    - description: The AWS TargetGroup's TargetType
      jsonPath: .spec.targetType
      name: TARGET-TYPE
      type: string
    - description: The AWS TargetGroup's Amazon Resource Name
      jsonPath: .spec.targetGroupARN
      name: ARN
      priority: 1
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: AGE
      type: date
    name: v1beta1
    schema:
      openAPIV3Schema:
        description: TargetGroupBinding is the Schema for the TargetGroupBinding API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: TargetGroupBindingSpec defines the desired state of TargetGroupBinding
            properties:
              networking:
                description: networking defines the networking rules to allow ELBV2 LoadBalancer to access targets in TargetGroup.
                properties:
                  ingress:
                    description: List of ingress rules to allow ELBV2 LoadBalancer to access targets in TargetGroup.
                    items:
                      description: NetworkingIngressRule defines a particular set of traffic that is allowed to access TargetGroup's targets.
                      properties:
                        from:
                          description: List of peers which should be able to access the targets in TargetGroup. At least one NetworkingPeer should be specified.
                          items:
                            description: NetworkingPeer defines the source/destination peer for networking rules.
                            properties:
                              ipBlock:
                                description: IPBlock defines an IPBlock peer. If specified, none of the other fields can be set.
                                properties:
                                  cidr:
                                    description: CIDR is the network CIDR. Both IPV4 or IPV6 CIDR are accepted.
                                    type: string
                                required:
                                - cidr
                                type: object
                              securityGroup:
                                description: SecurityGroup defines a SecurityGroup peer. If specified, none of the other fields can be set.
                                properties:
                                  groupID:
                                    description: GroupID is the EC2 SecurityGroupID.
                                    type: string
                                required:
                                - groupID
                                type: object
                            type: object
                          type: array
                        ports:
                          description: List of ports which should be made accessible on the targets in TargetGroup. If ports is empty or unspecified, it defaults to all ports with TCP.
                          items:
                            description: NetworkingPort defines the port and protocol for networking rules.
                            properties:
                              port:
                                anyOf:
                                - type: integer
                                - type: string
                                description: The port which traffic must match. When NodePort endpoints(instance TargetType) is used, this must be a numerical port. When Port endpoints(ip TargetType) is used, this can be either numerical or named port on pods. if port is unspecified, it defaults to all ports.
                                x-kubernetes-int-or-string: true
                              protocol:
                                description: The protocol which traffic must match. If protocol is unspecified, it defaults to TCP.
                                enum:
                                - TCP
                                - UDP
                                type: string
                            type: object
                          type: array
                      required:
                      - from
                      - ports
                      type: object
                    type: array
                type: object
              nodeSelector:
                description: node selector for instance type target groups to only register certain nodes
                properties:
                  matchExpressions:
                    description: matchExpressions is a list of label selector requirements. The requirements are ANDed.
                    items:
                      description: A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
                      properties:
                        key:
                          description: key is the label key that the selector applies to.
                          type: string
                        operator:
                          description: operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
                          type: string
                        values:
                          description: values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
                          items:
                            type: string
                          type: array
                      required:
                      - key
                      - operator
                      type: object
                    type: array
                  matchLabels:
                    additionalProperties:
                      type: string
                    description: matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
                    type: object
                type: object
              serviceRef:
                description: serviceRef is a reference to a Kubernetes Service and ServicePort.
                properties:
                  name:
                    description: Name is the name of the Service.
                    type: string
                  port:
                    anyOf:
                    - type: integer
                    - type: string
                    description: Port is the port of the ServicePort.
                    x-kubernetes-int-or-string: true
                required:
                - name
                - port
                type: object
              targetGroupARN:
                description: targetGroupARN is the Amazon Resource Name (ARN) for the TargetGroup.
                minLength: 1
                type: string
              targetType:
                description: targetType is the TargetType of TargetGroup. If unspecified, it will be automatically inferred.
                enum:
                - instance
                - ip
                type: string
            required:
            - serviceRef
            - targetGroupARN
            type: object
          status:
            description: TargetGroupBindingStatus defines the observed state of TargetGroupBinding
            properties:
              observedGeneration:
                description: The generation observed by the TargetGroupBinding controller.
                format: int64
                type: integer
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []

================
File: networking/eks/lbc-crd/kustomization.yaml
================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- crds.yaml

================
File: networking/eks/manifests/dashboard/dashboard-admin.yaml
================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: eks-admin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: eks-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: eks-admin
  namespace: kube-system

================
File: networking/eks/manifests/dashboard/dashboard-ingress.yaml
================
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: dashboard
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/configuration-snippet: |
      rewrite ^(/dashboard)$ $1/ redirect;
  namespace: kubernetes-dashboard
spec:
  rules:
  - http:
      paths:
      - path: /dashboard(/|$)(.*)
        backend:
          serviceName: kubernetes-dashboard
          servicePort: 443
  ingressClassName: nginx

================
File: networking/eks/manifests/dashboard/deployment.yaml
================
apiVersion: v1
kind: Namespace
metadata:
  name: kubernetes-dashboard
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
---
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  ports:
    - port: 443
      targetPort: 8443
  selector:
    k8s-app: kubernetes-dashboard
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-certs
  namespace: kubernetes-dashboard
type: Opaque
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-csrf
  namespace: kubernetes-dashboard
type: Opaque
data:
  csrf: "50fd8cbfb9a1e6777d35"
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-key-holder
  namespace: kubernetes-dashboard
type: Opaque
---
kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-settings
  namespace: kubernetes-dashboard
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
rules:
  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["kubernetes-dashboard-key-holder", "kubernetes-dashboard-certs", "kubernetes-dashboard-csrf"]
    verbs: ["get", "update", "delete"]
    # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["kubernetes-dashboard-settings"]
    verbs: ["get", "update"]
    # Allow Dashboard to get metrics.
  - apiGroups: [""]
    resources: ["services"]
    resourceNames: ["heapster", "dashboard-metrics-scraper"]
    verbs: ["proxy"]
  - apiGroups: [""]
    resources: ["services/proxy"]
    resourceNames: ["heapster", "http:heapster:", "https:heapster:", "dashboard-metrics-scraper", "http:dashboard-metrics-scraper"]
    verbs: ["get"]
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
rules:
  # Allow Metrics Scraper to get metrics from the Metrics server
  - apiGroups: ["metrics.k8s.io"]
    resources: ["pods", "nodes"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
---
kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: kubernetes-dashboard
  template:
    metadata:
      labels:
        k8s-app: kubernetes-dashboard
    spec:
      containers:
        - name: kubernetes-dashboard
          image: kubernetesui/dashboard:v${dashboard_version}
          imagePullPolicy: Always
          ports:
            - containerPort: 8443
              protocol: TCP
          args:
            - --auto-generate-certificates
            - --namespace=kubernetes-dashboard
            # Uncomment the following line to manually specify Kubernetes API server Host
            # If not specified, Dashboard will attempt to auto discover the API server and connect
            # to it. Uncomment only if the default does not work.
            # - --apiserver-host=http://my-address:port
          volumeMounts:
            - name: kubernetes-dashboard-certs
              mountPath: /certs
              # Create on-disk volume to store exec logs
            - mountPath: /tmp
              name: tmp-volume
          livenessProbe:
            httpGet:
              scheme: HTTPS
              path: /
              port: 8443
            initialDelaySeconds: 30
            timeoutSeconds: 30
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      volumes:
        - name: kubernetes-dashboard-certs
          secret:
            secretName: kubernetes-dashboard-certs
        - name: tmp-volume
          emptyDir: {}
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "kubernetes.io/os": linux
      # Comment the following tolerations if Dashboard must not be deployed on master
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
---
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  ports:
    - port: 8000
      targetPort: 8000
  selector:
    k8s-app: dashboard-metrics-scraper
---
kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: dashboard-metrics-scraper
  template:
    metadata:
      labels:
        k8s-app: dashboard-metrics-scraper
    spec:
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: dashboard-metrics-scraper
          image: kubernetesui/metrics-scraper:v1.0.7
          ports:
            - containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              scheme: HTTP
              path: /
              port: 8000
            initialDelaySeconds: 30
            timeoutSeconds: 30
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "kubernetes.io/os": linux
      # Comment the following tolerations if Dashboard must not be deployed on master
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      volumes:
        - name: tmp-volume
          emptyDir: {}

================
File: networking/eks/policies/external-dns.json
================
{
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow",
        "Action": [
          "route53:ChangeResourceRecordSets"
        ],
        "Resource": [
          "arn:aws:route53:::hostedzone/*"
        ]
      },
      {
        "Effect": "Allow",
        "Action": [
          "route53:ListHostedZones",
          "route53:ListResourceRecordSets"
        ],
        "Resource": [
          "*"
        ]
      }
    ]
  }

================
File: networking/eks/policies/iam-policy.json
================
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "iam:CreateServiceLinkedRole",
                "ec2:DescribeAccountAttributes",
                "ec2:DescribeAddresses",
                "ec2:DescribeAvailabilityZones",
                "ec2:DescribeInternetGateways",
                "ec2:DescribeVpcs",
                "ec2:DescribeSubnets",
                "ec2:DescribeSecurityGroups",
                "ec2:DescribeInstances",
                "ec2:DescribeNetworkInterfaces",
                "ec2:DescribeTags",
                "ec2:GetCoipPoolUsage",
                "ec2:DescribeCoipPools",
                "elasticloadbalancing:DescribeLoadBalancers",
                "elasticloadbalancing:DescribeLoadBalancerAttributes",
                "elasticloadbalancing:DescribeListeners",
                "elasticloadbalancing:DescribeListenerCertificates",
                "elasticloadbalancing:DescribeSSLPolicies",
                "elasticloadbalancing:DescribeRules",
                "elasticloadbalancing:DescribeTargetGroups",
                "elasticloadbalancing:DescribeTargetGroupAttributes",
                "elasticloadbalancing:DescribeTargetHealth",
                "elasticloadbalancing:DescribeTags"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "cognito-idp:DescribeUserPoolClient",
                "acm:ListCertificates",
                "acm:DescribeCertificate",
                "iam:ListServerCertificates",
                "iam:GetServerCertificate",
                "waf-regional:GetWebACL",
                "waf-regional:GetWebACLForResource",
                "waf-regional:AssociateWebACL",
                "waf-regional:DisassociateWebACL",
                "wafv2:GetWebACL",
                "wafv2:GetWebACLForResource",
                "wafv2:AssociateWebACL",
                "wafv2:DisassociateWebACL",
                "shield:GetSubscriptionState",
                "shield:DescribeProtection",
                "shield:CreateProtection",
                "shield:DeleteProtection"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "ec2:AuthorizeSecurityGroupIngress",
                "ec2:RevokeSecurityGroupIngress"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "ec2:CreateSecurityGroup"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "ec2:CreateTags"
            ],
            "Resource": "arn:aws:ec2:*:*:security-group/*",
            "Condition": {
                "StringEquals": {
                    "ec2:CreateAction": "CreateSecurityGroup"
                },
                "Null": {
                    "aws:RequestTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "ec2:CreateTags",
                "ec2:DeleteTags"
            ],
            "Resource": "arn:aws:ec2:*:*:security-group/*",
            "Condition": {
                "Null": {
                    "aws:RequestTag/elbv2.k8s.aws/cluster": "true",
                    "aws:ResourceTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "ec2:AuthorizeSecurityGroupIngress",
                "ec2:RevokeSecurityGroupIngress",
                "ec2:DeleteSecurityGroup"
            ],
            "Resource": "*",
            "Condition": {
                "Null": {
                    "aws:ResourceTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:CreateLoadBalancer",
                "elasticloadbalancing:CreateTargetGroup"
            ],
            "Resource": "*",
            "Condition": {
                "Null": {
                    "aws:RequestTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:CreateListener",
                "elasticloadbalancing:DeleteListener",
                "elasticloadbalancing:CreateRule",
                "elasticloadbalancing:DeleteRule"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:AddTags",
                "elasticloadbalancing:RemoveTags"
            ],
            "Resource": [
                "arn:aws:elasticloadbalancing:*:*:targetgroup/*/*",
                "arn:aws:elasticloadbalancing:*:*:loadbalancer/net/*/*",
                "arn:aws:elasticloadbalancing:*:*:loadbalancer/app/*/*"
            ],
            "Condition": {
                "Null": {
                    "aws:RequestTag/elbv2.k8s.aws/cluster": "true",
                    "aws:ResourceTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:AddTags",
                "elasticloadbalancing:RemoveTags"
            ],
            "Resource": [
                "arn:aws:elasticloadbalancing:*:*:listener/net/*/*/*",
                "arn:aws:elasticloadbalancing:*:*:listener/app/*/*/*",
                "arn:aws:elasticloadbalancing:*:*:listener-rule/net/*/*/*",
                "arn:aws:elasticloadbalancing:*:*:listener-rule/app/*/*/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:ModifyLoadBalancerAttributes",
                "elasticloadbalancing:SetIpAddressType",
                "elasticloadbalancing:SetSecurityGroups",
                "elasticloadbalancing:SetSubnets",
                "elasticloadbalancing:DeleteLoadBalancer",
                "elasticloadbalancing:ModifyTargetGroup",
                "elasticloadbalancing:ModifyTargetGroupAttributes",
                "elasticloadbalancing:DeleteTargetGroup"
            ],
            "Resource": "*",
            "Condition": {
                "Null": {
                    "aws:ResourceTag/elbv2.k8s.aws/cluster": "false"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:RegisterTargets",
                "elasticloadbalancing:DeregisterTargets"
            ],
            "Resource": "arn:aws:elasticloadbalancing:*:*:targetgroup/*/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:SetWebAcl",
                "elasticloadbalancing:ModifyListener",
                "elasticloadbalancing:AddListenerCertificates",
                "elasticloadbalancing:RemoveListenerCertificates",
                "elasticloadbalancing:ModifyRule"
            ],
            "Resource": "*"
        }
    ]
}

================
File: networking/eks/.terraform-version
================
latest:^1.4

================
File: networking/eks/dashboard.tf
================
/* data "kubectl_path_documents" "docs" {
  pattern = "./manifests/dashboard/*.yaml"
  vars = {
    dashboard_version = var.dashboard_version
  }
}

resource "kubectl_manifest" "dashboard" {
  for_each  = data.kubectl_path_documents.docs.manifests
  yaml_body = each.value
} */

resource "kubernetes_namespace" "kubernetes-dashboard" {
  metadata {
    name = "kubernetes-dashboard"
  }
}

resource "kubernetes_service_account" "eks-admin" {
  metadata {
    name      = "eks-admin"
    namespace = "kube-system"
  }
}

resource "kubernetes_cluster_role_binding" "eks-admin" {
  metadata {
    name = "eks-admin"
  }
  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = "cluster-admin"
  }
  subject {
    kind      = "ServiceAccount"
    name      = "eks-admin"
    namespace = "kube-system"
  }
}

resource "kubernetes_ingress" "kubernetes-dashboard" {
  metadata {
    name      = "dashboard"
    namespace = "kubernetes-dashboard"
    annotations = {
      "nginx.ingress.kubernetes.io/backend-protocol"      = "HTTPS"
      "nginx.ingress.kubernetes.io/configuration-snippet" = <<-EOT
        rewrite ^(/dashboard)$ $1/ redirect;
        EOT
      "nginx.ingress.kubernetes.io/rewrite-target"        = "/$2"
    }
  }

  spec {
    ingress_class_name = "nginx"
    rule {
      http {
        path {
          backend {
            service_name = "kubernetes-dashboard"
            service_port = 443
          }

          path = "/dashboard(/|$)(.*)"
        }
      }
    }
  }
}

================
File: networking/eks/dev.backend.tfvars
================
key = "dev/sre-shared-eks/terraform.tfstate"

================
File: networking/eks/dev.tfvars
================
kubernetes_version  = "1.21"
ports               = [22, 80, 443]
admin_user_role_arn = "arn:aws:iam::449228620267:role/AWSReservedSSO_AdministratorAccess_76283c08b8d6627d"
terraform_user_arn  = "arn:aws:iam::449228620267:user/terraform-admin"
terraform_role_arn  = "arn:aws:iam::449228620267:role/terraform"
ec2-name            = "aws-ue1-dev-eks-node"
awx_domain          = "dev.sre.enverus.com"
sg_rules = [
  {
    from_port = 443
    to_port   = 443
    protocol  = "tcp"
  },
  {
    from_port = 22
    to_port   = 22
    protocol  = "tcp"
  },
  {
    from_port = 443
    to_port   = 443
    protocol  = "tcp"
  },
  {
    from_port = 1025
    to_port   = 65535
    protocol  = "tcp"
  },
]
external_dns_version = "0.10.0"
dashboard_version    = "2.4.0"
desired_capacity     = "3"
max_capacity         = "5"
min_capacity         = "2"

================
File: networking/eks/eks-cluster.tf
================
#### This cluster was decommissioned. The code remains here for the reference. It can be removed if not needed anymore.####
data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = ["sre-vpc-${var.env}"]
  }
}

data "aws_subnet_ids" "private_subnets" {
  vpc_id = data.aws_vpc.vpc_id.id

  filter {
    name   = "tag:Name"
    values = ["*| AZ1 | INSIDE |*", "*| AZ2 | INSIDE |*", "*| AZ3 | INSIDE |*", "*| AZ4 | INSIDE |*", "*| AZ6 | INSIDE |*"]
  }
}

locals {
  cluster_name = "sre-shared-eks-${random_string.suffix.result}"
}

resource "random_string" "suffix" {
  length  = 8
  special = false
}

resource "aws_iam_policy" "eks_node_tags_policy" {
  name        = "eks_node_tags"
  description = "allows eks managed nodes to set tags during cloud-init"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = [
          "ec2:DeleteTags",
          "ec2:CreateTags"
        ]
        Effect   = "Allow"
        Resource = "*"
      },
    ]
  })
}

resource "aws_iam_policy" "eks_node_s3_policy" {
  name        = "eks_node_s3"
  description = "allows eks managed nodes to write to s3 buckets"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = [
          "s3:*"
        ]
        Effect   = "Allow"
        Resource = "*"
      },
    ]
  })
}

module "eks" {
  source          = "terraform-aws-modules/eks/aws"
  version         = "17.20.0"
  enable_irsa     = true
  cluster_name    = local.cluster_name
  cluster_version = var.kubernetes_version
  subnets         = data.aws_subnet_ids.private_subnets.ids
  /* worker_ami_owner_id    = "070551638384"
  worker_ami_name_filter = "drillinginfo/ubuntu2004/base-20-04-ubuntu-20.04-amd64-*" */
  worker_additional_security_group_ids           = [aws_security_group.all_worker_mgmt.id]
  workers_additional_policies                    = [aws_iam_policy.eks_node_tags_policy.arn, aws_iam_policy.external-dns-policy.arn, aws_iam_policy.eks_node_s3_policy.arn]
  cluster_endpoint_private_access                = true
  cluster_endpoint_public_access                 = false
  cluster_create_endpoint_private_access_sg_rule = true
  cluster_endpoint_private_access_cidrs          = ["10.0.0.0/8", "172.16.0.0/12", "192.168.0.0/16"]

  tags = {
    environment   = "dev"
    business_unit = "sre"
    component     = "eks"
    basename      = "sre-shared"
  }

  vpc_id = data.aws_vpc.vpc_id.id

  /* workers_group_defaults = {
    root_volume_type = "gp3"
    root_volume_size = "100"
  }

  // https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/locals.tf#L36
  worker_groups = [
    {
      name                          = "workers_m5a"
      instance_type                 = "m5a.xlarge"
      additional_userdata           = "echo foo bar"
      asg_desired_capacity          = var.desired_capacity
      additional_security_group_ids = [aws_security_group.worker_group_mgmt_one.id]
    }
  ] */

  node_groups = {
    group_sre_01 = {
      desired_capacity = var.desired_capacity
      max_capacity     = var.max_capacity
      min_capacity     = var.min_capacity

      launch_template_id      = aws_launch_template.default.id
      launch_template_version = aws_launch_template.default.default_version

      instance_types = var.instance_types

      additional_tags = {
        CustomTag = "sre_eks_01"
      }
    }
  }

  # AWS Auth (kubernetes_config_map)
  map_roles = [
    {
      rolearn  = var.admin_user_role_arn
      username = "djordje.petrovic@drillinginfo.com"
      groups   = ["system:masters"]
    },
    {
      rolearn  = var.terraform_role_arn
      username = "terraform"
      groups   = ["system:masters"]
    },
  ]

  map_users = [
    {
      userarn  = var.terraform_user_arn
      username = "terraform"
      groups   = ["system:masters"]
    }
  ]

}

data "aws_eks_cluster" "cluster" {
  name = module.eks.cluster_id
}

data "aws_eks_cluster_auth" "cluster" {
  name = module.eks.cluster_id
}

================
File: networking/eks/external-dns.tf
================
data "aws_route53_zone" "sre" {
  name = var.awx_domain
}

resource "aws_iam_policy" "external-dns-policy" {
  name   = "external-dns-policy"
  policy = file("${path.module}/policies/external-dns.json")
}

module "iam_assumable_role_edns" {
  source  = "terraform-aws-modules/iam/aws//modules/iam-assumable-role-with-oidc"
  version = "~> 4.0"

  create_role                   = true
  role_name                     = "ExternalDNSIAMRole"
  provider_url                  = replace(module.eks.cluster_oidc_issuer_url, "https://", "")
  role_policy_arns              = [aws_iam_policy.external-dns-policy.arn]
  oidc_fully_qualified_subjects = ["system:serviceaccount:default:external-dns"]
}

resource "kubernetes_service_account" "eks-service-account-edns" {
  metadata {
    name      = "external-dns"
    namespace = "default"

    annotations = {
      "eks.amazonaws.com/role-arn" = module.iam_assumable_role_edns.iam_role_arn
    }
  }
}

resource "kubernetes_cluster_role" "edns" {
  metadata {
    name = "external-dns"
  }

  rule {
    api_groups = ["extensions", "networking.k8s.io"]
    resources  = ["ingresses"]
    verbs      = ["get", "list", "watch"]
  }

  rule {
    api_groups = [""]
    resources  = ["nodes"]
    verbs      = ["list", "watch"]
  }

  rule {
    api_groups = [""]
    resources  = ["services", "endpoints", "pods"]
    verbs      = ["get", "list", "watch"]
  }
}

resource "kubernetes_cluster_role_binding" "edns" {
  metadata {
    name = "external-dns-viewer"
  }
  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = "external-dns"
  }
  subject {
    kind      = "ServiceAccount"
    name      = "external-dns"
    namespace = "default"
  }
}

resource "kubernetes_deployment" "edns" {
  metadata {
    name = "external-dns"
  }
  spec {
    selector {
      match_labels = {
        app = "external-dns"
      }
    }
    strategy {
      type = "Recreate"
    }
    template {
      metadata {
        labels = {
          app = "external-dns"
        }
      }
      spec {
        container {
          image = "bitnami/external-dns:${var.external_dns_version}"
          name  = "external-dns"
          args = [
            "--source=service",
            "--source=ingress",
            "--domain-filter=${var.awx_domain}",
            "--provider=aws",
            "--policy=upsert-only",
            "--aws-zone-type=public",
            "--registry=txt",
            "--txt-owner-id=${data.aws_route53_zone.sre.zone_id}",
          ]
        }
        security_context {
          fs_group = 65534
        }
        service_account_name = "external-dns"
      }
    }
  }
}

================
File: networking/eks/general-purpose-alb.tf
================
data "aws_acm_certificate" "sre-shared-dev" {
  domain = "*.${var.awx_domain}"
}

resource "kubernetes_namespace" "ingress-nginx" {
  metadata {
    name = "ingress-nginx"
  }
}

resource "kubernetes_ingress" "gp-ingress-nginx" {
  metadata {
    name      = "alb-ingress"
    namespace = "ingress-nginx"
    annotations = {
      "alb.ingress.kubernetes.io/actions.ssl-redirect" = "{\"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"StatusCode\": \"HTTP_301\"}}"
      "alb.ingress.kubernetes.io/certificate-arn"      = "${data.aws_acm_certificate.sre-shared-dev.arn}"
      "alb.ingress.kubernetes.io/healthcheck-path"     = "/dashboard/"
      "alb.ingress.kubernetes.io/listen-ports"         = "[{\"HTTP\": 80}, {\"HTTPS\":443}]"
      "alb.ingress.kubernetes.io/scheme"               = "internal"
      "external-dns.alpha.kubernetes.io/hostname"      = "k8s.${var.awx_domain}"
      "kubernetes.io/ingress.class"                    = "alb"
    }
  }

  spec {
    rule {
      http {
        path {
          backend {
            service_name = "ssl-redirect"
            service_port = "use-annotation"
          }

          path = "/*"
        }
        path {
          backend {
            service_name = "ingress-nginx-controller"
            service_port = 80
          }

          path = "/*"
        }
      }
    }
  }
}

================
File: networking/eks/helm_packages.tf
================
resource "helm_release" "metrics-server" {
  name       = "metrics-server"
  repository = "https://kubernetes-sigs.github.io/metrics-server/"
  chart      = "metrics-server"
}

resource "helm_release" "aws-load-balancer-controller" {
  name       = "aws-load-balancer-controller"
  repository = "https://aws.github.io/eks-charts"
  chart      = "aws-load-balancer-controller"
  namespace  = "kube-system"

  set {
    name  = "clusterName"
    value = module.eks.cluster_id
  }

  set {
    name  = "serviceAccount.create"
    value = false
  }

  set {
    name  = "serviceAccount.name"
    value = local.k8s_service_account_name
  }
  depends_on = [kubernetes_service_account.eks-service-account]
}

resource "helm_release" "ingress-nginx" {
  name       = "ingress-nginx"
  namespace  = "ingress-nginx"
  repository = "https://kubernetes.github.io/ingress-nginx"
  chart      = "ingress-nginx"

  set {
    name  = "controller.service.type"
    value = "NodePort"
  }
}

resource "helm_release" "kubernetes-dashboard" {
  name       = "kubernetes-dashboard"
  namespace  = "kubernetes-dashboard"
  repository = "https://kubernetes.github.io/dashboard/"
  chart      = "kubernetes-dashboard"
  version    = "5.0.4" #appVersion 2.4.0

  depends_on = [resource.kubernetes_namespace.kubernetes-dashboard]
}

================
File: networking/eks/helm.tf
================
provider "helm" {
  kubernetes {
    host                   = data.aws_eks_cluster.cluster.endpoint
    cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority.0.data)
    token                  = data.aws_eks_cluster_auth.cluster.token
    exec {
      api_version = "client.authentication.k8s.io/v1"
      args        = ["eks", "get-token", "--cluster-name", data.aws_eks_cluster.cluster.name]
      command     = "aws"
    }
  }
}

================
File: networking/eks/kubernetes.tf
================
provider "kubernetes" {
  host                   = data.aws_eks_cluster.cluster.endpoint
  token                  = data.aws_eks_cluster_auth.cluster.token
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority.0.data)
}

provider "kubectl" {
  host                   = data.aws_eks_cluster.cluster.endpoint
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority.0.data)
  token                  = data.aws_eks_cluster_auth.cluster.token
  config_path            = "${path.module}/${module.eks.kubeconfig_filename}"
}

================
File: networking/eks/launchtemplate.tf
================
data "template_file" "launch_template_userdata" {
  template = file("${path.module}/userdata.sh.tpl")

  vars = {
    cluster_name         = local.cluster_name
    endpoint             = module.eks.cluster_endpoint
    cluster_auth_base64  = module.eks.cluster_certificate_authority_data
    ec2-name             = var.ec2-name
    bootstrap_extra_args = ""
    kubelet_extra_args   = ""
  }
}

data "aws_ami" "eks-ami" {
  most_recent = true

  filter {
    name   = "name"
    values = ["drillinginfo/ubuntu2004/base-kubes-amazon-eks-node-ubuntu2004-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["070551638384"]
}


resource "aws_launch_template" "default" {
  name_prefix            = "eks-sre-shared-"
  description            = "eks-sre-shared default launch template"
  update_default_version = true

  block_device_mappings {
    device_name = "/dev/xvda"

    ebs {
      volume_size           = 50
      volume_type           = "gp3"
      delete_on_termination = true
    }
  }

  monitoring {
    enabled = true
  }

  network_interfaces {
    associate_public_ip_address = false
    delete_on_termination       = true
    security_groups             = [module.eks.worker_security_group_id, aws_security_group.all_worker_mgmt.id]
  }

  image_id = data.aws_ami.eks-ami.image_id

  user_data = base64encode(
    data.template_file.launch_template_userdata.rendered,
  )

  lifecycle {
    create_before_destroy = true
  }
}

================
File: networking/eks/lb-controller.tf
================
locals {
  k8s_service_account_namespace = "kube-system"
  k8s_service_account_name      = "aws-load-balancer-controller"
}

resource "aws_iam_policy" "lbc-policy" {
  name   = "AWSLoadBalancerControllerIAMPolicy"
  policy = file("${path.module}/policies/iam-policy.json")
}

module "iam_assumable_role_lbc" {
  source  = "terraform-aws-modules/iam/aws//modules/iam-assumable-role-with-oidc"
  version = "~> 4.0"

  create_role                   = true
  role_name                     = "AWSLoadBalancerControllerIAMRole"
  provider_url                  = replace(module.eks.cluster_oidc_issuer_url, "https://", "")
  role_policy_arns              = [aws_iam_policy.lbc-policy.arn]
  oidc_fully_qualified_subjects = ["system:serviceaccount:${local.k8s_service_account_namespace}:${local.k8s_service_account_name}"]
}

resource "kubernetes_service_account" "eks-service-account" {
  metadata {
    name      = local.k8s_service_account_name
    namespace = "kube-system"

    annotations = {
      "eks.amazonaws.com/role-arn" = module.iam_assumable_role_lbc.iam_role_arn
    }
  }
}

resource "aws_ec2_tag" "private_subnet_tag" {
  for_each    = toset(data.aws_subnet_ids.private_subnets.ids)
  resource_id = each.value
  key         = "kubernetes.io/role/internal-elb"
  value       = "1"
}

resource "null_resource" "crd" {

  provisioner "local-exec" {
    /* command = "kubectl apply -k 'github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=main'" */
    command = "kubectl apply -k '${path.cwd}/lbc-crd'"
  }
  triggers = {
    always_run = "${timestamp()}"
  }
}

================
File: networking/eks/outputs.tf
================
output "cluster_id" {
  description = "EKS cluster ID."
  value       = module.eks.cluster_id
}

output "cluster_endpoint" {
  description = "Endpoint for EKS control plane."
  value       = module.eks.cluster_endpoint
}

output "cluster_security_group_id" {
  description = "Security group ids attached to the cluster control plane."
  value       = module.eks.cluster_security_group_id
}

output "kubectl_config" {
  description = "kubectl config as generated by the module."
  value       = module.eks.kubeconfig
}

output "config_map_aws_auth" {
  description = "A kubernetes configuration to authenticate to this EKS cluster."
  value       = module.eks.config_map_aws_auth
}

output "cluster_name" {
  description = "Kubernetes Cluster Name"
  value       = local.cluster_name
}

================
File: networking/eks/security-groups.tf
================
resource "aws_security_group" "all_worker_mgmt" {
  name_prefix = "all_worker_management"
  vpc_id      = data.aws_vpc.vpc_id.id

  dynamic "ingress" {
    for_each = var.sg_rules
    content {
      from_port = ingress.value["from_port"]
      to_port   = ingress.value["to_port"]
      protocol  = ingress.value["protocol"]
      cidr_blocks = [
        "10.0.0.0/8",
        "172.16.0.0/12",
        "192.168.0.0/16",
      ]
    }
  }
}

================
File: networking/eks/userdata.sh.tpl
================
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="//"

--//
Content-Type: text/x-shellscript; charset="us-ascii"
#!/bin/bash
set -e

function error_exit()
{
    echo "userdata exited with error"
    echo "$1"
    exit 1
}

curl -sLo /bin/ec2metadata http://s3.amazonaws.com/ec2metadata/ec2-metadata && chmod +x /bin/ec2metadata
instanceId=`ec2metadata --instance-id | cut -b 14-`
shortInstanceId=`ec2metadata --instance-id | cut -b 16-`

# Setup vars for ease of use later in script
region=`ec2metadata --availability-zone| grep -m 1 -Po "(us|sa|eu|ap)-(north|south)?(east|west)?-[0-9]+"`

# Set hostname
hostnamectl set-hostname ${ec2-name}-$${shortInstanceId}

if [[ ! -e /bin/ec2metadata && -e /usr/bin/ec2metadata ]]; then
  ln -sf /usr/bin/ec2metadata /bin/ec2metadata
fi

# Begin tagging instance with instance id
echo "aws ec2 create-tags --resources $instanceId --tags Key=Name,Value=${ec2-name}-$shortInstanceId --region=$region " > /tmp/create-tags-command.log 2>&1 || error_exit 'Failed to create tag log for ec2 instance'
aws ec2 create-tags --resources $instanceId --tags Key=Name,Value=${ec2-name}-$shortInstanceId --region=$region > /tmp/create-tags.log 2>&1 || error_exit 'Failed to create tag for ec2 instance'

# Verify tag was set and if not try resetting it
for i in {1..3};do
  if [[ -z `aws ec2 describe-tags --output=text --filters Name=resource-id,Values=$instanceId --region=$region | grep ${ec2-name}-$shortInstanceId` ]];then
    aws ec2 create-tags --region=$region --resources $instanceId --tags Key=Name,Values=${ec2-name}-$shortInstanceId
  fi
done

if [[ -n `aws ec2 describe-tags --output=text --filters Name=resource-id,Values=$instanceId --region=$region | grep ${ec2-name}-$shortInstanceId` ]];then
  echo tag was correctly set > /tmp/create-tag-result.log
else
  echo tag was not correctly set > /tmp/create-tag-result.log
fi

# Bootstrap and join the cluster
/etc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' ${bootstrap_extra_args} --kubelet-extra-args "${kubelet_extra_args}" '${cluster_name}'

--//--

================
File: networking/eks/variables.tf
================
variable "kubernetes_version" {
  type = string
}

variable "aws_region" {
  default = "us-east-1"
  type    = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "dev, preprod, prod"
  type        = string
}

variable "instance_types" {
  description = "Instance types"
  type        = list(string)
  default     = ["m6i.xlarge"]
}

variable "ports" {
  description = "sg ports"
  type        = list(any)
}
variable "admin_user_role_arn" {
  description = "role arn for k8s config map"
  type        = string
}
variable "terraform_user_arn" {
  description = "tf user arn for k8s config map"
  type        = string
}
variable "terraform_role_arn" {}
variable "ec2-name" {
  description = "ec2 instane name for managed nodes group"
  type        = string
}
variable "awx_domain" {
  description = ""
  type        = string
}
variable "sg_rules" {
  type = list(object({
    from_port = number
    to_port   = number
    protocol  = string
  }))

  default = [
    {
      from_port = 443
      to_port   = 443
      protocol  = "tcp"
    },
    {
      from_port = 22
      to_port   = 22
      protocol  = "tcp"
    }
  ]
}
variable "external_dns_version" {
  description = "image version"
  type        = string
}
variable "dashboard_version" {
  description = "kubernetes dashboard version"
  type        = string
}

variable "desired_capacity" {
  description = "value for desired size EKS cluster"
  default     = "2"
}

variable "max_capacity" {
  description = "value for max size EKS cluster"
  default     = "3"
}

variable "min_capacity" {
  description = "value for min size EKS cluster"
  default     = "1"
}

================
File: networking/eks/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }

    random = {
      source  = "hashicorp/random"
      version = ">=3.1.0"
    }

    local = {
      source  = "hashicorp/local"
      version = ">=2.1.0"
    }

    null = {
      source  = "hashicorp/null"
      version = ">=3.1.0"
    }

    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = ">= 2.16"
    }

    kubectl = {
      source  = "gavinbunney/kubectl"
      version = "1.13.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "CTS-Networking"
      Component        = "EKS"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/shared-terraform/eks"
      TerraformCreated = "true"
      Environment      = "dev"
      Product          = "shared"
    }
  }
}

================
File: networking/github-actions-for-ghe/.terraform-version
================
latest:^1.4

================
File: networking/github-actions-for-ghe/dev.backend.tfvars
================
key = "dev/github-actions-for-ghe/terraform.tfstate"

================
File: networking/github-actions-for-ghe/dev.tfvars
================
s3_bucket_name = "enverus-github-enterprise-actions"
iam_user_name  = "github-enterprise-actions-s3"

================
File: networking/github-actions-for-ghe/main.tf
================
# github actions for enterprise requires and s3 bucket and an IAM user:
# ref: https://docs.github.com/en/enterprise-server@3.1/admin/github-actions/enabling-github-actions-for-github-enterprise-server/enabling-github-actions-with-amazon-s3-storage

resource "aws_s3_bucket" "bucket" {
  bucket = var.s3_bucket_name
  acl    = "private"
}

# create a dr bucket - initially used for enabling actions on a test appliance for upgrade testing
resource "aws_s3_bucket" "dr-bucket" {
  bucket = "${var.s3_bucket_name}-dr"
  acl    = "private"
}

resource "aws_iam_user" "user" {
  name          = var.iam_user_name
  force_destroy = true
}

data "aws_iam_policy_document" "actions" {
  statement {
    actions = [
      "s3:PutObject",
      "s3:GetObject",
      "s3:ListBucketMultipartUploads",
      "s3:ListMultipartUploadParts",
      "s3:AbortMultipartUpload",
      "s3:DeleteObject",
      "s3:ListBucket"
    ]

    resources = [
      "arn:aws:s3:::${aws_s3_bucket.bucket.id}",
      "arn:aws:s3:::${aws_s3_bucket.bucket.id}/*",
      "arn:aws:s3:::${aws_s3_bucket.dr-bucket.id}",
      "arn:aws:s3:::${aws_s3_bucket.dr-bucket.id}/*",
    ]
  }
}

resource "aws_iam_user_policy" "policy" {
  name   = "github-enterprise-actions"
  user   = aws_iam_user.user.name
  policy = data.aws_iam_policy_document.actions.json
}

resource "aws_iam_access_key" "key" {
  user = aws_iam_user.user.name
}

resource "vault_generic_secret" "secret" {
  path = "di-secrets/aws-api-keys/github-actions-s3"

  data_json = jsonencode(
    {
      "AWS_SECRET_ACCESS_KEY" = aws_iam_access_key.key.secret
      "AWS_ACCESS_KEY_ID"     = aws_iam_access_key.key.id
    }
  )
}

================
File: networking/github-actions-for-ghe/variables.tf
================
variable "env" {
  description = "environment"
  type        = string
}

variable "s3_bucket_name" {
  description = "Name of s3 bucket for actions"
  type        = string
}

variable "iam_user_name" {
  description = "Name of IAM user"
  type        = string
}

variable "assume_role_arn" {}

variable "aws_region" {
  description = "The AWS region where the provider will operate."
  type        = string
}

================
File: networking/github-actions-for-ghe/versions.tf
================
# Providers
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      environment = var.env
      component   = "github-enterprise"
      team        = "sre"
      source_code = ""
    }
  }
}

provider "vault" {}

================
File: networking/github-oidc/policies/github_oidc_resource_policy.json
================
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllObjectActions",
            "Effect": "Allow",
            "Action": [
                "ecr:GetDownloadUrlForLayer",
                "ecr:BatchGetImage",
                "ecr:BatchCheckLayerAvailability",
                "ecr:PutImage",
                "ecr:InitiateLayerUpload",
                "ecr:UploadLayerPart",
                "ecr:CompleteLayerUpload",
                "ecr:ListImages",
                "ecr:TagResource",
                "ecr:GetAuthorizationToken",
                "secretsmanager:GetSecretValue"
            ],
            "Resource": ["*"]
        },
        {
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Resource": "arn:aws:iam::449228620267:role/github_oidc_role"
        }
    ]
}

================
File: networking/github-oidc/.terraform-version
================
latest:^1.4

================
File: networking/github-oidc/dev.backend.tfvars
================
key = "dev/github-oidc/terraform.state"

================
File: networking/github-oidc/dev.tfvars
================
allow_list_github_organizations = [
  "enverus-cts/*",
  "enverus-ea/*",
  "enverus-tr/*",
  "RSEnergyGroup/*",
  "enverus-cts-sandbox/*",
  "enverus-pr/*"
]

================
File: networking/github-oidc/main.tf
================
resource "aws_iam_openid_connect_provider" "gh_oidc_provider" {
  url            = "https://token.actions.githubusercontent.com"
  client_id_list = ["sts.amazonaws.com"]
  thumbprint_list = [
    "a031c46782e6e6c662c2c87c76da9aa62ccabd8e",
    "6938fd4d98bab03faadb97b34396831e3780aea1"
  ]

}
locals {
  condition_list = formatlist("repo:%s", var.allow_list_github_organizations)
}

resource "aws_iam_role" "resource_role" {
  name = "github_oidc_role"

  assume_role_policy = <<EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "sts:AssumeRole",
            "Principal": {
              "Service": [
                "ec2.amazonaws.com"
              ]
            },
            "Effect": "Allow",
            "Sid": "GitHubActionsOidcRole"
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::449228620267:root"
            },
            "Action": "sts:AssumeRole"
        },
        {
        "Effect": "Allow",
        "Principal": {"Federated": "arn:aws:iam::449228620267:oidc-provider/${aws_iam_openid_connect_provider.gh_oidc_provider.url}"},
        "Action": "sts:AssumeRoleWithWebIdentity",
        "Condition": {
          "StringLike": {
            "token.actions.githubusercontent.com:sub": ${jsonencode(local.condition_list)}
            }
        }

    }
    ]
}
EOF
}

resource "aws_iam_role_policy" "resource_policy" {
  name   = "github_action_oidc_policy"
  role   = aws_iam_role.resource_role.id
  policy = file("./policies/github_oidc_resource_policy.json")
}

resource "aws_iam_policy" "github_runner_ecr_policy" {
  name        = "github_runner_ecr_policy"
  path        = "/"
  description = "Policy for hosted GHA runners"

  policy = file("./policies/github_oidc_resource_policy.json")
}

================
File: networking/github-oidc/README.md
================
# How to add a new GitHub Organization
Add the organization name to the allow_list_github_organizations.
```
allow_list_github_organizations = [
  "enverus-cts/*",
  "enverus-ea/*",
  "enverus-tr/*",
  "RSEnergyGroup/*",
  "enverus-cts-sandbox/*",
  "{new_organization_name}/*
]
```

================
File: networking/github-oidc/variables.tf
================
variable "aws_region" {}
variable "assume_role_arn" {}
variable "allow_list_github_organizations" {
  type        = list(string)
  description = "Organization names that can be authenticate with this OIDC provider"
}

================
File: networking/github-oidc/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws",
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      business_unit     = "sre"
      component         = "github-oidc"
      team              = "sre"
      source_code       = "https://github.com/enverus-cts/shared-terraform/github-oidc"
      terraform_created = "true"
    }
  }
}

================
File: networking/grafana/datasources/.terraform-version
================
latest:^1.4

================
File: networking/grafana/datasources/dev.backend.tfvars
================
key = "dev/grafana-datasources/us-east-1/terraform.tfstate"

================
File: networking/grafana/datasources/dev.tfvars
================
region = "us-east-1"
bu     = "ea"

================
File: networking/grafana/datasources/main.tf
================
data "vault_generic_secret" "grafana_api" {
  path = "di-secrets/terraform/grafana-provider"
}

# Create IAM policy
resource "aws_iam_policy" "iam_policy" {
  name        = "grafana-cloudwatch-access-${var.env}-${var.region}"
  path        = "/"
  description = "IAM policy for enverus.grafana.net IAM user to access cloudwatch metrics"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        "Sid" : "AllowReadingMetricsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "cloudwatch:DescribeAlarmsForMetric",
          "cloudwatch:DescribeAlarmHistory",
          "cloudwatch:DescribeAlarms",
          "cloudwatch:ListMetrics",
          "cloudwatch:GetMetricStatistics",
          "cloudwatch:GetMetricData"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingLogsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "logs:DescribeLogGroups",
          "logs:GetLogGroupFields",
          "logs:StartQuery",
          "logs:StopQuery",
          "logs:GetQueryResults",
          "logs:GetLogEvents"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingTagsInstancesRegionsFromEC2",
        "Effect" : "Allow",
        "Action" : [
          "ec2:DescribeTags",
          "ec2:DescribeInstances",
          "ec2:DescribeRegions"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingResourcesForTags",
        "Effect" : "Allow",
        "Action" : "tag:GetResources",
        "Resource" : "*"
      },
    ]
  })
}

# Create IAM User
resource "aws_iam_user" "iam_user" {
  name = "grafana-cloudwatch-metrics-${var.env}-${var.region}"
  path = "/"
}

resource "aws_iam_access_key" "iam_access_key" {
  user = aws_iam_user.iam_user.name
}

# Attach IAM policy to IAM User
resource "aws_iam_user_policy_attachment" "iam_user_policy_attachment" {
  user       = aws_iam_user.iam_user.name
  policy_arn = aws_iam_policy.iam_policy.arn
}

# Stash IAM user in Vault
resource "vault_generic_secret" "generic_secret" {
  path      = "di-secrets/terraform/aws/grafana/${var.bu}/${var.env}/${var.region}"
  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.iam_access_key.id}",
  "secret_key": "${aws_iam_access_key.iam_access_key.secret}"
}
EOF
}

# Create Grafana Datasource
module "datasource" {
  source          = "git@github.com/enverus-cts/sre.tf-modules.hosted-grafana.git//datasources"
  datasource_name = "Cloudwatch-sre-dev-${var.region}"
  grafana_API_key = data.vault_generic_secret.grafana_api.data["api_key"]
  region          = var.region
  env             = var.env
  datasource_type = "cloudwatch"
  access_key      = aws_iam_access_key.iam_access_key.id
  secret_key      = aws_iam_access_key.iam_access_key.secret
}

================
File: networking/grafana/datasources/Makefile
================
.PHONY: gen _gen-main _gen-examples _gen-modules

CURRENT_DIR     = $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
TF_EXAMPLES     = $(sort $(dir $(wildcard $(CURRENT_DIR)examples/*/)))
TF_MODULES      = $(sort $(dir $(wildcard $(CURRENT_DIR)modules/*/)))
TF_DOCS_VERSION = 0.16.0

# Adjust your delimiter here or overwrite via make arguments
DELIM_START = <!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
DELIM_CLOSE = <!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

gen:
	@echo "################################################################################"
	@echo "# Terraform-docs generate"
	@echo "################################################################################"
	@$(MAKE) _gen-main

_gen-main:
	@echo "------------------------------------------------------------"
	@echo "# Main module"
	@echo "------------------------------------------------------------"
	@if docker run --rm \
		-v $(CURRENT_DIR):/data \
		-e DELIM_START='$(DELIM_START)' \
		-e DELIM_CLOSE='$(DELIM_CLOSE)' \
		cytopia/terraform-docs:${TF_DOCS_VERSION} \
		terraform-docs-replace-012 md README.md; then \
		echo "OK"; \
	else \
		echo "Failed"; \
		exit 1; \
	fi

================
File: networking/grafana/datasources/README.md
================
<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.2.9 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | ~> 3.75 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_aws"></a> [aws](#provider\_aws) | ~> 3.75 |
| <a name="provider_vault"></a> [vault](#provider\_vault) | n/a |

## Modules

| Name | Source | Version |
|------|--------|---------|
| <a name="module_datasource"></a> [datasource](#module\_datasource) | git@git.drillinginfo.com:TF-Modules/hosted_grafana.git//datasources | n/a |

## Resources

| Name | Type |
|------|------|
| [aws_iam_access_key.iam_access_key](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_access_key) | resource |
| [aws_iam_policy.iam_policy](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy) | resource |
| [aws_iam_user.iam_user](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user) | resource |
| [aws_iam_user_policy_attachment.iam_user_policy_attachment](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_policy_attachment) | resource |
| [vault_generic_secret.generic_secret](https://registry.terraform.io/providers/hashicorp/vault/latest/docs/resources/generic_secret) | resource |
| [vault_generic_secret.grafana_api](https://registry.terraform.io/providers/hashicorp/vault/latest/docs/data-sources/generic_secret) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_VAULT_ADDR"></a> [VAULT\_ADDR](#input\_VAULT\_ADDR) | n/a | `any` | n/a | yes |
| <a name="input_assume_role_arn"></a> [assume\_role\_arn](#input\_assume\_role\_arn) | The arn of the role to assume. specific to the account being deployed to | `any` | n/a | yes |
| <a name="input_bu"></a> [bu](#input\_bu) | Business Unit | `string` | n/a | yes |
| <a name="input_env"></a> [env](#input\_env) | Environment level (dev/preprod/prod) | `string` | n/a | yes |
| <a name="input_region"></a> [region](#input\_region) | Region | `string` | n/a | yes |

## Outputs

No outputs.

<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

================
File: networking/grafana/datasources/variables.tf
================
variable "VAULT_ADDR" {}

variable "region" {
  type        = string
  description = "Region"
}

variable "bu" {
  type        = string
  description = "Business Unit"
}

variable "env" {
  type        = string
  description = "Environment level (dev/preprod/prod)"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

================
File: networking/grafana/datasources/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws",
      version = ">= 4.45"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

#Providers
provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "ea"
      Component        = "grafana-datasources"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/shared-terraform/tree/master/grafana/datasources"
      TerraformCreated = "true"
      Product          = "shared"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: networking/iam/users/.terraform-version
================
latest:^1.9

================
File: networking/iam/users/atlantis_assume_role_cross_account.tf
================
data "aws_iam_role" "service_role" {
  name = "service-role"
}
output "service-role" { value = data.aws_iam_role.service_role }

data "aws_iam_policy_document" "atlantis_assume_role_cross_account" {
  policy_id = "AssumeRole"
  statement {
    sid       = "AtlantisAssumeRoleCrossAccount"
    actions   = ["sts:AssumeRole"]
    resources = ["arn:aws:iam::*:role/terraform"]
    effect    = "Allow"
  }
}
output "atlantis_assume_role_cross_account_document" { value = data.aws_iam_policy_document.atlantis_assume_role_cross_account }

resource "aws_iam_policy" "atlantis_assume_role_cross_account_policy" {
  name_prefix = "atlantis_assume_role_cross_account_policy"
  policy      = data.aws_iam_policy_document.atlantis_assume_role_cross_account.json
}
output "aws_iam_policy_atlantis_assume_role_cross_account_policy" { value = aws_iam_policy.atlantis_assume_role_cross_account_policy }

resource "aws_iam_role_policy_attachment" "atlantis_assume_role_cross_account" {
  role       = data.aws_iam_role.service_role.name
  policy_arn = aws_iam_policy.atlantis_assume_role_cross_account_policy.arn
}

================
File: networking/iam/users/dev.backend.tfvars
================
key = "dev/iam/users/terraform.tfstate"

================
File: networking/iam/users/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "assume_role_arn" {}

================
File: networking/iam/users/versions.tf
================
terraform {
  backend "s3" {}
  required_version = ">= 1.9"
  required_providers {
    aws = {
      source = "hashicorp/aws"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: networking/route-53/.terraform-version
================
latest

================
File: networking/route-53/dev.backend.tfvars
================
key = "dev/route-53/terraform.tfstate"

================
File: networking/route-53/resolver.tf
================
data "aws_vpc" "vpc_id" {
  filter {
    name   = "tag:Name"
    values = ["sre-vpc-${var.env}"]
  }
}

module "route53_resolver" {
  source           = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.route53-resolvers.git?ref=v1.2.0"
  vpc_name         = lookup(data.aws_vpc.vpc_id.tags, "Name")
  subnet_name_tags = ["*INSIDE | Private Subnet"]
  env              = var.env
}

================
File: networking/route-53/variables.tf
================
variable "env" {}
variable "aws_region" {}
variable "assume_role_arn" {}

================
File: networking/route-53/versions.tf
================
terraform {
  required_version = ">= 1.10"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.45"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = var.env
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: networking/route-53/zones.tf
================
resource "aws_route53_zone" "primary" {
  name = "${var.env}.sre.enverus.com"
}

================
File: networking/s3/.terraform-version
================
latest:^0.12

================
File: networking/s3/aviatrix.tf
================
resource "aws_s3_bucket" "aviatrix_backup" {
  bucket = "en-sre-aviatrix-backup"
}

================
File: networking/s3/chef-validator.tf
================
data "aws_caller_identity" "current" {}

locals {
  bucket_name = "di-sre-${var.env}-chef-validator"
}

module "chef_validator_bucket" {
  source = "terraform-aws-modules/s3-bucket/aws"

  attach_policy = true
  policy        = data.aws_iam_policy_document.chef_bucket_policy.json
  bucket        = local.bucket_name
  acl           = "private"

  versioning = {
    enabled = true
  }

  tags = {
    Team      = "sre"
    bu        = "tools"
    component = "chef"
    env       = var.env
  }
}

data "aws_iam_policy_document" "chef_bucket_policy" {
  statement {
    principals {
      type = "AWS"
      identifiers = [
        "arn:aws:iam::${data.aws_caller_identity.current.account_id}:user/iam-base-chef-user",
        "arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"
      ]
    }

    actions = [
      "s3:GetObject",
    ]

    resources = [
      "arn:aws:s3:::${local.bucket_name}/*",
    ]
  }
}

================
File: networking/s3/dev.backend.tfvars
================
key = "dev/s3/terraform.tfstate"

================
File: networking/s3/dev.tfvars
================
env = "dev"

================
File: networking/s3/main.tf
================
terraform {
  backend "s3" {}
  required_version = "~> 0.12.31"
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
}

================
File: networking/s3/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {}
variable "assume_role_arn" {}

================
File: networking/shared-managed-prefix-lists/module/managed-prefix-list/main.tf
================
# create managed prefix lists to be shared with the Organization
locals {
  ## Splits a Carrier Grade NAT range into /19 (3 bits of /16). Excludes the first /18 (100.64.0.0-100.64.32.255) due to clash with pre-existing vpc-peers
  cidrsubnets = cidrsubnets("100.64.0.0/16", 2, 3, 3, 3, 3, 3, 3)

  ## Excludes the first /18 (100.64.0.0-100.64.32.255) due to clash with pre-existing vpc-peers
  secondary_eks_cidrs        = slice(local.cidrsubnets, 1, "5" + 1)
}

resource "aws_ec2_managed_prefix_list" "vpn" {
  name           = "VPN/Office CIDRs - shared"
  address_family = "IPv4"
  max_entries    = 10

  entry {
    cidr        = "10.8.0.0/16"
    description = "Met2 - Old"
  }

  entry {
    cidr        = "10.150.0.0/16"
    description = "Met2"
  }

  entry {
    cidr        = "10.52.0.0/14"
    description = "DC2"
  }

  entry {
    cidr        = "172.16.0.0/12"
    description = "Branch Offices"
  }

  entry {
    cidr        = "10.54.248.0/21"
    description = "PaloAltoVPN_Virginia"
  }

  entry {
    cidr        = "10.50.248.0/21"
    description = "PaloAltoVPN_Chicago"
  }

}

resource "aws_ec2_managed_prefix_list" "eks_extended_subnets" {
  name           = "EKS extended 100.64 Subnets - shared"
  address_family = "IPv4"
  max_entries    = "5"

  dynamic "entry" {
    for_each = local.secondary_eks_cidrs
    content {
      cidr        = entry.value
      description = "A secondary CIDR for EKS subnets"
    }
  }

}

resource "aws_ec2_managed_prefix_list" "rfc-1918" {
  name           = "All RFC-1918 CIDR-s - shared"
  address_family = "IPv4"
  max_entries    = 10

  entry {
    cidr        = "10.0.0.0/8"
    description = "Primary"
  }

  entry {
    cidr        = "172.16.0.0/12"
    description = "Secondary"
  }
  entry {
    cidr        = "192.168.0.0/16"
    description = "Tertiary"
  }
  entry {
    cidr        = "100.64.0.0/27"
    description = "Overlapping CIDR"
  }
  entry {
    cidr        = "100.64.0.32/27"
    description = "Overlapping CIDR"
  }
}

resource "aws_ram_resource_share" "managed_prefix_lists" {
  name = "Managed Prefix Lists"
  allow_external_principals = false
}

resource "aws_ram_resource_association" "vpn" {
  resource_share_arn = aws_ram_resource_share.managed_prefix_lists.arn
  resource_arn       = aws_ec2_managed_prefix_list.vpn.arn
}

resource "aws_ram_resource_association" "eks_extended_subnets" {
  resource_share_arn = aws_ram_resource_share.managed_prefix_lists.arn
  resource_arn       = aws_ec2_managed_prefix_list.eks_extended_subnets.arn
}

resource "aws_ram_resource_association" "rfc-1918" {
  resource_share_arn = aws_ram_resource_share.managed_prefix_lists.arn
  resource_arn       = aws_ec2_managed_prefix_list.rfc-1918.arn
}

data "aws_organizations_organization" "main" {}

resource "aws_ram_principal_association" "aws_organization" {
  principal = data.aws_organizations_organization.main.arn
  resource_share_arn = aws_ram_resource_share.managed_prefix_lists.arn
}

================
File: networking/shared-managed-prefix-lists/module/managed-prefix-list/README.md
================
This is a local module - terraform commands should not be run in this folder.

================
File: networking/shared-managed-prefix-lists/module/managed-prefix-list/versions.tf
================
terraform {
  required_version = "~> 1.8.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

================
File: networking/shared-managed-prefix-lists/.terraform-version
================
latest:^1.8

================
File: networking/shared-managed-prefix-lists/main.tf
================
# create managed prefix lists to be shared with the Organization
# use provider aliases to create in multiple regions

module "prefix-list-ue1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.ue1
  }
}

module "prefix-list-uw1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.uw1
  }
}

module "prefix-list-uw2" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.uw2
  }
}

module "prefix-list-ew1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.ew1
  }
}

module "prefix-list-en1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.en1
  }
}

module "prefix-list-ec1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.ec1
  }
}

module "prefix-list-as1" {
  source = "./module/managed-prefix-list"
  providers = {
    aws = aws.as1
  }
}

================
File: networking/shared-managed-prefix-lists/prod.backend.tfvars
================
key    = "449228620267/prod/shared-managed-prefix-lists/terraform.tfstate"
bucket = "enverus-centralized-terraform-state"

================
File: networking/shared-managed-prefix-lists/README.md
================
This code creates and shares managed prefix lists for VPCs in multiple regions.

Regions are defined in the providers in [versions.tf](./versions.tf) which are used in [main.tf](./main.tf).

Resources are defined in the [local module](./module/managed-prefix-list/)

================
File: networking/shared-managed-prefix-lists/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "env" {
  type        = string
  description = "example, prod"
}
variable "assume_role_arn" {
  type        = string
  description = "Role for Terraform to assume"
}

================
File: networking/shared-managed-prefix-lists/versions.tf
================
terraform {
  required_version = "~> 1.8.0"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  alias = "ue1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "us-west-1"
  alias = "uw1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "us-west-2"
  alias = "uw2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "eu-west-1"
  alias = "ew1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "eu-north-1"
  alias = "en1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "eu-central-1"
  alias = "ec1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = "ap-south-1"
  alias = "as1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "managed-prefix-list"
      Team             = "sre@enverus.com"
      Environment      = "prod"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/shared-managed-prefix-lists"
      Product          = "shared"
    }
  }
}

================
File: networking/vault/.terraform-version
================
latest:^1.7

================
File: networking/vault/dev.backend.tfvars
================
key = "dev-sre/vault/ue1/terraform.tfstate"

================
File: networking/vault/dev.tfvars
================
#keys
consul_token = "ItWC9TmfeecGGr1f3KSxdg=="
#module componements
datacenter    = "aws-ue1"
ec2-region    = "us-east-1"
os            = "ubuntu16"
vpc_name_tag  = "sre-vpc-dev"
instance_type = "c5d.large"
ec2-name      = "aws-ue1-dev-sre-vault"
asg-name      = "ue1-dev-sre-vault-asg"
elb-name      = "ue1-dev-sre-vault-lb"
dns-name      = "vault.dev.sre.drillinginfo.com"
#Chef
chef-environment = "dev-docker"
#Tagging
tagTeam                 = "sre"
tagComponent            = "vault"
env                     = "dev"
bu                      = "sre"
iam-profile             = "service-instance-profile"
inside_subnet_filter    = ["*| INSIDE | Private Subnet"]
bucket_hook_environment = "dev_sre"
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"

================
File: networking/vault/main.tf
================
data "aws_route53_zone" "selected" {
  name = "${var.env}.sre.drillinginfo.com"
}

module "aws-asg-ue1-sre-root-vault-server" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault.git?ref=v1.3.2"

  generate_certs = 1
  cert_type      = "AMAZON_ISSUED"
  cert_domain    = "*.${var.env}.sre.drillinginfo.com"
  datacenter     = var.datacenter
  consul_token   = var.consul_token
  bu             = var.bu
  vo_routing_key = var.vo_routing_key

  organization_name     = "Drillinginfo"
  ca_common_name        = var.dns-name
  common_name           = var.dns-name
  dns_names             = ["vault.service.consul, ${var.dns-name}, localhost"]
  ip_addresses          = ["127.0.0.1"]
  validity_period_hours = "87658"
  vpc_name_tag          = var.vpc_name_tag
  inside_subnet_filter  = var.inside_subnet_filter
  # ami search filters
  ami-filters = {
    name           = var.image
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lc params and userdata
  environment             = var.env
  bucket_hook_environment = var.bucket_hook_environment
  os                      = var.os
  ec2-name                = var.ec2-name
  instance-type           = var.instance_type
  keypair-name            = var.keypair-name
  iam-profile             = var.iam-profile
  ebs-optimized           = "true"

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = "2"
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "1"
  suspended-processes       = ["AZRebalance"]

  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
      playbook_file = "install-alloy.yml",
      git_host      = "cloud",
      additional_args = [
        "--extra-vars \"alloy_environment_name=${var.env} alloy_business_unit=${var.bu}\"",
        "-C main"
      ],
    }
  ]

  # Chef
  chef-version     = "12.21.14"
  chef-environment = var.chef-environment

  # Tagging
  tagComponent  = var.tagComponent
  tagStack      = var.env
  tagProduct    = "nexus"
  tagAutospot   = "false"
  tagLocation   = var.ec2-region
  tagTeam       = var.tagTeam
  tagSourceCode = "https://github.com/enverus-cts/shared-terraform/tree/master/vault"

  #elb dns stuff

  elb-name                  = var.elb-name
  internal                  = true
  cross_zone_load_balancing = true
  idle_timeout              = "60"
  lb_port                   = "443"
  vault_api_port            = "8200"
  create_dns_entry          = 1
  hosted_zone_id            = data.aws_route53_zone.selected.zone_id
  domain_name               = var.dns-name
}

================
File: networking/vault/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "ec2-region" {
  description = "region in which to create instance"
  type        = string
}

variable "datacenter" {
  description = "the name of the dc, in our case could be 'aws-ue1'"
  type        = string
}

variable "os" {
  description = "used to configure scripts"
  type        = string
}

variable "bu" {
  description = "the business unit"
  default     = "upstream"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "consul_token" {
  description = "key to connect to consul"
  type        = string
}

variable "vpc_name_tag" {
  description = "Value of Name tag applied to target VPC, eg 'dev-VPC'"
  type        = string
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "ec2-name" {
  description = "used for naming the instances"
  type        = string
}

variable "asg-name" {
  description = "used for naming autoscaling group"
  type        = string
}

variable "elb-name" {
  description = "used for naming load balancer"
  type        = string
}

variable "dns-name" {
  description = "used for naming domain name"
  type        = string
}

variable "chef-environment" {
  description = "chef environment into which the node should bootstrap"
  type        = string
}

variable "tagTeam" {
  description = "used to set team tag"
  type        = string
}

variable "tagComponent" {
  description = "used to set component tag"
  type        = string
}

variable "keypair-name" {
  default     = "cm@drillinginfo.com"
  description = "keypair for ssh"
}

variable "iam-profile" {}

variable "inside_subnet_filter" {}
variable "assume_role_arn" {}
variable "bucket_hook_environment" {}
variable "image" {}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

================
File: networking/vault/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.43"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }

  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = var.tagComponent
      Team             = var.tagTeam
      SourceCode       = "https://github.com/shared-terraform/vault"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: networking/vault_azuread_sso/.terraform-version
================
latest:^1.8

================
File: networking/vault_azuread_sso/dev.backend.tfvars
================
key = "dev-sre/vault_azuread_sso/ue1/terraform.tfstate"

================
File: networking/vault_azuread_sso/dev.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "http://localhost:8200",
  "https://vault.dev.sre.drillinginfo.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_SRE_ADMIN_USERS"
# vault_identity_group_alias_dev = {
#   SEC_ENTITLE_AWS_CDS_DEV_POWER_USERS = {
#     uid = "57acfb35-9cee-49f7-93a3-653b0650cc67"
#     policies = [
#       "terraform-read-policy",
#     ]
#   }
# }
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_SRE_DEV_DATA_TEAM_RW = {
    policies = [
      "data-team-rw",
    ]
  }
}
vault_path_oidc_client_secret               = "sre_tools_secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "sre_tools_secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault.dev.sre.drillinginfo.com"

================
File: networking/vault_azuread_sso/main.tf
================
data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

module "vault_azuread_sso" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-azuread-sso.git?ref=v0.1.0"

  oidc_client_id                 = var.oidc_client_id
  oidc_discovery_url             = var.oidc_discovery_url
  allowed_redirect_uris_prefix   = var.allowed_redirect_uris_prefix
  vault_identity_group_alias_sre = var.vault_identity_group_alias_sre
  vault_identity_group_alias_dev = var.vault_identity_group_alias_dev
  vault_path_oidc_client_secret  = var.vault_path_oidc_client_secret
}
output "vault_azuread_sso" { value = module.vault_azuread_sso }

output "REMINDER" { value = "SEC_ENTITLE groups created by this module, will also have to be manually added to Azure AD Vault app https://portal.azure.com/#blade/Microsoft_AAD_IAM/ManagedAppMenuBlade/Users/appId/495c468a-6481-4be6-b9ac-8711fc6223af/objectId/3cfd6569-cf05-406f-967a-59a7d85f06f8" }

================
File: networking/vault_azuread_sso/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "vault_path_azure_service_principal_atlantis" {
  description = "The vault path to AzureAD Service Principal secret"
  type        = string
}

variable "vault_path_oidc_client_secret" {
  description = "The vault path to AzureAD OIDC secret"
  type        = string
}

variable "oidc_client_id" {
  description = "The client id for credentials to query the Azure APIs. Currently read permissions to query compute resources are required."
  type        = string
}

variable "oidc_discovery_url" {
  description = "The OIDC Discovery URL, without any .well-known component (base"
  type        = string
}

variable "allowed_redirect_uris_prefix" {
  description = "The list of allowed values for redirect_uri during OIDC logins. Required for OIDC roles"
  type        = list(string)
}

variable "vault_identity_group_alias_sre" {
  description = "Azure ID of the group alias to create."
  type        = string
  default     = null
}

variable "vault_identity_group_alias_dev" {
  description = "list of Azure IDs of the group alias to create."
  type        = any
  default     = {}
}

================
File: networking/vault_azuread_sso/versions.tf
================
terraform {
  required_version = ">= 1.8.1, < 1.8.2"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: networking/vault_mounts/.terraform-version
================
latest:^1.8

================
File: networking/vault_mounts/dev.backend.tfvars
================
key = "449228620267/dev/vault_mounts/terraform.tfstate"

================
File: networking/vault_mounts/dev.tfvars
================
VAULT_ADDR        = "https://vault.dev.sre.drillinginfo.com/"
list_vault_mounts = ["enverus-cts"]

================
File: networking/vault_mounts/main.tf
================
resource "vault_mount" "mounts" {
  for_each = var.list_vault_mounts

  path = each.key
  type = "kv-v2"
}

================
File: networking/vault_mounts/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_mounts" {
  description = "a list of vault mounts"
  type        = set(any)
}

================
File: networking/vault_mounts/versions.tf
================
terraform {
  required_version = ">= 1.8.1, < 1.8.2"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: networking/vault_policies_and_roles/.terraform-version
================
latest:^1.8

================
File: networking/vault_policies_and_roles/dev.backend.tfvars
================
key = "dev-sre/vault_policies_and_roles/ue1/terraform.tfstate"

================
File: networking/vault_policies_and_roles/dev.tfvars
================
env                = "dev"
bu                 = "sre_tools"
secrets_mountpoint = "sre_tools_secrets"
VAULT_ADDR         = "https://vault.dev.sre.drillinginfo.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  terraform-read-policy = [
    {
      path         = "sre_tools_secrets/*"
      capabilities = ["read"]
      description  = "Allow reading sre_tools_secrets"
    },
    {
      path         = "enverus-cts/*"
      capabilities = ["read"]
      description  = "Allow reading enverus-cts"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/aws/role/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/aws/role/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "Allow revoking tokens that should no longer exist. This allows revoking tokens for dead tasks."
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "di-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys/*"
    },
    {
      path         = "di-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "di-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to prometheus-api-keys/*"
    },
    {
      path         = "di-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to promtail-api-keys/*"
    },
    {
      path         = "sre_tools_secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis/*"
    },
    {
      path         = "sre_tools_secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "sre_tools_secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "sre_tools_secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "sre_tools_secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "sre_tools_secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis secrets"
    },
    {
      path         = "sre_tools_secrets/data/chef"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to chef"
    },
    {
      path         = "enverus-cts/data/github-enterprise*"
      capabilities = ["read"]
      description  = "access github enterprise credentials"
    },
    {
      path         = "enverus-cts/data/github*"
      capabilities = ["read"]
      description  = "access github app credentials"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["read", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACLs broadly across Vault."
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  data-team-rw = [
    {
      path         = "di-secrets*"
      capabilities = ["list"]
      description  = "access to di-secrets"
    },
    {
      path         = "di-secrets/data/terraform/data-team/*"
      capabilities = ["read", "update", "list", "create", "delete"]
      description  = "access to data team secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: networking/vault_policies_and_roles/main.tf
================
module "vault_policies_and_roles" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-policies-and-roles.git?ref=main"

  list_vault_policies = var.list_vault_policies
  secrets_mountpoint  = var.secrets_mountpoint
  bu                  = var.bu
  env                 = var.env
}
output "vault_policies_and_roles" { value = module.vault_policies_and_roles }

================
File: networking/vault_policies_and_roles/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_policies" {
  description = "a list of vault policies"
  type = map(list(object(
    {
      path         = string
      capabilities = list(string)
      description  = string
  })))
}

variable "secrets_mountpoint" {
  description = "Mountpoint of Secret path"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Env"
  type        = string
}

================
File: networking/vault_policies_and_roles/versions.tf
================
terraform {
  required_version = ">= 1.8.1, < 1.8.2"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: networking/vpc/vpc-dev/.terraform-version
================
latest:^1.4

================
File: networking/vpc/vpc-dev/dev.backend.tfvars
================
key = "dev/vpc/terraform.tfstate"

================
File: networking/vpc/vpc-dev/dev.tfvars
================
vpc_cidr_block                = "10.25.96.0/21"
cloud_wan_core_network_id     = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment         = "nonprod"
ecr_endpoint_type             = null
cloudwatch_logs_endpoint_type = null
enable_ue1_az3                = true

================
File: networking/vpc/vpc-dev/main.tf
================
module "vpc" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.10.1"

  aws_region                      = var.aws_region
  tag_name                        = "sre-vpc-${var.env}"
  tag_environment                 = var.env
  vpc_cidr_block                  = var.vpc_cidr_block
  cloud_wan_core_network_id       = var.cloud_wan_core_network_id
  tag_cloud_wan_segment           = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment = true
  ecr_endpoint_type               = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type   = var.cloudwatch_logs_endpoint_type
  enable_ue1_az3                  = var.enable_ue1_az3

  providers = {
    aws.cts_networking = aws.cts_networking
  }
}

================
File: networking/vpc/vpc-dev/variables.tf
================
variable "aws_region" {
  description = "AWS ec2 region, used to configure provider"
  type        = string
}

variable "vpc_cidr_block" {
  type        = string
  description = "VPC CIDR Block"
}

variable "env" {
  type        = string
  description = "Dev/Preprod/Prod"
}
variable "assume_role_arn" {
  type        = string
  description = "Role for Terraform to assume"
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC
variable "ecr_endpoint_type" {
  description = "Value to determine ECR endpoint type. Null by default to use NAT Gateway. false = decentralized, true = centralized, null = NAT Gateway."
  type        = bool
  nullable    = true
  default     = null
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine CloudWatch Logs endpoint type. Null by default to use NAT Gateway. false = decentralized, true = centralized, null = NAT Gateway."
  type        = bool
  nullable    = true
  default     = null
}

# If you have resources in AZ3 currently, enable this variable to use us-east-1-az3. Otherwise the subnet and its resources will be destroyed.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

================
File: networking/vpc/vpc-dev/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.45"
    }
  }
}

provider "aws" {
  region = var.aws_region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = "dev"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

# Alias for VPC module to use in PHZ association using CTS networking role
provider "aws" {
  alias  = "cts_networking"
  region = var.aws_region
  assume_role {
    role_arn = "arn:aws:iam::449228620267:role/terraform"
  }

  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "vpc"
      Team             = "sre@enverus.com"
      Environment      = "dev"
      SourceCode       = "https://github.com/enverus-cts/sre.terraform.cts-networking/tree/main/vpc"
      TerraformCreated = "true"
    }
  }
}

================
File: networking/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_route53_record.consul-server-lb": [
      "aws_lb.consul-server-lb"
    ],
    "aws_lb_listener.consul-listener": [
      "aws_lb.consul-server-lb",
      "aws_lb_target_group.consul-tg"
    ],
    "aws_autoscaling_attachment.consul": [
      "aws_lb_target_group.consul-tg"
    ],
    "aws_iam_role_policy.resource_policy": [
      "aws_iam_role.resource_role"
    ],
    "aws_dx_transit_virtual_interface.ashburn_primary": [
      "aws_dx_gateway.primary",
      "aws_dx_connection.ashburn_primary"
    ],
    "aws_dx_transit_virtual_interface.ashburn_secondary": [
      "aws_dx_gateway.primary",
      "aws_dx_connection.ashburn_secondary"
    ],
    "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan": [
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway",
      "aws_dx_connection.ashburn_primary"
    ],
    "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan": [
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway",
      "aws_dx_connection.ashburn_secondary"
    ],
    "aws_dx_transit_virtual_interface.reston_primary": [
      "aws_dx_connection.reston_primary",
      "aws_dx_gateway.primary"
    ],
    "aws_dx_transit_virtual_interface.chicago_primary": [
      "aws_dx_gateway.primary",
      "aws_dx_connection.chicago_primary"
    ],
    "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary": [
      "aws_dx_connection.cloudwan-sea1-zayo-portland-primary",
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway"
    ],
    "aws_dx_transit_virtual_interface.cloudwan-reston-primary": [
      "aws_dx_connection.reston_primary",
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway"
    ],
    "aws_iam_user_policy.policy": [
      "aws_iam_user.user"
    ],
    "aws_iam_access_key.key": [
      "aws_iam_user.user"
    ],
    "vault_generic_secret.secret": [
      "aws_iam_access_key.key"
    ],
    "aws_networkmanager_core_network_policy_attachment.initial_policy_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_networkmanager_core_network_policy_attachment.policy_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_networkmanager_dx_gateway_attachment.dx_gateway_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_ram_principal_association.core_network": [
      "aws_ram_resource_share.core_network"
    ],
    "aws_ram_resource_association.core_network": [
      "aws_ram_resource_share.core_network",
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ue1": [
      "aws_ram_resource_share.route53_endpoint_profile_ue1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_uw2": [
      "aws_ram_resource_share.route53_endpoint_profile_uw2"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_en1": [
      "aws_ram_resource_share.route53_endpoint_profile_en1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ew1": [
      "aws_ram_resource_share.route53_endpoint_profile_ew1"
    ],
    "aws_ram_principal_association.route53_profile_ue1": [
      "aws_ram_resource_share.route53_endpoint_profile_ue1",
      "aws_ram_resource_association.route53_endpoint_profile_association_ue1"
    ],
    "aws_ram_principal_association.route53_profile_uw2": [
      "aws_ram_resource_association.route53_endpoint_profile_association_uw2",
      "aws_ram_resource_share.route53_endpoint_profile_uw2"
    ],
    "aws_ram_principal_association.route53_profile_en1": [
      "aws_ram_resource_share.route53_endpoint_profile_en1",
      "aws_ram_resource_association.route53_endpoint_profile_association_en1"
    ],
    "aws_ram_principal_association.route53_profile_ew1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_ew1",
      "aws_ram_resource_share.route53_endpoint_profile_ew1"
    ],
    "helm_release.aws-load-balancer-controller": [
      "kubernetes_service_account.eks-service-account"
    ],
    "helm_release.kubernetes-dashboard": [
      "kubernetes_namespace.kubernetes-dashboard"
    ],
    "aws_acm_certificate_validation.enverus": [
      "aws_acm_certificate.enverus"
    ],
    "aws_iam_role_policy_attachment.atlantis_assume_role_cross_account": [
      "aws_iam_policy.atlantis_assume_role_cross_account_policy"
    ],
    "aws_ram_resource_association.vpn": [
      "aws_ram_resource_share.managed_prefix_lists",
      "aws_ec2_managed_prefix_list.vpn"
    ],
    "aws_ram_resource_association.eks_extended_subnets": [
      "aws_ram_resource_share.managed_prefix_lists",
      "aws_ec2_managed_prefix_list.eks_extended_subnets"
    ],
    "aws_ram_resource_association.rfc-1918": [
      "aws_ram_resource_share.managed_prefix_lists",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_ram_principal_association.aws_organization": [
      "aws_ram_resource_share.managed_prefix_lists"
    ],
    "aws_iam_access_key.iam_access_key": [
      "aws_iam_user.iam_user"
    ],
    "aws_iam_user_policy_attachment.iam_user_policy_attachment": [
      "aws_iam_user.iam_user",
      "aws_iam_policy.iam_policy"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy",
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ],
    "vault_generic_secret.shared_secret": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-cts": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-pr": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-it": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-ba": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-tr": [
      "random_password.shared_secret"
    ]
  },
  "dependents": {
    "aws_lb.consul-server-lb": [
      "aws_route53_record.consul-server-lb",
      "aws_lb_listener.consul-listener"
    ],
    "aws_lb_target_group.consul-tg": [
      "aws_lb_listener.consul-listener",
      "aws_autoscaling_attachment.consul"
    ],
    "aws_iam_role.resource_role": [
      "aws_iam_role_policy.resource_policy"
    ],
    "aws_dx_gateway.primary": [
      "aws_dx_transit_virtual_interface.ashburn_primary",
      "aws_dx_transit_virtual_interface.ashburn_secondary",
      "aws_dx_transit_virtual_interface.reston_primary",
      "aws_dx_transit_virtual_interface.chicago_primary"
    ],
    "aws_dx_connection.ashburn_primary": [
      "aws_dx_transit_virtual_interface.ashburn_primary",
      "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan"
    ],
    "aws_dx_connection.ashburn_secondary": [
      "aws_dx_transit_virtual_interface.ashburn_secondary",
      "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan"
    ],
    "aws_dx_gateway.cloudwan-directconnect-prod-gateway": [
      "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan",
      "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan",
      "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary",
      "aws_dx_transit_virtual_interface.cloudwan-reston-primary"
    ],
    "aws_dx_connection.reston_primary": [
      "aws_dx_transit_virtual_interface.reston_primary",
      "aws_dx_transit_virtual_interface.cloudwan-reston-primary"
    ],
    "aws_dx_connection.chicago_primary": [
      "aws_dx_transit_virtual_interface.chicago_primary"
    ],
    "aws_dx_connection.cloudwan-sea1-zayo-portland-primary": [
      "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary"
    ],
    "aws_iam_user.user": [
      "aws_iam_user_policy.policy",
      "aws_iam_access_key.key"
    ],
    "aws_iam_access_key.key": [
      "vault_generic_secret.secret"
    ],
    "aws_networkmanager_core_network.core_network": [
      "aws_networkmanager_core_network_policy_attachment.initial_policy_attachment",
      "aws_networkmanager_core_network_policy_attachment.policy_attachment",
      "aws_networkmanager_dx_gateway_attachment.dx_gateway_attachment",
      "aws_ram_resource_association.core_network"
    ],
    "aws_ram_resource_share.core_network": [
      "aws_ram_principal_association.core_network",
      "aws_ram_resource_association.core_network"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_ue1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_ue1",
      "aws_ram_principal_association.route53_profile_ue1"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_uw2": [
      "aws_ram_resource_association.route53_endpoint_profile_association_uw2",
      "aws_ram_principal_association.route53_profile_uw2"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_en1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_en1",
      "aws_ram_principal_association.route53_profile_en1"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_ew1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_ew1",
      "aws_ram_principal_association.route53_profile_ew1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ue1": [
      "aws_ram_principal_association.route53_profile_ue1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_uw2": [
      "aws_ram_principal_association.route53_profile_uw2"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_en1": [
      "aws_ram_principal_association.route53_profile_en1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ew1": [
      "aws_ram_principal_association.route53_profile_ew1"
    ],
    "kubernetes_service_account.eks-service-account": [
      "helm_release.aws-load-balancer-controller"
    ],
    "kubernetes_namespace.kubernetes-dashboard": [
      "helm_release.kubernetes-dashboard"
    ],
    "aws_acm_certificate.enverus": [
      "aws_acm_certificate_validation.enverus"
    ],
    "aws_iam_policy.atlantis_assume_role_cross_account_policy": [
      "aws_iam_role_policy_attachment.atlantis_assume_role_cross_account"
    ],
    "aws_ram_resource_share.managed_prefix_lists": [
      "aws_ram_resource_association.vpn",
      "aws_ram_resource_association.eks_extended_subnets",
      "aws_ram_resource_association.rfc-1918",
      "aws_ram_principal_association.aws_organization"
    ],
    "aws_ec2_managed_prefix_list.vpn": [
      "aws_ram_resource_association.vpn"
    ],
    "aws_ec2_managed_prefix_list.eks_extended_subnets": [
      "aws_ram_resource_association.eks_extended_subnets"
    ],
    "aws_ec2_managed_prefix_list.rfc-1918": [
      "aws_ram_resource_association.rfc-1918"
    ],
    "aws_iam_user.iam_user": [
      "aws_iam_access_key.iam_access_key",
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.iam_policy": [
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "random_password.shared_secret": [
      "vault_generic_secret.shared_secret",
      "github_organization_webhook.enverus-cts",
      "github_organization_webhook.enverus-pr",
      "github_organization_webhook.enverus-it",
      "github_organization_webhook.enverus-ba",
      "github_organization_webhook.enverus-tr"
    ]
  },
  "cross_repo_references": [
    "external.aws_default_tags.current",
    "external.enable_ue1_az3",
    "external.aws_iam_policy_document.chef_bucket_policy",
    "external.aws_organizations_organization.parent_organization",
    "external.aws_route53_zone.enverus",
    "external.vpc_name_tag",
    "external.aws_route53_zone.selected",
    "external.create_route53_record",
    "external.ec2",
    "external.spot_price",
    "external.enable",
    "external.aws_tag_product",
    "external.asg",
    "external.alb_https_security_group_tags",
    "external.atlantis_port",
    "external.tagComponent",
    "external.tag_cloud_wan_segment",
    "external.team",
    "external.aws_tag_source_code",
    "external.awx_domain",
    "external.aws_route53_zone.this",
    "external.os",
    "external.kubectl_path_documents.docs",
    "external.aws_vpc.main",
    "external.aws_networkmanager_core_network_policy_document.initial_nw_policy",
    "external.kubernetes_version",
    "external.iam",
    "external.tagTeam",
    "external.vault_generic_secret.Azure_Service_Principal_Atlantis",
    "external.aws_iam_role.service_role",
    "external.vpc_name",
    "external.vault_identity_group_alias_dev",
    "external.resource_type_exclusion_list",
    "external.atlantis_security_group_tags",
    "external.cloudwatch_logs_kms_key_id",
    "external.url",
    "external.acm",
    "external.kms_exclusion_list",
    "external.name",
    "external.aws_vpc.vpc_id",
    "external.bucket_hook_environment",
    "external.aws_regions",
    "external.vmware",
    "external.terraform_role_arn",
    "external.instance_type",
    "external.secrets_mountpoint",
    "external.aws_tag_business_unit",
    "external.iam_assumable_role_lbc",
    "external.aws_region",
    "external.route53_zone_name",
    "external.vault_addr",
    "external.aws_subnets.public",
    "external.oidc_client_id",
    "external.direct_connect_gateway_id",
    "external.vault_generic_secret.direct_connect",
    "external.vault_generic_secret.gh_token",
    "external.alb_enable_deletion_protection",
    "external.egress_vpc_cidr_block",
    "external.aws_route53_zone.sre",
    "external.min_capacity",
    "external.cloud_wan_core_network_id",
    "external.alb_ingress_cidr_blocks",
    "external.s3_bucket_name",
    "external.alb_http_sg",
    "external.vault_path_azure_service_principal_atlantis",
    "external.route53_private_zone",
    "external.max_capacity",
    "external.encryption",
    "external.consul_servers",
    "external.keypair",
    "external.vault_path_oidc_client_secret",
    "external.iam_assumable_role_edns",
    "external.environment",
    "external.aws_iam_policy_document.actions",
    "external.bu",
    "external.alb_log_location_prefix",
    "external.cloudwatch_log_retention_in_days",
    "external.aws_lb.edge",
    "external.security_group_ids",
    "external.configBackend",
    "external.vo_routing_key",
    "external.alb_http_security_group_tags",
    "external.vpc",
    "external.vault_identity_group_alias_sre",
    "external.list_vault_policies",
    "external.datacenter",
    "external.vault_generic_secret.grafana_api",
    "external.eks",
    "external.user_provided_ansible_pull_playbook_list",
    "external.aws_eks_cluster.cluster",
    "external.aws_subnets.private_subnets",
    "external.iam_user_name",
    "external.route53_record_name",
    "external.multi",
    "external.vpc_cidr_block",
    "external.certificate_arn",
    "external.alb_logging_enabled",
    "external.list_vault_mounts",
    "external.allow_unauthenticated_webhook_access_priority",
    "external.allow_github_webhooks",
    "external.template_file.launch_template_userdata",
    "external.alb_listener_ssl_policy_default",
    "external.admin_user_role_arn",
    "external.dns",
    "external.aws_tag_env",
    "external.alb_authenticate_cognito",
    "external.edge_proxy_lb_name",
    "external.allow_list_github_organizations",
    "external.internal_route53_record_name",
    "external.instance_types",
    "external.aws_organizations_organization.main",
    "external.allowed_redirect_uris_prefix",
    "external.aws_subnet_ids.private_subnets",
    "external.allow_unauthenticated_access",
    "external.alb_drop_invalid_header_fields",
    "external.alb",
    "external.business",
    "external.aws_config_sns",
    "external.env",
    "external.project_identifier",
    "external.internal",
    "external.desired_capacity",
    "external.consul_token",
    "external.github_webhooks_cidr_blocks",
    "external.aws_vpc.vpc",
    "external.cloudwatch_logs_endpoint_type",
    "external.VAULT_ADDR",
    "external.external_dns_version",
    "external.aws_networkmanager_core_network_policy_document.core_nw_policy",
    "external.assume_role_arn",
    "external.ecr_endpoint_type",
    "external.sg_rules",
    "external.egress_vpc_name",
    "external.image",
    "external.alb_authenticate_oidc",
    "external.region",
    "external.business_unit",
    "external.aws_iam_policy_document.atlantis_assume_role_cross_account",
    "external.source_code",
    "external.inside_subnet_filter",
    "external.aws_tag_component",
    "external.aws_availability_zones.good_zone_ids",
    "external.oidc_discovery_url",
    "external.aws_tag_team",
    "external.aws_caller_identity.current",
    "external.dashboard_version",
    "external.recursors",
    "external.whitelist_unauthenticated_cidr_blocks",
    "external.atlantis_github_user_token",
    "external.elb",
    "external.chef",
    "external.alb_https_sg",
    "external.subnet",
    "external.acm_certificate_domain_name",
    "external.allow_unauthenticated_access_priority",
    "external.terraform_user_arn",
    "external.aws_eks_cluster_auth.cluster",
    "external.tags",
    "external.alb_log_bucket_name",
    "external.aws"
  ],
  "outputs": [
    "good_zone_ids",
    "private_subnets",
    "consul_servers",
    "alb_dns_name",
    "alb_zone_id",
    "alb_arn",
    "alb_security_group_id",
    "alb_http_listeners_id",
    "alb_http_listeners_arn",
    "alb_https_listeners_id",
    "alb_https_listeners_arn",
    "good_zone_ids",
    "cloudwan-sea1-zayo-portland-primary",
    "vault_azuread_sso",
    "REMINDER",
    "cts-ue1-egress-vpc",
    "cts-uw2-egress-vpc",
    "cts-en1-egress-vpc",
    "cts-ew1-egress-vpc",
    "global-network",
    "core-network",
    "account_ids",
    "vpc_ue1",
    "vpc_uw2",
    "vpc_ew1",
    "vpc_en1",
    "cluster_id",
    "cluster_endpoint",
    "cluster_security_group_id",
    "kubectl_config",
    "config_map_aws_auth",
    "cluster_name",
    "vault_policies_and_roles",
    "service-role",
    "atlantis_assume_role_cross_account_document",
    "aws_iam_policy_atlantis_assume_role_cross_account_policy"
  ],
  "metadata": {
    "total_resources": 78,
    "resources_with_dependencies": 46,
    "resources_that_are_dependencies": 37,
    "cross_repo_refs_count": 160,
    "outputs_count": 36,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: networking/.gitattributes
================
# https://docs.github.com/en/github/using-git/configuring-git-to-handle-line-endings
* text=auto

================
File: networking/.gitignore
================
**/.terraform/*
*.tfstate
*.tfstate.*
*.terraform.lock.hcl
shared-terraform.test.dswanignore

================
File: networking/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.88.4
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"

================
File: networking/atlantis.yaml
================
version: 3
automerge: false
projects:
  #### vpcs ####
  - name: vpc-dev
    dir: vpc/vpc-dev
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  #### s3 ####
  - name: s3-dev
    dir: s3
    workflow: dev
    terraform_version: v0.12.31
    autoplan:
      when_modified: ["*.tf*"]
  - name: route-53-dev
    dir: route-53
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  # - name: direct-connect-dev
  #   dir: direct-connect
  #   workflow: dev
  #   terraform_version: v1.7.5
  #   autoplan:
  #     when_modified: ["*.tf*"]
  - name: direct-connect-prod
    dir: direct-connect
    workflow: sre-tools-dev-vault
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  #### consul cluster dev ####
  - name: consul-cluster-dev
    dir: consul-cluster
    workflow: sre-tools-dev-vault
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  #### vault cluster dev ####
  - name: vault-cluster-dev
    dir: vault
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault_policies_and_roles-dev
    dir: vault_policies_and_roles
    workflow: sre-tools-dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault_azuread_sso-dev
    dir: vault_azuread_sso
    workflow: sre-tools-dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  ############ vault mounts ################
  - name: vault-mounts-dev
    dir: vault_mounts
    workflow: sre-tools-dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  ### GitHub OIDC ###
  - name: github-oidc
    dir: github-oidc
    workflow: dev
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  ############ iam user for cloud-init #################
  - name: iam-dev-users
    dir: iam/users
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  #### AWS Config aggregator ####
  - name: aws-config-aggregrator
    dir: config
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  #### Github Actions for GHE ###
  - name: github-actions-for-ghe
    dir: github-actions-for-ghe
    workflow: dev
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  #### CloudWAN ####
  # Dev is disabled and can be spun up when necessary.
  # - name: cloudwan-dev
  #   dir: cloud-wan
  #   workflow: dev
  #   autoplan:
  #     when_modified: ["*.tf*"]
  - name: cloudwan-prod
    dir: cloud-wan
    workflow: prod
    autoplan:
      when_modified: ["*.tf*"]
  #### Github org webhooks ####
  - name: atlantis-github-webhook-infra-github-org-webhooks
    dir: atlantis-github-webhook-infra/github-org-webhooks
    workflow: cts-dev-prod-vault
    terraform_version: v7.5
    autoplan:
      when_modified: ["*.tf*"]
  #### END Github org webhooks ####

  #### VPC Peering for cloudwan ####
  - name: vpc-peering-cloudwan
    dir: cloud-wan-peering
    workflow: prod
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]

  #### VPC Peering for cloudwan ####
  - name: shared-managed-prefix-lists
    dir: shared-managed-prefix-lists
    workflow: prod

================
File: networking/global-dev-backend.tfvars
================
bucket         = "di-sre-dev-terraform"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::449228620267:role/terraform" }

================
File: networking/global-dev.tfvars
================
aws_region      = "us-east-1"
VAULT_ADDR      = "https://vault.dev.sre.drillinginfo.com"
env             = "dev"
assume_role_arn = "arn:aws:iam::449228620267:role/terraform"
vo_routing_key  = "Key-DevUptime"

================
File: networking/global-prod-backend.tfvars
================
bucket         = "di-sre-prod-terraform"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::449228620267:role/terraform" }

================
File: networking/global-prod.tfvars
================
aws_region      = "us-east-1"
VAULT_ADDR      = "https://vault.dev.sre.drillinginfo.com"
env             = "prod"
assume_role_arn = "arn:aws:iam::449228620267:role/terraform"
vo_routing_key  = "Key-ProdUptime"

================
File: networking/networking_dependency_graph.json
================
{
  "repo_name": "networking",
  "dependencies": {
    "aws_route53_record.consul-server-lb": [
      "aws_lb.consul-server-lb"
    ],
    "aws_lb_listener.consul-listener": [
      "aws_lb.consul-server-lb",
      "aws_lb_target_group.consul-tg"
    ],
    "aws_autoscaling_attachment.consul": [
      "aws_lb_target_group.consul-tg"
    ],
    "aws_iam_role_policy.resource_policy": [
      "aws_iam_role.resource_role"
    ],
    "aws_dx_transit_virtual_interface.ashburn_primary": [
      "aws_dx_connection.ashburn_primary",
      "aws_dx_gateway.primary"
    ],
    "aws_dx_transit_virtual_interface.ashburn_secondary": [
      "aws_dx_connection.ashburn_secondary",
      "aws_dx_gateway.primary"
    ],
    "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan": [
      "aws_dx_connection.ashburn_primary",
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway"
    ],
    "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan": [
      "aws_dx_connection.ashburn_secondary",
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway"
    ],
    "aws_dx_transit_virtual_interface.reston_primary": [
      "aws_dx_gateway.primary",
      "aws_dx_connection.reston_primary"
    ],
    "aws_dx_transit_virtual_interface.chicago_primary": [
      "aws_dx_connection.chicago_primary",
      "aws_dx_gateway.primary"
    ],
    "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary": [
      "aws_dx_connection.cloudwan-sea1-zayo-portland-primary",
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway"
    ],
    "aws_dx_transit_virtual_interface.cloudwan-reston-primary": [
      "aws_dx_gateway.cloudwan-directconnect-prod-gateway",
      "aws_dx_connection.reston_primary"
    ],
    "aws_iam_user_policy.policy": [
      "aws_iam_user.user"
    ],
    "aws_iam_access_key.key": [
      "aws_iam_user.user"
    ],
    "vault_generic_secret.secret": [
      "aws_iam_access_key.key"
    ],
    "aws_networkmanager_core_network_policy_attachment.initial_policy_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_networkmanager_core_network_policy_attachment.policy_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_networkmanager_dx_gateway_attachment.dx_gateway_attachment": [
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_ram_principal_association.core_network": [
      "aws_ram_resource_share.core_network"
    ],
    "aws_ram_resource_association.core_network": [
      "aws_ram_resource_share.core_network",
      "aws_networkmanager_core_network.core_network"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ue1": [
      "aws_ram_resource_share.route53_endpoint_profile_ue1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_uw2": [
      "aws_ram_resource_share.route53_endpoint_profile_uw2"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_en1": [
      "aws_ram_resource_share.route53_endpoint_profile_en1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ew1": [
      "aws_ram_resource_share.route53_endpoint_profile_ew1"
    ],
    "aws_ram_principal_association.route53_profile_ue1": [
      "aws_ram_resource_share.route53_endpoint_profile_ue1",
      "aws_ram_resource_association.route53_endpoint_profile_association_ue1"
    ],
    "aws_ram_principal_association.route53_profile_uw2": [
      "aws_ram_resource_association.route53_endpoint_profile_association_uw2",
      "aws_ram_resource_share.route53_endpoint_profile_uw2"
    ],
    "aws_ram_principal_association.route53_profile_en1": [
      "aws_ram_resource_share.route53_endpoint_profile_en1",
      "aws_ram_resource_association.route53_endpoint_profile_association_en1"
    ],
    "aws_ram_principal_association.route53_profile_ew1": [
      "aws_ram_resource_share.route53_endpoint_profile_ew1",
      "aws_ram_resource_association.route53_endpoint_profile_association_ew1"
    ],
    "helm_release.aws-load-balancer-controller": [
      "kubernetes_service_account.eks-service-account"
    ],
    "helm_release.kubernetes-dashboard": [
      "kubernetes_namespace.kubernetes-dashboard"
    ],
    "aws_acm_certificate_validation.enverus": [
      "aws_acm_certificate.enverus"
    ],
    "aws_iam_role_policy_attachment.atlantis_assume_role_cross_account": [
      "aws_iam_policy.atlantis_assume_role_cross_account_policy"
    ],
    "aws_ram_resource_association.vpn": [
      "aws_ec2_managed_prefix_list.vpn",
      "aws_ram_resource_share.managed_prefix_lists"
    ],
    "aws_ram_resource_association.eks_extended_subnets": [
      "aws_ec2_managed_prefix_list.eks_extended_subnets",
      "aws_ram_resource_share.managed_prefix_lists"
    ],
    "aws_ram_resource_association.rfc-1918": [
      "aws_ram_resource_share.managed_prefix_lists",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_ram_principal_association.aws_organization": [
      "aws_ram_resource_share.managed_prefix_lists"
    ],
    "aws_iam_access_key.iam_access_key": [
      "aws_iam_user.iam_user"
    ],
    "aws_iam_user_policy_attachment.iam_user_policy_attachment": [
      "aws_iam_policy.iam_policy",
      "aws_iam_user.iam_user"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role",
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ],
    "vault_generic_secret.shared_secret": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-cts": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-pr": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-it": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-ba": [
      "random_password.shared_secret"
    ],
    "github_organization_webhook.enverus-tr": [
      "random_password.shared_secret"
    ]
  },
  "dependents": {
    "aws_lb.consul-server-lb": [
      "aws_route53_record.consul-server-lb",
      "aws_lb_listener.consul-listener"
    ],
    "aws_lb_target_group.consul-tg": [
      "aws_lb_listener.consul-listener",
      "aws_autoscaling_attachment.consul"
    ],
    "aws_iam_role.resource_role": [
      "aws_iam_role_policy.resource_policy"
    ],
    "aws_dx_connection.ashburn_primary": [
      "aws_dx_transit_virtual_interface.ashburn_primary",
      "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan"
    ],
    "aws_dx_gateway.primary": [
      "aws_dx_transit_virtual_interface.ashburn_primary",
      "aws_dx_transit_virtual_interface.ashburn_secondary",
      "aws_dx_transit_virtual_interface.reston_primary",
      "aws_dx_transit_virtual_interface.chicago_primary"
    ],
    "aws_dx_connection.ashburn_secondary": [
      "aws_dx_transit_virtual_interface.ashburn_secondary",
      "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan"
    ],
    "aws_dx_gateway.cloudwan-directconnect-prod-gateway": [
      "aws_dx_transit_virtual_interface.ashburn_primary_cloudwan",
      "aws_dx_transit_virtual_interface.ashburn_secondary_cloudwan",
      "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary",
      "aws_dx_transit_virtual_interface.cloudwan-reston-primary"
    ],
    "aws_dx_connection.reston_primary": [
      "aws_dx_transit_virtual_interface.reston_primary",
      "aws_dx_transit_virtual_interface.cloudwan-reston-primary"
    ],
    "aws_dx_connection.chicago_primary": [
      "aws_dx_transit_virtual_interface.chicago_primary"
    ],
    "aws_dx_connection.cloudwan-sea1-zayo-portland-primary": [
      "aws_dx_transit_virtual_interface.cloudwan-sea1-zayo-portland-primary"
    ],
    "aws_iam_user.user": [
      "aws_iam_user_policy.policy",
      "aws_iam_access_key.key"
    ],
    "aws_iam_access_key.key": [
      "vault_generic_secret.secret"
    ],
    "aws_networkmanager_core_network.core_network": [
      "aws_networkmanager_core_network_policy_attachment.initial_policy_attachment",
      "aws_networkmanager_core_network_policy_attachment.policy_attachment",
      "aws_networkmanager_dx_gateway_attachment.dx_gateway_attachment",
      "aws_ram_resource_association.core_network"
    ],
    "aws_ram_resource_share.core_network": [
      "aws_ram_principal_association.core_network",
      "aws_ram_resource_association.core_network"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_ue1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_ue1",
      "aws_ram_principal_association.route53_profile_ue1"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_uw2": [
      "aws_ram_resource_association.route53_endpoint_profile_association_uw2",
      "aws_ram_principal_association.route53_profile_uw2"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_en1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_en1",
      "aws_ram_principal_association.route53_profile_en1"
    ],
    "aws_ram_resource_share.route53_endpoint_profile_ew1": [
      "aws_ram_resource_association.route53_endpoint_profile_association_ew1",
      "aws_ram_principal_association.route53_profile_ew1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ue1": [
      "aws_ram_principal_association.route53_profile_ue1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_uw2": [
      "aws_ram_principal_association.route53_profile_uw2"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_en1": [
      "aws_ram_principal_association.route53_profile_en1"
    ],
    "aws_ram_resource_association.route53_endpoint_profile_association_ew1": [
      "aws_ram_principal_association.route53_profile_ew1"
    ],
    "kubernetes_service_account.eks-service-account": [
      "helm_release.aws-load-balancer-controller"
    ],
    "kubernetes_namespace.kubernetes-dashboard": [
      "helm_release.kubernetes-dashboard"
    ],
    "aws_acm_certificate.enverus": [
      "aws_acm_certificate_validation.enverus"
    ],
    "aws_iam_policy.atlantis_assume_role_cross_account_policy": [
      "aws_iam_role_policy_attachment.atlantis_assume_role_cross_account"
    ],
    "aws_ec2_managed_prefix_list.vpn": [
      "aws_ram_resource_association.vpn"
    ],
    "aws_ram_resource_share.managed_prefix_lists": [
      "aws_ram_resource_association.vpn",
      "aws_ram_resource_association.eks_extended_subnets",
      "aws_ram_resource_association.rfc-1918",
      "aws_ram_principal_association.aws_organization"
    ],
    "aws_ec2_managed_prefix_list.eks_extended_subnets": [
      "aws_ram_resource_association.eks_extended_subnets"
    ],
    "aws_ec2_managed_prefix_list.rfc-1918": [
      "aws_ram_resource_association.rfc-1918"
    ],
    "aws_iam_user.iam_user": [
      "aws_iam_access_key.iam_access_key",
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.iam_policy": [
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "random_password.shared_secret": [
      "vault_generic_secret.shared_secret",
      "github_organization_webhook.enverus-cts",
      "github_organization_webhook.enverus-pr",
      "github_organization_webhook.enverus-it",
      "github_organization_webhook.enverus-ba",
      "github_organization_webhook.enverus-tr"
    ]
  },
  "cross_repo_references": [
    "external.encryption",
    "external.chef",
    "external.aws_tag_component",
    "external.cloudwatch_logs_endpoint_type",
    "external.external_dns_version",
    "external.aws_organizations_organization.main",
    "external.enable_ue1_az3",
    "external.aws_config_sns",
    "external.business_unit",
    "external.ecr_endpoint_type",
    "external.awx_domain",
    "external.atlantis_port",
    "external.atlantis_github_user_token",
    "external.aws_default_tags.current",
    "external.bucket_hook_environment",
    "external.alb_authenticate_oidc",
    "external.route53_private_zone",
    "external.inside_subnet_filter",
    "external.kubernetes_version",
    "external.vpc",
    "external.multi",
    "external.aws_networkmanager_core_network_policy_document.initial_nw_policy",
    "external.create_route53_record",
    "external.kms_exclusion_list",
    "external.route53_zone_name",
    "external.spot_price",
    "external.aws_tag_source_code",
    "external.aws_regions",
    "external.keypair",
    "external.aws",
    "external.aws_subnets.private_subnets",
    "external.enable",
    "external.user_provided_ansible_pull_playbook_list",
    "external.allow_unauthenticated_access_priority",
    "external.iam_user_name",
    "external.aws_route53_zone.sre",
    "external.vpc_name_tag",
    "external.vault_addr",
    "external.ec2",
    "external.iam",
    "external.vpc_name",
    "external.aws_iam_policy_document.actions",
    "external.allow_unauthenticated_webhook_access_priority",
    "external.egress_vpc_cidr_block",
    "external.aws_vpc.main",
    "external.aws_route53_zone.this",
    "external.vault_identity_group_alias_sre",
    "external.tags",
    "external.resource_type_exclusion_list",
    "external.url",
    "external.datacenter",
    "external.aws_caller_identity.current",
    "external.aws_vpc.vpc_id",
    "external.s3_bucket_name",
    "external.security_group_ids",
    "external.env",
    "external.acm",
    "external.allow_unauthenticated_access",
    "external.aws_vpc.vpc",
    "external.instance_types",
    "external.template_file.launch_template_userdata",
    "external.alb_http_sg",
    "external.cloudwatch_logs_kms_key_id",
    "external.aws_tag_product",
    "external.aws_availability_zones.good_zone_ids",
    "external.list_vault_mounts",
    "external.alb_logging_enabled",
    "external.allow_github_webhooks",
    "external.aws_tag_team",
    "external.VAULT_ADDR",
    "external.source_code",
    "external.aws_iam_policy_document.atlantis_assume_role_cross_account",
    "external.iam_assumable_role_lbc",
    "external.team",
    "external.vault_identity_group_alias_dev",
    "external.oidc_discovery_url",
    "external.vault_generic_secret.Azure_Service_Principal_Atlantis",
    "external.admin_user_role_arn",
    "external.aws_subnets.public",
    "external.aws_region",
    "external.tagComponent",
    "external.aws_eks_cluster.cluster",
    "external.vault_generic_secret.direct_connect",
    "external.aws_subnet_ids.private_subnets",
    "external.os",
    "external.instance_type",
    "external.secrets_mountpoint",
    "external.consul_token",
    "external.iam_assumable_role_edns",
    "external.alb_ingress_cidr_blocks",
    "external.vault_generic_secret.grafana_api",
    "external.aws_lb.edge",
    "external.aws_route53_zone.selected",
    "external.subnet",
    "external.alb_log_bucket_name",
    "external.elb",
    "external.tag_cloud_wan_segment",
    "external.assume_role_arn",
    "external.aws_route53_zone.enverus",
    "external.acm_certificate_domain_name",
    "external.aws_iam_role.service_role",
    "external.vmware",
    "external.tagTeam",
    "external.region",
    "external.certificate_arn",
    "external.alb_log_location_prefix",
    "external.terraform_role_arn",
    "external.whitelist_unauthenticated_cidr_blocks",
    "external.direct_connect_gateway_id",
    "external.oidc_client_id",
    "external.cloud_wan_core_network_id",
    "external.eks",
    "external.sg_rules",
    "external.internal",
    "external.aws_tag_business_unit",
    "external.alb_authenticate_cognito",
    "external.alb_https_sg",
    "external.business",
    "external.aws_iam_policy_document.chef_bucket_policy",
    "external.internal_route53_record_name",
    "external.aws_tag_env",
    "external.aws_networkmanager_core_network_policy_document.core_nw_policy",
    "external.alb_http_security_group_tags",
    "external.vault_path_azure_service_principal_atlantis",
    "external.dns",
    "external.asg",
    "external.consul_servers",
    "external.alb_https_security_group_tags",
    "external.min_capacity",
    "external.edge_proxy_lb_name",
    "external.vault_generic_secret.gh_token",
    "external.bu",
    "external.aws_organizations_organization.parent_organization",
    "external.vault_path_oidc_client_secret",
    "external.vpc_cidr_block",
    "external.kubectl_path_documents.docs",
    "external.image",
    "external.atlantis_security_group_tags",
    "external.cloudwatch_log_retention_in_days",
    "external.desired_capacity",
    "external.list_vault_policies",
    "external.terraform_user_arn",
    "external.recursors",
    "external.alb",
    "external.environment",
    "external.alb_drop_invalid_header_fields",
    "external.egress_vpc_name",
    "external.route53_record_name",
    "external.max_capacity",
    "external.name",
    "external.project_identifier",
    "external.aws_eks_cluster_auth.cluster",
    "external.allowed_redirect_uris_prefix",
    "external.alb_enable_deletion_protection",
    "external.configBackend",
    "external.allow_list_github_organizations",
    "external.vo_routing_key",
    "external.dashboard_version",
    "external.github_webhooks_cidr_blocks",
    "external.alb_listener_ssl_policy_default"
  ],
  "outputs": [
    "good_zone_ids",
    "private_subnets",
    "consul_servers",
    "alb_dns_name",
    "alb_zone_id",
    "alb_arn",
    "alb_security_group_id",
    "alb_http_listeners_id",
    "alb_http_listeners_arn",
    "alb_https_listeners_id",
    "alb_https_listeners_arn",
    "good_zone_ids",
    "cloudwan-sea1-zayo-portland-primary",
    "vault_azuread_sso",
    "REMINDER",
    "cts-ue1-egress-vpc",
    "cts-uw2-egress-vpc",
    "cts-en1-egress-vpc",
    "cts-ew1-egress-vpc",
    "global-network",
    "core-network",
    "account_ids",
    "vpc_ue1",
    "vpc_uw2",
    "vpc_ew1",
    "vpc_en1",
    "cluster_id",
    "cluster_endpoint",
    "cluster_security_group_id",
    "kubectl_config",
    "config_map_aws_auth",
    "cluster_name",
    "vault_policies_and_roles",
    "service-role",
    "atlantis_assume_role_cross_account_document",
    "aws_iam_policy_atlantis_assume_role_cross_account_policy"
  ],
  "metadata": {
    "total_resources": 78,
    "resources_with_dependencies": 46,
    "resources_that_are_dependencies": 37,
    "cross_repo_refs_count": 160,
    "outputs_count": 36,
    "generated_from": ".",
    "repo_name": "networking"
  }
}

================
File: pr/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: pr/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: pr/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: pr/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: pr/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: pr/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: pr/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: pr/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: pr/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: pr/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: pr/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: pr/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: pr/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: pr/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: pr/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 2e9182c66e38bf3c3f88a557e94989aa746681d5 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406166 -0600	clone: from github.com:enverus-cts/sre.pr.terraform.git

================
File: pr/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 2e9182c66e38bf3c3f88a557e94989aa746681d5 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406166 -0600	clone: from github.com:enverus-cts/sre.pr.terraform.git

================
File: pr/.git/logs/HEAD
================
0000000000000000000000000000000000000000 2e9182c66e38bf3c3f88a557e94989aa746681d5 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406166 -0600	clone: from github.com:enverus-cts/sre.pr.terraform.git

================
File: pr/.git/refs/heads/main
================
2e9182c66e38bf3c3f88a557e94989aa746681d5

================
File: pr/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: pr/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.pr.terraform.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: pr/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: pr/.git/HEAD
================
ref: refs/heads/main

================
File: pr/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
7f22e51bc1e9280692f5c8a9e7aa0a2c2f75717c refs/remotes/origin/SRE-9461
4ec293f87251c08754fed430be6234fdf0a65bcb refs/remotes/origin/eks-experiment
75e5b02da695c894179fb467b35d35bf1d22cd64 refs/remotes/origin/feat/SRE-12315_Update_Trust_policy_for_new_atlantis_irsa
ac81e61a971ac93211f21555a341f8993d48a353 refs/remotes/origin/feat/sre-12427-add-enverus-cts
065640765b0c3017da8c899369fb221d22202d68 refs/remotes/origin/feat/sre-13410-github-runner-oidc-access
2e9182c66e38bf3c3f88a557e94989aa746681d5 refs/remotes/origin/main
b06fe0cf5dadd7ab17fc3b39ebbcd7c92214dcde refs/remotes/origin/nexus-433-4
72977fee1b4fb5f3f9417d271440f246e3c91a8f refs/remotes/origin/sre-12674

================
File: pr/.github/CODEOWNERS
================
/.github/CODEOWNERS @enverus-cts/sre

* @enverus-cts/sre

================
File: pr/.github/dependabot.yaml
================
version: 2
updates:
  # Maintain dependencies for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"

================
File: pr/acm/.terraform-version
================
latest:^1.4

================
File: pr/acm/acm.tf
================
resource "aws_acm_certificate" "pr" {
  domain_name       = "*.${var.env}.pr.enverus.com"
  validation_method = "DNS"

  lifecycle {
    create_before_destroy = true
  }
}

data "aws_route53_zone" "pr" {
  name         = "${var.env}.pr.enverus.com"
  private_zone = false
}


resource "aws_route53_record" "pr" {
  for_each = {
    for dvo in aws_acm_certificate.pr.domain_validation_options : dvo.domain_name => {
      name   = dvo.resource_record_name
      record = dvo.resource_record_value
      type   = dvo.resource_record_type
    }
  }

  allow_overwrite = true
  zone_id         = data.aws_route53_zone.pr.zone_id
  name            = each.value.name
  type            = each.value.type
  ttl             = "300"
  records         = [each.value.record]
}

resource "aws_acm_certificate_validation" "cert_validation" {
  certificate_arn         = aws_acm_certificate.pr.arn
  validation_record_fqdns = [for record in aws_route53_record.pr : record.fqdn]
}

================
File: pr/acm/dev.backend.tfvars
================
key = "040927785588/dev/acm/terraform.tfstate"

================
File: pr/acm/prod.backend.tfvars
================
key = "330682006453/prod/acm/terraform.tfstate"

================
File: pr/acm/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "environment"
  type        = string
}

variable "bu" {
  description = "business unit abbreviation"
  type        = string
}

================
File: pr/acm/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "acm"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform/tree/main/acm"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: pr/config/remediation/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml
================
description: Automation Document to enable/re-enable Amazon Elastic Block Store (EBS) encryption
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  AccountID:
    description: (Required) Account ID
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.11
      Handler: script_handler
      Script: |-
        import boto3

        ec2 = boto3.client('ec2')

        def enableEBSEncryptionByDefault(account_id, region):
          try:
            response = ec2.enable_ebs_encryption_by_default()
            print("Successfully enabled EBS encryption in account ID: ", account_id,"region:", region)
          except Exception as e:
            print("Error enabling ebs encryption. Actual error: ", e)

        def script_handler(events, context):
          account_id = events['AccountID']
          region     = events['Region']
          enableEBSEncryptionByDefault(account_id, region)

      InputPayload:
        AccountID: '{{ AccountID }}'
        Region: '{{ global:REGION }}'
    isEnd: true

================
File: pr/config/remediation/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml
================
description: Automation Document to cancel KMS key deletion if the key is not in the exception list
schemaVersion: '0.3'
assumeRole: '{{ AutomationAssumeRole }}'
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ExcListParameter:
    default: /kms/exception/list
    description: (Required) AWS SSM Parameter for KMS key exception list
    type: String
  KMSKeyID:
    description: (Required) Deleted KMS Key ID
    type: String
  SNSTopic:
    description: (Required) SNS topic to send notifications
    type: String
mainSteps:
  - name: CheckExceptionList
    action: 'aws:executeScript'
    onFailure: 'step:cancelKeyDelete'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3
        from botocore.exceptions import ClientError

        ssm = boto3.client('ssm', region_name='us-east-1')

        def getParameter(exc_list_parameter):
          try:
            response = ssm.get_parameter(
              Name=exc_list_parameter,
              WithDecryption=True
            )['Parameter']['Value']
            print(response)
            return { "parameter": response,"errorMessage":"none" }
          except ClientError as e:
            print('Error getting parameter: ', e)
            return { "parameter":"error","errorMessage":"error" }

        def checkParameter(kms_key_id, exc_list_parameter):
          block_Key_Delete = 'true'
          parameter        = getParameter(exc_list_parameter)
          if parameter["parameter"] == "error":
            return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }
          elif parameter["parameter"] != " ":
            parameter_list = parameter["parameter"].split(",")
            if kms_key_id in parameter_list:
              block_Key_Delete = 'false'

          return { "errorMessage": parameter["errorMessage"],"block_Key_Delete": block_Key_Delete }

        def script_handler(events, context):
          exc_list_parameter = events['ExcListParameter']
          kms_key_id         = events['KMSKeyID']
          results            = checkParameter(kms_key_id, exc_list_parameter)

          return { "errorMessage": results["errorMessage"], "blockKeyDelete": results["block_Key_Delete"] }
      InputPayload:
        ExcListParameter: '{{ ExcListParameter }}'
        KMSKeyID: '{{ KMSKeyID }}'
    outputs:
      - Name: errorMessage
        Selector: $.Payload.errorMessage
        Type: String
      - Name: blockKeyDelete
        Selector: $.Payload.blockKeyDelete
        Type: String
  - name: chooseToBlock
    action: aws:branch
    onFailure: 'step:onFailure'
    inputs:
      Choices:
      - NextStep: cancelKeyDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'true'
      - NextStep: allowDelete
        Variable: '{{ CheckExceptionList.blockKeyDelete }}'
        StringEquals: 'false'
      Default:
        onFailure
  - name: cancelKeyDelete
    action: 'aws:executeScript'
    onFailure: 'step:onFailure'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        kms = boto3.client('kms')

        def cancelKeyDeletion(kms_key_id):
          try:
            response = kms.cancel_key_deletion(
                KeyId=kms_key_id
            )
            return {"canceled":"true","error":"null"}
          except Exception as e:
            return {"canceled":"false","error":str(e)}

        def enableKey(kms_key_id):
          try:
            response = kms.enable_key(
                KeyId=kms_key_id
            )
            return {"enabled":"true","error":"null"}
          except Exception as e:
            print('Enable key error: ', e)
            return {"enabled":"false", "error":str(e)}

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id):
          cancel_Key_Deletion = cancelKeyDeletion(kms_key_id)
          if ('CheckExceptionList.errorMessage' or 'error') in error_message:
            if cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Error getting KMS key exception list from SSM parameter ' + exc_list_parameter + '. Therefore, deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled'
                           ' for account alias ' + account_alias + ' and account ID: ' + account_id + '. Check error of getting exception list before trying to delete the key again.')
          elif cancel_Key_Deletion["canceled"] == "true":
              enable_Key = enableKey(kms_key_id)
              if enable_Key["enabled"] == "true":
                message = ('Deletion of KMS key with ID: ' + kms_key_id + ' was canceled and the key re-enabled for account alias ' + account_alias + ' and account ID:' + account_id + '. Key ID must be added'
                           ' to the exception list before the key can be permanently deleted.')
              else:
                message = ('Deletion of KMS key with ID: ',kms_key_id,' was canceled but there was an error during key re-enabled for account alias ',account_alias,' and account ID: ',account_id,'.Check the'
                           'error and note that key ID must be added to the exception list before the key can be permanently deleted.')
          else:
            message = 'Error canceling deletion of KMS key with ID: ' + kms_key_id + ' for the account alias ' + account_alias +' and account ID:' + account_id + '.The key is not in the exception list'

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sns = boto3.client('sns')
          sts = boto3.client('sts')
          iam = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]

          exc_list_parameter = events['ExcListParameter']
          kms_key_id     = events['KMSKeyID']
          error_message  = events['ErrorMessage']
          sns_topic      = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, error_message, exc_list_parameter, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        ErrorMessage: '{{ CheckExceptionList.errorMessage }}'
        SNSTopic: '{{ SNSTopic }}'
        ExcListParameter: '{{ ExcListParameter }}'
    isEnd: true
  - name: allowDelete
    action: 'aws:executeScript'
    onFailure: Abort
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id):
          message = ('Key with ID: ' + kms_key_id + ' is scheduled for deletion in account alias ' + account_alias + 'and account ID: ' + account_id + '. The key is allowed to be deleted since it is in the'
                    ' excepption list. SRE confirm the key is allowed to be deleted.')

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processCancelKeyDeletion(kms_key_id, sns_topic, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true
  - name: onFailure
    action: 'aws:executeScript'
    inputs:
      Runtime: python3.8
      Handler: script_handler
      Script: |-
        import boto3

        sns = boto3.client('sns')

        def sendSNSMessage(sns_topic, message):
          sns = boto3.client('sns', region_name='us-east-1')
          response = sns.publish(
             TopicArn=sns_topic,
             Message=message
          )

        def processFailure(kms_key_id, sns_topic, account_alias, account_id):
          message = 'ALERT: Key with ID: ' + kms_key_id + ' is scheduled for deletion. There was an unkown error and remediation did not complete. Check errors and make sure the key is allowed to be deleted.'

          sendSNSMessage(sns_topic, message)

        def script_handler(events, context):
          sts           = boto3.client('sts')
          iam           = boto3.client('iam')

          account_id    = sts.get_caller_identity()["Account"]
          account_alias = iam.list_account_aliases()["AccountAliases"][0]
          kms_key_id    = events['KMSKeyID']
          sns_topic     = events['SNSTopic']

          processFailure(kms_key_id, sns_topic, account_alias, account_id)
      InputPayload:
        KMSKeyID: '{{ KMSKeyID }}'
        SNSTopic: '{{ SNSTopic }}'
    isEnd: true

================
File: pr/config/remediation/data.tf
================
data "local_file" "kms-cmk-not-scheduled-for-deletion-remediation-doc" {
  filename = "${path.module}/documents/automation/kms-cmk-not-scheduled-for-deletion-remediation.yaml"
}

data "local_file" "ec2-ebs-encryption-by-default-remediation-doc" {
  filename = "${path.module}/documents/automation/ec2-ebs-encryption-by-default-remediation.yaml"
}

data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: pr/config/remediation/document_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-remediation-document-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "kms-cmk-not-scheduled-for-deletion-remediation"
  document_type   = "Automation"
  content         = data.local_file.kms-cmk-not-scheduled-for-deletion-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: pr/config/remediation/documents_ec2_ebs_encryption_by_default.tf
================
#trigger atlantis
module "ec2-ebs-encryption-by-default-remediation-document-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

module "ec2-ebs-encryption-by-default-remediation-document-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ue2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.uw2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.cc1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.aps1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apne2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.apse2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ec1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew2
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.ew3
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.se1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}


module "ec2-ebs-encryption-by-default-remediation-document-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_document"
  providers = {
    aws = aws.en1
  }
  environment     = var.environment
  name            = "ec2-ebs-encryption-by-default-remediation"
  document_type   = "Automation"
  content         = data.local_file.ec2-ebs-encryption-by-default-remediation-doc.content
  document_format = "YAML"
  default_tags    = data.aws_default_tags.current.tags
}

================
File: pr/config/remediation/iam.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################
data "aws_iam_policy_document" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  statement {
    sid = "GetSSMparameter"
    actions = [
      "ssm:GetParameter"
    ]
    resources = [
      join(":", ["arn:aws:ssm", "*", data.aws_caller_identity.current.account_id, join("", ["parameter", module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name])])
    ]
    effect = "Allow"
  }
  statement {
    sid = "CancelKMSDelete"
    actions = [
      "kms:CancelKeyDeletion",
      "iam:ListAccountAliases",
      "kms:EnableKey"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
  statement {
    sid = "PublishToSNS"
    actions = [
      "SNS:Publish"
    ]
    resources = [
      var.aws_config_sns
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name   = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].json
}

resource "aws_iam_role" "kms-cmk-not-scheduled-for-deletion-remediation-document-role" {
  count = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  name  = join("-", [var.environment, "kms", "cmk", "not", "scheduled", "for", "deletion", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": "SNSaccess"
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment" {
  count      = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  role       = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].name
  policy_arn = aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy[count.index].arn
}

################################################################################
##########ec2-ebs-encryption-by-default
################################################################################
data "aws_iam_policy_document" "ec2-ebs-encryption-by-default-remediation-document" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  statement {
    sid = ""
    actions = [
      "ec2:EnableEbsEncryptionByDefault"
    ]
    resources = [
      "*"
    ]
    effect = "Allow"
  }
}

resource "aws_iam_policy" "ec2-ebs-encryption-by-default-remediation-policy" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name   = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "policy"])
  path   = "/"
  policy = data.aws_iam_policy_document.ec2-ebs-encryption-by-default-remediation-document[count.index].json
}

resource "aws_iam_role" "ec2-ebs-encryption-by-default-remediation-role" {
  count = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  name  = join("-", [var.environment, "ec2", "ebs", "encryption", "by", "default", "remediation", "role"])

  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ssm.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "ec2-ebs-encryption-by-default-remediation-policy-attachment" {
  count      = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  role       = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].name
  policy_arn = aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy[count.index].arn
}

================
File: pr/config/remediation/parameters.tf
================
################################################################################
##########kms-cmk-not-scheduled-for-deletion
################################################################################

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ue2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.uw2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.cc1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.aps1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apne2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.apse2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ec1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew2
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.ew3
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.se1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

module "kms-cmk-not-scheduled-for-deletion-exclusion-list-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_ssm//ssm_parameter"
  providers = {
    aws = aws.en1
  }
  environment  = var.environment
  name         = "/kms/exception/list"
  description  = "KMS key exclusion list. List of KMS key ID not to be remediated by kms-cmk-not-scheduled-for-deletion config rule."
  type         = "SecureString"
  value        = tostring(var.kms_exclusion_list)
  default_tags = data.aws_default_tags.current.tags
}

================
File: pr/config/remediation/remediation_ec2_ebs_encryption_by_default.tf
================
module "ec2-ebs-encryption-by-default-remediation-ue1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ue2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ue2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-uw2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-uw2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-cc1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-cc1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-aps1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-aps1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apne2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apne2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-apse2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-apse2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ec1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ec1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew2" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew2[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-ew3" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-ew3[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-se1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-se1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

module "ec2-ebs-encryption-by-default-remediation-en1" {
  count  = var.enable-ec2-ebs-encryption-by-default-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/ec2_ebs_encryption_by_default_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  ec2-ebs-encryption-by-default-remediation = var.enable-ec2-ebs-encryption-by-default-remediation
  target_id                                 = module.ec2-ebs-encryption-by-default-remediation-document-en1[count.index].document_name
  aws_iam_role                              = aws_iam_role.ec2-ebs-encryption-by-default-remediation-role[count.index].arn
}

================
File: pr/config/remediation/remediation_kms_cmk_not_scheduled_for_deletion.tf
================
module "kms-cmk-not-scheduled-for-deletion-remediation-ue1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-ue2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ue2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ue2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ue2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-uw1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-uw2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.uw2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-uw2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-uw2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-cc1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.cc1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-cc1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-cc1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-aps1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.aps1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-aps1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-aps1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apne2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apne2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apne2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apne2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

module "kms-cmk-not-scheduled-for-deletion-remediation-apse1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-apse2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.apse2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-apse2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-apse2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ec1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ec1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ec1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ec1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew2" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew2
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew2[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew2[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-ew3" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.ew3
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-ew3[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-ew3[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-en1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.en1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-en1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-en1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}


module "kms-cmk-not-scheduled-for-deletion-remediation-se1" {
  count  = var.enable-kms-cmk-not-scheduled-for-deletion-remediation ? 1 : 0
  source = "git::ssh://git@git.drillinginfo.com/TF-Modules/tf_module_aws_config//remediations/kms_cmk_not_scheduled_for_deletion_config_remediation?ref=V2.0.3"
  providers = {
    aws = aws.se1
  }
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  target_id                                             = module.kms-cmk-not-scheduled-for-deletion-remediation-document-se1[count.index].document_name
  aws_iam_role                                          = aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role[count.index].arn
  exception_list_parameter                              = module.kms-cmk-not-scheduled-for-deletion-exclusion-list-se1[count.index].parameter_name
  sns_topic                                             = var.aws_config_sns
}

================
File: pr/config/remediation/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "aws_config_sns" {
  description = "AWS SNS topic used for AWS Config"
  type        = string
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}

================
File: pr/config/remediation/versions.tf
================
terraform {
  required_providers {
    aws = {
      source                = "hashicorp/aws"
      version               = ">=2.7.0"
      configuration_aliases = [aws.ue1, aws.ue2, aws.uw1, aws.uw2, aws.cc1, aws.aps1, aws.apne1, aws.apne2, aws.apse1, aws.apse2, aws.ec1, aws.ew1, aws.ew2, aws.ew3, aws.se1, aws.en1]
    }
  }
}

================
File: pr/config/.terraform-version
================
latest:^1.8

================
File: pr/config/data.tf
================
data "aws_caller_identity" "current" {}

data "aws_default_tags" "current" {}

================
File: pr/config/dev.backend.tfvars
================
key = "040927785588/dev/aws_config/terraform.tfstate"

================
File: pr/config/dev.tfvars
================
environment             = "dev"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: pr/config/main.tf
================
##AWS Config
module "configBackend" {
  source      = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git//aws_config_requirements?ref=v2.2.0"
  bu          = var.business_unit
  environment = var.environment
}

module "configRules" {
  source                                    = "git@github.com:enverus-cts/sre.tf-modules.aws-config.git?ref=v2.2.0"
  business_unit                             = var.business_unit
  environment                               = var.environment
  aws_config_sns                            = module.configBackend.aws_config_sns
  configIamRole                             = module.configBackend.aws_config_iamRole
  enable-required-tags                      = var.enable-required-tags
  enable-kms-cmk-not-scheduled-for-deletion = var.enable-kms-cmk-not-scheduled-for-deletion
  enable-access-keys-rotated                = var.enable-access-keys-rotated
  enable-ec2-ebs-encryption-by-default      = var.enable-ec2-ebs-encryption-by-default
  enable-ssm-document-not-public            = var.enable-ssm-document-not-public
  resource_type_exclusion_list              = var.resource_type_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

module "configRemediations" {
  source                                                = "./remediation"
  business_unit                                         = var.business_unit
  environment                                           = var.environment
  assume_role_arn                                       = var.assume_role_arn
  aws_config_sns                                        = module.configBackend.aws_config_sns
  enable-kms-cmk-not-scheduled-for-deletion-remediation = var.enable-kms-cmk-not-scheduled-for-deletion-remediation
  enable-ec2-ebs-encryption-by-default-remediation      = var.enable-ec2-ebs-encryption-by-default-remediation
  kms_exclusion_list                                    = var.kms_exclusion_list
  providers = {
    aws.ue1   = aws
    aws.ue2   = aws.ue2
    aws.uw1   = aws.uw1
    aws.uw2   = aws.uw2
    aws.cc1   = aws.cc1
    aws.aps1  = aws.aps1
    aws.apne1 = aws.apne1
    aws.apne2 = aws.apne2
    aws.apse1 = aws.apse1
    aws.apse2 = aws.apse2
    aws.ec1   = aws.ec1
    aws.ew1   = aws.ew1
    aws.ew2   = aws.ew2
    aws.ew3   = aws.ew3
    aws.se1   = aws.se1
    aws.en1   = aws.en1
  }
  depends_on = [
    module.configBackend
  ]
}

================
File: pr/config/prod.backend.tfvars
================
key = "330682006453/prod/aws_config/terraform.tfstate"

================
File: pr/config/prod.tfvars
================
environment             = "prod"
business_unit           = "sre"
backup_retention_period = "5"
resource_type_exclusion_list = [
  "AWS::EC2::Volume",
  "AWS::EC2::NetworkInterface",
  "AWS::Config::ResourceCompliance"
]
###############################################################
###  Rules
###############################################################
enable-required-tags                                    = true
enable-ec2-stopped-instance                             = true
ec2-stopped-instance-days                               = 7
enable-access-keys-rotated                              = false
enable-alb-http-drop-invalid-header-enabled             = false
enable-alb-http-to-https-redirection-check              = false
enable-alb-waf-enabled                                  = false
enable-autoscaling-group-elb-healthcheck-required       = false
enable-autoscaling-launch-config-public-ip-disabled     = false
enable-cloud-trail-cloud-watch-logs-enabled             = false
enable-cloud-trail-encryption-enabled                   = false
enable-cloud-trail-log-file-validation-enabled          = false
enable-cloudtrail-enabled                               = false
enable-cloudwatch-alarm-action-check                    = false
enable-cloudwatch-alarm-resource-check                  = false
enable-cloudwatch-alarm-settings-check                  = false
enable-cloudwatch-log-group-encrypted                   = false
enable-cmk-backing-key-rotation-enabled                 = false
enable-cw-loggroup-retention-period-check               = false
enable-db-instance-backup-enabled                       = false
enable-dynamodb-autoscaling-enabled                     = false
enable-dynamodb-in-backup-plan                          = false
enable-dynamodb-pitr-enabled                            = false
enable-dynamodb-resources-protected-by-backup-plan      = false
enable-dynamodb-table-encrypted-kms                     = false
enable-dynamodb-table-encryption-enabled                = false
enable-dynamodb-throughput-limit-check                  = false
enable-ebs-in-backup-plan                               = false
enable-ebs-optimized-instance                           = false
enable-ebs-resources-protected-by-backup-plan           = false
enable-ebs-snapshot-public-restorable-check             = false
enable-ec2-ebs-encryption-by-default                    = true
enable-ec2-imdsv2-check                                 = false
enable-ec2-instance-detailed-monitoring-enabled         = false
enable-ec2-instance-multiple-eni-check                  = false
enable-ec2-instance-no-public-ip                        = false
enable-ec2-instance-profile-attached                    = false
enable-ec2-instances-in-vpc                             = false
enable-ec2-resources-protected-by-backup-plan           = false
enable-ec2-security-group-attached-to-eni               = false
enable-ec2-volume-inuse-check                           = false
enable-eip-attached                                     = false
enable-elasticache-redis-cluster-automatic-backup-check = false
enable-elasticsearch-encrypted-at-rest                  = false
enable-elasticsearch-in-vpc-only                        = false
enable-elasticsearch-logs-to-cloudwatch                 = false
enable-elasticsearch-node-to-node-encryption-check      = false
enable-elb-acm-certificate-required                     = false
enable-elb-cross-zone-load-balancing-enabled            = false
enable-elb-custom-security-policy-ssl-check             = false
enable-elb-deletion-protection-enabled                  = false
enable-elb-logging-enabled                              = false
enable-elb-predefined-security-policy-ssl-check         = false
enable-elb-tls-https-listeners-only                     = false
enable-elbv2-acm-certificate-required                   = false
enable-encrypted-volumes                                = false
enable-guardduty-enabled-centralized                    = false
enable-guardduty-non-archived-findings                  = false
guardduty-non-archived-findings-highsev                 = 1
guardduty-non-archived-findings-lowsev                  = 14
guardduty-non-archived-findings-medsev                  = 3
enable-iam-customer-policy-blocked-kms-actions          = false
enable-iam-group-has-users-check                        = false
enable-iam-inline-policy-blocked-kms-actions            = false
enable-iam-no-inline-policy-check                       = false
enable-iam-password-policy                              = false
#enable-iam-policy-in-use                                = false
enable-iam-policy-no-statements-with-admin-access  = false
enable-iam-policy-no-statements-with-full-access   = false
enable-iam-root-access-key-check                   = false
enable-iam-user-group-membership-check             = false
enable-iam-user-mfa-enabled                        = false
enable-iam-user-no-policies-check                  = false
enable-iam-user-unused-credentials-check           = false
max_credentials_usage_age                          = 90
enable-kms-cmk-not-scheduled-for-deletion          = true
enable-lambda-concurrency-check                    = false
enable-lambda-dlq-check                            = false
enable-lambda-function-public-access-prohibited    = false
enable-lambda-function-settings-check              = false
enable-lambda-inside-vpc                           = false
enable-mfa-enabled-for-iam-console-access          = false
enable-multi-region-cloudtrail-enabled             = false
enable-no-unrestricted-route-to-igw                = false
enable-rds-automatic-minor-version-upgrade-enabled = false
enable-rds-cluster-deletion-protection-enabled     = false
enable-rds-cluster-iam-authentication-enabled      = false
enable-rds-cluster-multi-az-enabled                = false
enable-rds-enhanced-monitoring-enabled             = false
enable-rds-in-backup-plan                          = false
enable-rds-instance-deletion-protection-enabled    = false
enable-rds-instance-iam-authentication-enabled     = false
enable-rds-instance-public-access-check            = false
enable-rds-logging-enabled                         = false
enable-rds-multi-az-support                        = false
enable-rds-resources-protected-by-backup-plan      = false
enable-rds-snapshot-encrypted                      = false
enable-rds-snapshots-public-prohibited             = false
enable-rds-storage-encrypted                       = false
#enable-restricted-common-ports                        = false
enable-restricted-ssh                                 = false
enable-root-account-mfa-enabled                       = false
enable-s3-account-level-public-access-blocks          = false
enable-s3-account-level-public-access-blocks-periodic = false
enable-s3-bucket-default-lock-enabled                 = false
enable-s3-bucket-level-public-access-prohibited       = false
enable-s3-bucket-logging-enabled                      = false
enable-s3-bucket-public-read-prohibited               = false
enable-s3-bucket-public-write-prohibited              = false
enable-s3-bucket-server-side-encryption-enabled       = false
enable-s3-bucket-ssl-requests-only                    = false
enable-s3-bucket-versioning-enabled                   = false
enable-s3-default-encryption-kms                      = false
enable-securityhub-enabled                            = false
enable-sns-encrypted-kms                              = false
enable-ssm-document-not-public                        = true
enable-subnet-auto-assign-public-ip-disabled          = false
enable-vpc-default-security-group-closed              = false
enable-vpc-flow-logs-enabled                          = false
enable-vpc-network-acl-unused-check                   = false

###############################################################
###  Remediations
###############################################################
enable-ec2-ebs-encryption-by-default-remediation      = true
enable-kms-cmk-not-scheduled-for-deletion-remediation = false

# KMS key ID seperate by comma, no spaces
kms_exclusion_list = ""

================
File: pr/config/variables.tf
================
variable "environment" {
  description = "Environment for cluster, eg. dev, preprod, prod"
  type        = string
}

variable "business_unit" {
  description = "Business Unit"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "prefix_list_vpc" {
  description = "The vpc name where the prefix list exist. Some accounts like EA Preprod don't have its own VPC"
  type        = string
  default     = null
}

variable "resource_type_exclusion_list" {
  description = "list of resource types to exlude from recording https://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType"
  type        = list(string)
  default     = []
}

variable "enable-access-keys-rotated" {
  description = "Checks if the active access keys are rotated within the number of days specified in maxAccessKeyAge. The rule is NON_COMPLIANT if the access keys have not been rotated for more than maxAccessKeyAge number of days."
  type        = bool
  default     = false
}

variable "enable-alb-http-drop-invalid-header-enabled" {
  description = "Checks if rule evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. The rule is NON_COMPLIANT if the value of routing.http.drop_invalid_header_fields.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-alb-http-to-https-redirection-check" {
  description = "Checks if HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancers. The rule is NON_COMPLIANT if one or more HTTP listeners of Application Load Balancer do not have HTTP to HTTPS redirection configured. The rule is also NON_COMPLIANT if one of more HTTP listeners have forwarding to an HTTP listener instead of redirection."
  type        = bool
  default     = false
}

variable "enable-alb-waf-enabled" {
  description = "Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs). This rule is NON_COMPLIANT if key: waf.enabled is set to false."
  type        = bool
  default     = false
}

variable "enable-autoscaling-group-elb-healthcheck-required" {
  description = "Checks whether your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks."
  type        = bool
  default     = false
}

variable "enable-autoscaling-launch-config-public-ip-disabled" {
  description = "Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is NON_COMPLIANT if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-action-check" {
  description = "Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action, or one OK action enabled."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-resource-check" {
  description = "Checks whether the specified resource type has a CloudWatch alarm for the specified metric. For resource type, you can specify EBS volumes, EC2 instances, RDS clusters, or S3 buckets."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-alarm-settings-check" {
  description = "Checks whether CloudWatch alarms with the given metric name have the specified settings."
  type        = bool
  default     = false
}

variable "enable-cloudwatch-log-group-encrypted" {
  description = "Checks if a log group in Amazon CloudWatch Logs is encrypted with a AWS Key Management Service (KMS) managed Customer Master Keys (CMK). The rule is NON_COMPLIANT if no AWS KMS CMK is configured on the log groups."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-cloud-watch-logs-enabled" {
  description = "Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch logs. The trail is non-compliant if the CloudWatchLogsLogGroupArn property of the trail is empty."
  type        = bool
  default     = false
}

variable "enable-cloudtrail-enabled" {
  description = "Checks if AWS CloudTrail is enabled in your AWS account. Optionally, you can specify which S3 bucket, SNS topic, and AWS CloudTrail ARN to use."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-encryption-enabled" {
  description = "Checks if AWS CloudTrail is configured to use the server side encryption (SSE) AWS Key Management Service KMS key encryption. The rule is COMPLIANT if the KmsKeyId is defined."
  type        = bool
  default     = false
}

variable "enable-cloud-trail-log-file-validation-enabled" {
  description = "Checks whether AWS CloudTrail creates a signed digest file with logs. AWS recommends that the file validation must be enabled on all trails. The rule is noncompliant if the validation is not enabled."
  type        = bool
  default     = false
}

variable "enable-cmk-backing-key-rotation-enabled" {
  description = "Checks if key rotation is enabled for each key and matches to the key ID of the customer created AWS KMS key (KMS key). The rule is COMPLIANT, if the key rotation is enabled for specific key object. The rule is not applicable to KMS keys that have imported key material."
  type        = bool
  default     = false
}

variable "enable-cw-loggroup-retention-period-check" {
  description = "Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days. The rule is NON_COMPLIANT if the retention period is not set or is less than the configured retention period."
  type        = bool
  default     = false
}

variable "enable-db-instance-backup-enabled" {
  description = "Checks if RDS DB instances have backups enabled. Optionally, the rule checks the backup retention period and the backup window."
  type        = bool
  default     = false
}

variable "enable-dynamodb-autoscaling-enabled" {
  description = "Checks if Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes. Optionally you can set the read and write capacity units for the table or global secondary index."
  type        = bool
  default     = false
}

variable "enable-dynamodb-in-backup-plan" {
  description = "Checks whether Amazon DynamoDB table is present in AWS Backup Plans. The rule is NON_COMPLIANT if Amazon DynamoDB tables are not present in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-pitr-enabled" {
  description = "Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables. The rule is NON_COMPLIANT if point in time recovery is not enabled for Amazon DynamoDB tables."
  type        = bool
  default     = false
}

variable "enable-dynamodb-resources-protected-by-backup-plan" {
  description = "Checks if Amazon DynamoDB tables are protected by a backup plan. The rule is NON_COMPLIANT if the DynamoDB Table is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encrypted-kms" {
  description = "Checks if Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS). The rule is NON_COMPLIANT if Amazon DynamoDB table is not encrypted with AWS KMS. The rule is also NON_COMPLIANT if the encrypted AWS KMS key is not present in kmsKeyArns input parameter."
  type        = bool
  default     = false
}

variable "enable-dynamodb-table-encryption-enabled" {
  description = "Checks if the Amazon DynamoDB tables are encrypted and checks their status. The rule is COMPLIANT if the status is enabled or enabling."
  type        = bool
  default     = false
}

variable "enable-dynamodb-throughput-limit-check" {
  description = "Checks if provisioned DynamoDB throughput is approaching the maximum limit for your account. By default, the rule checks if provisioned throughput exceeds a threshold of 80 percent of your account limits."
  type        = bool
  default     = false
}

variable "enable-ebs-in-backup-plan" {
  description = "Check if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup. The rule is NON_COMPLIANT if Amazon EBS volumes are not included in backup plans."
  type        = bool
  default     = false
}

variable "enable-ebs-optimized-instance" {
  description = "Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized. The rule is NON_COMPLIANT if EBS optimization is not enabled for an EC2 instance that can be EBS-optimized."
  type        = bool
  default     = false
}

variable "enable-ebs-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EBS volume is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ebs-snapshot-public-restorable-check" {
  description = "Checks whether Amazon Elastic Block Store (Amazon EBS) snapshots are not publicly restorable. The rule is NON_COMPLIANT if one or more snapshots with RestorableByUserIds field are set to all, that is, Amazon EBS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default" {
  description = "Check that Amazon Elastic Block Store (EBS) encryption is enabled by default. The rule is NON_COMPLIANT if the encryption is not enabled."
  type        = bool
  default     = false
}

variable "enable-ec2-imdsv2-check" {
  description = "Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The rule is NON_COMPLIANT if the HttpTokens is set to optional."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-detailed-monitoring-enabled" {
  description = "Checks if detailed monitoring is enabled for EC2 instances. The rule is NON_COMPLIANT if detailed monitoring is not enabled."
  type        = bool
  default     = false
}


variable "enable-ec2-instance-multiple-eni-check" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces) or Elastic Fabric Adapters (EFAs). This rule is NON_COMPLIANT an Amazon EC2 instance use multiple network interfaces."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-no-public-ip" {
  description = "Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association. The rule is NON_COMPLIANT if the publicIp field is present in the Amazon EC2 instance configuration item. This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instance-profile-attached" {
  description = "Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is attached to the Amazon EC2 instance."
  type        = bool
  default     = false
}

variable "enable-ec2-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon EC2 instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-ec2-security-group-attached-to-eni" {
  description = "Checks that non-default security groups are attached to Amazon Elastic Compute Cloud (EC2) instances or an elastic network interfaces (ENIs). The rule returns NON_COMPLIANT if the security group is not associated with an EC2 instance or an ENI."
  type        = bool
  default     = false
}

variable "enable-ec2-stopped-instance" {
  description = "Checks if there are instances stopped for more than the allowed number of days. The instance is NON_COMPLIANT if the state of the ec2 instance has been stopped for longer than the allowed number of days."
  type        = bool
  default     = false
}

variable "ec2-stopped-instance-days" {
  description = "Number of days to trigger non-compliance with ec2_stopped_instance rule"
  type        = number
  default     = 30
}

variable "enable-ec2-volume-inuse-check" {
  description = "Checks if EBS volumes are attached to EC2 instances. Optionally checks if EBS volumes are marked for deletion when an instance is terminated."
  type        = bool
  default     = false
}

variable "enable-eip-attached" {
  description = "Checks if all Elastic IP addresses that are allocated to an AWS account are attached to EC2 instances or in-use elastic network interfaces (ENIs)."
  type        = bool
  default     = false
}

variable "enable-elasticache-redis-cluster-automatic-backup-check" {
  description = "Check if the Amazon ElastiCache Redis clusters have automatic backup turned on. The rule is NON_COMPLIANT if the SnapshotRetentionLimit for Redis cluster is less than the SnapshotRetentionPeriod parameter. For example: If the parameter is 15 then the rule is non-compliant if the snapshotRetentionPeriod is between 0-15."
  type        = bool
  default     = false
}

variable "elasticache-redis-cluster-automatic-backup-shapshotRetentionPeriod" {
  description = "Minimum snapshot retention period in days for Redis cluster. Default is 15 days."
  type        = string
  default     = "15"
}
variable "enable-elasticsearch-encrypted-at-rest" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains have encryption at rest configuration enabled. The rule is NON_COMPLIANT if the EncryptionAtRestOptions field is not enabled."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-in-vpc-only" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are in Amazon Virtual Private Cloud (Amazon VPC). The rule is NON_COMPLIANT if the OpenSearch Service domain endpoint is public."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-logs-to-cloudwatch" {
  description = "Checks if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is COMPLIANT if a log is enabled for an OpenSearch Service domain. This rule is NON_COMPLIANT if logging is not configured."
  type        = bool
  default     = false
}

variable "enable-elasticsearch-node-to-node-encryption-check" {
  description = "Check that Amazon OpenSearch Service nodes are encrypted end to end. The rule is NON_COMPLIANT if the node-to-node encryption is disabled on the domain."
  type        = bool
  default     = false
}

variable "enable-elbv2-acm-certificate-required" {
  description = "Checks if Application Load Balancers and Network Load Balancers are configured to use certificates from AWS Certificate Manager (ACM). This rule is NON_COMPLIANT if at least 1 load balancer is configured without a certificate from ACM."
  type        = bool
  default     = false
}

variable "enable-elb-acm-certificate-required" {
  description = "Checks if the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager. To use this rule, use an SSL or HTTPS listener with your Classic Load Balancer. This rule is only applicable to Classic Load Balancers. This rule does not check Application Load Balancers and Network Load Balancers."
  type        = bool
  default     = false
}

variable "enable-elb-cross-zone-load-balancing-enabled" {
  description = "Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs). This rule is NON_COMPLIANT if cross-zone load balancing is not enabled for a CLB."
  type        = bool
  default     = false
}

variable "enable-elb-custom-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a custom policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "sslProtocolsAndCiphers" {
  description = "Comma-separated list of ciphers and protocols."
  type        = string
  default     = "tls1.2"
}
variable "enable-elb-deletion-protection-enabled" {
  description = "Checks if Elastic Load Balancing has deletion protection enabled. The rule is NON_COMPLIANT if deletion_protection.enabled is false."
  type        = bool
  default     = false
}

variable "enable-elb-logging-enabled" {
  description = "Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The rule is NON_COMPLIANT if the access_logs.s3.enabled is false or access_logs.S3.bucket is not equal to the s3BucketName that you provided."
  type        = bool
  default     = false
}

variable "enable-elb-predefined-security-policy-ssl-check" {
  description = "Checks whether your Classic Load Balancer SSL listeners are using a predefined policy. The rule is only applicable if there are SSL listeners for the Classic Load Balancer."
  type        = bool
  default     = false
}

variable "elb-predefined-security-policy-ssl-check-predefinedPolicyName" {
  description = "Name of the predefined policy."
  type        = string
  default     = "ELBSecurityPolicy-2016-08"
}
variable "enable-elb-tls-https-listeners-only" {
  description = "Checks if your Classic Load Balancer is configured with SSL or HTTPS listeners. \n    If the Classic Load Balancer does not have a listener configured, then the rule returns NOT_APPLICABLE. \n    The rule is COMPLIANT if the Classic Load Balancer listeners are configured with SSL or HTTPS. \n    The rule is NON_COMPLIANT if a listener is not configured with SSL or HTTPS."
  type        = bool
  default     = false
}

variable "enable-encrypted-volumes" {
  description = "Checks if the EBS volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryption using the kmsId parameter, the rule checks if the EBS volumes in an attached state are encrypted with that KMS key."
  type        = bool
  default     = false
}

variable "enable-guardduty-enabled-centralized" {
  description = "Checks if Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization, the rule evaluates the Amazon GuardDuty results in the centralized account. The rule is COMPLIANT when Amazon GuardDuty is enabled."
  type        = bool
  default     = false
}

variable "enable-guardduty-non-archived-findings" {
  description = "Checks whether Amazon GuardDuty has findings that are non archived. The rule is NON_COMPLIANT if Amazon GuardDuty has non archived low/medium/high severity findings older than the specified number in the daysLowSev/daysMediumSev/daysHighSev parameter."
  type        = bool
  default     = false
}

variable "guardduty-non-archived-findings-lowsev" {
  description = "The number of days Amazon GuardDuty low severity findings are allowed to stay non archived. The default is 30 days."
  type        = number
  default     = 30
}

variable "guardduty-non-archived-findings-medsev" {
  description = "The number of days Amazon GuardDuty medium severity findings are allowed to stay non archived. The default is 7 days."
  type        = number
  default     = 7
}

variable "guardduty-non-archived-findings-highsev" {
  description = "The number of days Amazon GuardDuty high severity findings are allowed to stay non archived. The default is 1 day."
  type        = number
  default     = 1
}

variable "enable-iam-customer-policy-blocked-kms-actions" {
  description = "Checks that the managed AWS Identity and Access Management (IAM) policies that you create do not allow blocked actions on all AWS KMS keys. The rule is NON_COMPLIANT if any blocked action is allowed on all AWS KMS keys by the managed IAM policy."
  type        = bool
  default     = false
}

variable "iam-customer-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-group-has-users-check" {
  description = "Checks whether IAM groups have at least one IAM user."
  type        = bool
  default     = false
}

variable "enable-iam-inline-policy-blocked-kms-actions" {
  description = "Checks that the inline policies attached to your IAM users, roles, and groups do not allow blocked actions on all AWS Key Management Service (KMS) keys. The rule is NON_COMPLIANT if any blocked action is allowed on all KMS keys in an inline policy."
  type        = bool
  default     = false
}

variable "iam-inline-policy-blocked-kms-actions-blockedActionsPatterns" {
  description = "Comma-separated list of blocked KMS action patterns, for example, kms:*, kms:Decrypt, kms:ReEncrypt*."
  type        = string
  default     = ""
}

variable "enable-iam-no-inline-policy-check" {
  description = "Checks that inline policy feature is not in use. The rule is NON_COMPLIANT if an AWS Identity and Access Management (IAM) user, IAM role or IAM group has any inline policy."
  type        = bool
  default     = false
}

#No parameters are set for this policy.  The defaults are fine.
variable "enable-iam-password-policy" {
  description = "Checks if the account password policy for IAM users meets the specified requirements indicated in the parameters. This rule is NON_COMPLIANT if the account password policy does not meet the specified requirements."
  type        = bool
  default     = false
}

# variable "enable-iam-policy-in-use" {
#   description = "Checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity."
#   type        = bool
#   default     = false
# }

variable "enable-iam-policy-no-statements-with-admin-access" {
  description = "Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources. The rule is NON_COMPLIANT if any policy statement includes \"Effect\": \"Allow\" with \"Action\": \"*\" over \"Resource\": \"*\"."
  type        = bool
  default     = false
}

variable "enable-iam-policy-no-statements-with-full-access" {
  description = "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is NON_COMPLIANT if the managed IAM policy allows full access to at least 1 AWS service."
  type        = bool
  default     = false
}

variable "enable-iam-root-access-key-check" {
  description = "Checks whether the root user access key is available. The rule is compliant if the user access key does not exist."
  type        = bool
  default     = false
}

variable "enable-iam-user-group-membership-check" {
  description = "Checks whether IAM users are members of at least one IAM group."
  type        = bool
  default     = false
}

variable "enable-iam-user-mfa-enabled" {
  description = "Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled."
  type        = bool
  default     = false
}

variable "enable-iam-user-no-policies-check" {
  description = "Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles. The rule is NONCOMPLIANT if there is at least one IAM user with policies attached."
  type        = bool
  default     = false
}

variable "enable-iam-user-unused-credentials-check" {
  description = "Checks if your AWS Identity and Access Management (IAM) users have passwords or active access keys that have not been used within the specified number of days you provided."
  type        = bool
  default     = false
}

variable "max_credentials_usage_age" {
  description = "Maximum number of days a credential cannot be used. The default value is 90 days."
  type        = number
  default     = 90
}

variable "enable-restricted-ssh" {
  description = "Checks if the incoming SSH traffic for the security groups is accessible. The rule is COMPLIANT when IP addresses of the incoming SSH traffic in the security groups are restricted (CIDR other than 0.0.0.0/0). This rule applies only to IPv4."
  type        = bool
  default     = false
}

variable "enable-ec2-instances-in-vpc" {
  description = "Checks if your EC2 instances belong to a virtual private cloud (VPC). Optionally, you can specify the VPC ID to associate with your instances."
  type        = bool
  default     = false
}

variable "instances-in-vpc-vpcid" {
  description = "VPC ID that contains these EC2 instances."
  type        = string
  default     = ""
}

variable "enable-kms-cmk-not-scheduled-for-deletion" {
  description = "Checks if AWS KMS keys (KMS keys) are not scheduled for deletion in AWS Key Management Service (AWS KMS). The rule is NON_COMPLAINT if KMS keys are scheduled for deletion."
  type        = bool
  default     = false
}

variable "enable-lambda-concurrency-check" {
  description = "Checks whether the AWS Lambda function is configured with function-level concurrent execution limit. The rule is NON_COMPLIANT if the Lambda function is not configured with function-level concurrent execution limit."
  type        = bool
  default     = false
}

variable "enable-lambda-dlq-check" {
  description = "Checks whether an AWS Lambda function is configured with a dead-letter queue. The rule is NON_COMPLIANT if the Lambda function is not configured with a dead-letter queue."
  type        = bool
  default     = false
}

variable "enable-lambda-function-public-access-prohibited" {
  description = "Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access it is NON_COMPLIANT."
  type        = bool
  default     = false
}

variable "enable-lambda-function-settings-check" {
  description = "Checks that the AWS Lambda function settings for runtime, role, timeout, and memory size match the expected values. The rule ignores functions with the 'Image' package type."
  type        = bool
  default     = false
}
variable "lambda-function-settings-check-runtime" {
  description = "Comma-separated list of AWS Lambda runtime values"
  type        = string
  default     = ""
}

variable "lambda-function-settings-check-timeout" {
  description = "AWS Lambda function timeout in seconds"
  type        = string
  default     = "3"
}

variable "lambda-function-settings-check-memorySize" {
  description = "AWS Lambda function size in megabytes"
  type        = string
  default     = "128"
}

variable "enable-lambda-inside-vpc" {
  description = "Checks whether an AWS Lambda function is allowed access to an Amazon Virtual Private Cloud. The rule is NON_COMPLIANT if the Lambda function is not VPC enabled."
  type        = bool
  default     = false
}

variable "enable-mfa-enabled-for-iam-console-access" {
  description = "Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password. The rule is compliant if MFA is enabled."
  type        = bool
  default     = false
}

variable "enable-multi-region-cloudtrail-enabled" {
  description = "Checks that there is at least one multi-region AWS CloudTrail. The rule is non-compliant if the trails do not match input parameters"
  type        = bool
  default     = false
}

variable "multi-region-cloudtrail-enabled-s3BucketName" {
  description = "Name of Amazon S3 bucket for AWS CloudTrail to deliver log files to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-snsTopicArn" {
  description = "Amazon SNS topic ARN for AWS CloudTrail to use for notifications."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-cloudWatchLogsLogGroupArn" {
  description = "Amazon CloudWatch log group ARN for AWS CloudTrail to send data to."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-includeManagementEvents" {
  description = "Event selector to include management events for the AWS CloudTrail."
  type        = string
  default     = ""
}

variable "multi-region-cloudtrail-enabled-readWriteType" {
  description = "Type of events to record. Valid values are ReadOnly, WriteOnly and ALL."
  type        = string
  default     = ""
  validation {
    condition     = contains(["", "ReadOnly", "WriteOnly", "ALL"], var.multi-region-cloudtrail-enabled-readWriteType)
    error_message = "Valid values for var: readWriteType are (NULL, ReadOnly, WriteOnly, ALL)."
  }
}
variable "enable-no-unrestricted-route-to-igw" {
  description = "Checks if there are public routes in the route table to an Internet Gateway (IGW). The rule is NON_COMPLIANT if a route to an IGW has a destination CIDR block of '0.0.0.0/0' or '::/0' or if a destination CIDR block does not match the rule parameter."
  type        = bool
  default     = false
}

variable "enable-rds-automatic-minor-version-upgrade-enabled" {
  description = "Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades. The rule is NON_COMPLIANT if the value of 'autoMinorVersionUpgrade' is false."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled. This rule is NON_COMPLIANT if an RDS cluster does not have deletion protection enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-iam-authentication-enabled" {
  description = "Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled. The rule is NON_COMPLIANT if an RDS Cluster does not have IAM authentication enabled."
  type        = bool
  default     = false
}

variable "enable-rds-cluster-multi-az-enabled" {
  description = "Checks if Multi-AZ replication is enabled on Amazon Aurora clusters managed by Amazon Relational Database Service (Amazon RDS). This rule is NON_COMPLIANT if an Amazon RDS instance is not configured with Multi-AZ."
  type        = bool
  default     = false
}

variable "enable-rds-enhanced-monitoring-enabled" {
  description = "Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances."
  type        = bool
  default     = false
}

variable "enable-rds-instance-deletion-protection-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have deletion protection enabled i.e deletionProtection is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-iam-authentication-enabled" {
  description = "Checks if an Amazon Relational Database Service (Amazon RDS) instance has AWS Identity and Access Management (IAM) authentication enabled. This rule is NON_COMPLIANT if an Amazon RDS instance does not have AWS IAM authentication enabled i.e configuration.iAMDatabaseAuthenticationEnabled is set to false."
  type        = bool
  default     = false
}

variable "enable-rds-instance-public-access-check" {
  description = "Check whether the Amazon Relational Database Service instances are not publicly accessible. The rule is NON_COMPLIANT if the publiclyAccessible field is true in the instance configuration item."
  type        = bool
  default     = false
}

variable "enable-rds-in-backup-plan" {
  description = "Checks whether Amazon RDS database is present in back plans of AWS Backup. The rule is NON_COMPLIANT if Amazon RDS databases are not included in any AWS Backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-logging-enabled" {
  description = "Checks if log types exported to Amazon CloudWatch for an Amazon Relational Database Service (Amazon RDS) instance are enabled. The rule is NON_COMPLIANT if any such log types are not enabled."
  type        = bool
  default     = false
}

variable "enable-rds-multi-az-support" {
  description = "Checks whether high availability is enabled for your RDS DB instances. \n In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. For more information, see High Availability (Multi-AZ) in the Amazon RDS User Guide."
  type        = bool
  default     = false
}

variable "enable-rds-resources-protected-by-backup-plan" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan. The rule is NON_COMPLIANT if the Amazon RDS Database instance is not covered by a backup plan."
  type        = bool
  default     = false
}

variable "enable-rds-snapshots-public-prohibited" {
  description = "Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public. The rule is NON_COMPLIANT if any existing and new Amazon RDS snapshots are public."
  type        = bool
  default     = false
}

variable "enable-rds-snapshot-encrypted" {
  description = "Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted. The rule is NON_COMPLIANT, if the Amazon RDS DB snapshots are not encrypted."
  type        = bool
  default     = false
}

variable "enable-rds-storage-encrypted" {
  description = "Checks whether storage encryption is enabled for your RDS DB instances."
  type        = bool
  default     = false
}

variable "enable-required-tags" {
  description = "Checks if your resources have the tags that you specify. For example, you can check whether your Amazon EC2 instances have the CostCenter tag. Separate multiple values with commas. You can check up to 6 tags at a time."
  type        = bool
  default     = true
}

# variable "enable-restricted-common-ports" {
#   description = "Checks if the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports. The rule is COMPLIANT when the IP addresses for inbound TCP connections are restricted to the specified ports. This rule applies only to IPv4."
#   type        = bool
#   default     = false
# }

variable "enable-root-account-mfa-enabled" {
  description = "Checks whether the root user of your AWS account requires multi-factor authentication for console sign-in."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks" {
  description = "Checks if the required public access block settings are configured from account level. The rule is only NON_COMPLIANT when the fields set below do not match the corresponding fields in the configuration item."
  type        = bool
  default     = false
}

variable "enable-s3-account-level-public-access-blocks-periodic" {
  description = "Checks if the required public access block settings are configured from account level."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-default-lock-enabled" {
  description = "Checks whether Amazon S3 bucket has lock enabled, by default. The rule is NON_COMPLIANT if the lock is not enabled."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-level-public-access-prohibited" {
  description = "Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is NON_COMPLIANT if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-logging-enabled" {
  description = "Checks whether logging is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-read-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public read access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public read access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public read access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public read access. If the policy allows public read access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public read access. If the bucket ACL allows public read access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-public-write-prohibited" {
  description = <<EOS
"Checks if your Amazon S3 buckets do not allow public write access. The rule checks the Block Public Access settings, the bucket policy, and the bucket access control list (ACL).
The rule is compliant when both of the following are true:
The Block Public Access setting restricts public policies or the bucket policy does not allow public write access.
The Block Public Access setting restricts public ACLs or the bucket ACL does not allow public write access.
The rule is noncompliant when:
If the Block Public Access setting does not restrict public policies, AWS Config evaluates whether the policy allows public write access. If the policy allows public write access, the rule is noncompliant.
If the Block Public Access setting does not restrict public bucket ACLs, AWS Config evaluates whether the bucket ACL allows public write access. If the bucket ACL allows public write access, the rule is noncompliant."
EOS
  type        = bool
  default     = false
}

variable "enable-s3-bucket-server-side-encryption-enabled" {
  description = "Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption that uses AES-256 or AWS Key Management Service."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-ssl-requests-only" {
  description = "Checks if Amazon S3 buckets have policies that require requests to use Secure Socket Layer (SSL). The rule is COMPLIANT if buckets explicitly deny access to HTTP requests. The rule is NON_COMPLIANT if bucket policies allow HTTP requests."
  type        = bool
  default     = false
}

variable "enable-s3-bucket-versioning-enabled" {
  description = "Checks if versioning is enabled for your S3 buckets. Optionally, the rule checks if MFA delete is enabled for your S3 buckets."
  type        = bool
  default     = false
}

variable "enable-s3-default-encryption-kms" {
  description = "Checks whether the Amazon S3 buckets are encrypted with AWS Key Management Service(AWS KMS). The rule is NON_COMPLIANT if the Amazon S3 bucket is not encrypted with AWS KMS key."
  type        = bool
  default     = false
}

variable "enable-securityhub-enabled" {
  description = "Checks that AWS Security Hub is enabled for an AWS Account. The rule is NON_COMPLIANT if AWS Security Hub is not enabled."
  type        = bool
  default     = false
}

variable "enable-sns-encrypted-kms" {
  description = "Checks if Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS). The rule is NON_COMPLIANT if the Amazon SNS topic is not encrypted with AWS KMS. The rule is also NON_COMPLIANT when encrypted KMS key is not present in kmsKeyIds input parameter."
  type        = bool
  default     = false
}

variable "enable-ssm-document-not-public" {
  description = "Checks if AWS Systems Manager documents owned by the account are public. This rule is NON_COMPLIANT if SSM documents with owner 'Self' are public."
  type        = bool
  default     = false
}

variable "enable-subnet-auto-assign-public-ip-disabled" {
  description = "Checks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The rule is COMPLIANT if Amazon VPC does not have subnets that are assigned a public IP address. The rule is NON_COMPLIANT if Amazon VPC has subnets that are assigned a public IP address."
  type        = bool
  default     = false
}

variable "enable-vpc-default-security-group-closed" {
  description = "Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group is not default. The rule is NON_COMPLIANT if the default security group has one or more inbound or outbound traffic rules."
  type        = bool
  default     = false
}

variable "enable-vpc-flow-logs-enabled" {
  description = "Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC."
  type        = bool
  default     = false
}

variable "enable-vpc-network-acl-unused-check" {
  description = "Checks if there are unused network access control lists (network ACLs). The rule is COMPLIANT if each network ACL is associated with a subnet. The rule is NON_COMPLIANT if a network ACL is not associated with a subnet."
  type        = bool
  default     = false
}

variable "enable-ec2-ebs-encryption-by-default-remediation" {
  description = "Enables remediation for enable-ec2-ebs-encryption-by-default rule. The remediation enables EBS encryption on by default."
  type        = bool
  default     = false
}
variable "kms_exclusion_list" {
  description = "KMS key exclusion list. List of KMS key IDs not to be remediated by kms-cmk-not-scheduled-for-deletion config rule. Key Ids seperate by comma."
  type        = string
  default     = " "
}

variable "enable-kms-cmk-not-scheduled-for-deletion-remediation" {
  description = "Enables remediation for kms-cmk-not-scheduled-for-deletion rule. The remediation cancels primary KMS key deletion unless it is in the exception list."
  type        = bool
  default     = false
}

================
File: pr/config/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}
provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ue2"
  region = "us-east-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw1"
  region = "us-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "uw2"
  region = "us-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "cc1"
  region = "ca-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "aps1"
  region = "ap-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne1"
  region = "ap-northeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne2"
  region = "ap-northeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apne3"
  region = "ap-northeast-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse1"
  region = "ap-southeast-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "apse2"
  region = "ap-southeast-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ec1"
  region = "eu-central-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew1"
  region = "eu-west-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew2"
  region = "eu-west-2"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "ew3"
  region = "eu-west-3"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "es1"
  region = "eu-south-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "en1"
  region = "eu-north-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

provider "aws" {
  alias  = "se1"
  region = "sa-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = "cts"
      Component        = "config"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: pr/consul/.terraform-version
================
latest:^1.7

================
File: pr/consul/aws_ec2_managed_prefix_list.tf
================
data "aws_ec2_managed_prefix_list" "vpn_prefix_list" {
  name = "VPN/Office CIDRs - shared"
}

================
File: pr/consul/data.tf
================
data "aws_vpc" "vpc" {
  filter {
    name   = "tag:Name"
    values = [var.vpc_name_tag]
  }
}

data "aws_security_group" "inside_sg" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*-inside-sg", "*-INSIDE-SG"]
  }
}

data "aws_subnets" "inside" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.vpc.id]
  }
  filter {
    name   = "tag:Name"
    values = ["*AZ*INSIDE*"]
  }
}


data "aws_default_tags" "aws_default_tags" {}

data "aws_route53_zone" "main" {
  name         = "${var.env}.${var.bu}.enverus.com"
  private_zone = false
}

================
File: pr/consul/dev.backend.tfvars
================
key = "040927785588/dev/consul/terraform.tfstate"

================
File: pr/consul/dev.tfvars
================
env            = "dev"
encryption_key = "x48r8HjXLeQi8dJYOLQFEHtWJiMlv3MB0OeV/Bod6IY="
vpc_name_tag   = "pr-vpc-dev"
datacenter     = "aws-ue1"
ec2-region     = "us-east-1"
abv-region     = "ue1"

# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=dev alloy_business_unit=pr\"",
      "-C main"
    ],
  }
]

================
File: pr/consul/load-balancer.tf
================
resource "aws_security_group" "consul_lb_sg" {
  name        = "${var.abv-region}-${var.bu}-${var.env}-consul-ui-sg"
  description = "Allow acces to consul UI load balancer"
  vpc_id      = data.aws_vpc.vpc.id

  ingress {
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.vpn_prefix_list.id]
    cidr_blocks = [
      "10.0.0.0/8",
    ]
    security_groups = [data.aws_security_group.inside_sg.id]
  }

  egress {
    from_port   = 8500
    to_port     = 8500
    protocol    = "tcp"
    cidr_blocks = [data.aws_vpc.vpc.cidr_block]
  }
}

resource "aws_lb" "consul_lb" {
  name            = "${var.abv-region}-${var.bu}-${var.env}-consul-lb"
  internal        = true
  security_groups = [aws_security_group.consul_lb_sg.id, data.aws_security_group.inside_sg.id]
  subnets         = data.aws_subnets.inside.ids

  tags = {
    Component = "consul"
    Name      = "${var.bu}-${var.env}-consul-lb"
  }
}

resource "aws_lb_target_group" "consul_tg" {
  name     = "${var.abv-region}-${var.bu}-${var.env}-consul-tg"
  port     = 8500
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.vpc.id

  health_check {
    path = "/v1/status/leader"
  }
}

resource "aws_lb_listener" "consul_listener" {
  load_balancer_arn = aws_lb.consul_lb.arn
  port              = 80

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.consul_tg.arn
  }
}

resource "aws_autoscaling_attachment" "asg_attachment_bar" {
  autoscaling_group_name = module.consul_servers_aws.asg_name
  lb_target_group_arn    = aws_lb_target_group.consul_tg.arn
}

resource "aws_route53_record" "consul_ui" {
  zone_id = data.aws_route53_zone.main.zone_id
  name    = "consul-${var.abv-region}.${var.env}.${var.bu}.enverus.com"
  type    = "A"

  alias {
    name                   = aws_lb.consul_lb.dns_name
    zone_id                = aws_lb.consul_lb.zone_id
    evaluate_target_health = true
  }
}

================
File: pr/consul/main.tf
================
# sre-12884: comment to trigger atlantis

module "consul_servers_aws" {
  source         = "git@github.com:enverus-cts/sre.tf-modules.consul-cluster-aws.git?ref=v0.18.0"
  vpc_name_tag   = var.vpc_name_tag
  env            = var.env
  bu             = var.bu
  tagLocation    = var.ec2-region
  tagTeam        = data.aws_default_tags.aws_default_tags.tags.Team
  tagSourceCode  = data.aws_default_tags.aws_default_tags.tags.SourceCode
  encryption_key = var.encryption_key
  datacenter     = var.datacenter
  recursors      = var.recursors
  instance_type  = var.instance_type
  #ansible pull
  vo_routing_key                           = var.vo_routing_key
  user_provided_ansible_pull_playbook_list = var.user_provided_ansible_pull_playbook_list
}

================
File: pr/consul/prod.backend.tfvars
================
key = "330682006453/prod/consul/terraform.tfstate"

================
File: pr/consul/prod.tfvars
================
env            = "prod"
encryption_key = "P/xelUfn1SGsPPGvNMFpldouBEhbuFH6QJyklRHl0RY="
vpc_name_tag   = "pr-vpc-prod"
datacenter     = "aws-ue1"
ec2-region     = "us-east-1"
abv-region     = "ue1"

# Ansible

user_provided_ansible_pull_playbook_list = [
  {
    playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
    playbook_file = "install-alloy.yml",
    git_host      = "cloud",
    additional_args = [
      "--extra-vars \"alloy_environment_name=prod alloy_business_unit=pr\"",
      "-C main"
    ],
  }
]

================
File: pr/consul/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "env" {
  description = "environment"
  type        = string
}

variable "encryption_key" {
  description = "consul cluster encryption key"
  type        = string
}

variable "vpc_name_tag" {
  description = "tag to filter vpc by name"
  type        = string
}

variable "ec2-region" {
  description = "aws ec2 region"
  type        = string
}

variable "abv-region" {
  description = "region abbreviation"
  type        = string
}

variable "bu" {
  description = "business unit abbreviation"
  type        = string
}

variable "datacenter" {
  description = "name of datacenter for consul cluster"
  type        = string
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
  default     = "c5a.large"
}

variable "recursors" {
  description = "consul config dns recursors"
  type        = string
  default     = "10.52.8.26 10.52.8.36"
}

variable "vo_routing_key" {
  description = "Provide a Victor Ops Routing Key"
  type        = string
}

variable "user_provided_ansible_pull_playbook_list" {
  description = "List of Ansible playbooks to run at startup"
  type = list(object({
    playbook_repo   = string
    playbook_file   = string
    git_host        = string
    additional_args = optional(list(string))
  }))
}

================
File: pr/consul/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4" # this is blocked by hashicorp module using an old version of the ASG resource.
    }
    consul = {
      source  = "hashicorp/consul"
      version = "~> 2.12.0"
      # v2.13 is only compatible with consul 1.10 or newer
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "consul"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform/tree/main/consul"
      TerraformCreated = "true"
      Environment      = var.env
      Product          = "nexus"
    }
  }
}

provider "consul" {
  address    = aws_route53_record.consul_ui.fqdn
  datacenter = var.datacenter
}

================
File: pr/grafana/datasources/.terraform-version
================
latest:^1.4

================
File: pr/grafana/datasources/dev.backend.tfvars
================
key = "040927785588/dev/us-east-1/grafana/datasources/terraform.tfstate"

================
File: pr/grafana/datasources/dev.tfvars
================
region = "us-east-1"

================
File: pr/grafana/datasources/main.tf
================
data "vault_generic_secret" "grafana_api" {
  path = "pr-secrets/terraform/grafana-provider"
}

resource "aws_iam_policy" "iam_policy" {
  name        = "grafana-cloudwatch-access-${var.env}-${var.region}"
  path        = "/"
  description = "IAM policy for enverus.grafana.net IAM user to access cloudwatch metrics"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        "Sid" : "AllowReadingMetricsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "cloudwatch:DescribeAlarmsForMetric",
          "cloudwatch:DescribeAlarmHistory",
          "cloudwatch:DescribeAlarms",
          "cloudwatch:ListMetrics",
          "cloudwatch:GetInsightRuleReport",
          "cloudwatch:GetMetricStatistics",
          "cloudwatch:GetMetricData"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingLogsFromCloudWatch",
        "Effect" : "Allow",
        "Action" : [
          "logs:DescribeLogGroups",
          "logs:GetLogGroupFields",
          "logs:StartQuery",
          "logs:StopQuery",
          "logs:GetQueryResults",
          "logs:GetLogEvents"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingTagsInstancesRegionsFromEC2",
        "Effect" : "Allow",
        "Action" : [
          "ec2:DescribeTags",
          "ec2:DescribeInstances",
          "ec2:DescribeRegions"
        ],
        "Resource" : "*"
      },
      {
        "Sid" : "AllowReadingResourcesForTags",
        "Effect" : "Allow",
        "Action" : "tag:GetResources",
        "Resource" : "*"
      },
    ]
  })
}

# Create IAM User
resource "aws_iam_user" "iam_user" {
  name = "grafana-cloudwatch-metrics-${var.env}-${var.region}"
  path = "/"
}

resource "aws_iam_access_key" "iam_access_key" {
  user = aws_iam_user.iam_user.name
}

# Attach IAM policy to IAM User
resource "aws_iam_user_policy_attachment" "iam_user_policy_attachment" {
  user       = aws_iam_user.iam_user.name
  policy_arn = aws_iam_policy.iam_policy.arn
}

# Stash IAM user in Vault
resource "vault_generic_secret" "generic_secret" {
  path      = "pr-secrets/terraform/aws/grafana/pr/${var.env}/${var.region}"
  data_json = <<EOF
{
  "access_key": "${aws_iam_access_key.iam_access_key.id}",
  "secret_key": "${aws_iam_access_key.iam_access_key.secret}"
}
EOF
}

# Create Grafana Datasource
module "datasource" {
  source          = "git@github.com:enverus-cts/sre.tf-modules.hosted-grafana.git//datasources"
  datasource_name = "Cloudwatch-${var.bu}-${var.env}-${var.region}"
  grafana_API_key = data.vault_generic_secret.grafana_api.data["api_key"]
  region          = var.region
  env             = var.env
  datasource_type = "cloudwatch"
  access_key      = aws_iam_access_key.iam_access_key.id
  secret_key      = aws_iam_access_key.iam_access_key.secret
}

================
File: pr/grafana/datasources/prod.backend.tfvars
================
key = "330682006453/prod/us-east-1/grafana/datasources/terraform.tfstate"

================
File: pr/grafana/datasources/prod.tfvars
================
region = "us-east-1"

================
File: pr/grafana/datasources/variables.tf
================
variable "region" {
  description = "Region"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Environment level (dev/preprod/prod)"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: pr/grafana/datasources/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
    vault = {
      source = "hashicorp/vault"
    }
  }
}

provider "aws" {
  region = var.region
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Environment      = var.env
      TerraformCreated = "true"
      SourceCode       = "https://github.com/SRE/terraform/pr-terraform/grafana/datasources"
      Team             = "sre@enverus.com"
      Component        = "grafana"
      Product          = "nexus"
    }
  }
}

provider "vault" {
}

================
File: pr/route-53/.terraform-version
================
latest:^1.1.6

================
File: pr/route-53/dev.backend.tfvars
================
key = "040927785588/dev/route-53/terraform.tfstate"

================
File: pr/route-53/prod.backend.tfvars
================
key = "330682006453/prod/route-53/terraform.tfstate"

================
File: pr/route-53/resolver.tf
================
data "aws_default_tags" "aws_default_tags" {}

module "route53_resolver" {
  source           = "git@github.com:enverus-cts/sre.tf-modules.route53-resolvers.git?ref=v1.1.0"
  vpc_name         = "pr-vpc-${var.env}"
  subnet_name_tags = ["*INSIDE*Subnet"]
  env              = var.env
  enverus_domain_rules = {
    "enverus" = {
      "domain" = "enverus.com"
      "name"   = "DI-DNS-EN"
    },
    "drillinginfo" = {
      "domain" = "drillinginfo.com"
      "name"   = "DI-DNS"
    },
    "azure-windows-databases" = {
      "domain" = "database.windows.net"
      "name"   = "Azure-Database-windows"
    },
    "oraclevcn" = {
      "domain" = "oraclevcn.com"
      "name"   = "Oraclevcn-Drillinginfo"
    },
  }
  tags = {
    tag_team          = data.aws_default_tags.aws_default_tags.tags.Team
    tag_source_code   = data.aws_default_tags.aws_default_tags.tags.SourceCode
    tag_environment   = data.aws_default_tags.aws_default_tags.tags.Environment
    tag_business_unit = data.aws_default_tags.aws_default_tags.tags.BusinessUnit
  }
}

================
File: pr/route-53/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

================
File: pr/route-53/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "route53"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform/tree/main/route53"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: pr/route-53/zones.tf
================
resource "aws_route53_zone" "pr_env" {
  name = "${var.env}.pr.enverus.com"
}

================
File: pr/s3-buckets/policies/chef-validator.json.tpl
================
{
    "Version": "2008-10-17",
    "Id": "ReadPolicy",
    "Statement": [
        {
            "Sid": "ReadAccess",
            "Effect": "Allow",
            "Principal": {
                "AWS": [
                    "arn:aws:iam::${aid}:role/service-role",
                    "arn:aws:iam::${aid}:root"
                ]
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::di-${bu}-${env}-${name}/*"
        }
    ]
}

================
File: pr/s3-buckets/.terraform-version
================
latest:^1.4

================
File: pr/s3-buckets/buckets.tf
================
data "template_file" "policy" {
  template = templatefile("policies/chef-validator.json.tpl", {
    env  = var.env
    bu   = var.bu
    name = var.name
    aid  = data.aws_caller_identity.current.account_id
  })
}

data "aws_caller_identity" "current" {}

resource "aws_s3_bucket" "chef-validator" {
  bucket = "di-${var.bu}-${var.env}-${var.name}"
  policy = data.template_file.policy.rendered

  tags = {
    Name = "di-${var.bu}-${var.env}-${var.name}"
  }
}

================
File: pr/s3-buckets/dev.backend.tfvars
================
key = "040927785588/dev/s3/terraform.tfstate"

================
File: pr/s3-buckets/dev.tfvars
================
name = "chef-validator"

================
File: pr/s3-buckets/prod.backend.tfvars
================
key = "330682006453/prod/s3/terraform.tfstate"

================
File: pr/s3-buckets/prod.tfvars
================
name = "chef-validator"

================
File: pr/s3-buckets/variables.tf
================
variable "name" {
  description = "The name of the s3 bucket"
}

variable "bu" {
  description = "The business unit running this module"
}

variable "env" {
  description = "The environment running this module"
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

================
File: pr/s3-buckets/versions.tf
================
terraform {
  required_version = ">= 1.3"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.32"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "s3"
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform/tree/main/s3-buckets"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: pr/vault/.terraform-version
================
latest:^1.7

================
File: pr/vault/data.tf
================
data "aws_route53_zone" "selected" {
  name = "${var.env}.pr.enverus.com"
}

data "aws_default_tags" "aws_default_tags" {}

================
File: pr/vault/dev.backend.tfvars
================
key = "040927785588/dev/vault/terraform.tfstate"

================
File: pr/vault/dev.tfvars
================
#keys
consul_token = "x48r8HjXLeQi8dJYOLQFEHtWJiMlv3MB0OeV/Bod6IY="
#module componements
datacenter    = "aws-ue1"
ec2-region    = "us-east-1"
os            = "ubuntu20"
vpc_name_tag  = "pr-vpc-dev"
instance_type = "c5d.large"
ec2-name      = "aws-ue1-pr-dev-vault"
asg-name      = "ue1-dev-pr-vault-asg"
elb-name      = "ue1-dev-pr-vault-lb"
dns-name      = "vault.dev.pr.enverus.com"
#Chef
chef-environment = "pr-dev-docker"
#Tagging
tagComponent            = "vault"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "pr_dev"

================
File: pr/vault/main.tf
================
module "aws-asg-pr-vault-server" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault.git?ref=v1.6.1"

  generate_certs = 1
  cert_type      = "AMAZON_ISSUED"
  cert_domain    = "*.${var.env}.${var.bu}.enverus.com"
  datacenter     = var.datacenter
  consul_token   = var.consul_token
  bu             = var.bu

  organization_name     = "Drillinginfo"
  ca_common_name        = var.dns-name
  common_name           = var.dns-name
  dns_names             = ["vault.service.consul, ${var.dns-name}, localhost"]
  ip_addresses          = ["127.0.0.1"]
  validity_period_hours = "87658"
  vpc_name_tag          = var.vpc_name_tag
  inside_subnet_filter  = var.inside_subnet_filter
  vo_routing_key        = var.vo_routing_key
  # ami search filters
  ami-filters = {
    name           = var.image
    virtualization = "hvm"
    owner          = "070551638384"
  }

  # lc params and userdata
  environment             = var.env
  bucket_hook_environment = var.bucket_hook_environment
  os                      = var.os
  ec2-name                = var.ec2-name
  instance-type           = var.instance_type
  keypair-name            = var.keypair-name
  iam-profile             = "service-instance-profile"
  ebs-optimized           = "true"

  # asg params
  asg-name                  = var.asg-name
  desired-capacity          = "2"
  health-check-grace-period = "60"
  health-check-type         = "EC2"
  min-size                  = "2"
  suspended-processes       = ["AZRebalance"]

  # Chef
  chef-version     = "12.21.14"
  chef-environment = var.chef-environment
  chef-run-list    = "\"recipe[linux_base::default_no_resolvconf]\""

  # Tagging
  tagComponent  = var.tagComponent
  tagStack      = var.env
  tagProduct    = "nexus"
  tagAutospot   = "false"
  tagLocation   = var.ec2-region
  tagTeam       = data.aws_default_tags.aws_default_tags.tags.Team
  tagSourceCode = data.aws_default_tags.aws_default_tags.tags.SourceCode

  #elb dns stuff

  elb-name                  = var.elb-name
  internal                  = true
  cross_zone_load_balancing = true
  idle_timeout              = "60"
  lb_port                   = "443"
  vault_api_port            = "8200"
  create_dns_entry          = 1
  hosted_zone_id            = data.aws_route53_zone.selected.zone_id
  domain_name               = var.dns-name

  user_provided_ansible_pull_playbook_list = [
    {
      playbook_repo = "enverus-cts/sre.ansible.grafana-alloy",
      playbook_file = "install-alloy.yml",
      git_host      = "cloud",
      additional_args = [
        "--extra-vars \"alloy_environment_name=${var.env} alloy_business_unit=${var.bu}\"",
        "-C main"
      ],
    }
  ]
}

================
File: pr/vault/prod.backend.tfvars
================
key = "330682006453/prod/vault/terraform.tfstate"

================
File: pr/vault/prod.tfvars
================
#keys
consul_token = "P/xelUfn1SGsPPGvNMFpldouBEhbuFH6QJyklRHl0RY="
#module componements
datacenter    = "aws-ue1"
ec2-region    = "us-east-1"
os            = "ubuntu20"
vpc_name_tag  = "pr-vpc-prod"
instance_type = "c5d.large"
ec2-name      = "aws-ue1-pr-prod-vault"
asg-name      = "ue1-prod-pr-vault-asg"
elb-name      = "ue1-prod-pr-vault-lb"
dns-name      = "vault.prod.pr.enverus.com"
#Chef
chef-environment = "pr-prod-docker"
#Tagging
tagComponent            = "vault"
inside_subnet_filter    = ["*INSIDE | Private Subnet"]
image                   = "drillinginfo/ubuntu2004/vault-server-aws-ubuntu-20.04-amd64-*"
bucket_hook_environment = "pr_prod"

================
File: pr/vault/variables.tf
================
variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "ec2-region" {
  description = "region in which to create instance"
  type        = string
}

variable "datacenter" {
  description = "the name of the dc, in our case could be 'aws-ue1'"
  type        = string
}

variable "os" {
  description = "used to configure scripts"
  type        = string
}

variable "bu" {
  description = "the business unit"
  type        = string
}

variable "env" {
  description = "Which environment is the instance in"
  type        = string
}

variable "consul_token" {
  description = "key to connect to consul"
  type        = string
}

variable "vpc_name_tag" {
  description = "Value of Name tag applied to target VPC, eg 'dev-VPC'"
  type        = string
}

variable "instance_type" {
  description = "instance type of ec2 node"
  type        = string
}

variable "ec2-name" {
  description = "used for naming the instances"
  type        = string
}

variable "asg-name" {
  description = "used for naming autoscaling group"
  type        = string
}

variable "elb-name" {
  description = "used for naming load balancer"
  type        = string
}

variable "dns-name" {
  description = "used for naming domain name"
  type        = string
}

variable "chef-environment" {
  description = "chef environment into which the node should bootstrap"
  type        = string
}

variable "tagComponent" {
  description = "used to set component tag"
  type        = string
}

variable "keypair-name" {
  default     = "cm@drillinginfo.com"
  description = "keypair for ssh"
}

variable "inside_subnet_filter" {
}

variable "image" {
  description = "vault server image"
  type        = string
}

variable "bucket_hook_environment" {
  description = "string value for asg module"
  type        = string
}

variable "vo_routing_key" {
  type        = string
  description = "Victorops routing key"
}

================
File: pr/vault/versions.tf
================
terraform {
  required_version = ">= 1.7.5"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.8"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Team             = "sre@enverus.com"
      SourceCode       = "https://git.drillinginfo.com/SRE/pr-terraform/tree/main/vault"
      TerraformCreated = "true"
      Product          = "nexus"
    }
  }
}

================
File: pr/vault_azuread_sso/.terraform-version
================
latest:^1.8

================
File: pr/vault_azuread_sso/dev.backend.tfvars
================
key = "040927785588/dev/vault_azuread_sso/terraform.tfstate"

================
File: pr/vault_azuread_sso/dev.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault.dev.pr.enverus.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_PR_DEV_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_DEV_PR_DEVS_RO = {
    policies = [
      "pr-dev-read",
    ]
  },
  SEC_ENTITLE_HASHICORP_VAULT_DEV_PR_PRT_DEVS_RO = {
    policies = [
      "prt-dev-read",
    ]
  },
}
vault_path_oidc_client_secret               = "pr-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "pr-secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault.dev.pr.enverus.com"

================
File: pr/vault_azuread_sso/main.tf
================
data "vault_generic_secret" "Azure_Service_Principal_Atlantis" {
  path = var.vault_path_azure_service_principal_atlantis
}

module "vault_azuread_sso" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-azuread-sso.git?ref=v0.1.0"

  oidc_client_id                 = var.oidc_client_id
  oidc_discovery_url             = var.oidc_discovery_url
  allowed_redirect_uris_prefix   = var.allowed_redirect_uris_prefix
  vault_identity_group_alias_sre = var.vault_identity_group_alias_sre
  vault_identity_group_alias_dev = var.vault_identity_group_alias_dev
  vault_path_oidc_client_secret  = var.vault_path_oidc_client_secret
}
output "vault_azuread_sso" { value = module.vault_azuread_sso }

================
File: pr/vault_azuread_sso/prod.backend.tfvars
================
key = "330682006453/prod/vault_azuread_sso/terraform.tfstate"

================
File: pr/vault_azuread_sso/prod.tfvars
================
oidc_client_id     = "495c468a-6481-4be6-b9ac-8711fc6223af"
oidc_discovery_url = "https://login.microsoftonline.com/61f90f11-8d76-4b05-9b09-90af7d07328a/v2.0"
allowed_redirect_uris_prefix = [
  "https://vault.prod.pr.enverus.com"
]
vault_identity_group_alias_sre = "SEC_ENTITLE_AWS_PR_PROD_ADMIN_USERS"
vault_identity_group_alias_dev = {
  SEC_ENTITLE_HASHICORP_VAULT_PROD_PR_DEVS_RO = {
    policies = [
      "pr-prod-read",
    ]
  },
}
vault_path_oidc_client_secret               = "pr-secrets/terraform/vault_azure_sso"
vault_path_azure_service_principal_atlantis = "pr-secrets/terraform/Azure_Service_Principal_Atlantis"
VAULT_ADDR                                  = "https://vault.prod.pr.enverus.com"

================
File: pr/vault_azuread_sso/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "vault_path_azure_service_principal_atlantis" {
  description = "The vault path to AzureAD Service Principal secret"
  type        = string
}

variable "vault_path_oidc_client_secret" {
  description = "The vault path to AzureAD OIDC secret"
  type        = string
}

variable "oidc_client_id" {
  description = "The client id for credentials to query the Azure APIs. Currently read permissions to query compute resources are required."
  type        = string
}

variable "oidc_discovery_url" {
  description = "The OIDC Discovery URL, without any .well-known component (base"
  type        = string
}

variable "allowed_redirect_uris_prefix" {
  description = "The list of allowed values for redirect_uri during OIDC logins. Required for OIDC roles"
  type        = list(string)
}

variable "vault_identity_group_alias_sre" {
  description = "Azure ID of the group alias to create."
  type        = string
  default     = null
}

variable "vault_identity_group_alias_dev" {
  description = "list of Azure IDs of the group alias to create."
  type        = any
  default     = {}
}

================
File: pr/vault_azuread_sso/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    azuread = {
      source = "hashicorp/azuread"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

provider "azuread" {
  client_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_ID"]
  client_secret = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_CLIENT_SECRET"]
  tenant_id     = data.vault_generic_secret.Azure_Service_Principal_Atlantis.data["ARM_TENANT_ID"]
}

================
File: pr/vault_policies_and_roles/.terraform-version
================
latest:^1.8

================
File: pr/vault_policies_and_roles/dev.backend.tfvars
================
key = "040927785588/dev/vault_policies_and_roles/ue1/terraform.tfstate"

================
File: pr/vault_policies_and_roles/dev.tfvars
================
secrets_mountpoint = "pr-secrets"
VAULT_ADDR         = "https://vault.dev.pr.enverus.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  terraform-read-policy = [
    {
      path         = "pr-secrets/*"
      capabilities = ["read"]
      description  = "Allow reading pr-secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "delete", "sudo"]
      description  = "Create, update, and delete auth methods"
    },
    {
      path         = "auth/aws/role/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage new approles roles"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "Allow revoking tokens that should no longer exist. This allows revoking tokens for dead tasks."
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "pr-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys/*"
    },
    {
      path         = "pr-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "pr-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to prometheus-api-keys/*"
    },
    {
      path         = "pr-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to promtail-api-keys/*"
    },
    {
      path         = "pr-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis/*"
    },
    {
      path         = "pr-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "pr-secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "pr-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "pr-secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "pr-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis secrets"
    },
    {
      path         = "pr-secrets/data/chef"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to chef"
    },
    {
      path         = "pr-secrets/data/elm/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to elm secrets"
    },
    {
      path         = "pr-secrets/data/kotsiievskiy_github_pat"
      capabilities = ["read", "list"]
      description  = "access to github PAT for prefect"
    },
    {
      path         = "pr-secrets/data/solar-labeler/*"
      capabilities = ["read", "list"]
      description  = "access to solar-labeler secrets"
    },
    {
      path         = "pr-secrets/data/PR/*"
      capabilities = ["read", "list"]
      description  = "access to the PR team secrets"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["read", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACLs broadly across Vault."
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  pr-dev-read = [
    {
      path         = "pr-secrets/PR/*"
      capabilities = ["list", "read"]
      description  = "access to read P&R secrets"
    },
    {
      path         = "pr-secrets*"
      capabilities = ["list", "read"]
      description  = "access to pr-secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "pr-secrets*"
      capabilities = ["list"]
      description  = "access to pr-secrets"
    },
    {
      path         = "pr-secrets/data/elm/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  prt-dev-read = [
    {
      path         = "pr-secrets*"
      capabilities = ["list"]
      description  = "access to pr-secrets"
    },
    {
      path         = "pr-secrets/data/terraform/prt/*"
      capabilities = ["read", "list"]
      description  = "access to prt secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: pr/vault_policies_and_roles/main.tf
================
resource "vault_auth_backend" "userpass" {
  type = "userpass"
}

resource "vault_auth_backend" "aws" {
  description = "Auth Method for IAM"
  type        = "aws"
}

module "vault_policies_and_roles" {
  source = "git::ssh://git@github.com/enverus-cts/sre.tf-modules.vault-policies-and-roles.git?ref=main"

  list_vault_policies = var.list_vault_policies
  secrets_mountpoint  = var.secrets_mountpoint
  bu                  = var.bu
  env                 = var.env
}
output "vault_policies_and_roles" { value = module.vault_policies_and_roles }

================
File: pr/vault_policies_and_roles/prod.backend.tfvars
================
key = "330682006453/prod/vault_policies_and_roles/ue1/terraform.tfstate"

================
File: pr/vault_policies_and_roles/prod.tfvars
================
secrets_mountpoint = "pr-secrets"
VAULT_ADDR         = "https://vault.prod.pr.enverus.com"
list_vault_policies = {
  superuser = [
    {
      path         = "*"
      capabilities = ["create", "read", "update", "delete", "list", "sudo"]
      description  = "superuser"
    }
  ]
  terraform-read-policy = [
    {
      path         = "pr-secrets/*"
      capabilities = ["read"]
      description  = "Allow reading pr-secrets"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "read", "update", "list"]
      description  = "need to create a temporary token"
    }
  ]
  nomad-server = [
    {
      path         = "auth/token/create/nomad-cluster"
      capabilities = ["update"]
      description  = "Allow creating tokens under 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update", "sudo"]
      description  = "Allow updating tokens under 'nomad-cluster' role."
    },
    {
      path         = "auth/token/roles/nomad-cluster"
      capabilities = ["read"]
      description  = "Allow looking up 'nomad-cluster' role. The role name should be updated if 'nomad-cluster' is not used."
    },
    {
      path         = "auth/token/lookup-self"
      capabilities = ["read"]
      description  = "Allow looking up the token passed to Nomad to validate the token has the proper capabilities. This is provided by the 'default' policy."
    },
    {
      path         = "auth/token/lookup"
      capabilities = ["update"]
      description  = "Allow looking up incoming tokens to validate they have permissions to access the tokens they are requesting. This is only required if `allow_unauthenticated` is set to false."
    }
  ]
  atlantis-token = [
    {
      path         = "auth/token/create"
      capabilities = ["create", "update"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle/login*"
      capabilities = ["create", "update"]
      description  = "Allow create a login token for atlantis"
    }
  ]
  atlantis-rw = [
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "delete", "sudo"]
      description  = "Create, update, and delete auth methods"
    },
    {
      path         = "auth/aws/role/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/create/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create tokens for nomad"
    },
    {
      path         = "auth/token/create"
      capabilities = ["create", "update", "sudo"]
      description  = "Allow create a token for atlantis"
    },
    {
      path         = "auth/approle/role/atlantis*"
      capabilities = ["create", "read", "update", "list"]
      description  = "Manage atlantis role"
    },
    {
      path         = "auth/approle*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Manage new approles roles"
    },
    {
      path         = "auth/token/nomad-server"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/nomad-server/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to manage tokens for nomad"
    },
    {
      path         = "auth/token/roles/"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/roles/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to create roles"
    },
    {
      path         = "auth/token/lookup-accessor"
      capabilities = ["update"]
      description  = "require update access to create tokens"
    },
    {
      path         = "auth/token/revoke-accessor"
      capabilities = ["update"]
      description  = "Allow revoking tokens that should no longer exist. This allows revoking tokens for dead tasks."
    },
    {
      path         = "sys/capabilities-self"
      capabilities = ["update"]
      description  = "Allow checking the capabilities of our own token. This is used to validate the token upon startup."
    },
    {
      path         = "auth/token/renew-self"
      capabilities = ["update"]
      description  = "Allow our own token to be renewed."
    },
    {
      path         = "pr-secrets/data/aws-api-keys/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to aws-api-keys/*"
    },
    {
      path         = "pr-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "pr-secrets/data/prometheus/*"
      capabilities = ["read", "list"]
      description  = "access to prometheus-api-keys/*"
    },
    {
      path         = "pr-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to promtail-api-keys/*"
    },
    {
      path         = "pr-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis/*"
    },
    {
      path         = "pr-secrets/data/terraform/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform/*"
    },
    {
      path         = "pr-secrets/data/terraform"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to terraform"
    },
    {
      path         = "pr-secrets/data/promtail/*"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "pr-secrets/data/promtail"
      capabilities = ["read", "list"]
      description  = "access to grafana"
    },
    {
      path         = "pr-secrets/data/atlantis*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to atlantis secrets"
    },
    {
      path         = "pr-secrets/data/chef"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to chef"
    },
    {
      path         = "pr-secrets/data/elm/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "access to elm secrets"
    },
    {
      path         = "pr-secrets/data/kotsiievskiy_github_pat"
      capabilities = ["read", "list"]
      description  = "access to github PAT for prefect"
    },
    {
      path         = "pr-secrets/data/solar-labeler/*"
      capabilities = ["read", "list"]
      description  = "access to solar-labeler secrets"
    },
    {
      path         = "pr-secrets/data/PR/*"
      capabilities = ["read", "list"]
      description  = "access to the PR team secrets"
    },
    {
      path         = "auth/SRE*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "auth/Azure_AD_SSO*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts"
      capabilities = ["read"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/mounts/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage secrets engines broadly across Vault."
    },
    {
      path         = "sys/auth"
      capabilities = ["read", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/auth/*"
      capabilities = ["create", "update", "read", "delete", "list"]
      description  = "Configure auth methods"
    },
    {
      path         = "sys/policies"
      capabilities = ["read", "list"]
      description  = "Display the Policies tab in UI"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage ACLs broadly across Vault."
    },
    {
      path         = "sys/policies/acl"
      capabilities = ["read", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage policies"
    },
    {
      path         = "identity/*"
      capabilities = ["create", "read", "update", "delete", "list"]
      description  = "Create and manage entities and groups"
    }
  ]
  pr-prod-read = [
    {
      path         = "pr-secrets/PR/*"
      capabilities = ["list", "read"]
      description  = "access to read P&R secrets"
    },
    {
      path         = "pr-secrets*"
      capabilities = ["list", "read"]
      description  = "access to pr-secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
  elm-read = [
    {
      path         = "pr-secrets*"
      capabilities = ["list"]
      description  = "access to pr-secrets"
    },
    {
      path         = "pr-secrets/data/elm/*"
      capabilities = ["read", "list"]
      description  = "access to data secrets"
    },
    {
      path         = "aws-terraform_*"
      capabilities = ["deny"]
      description  = "deny to aws-terraform"
    },
    {
      path         = "sys/policies/acl/*"
      capabilities = ["list", "read"]
      description  = "limit ACLs."
    }
  ]
}

================
File: pr/vault_policies_and_roles/variables.tf
================
variable "VAULT_ADDR" {
  description = "address of hashi vault"
  type        = string
}

variable "list_vault_policies" {
  description = "a list of vault policies"
  type = map(list(object(
    {
      path         = string
      capabilities = list(string)
      description  = string
  })))
}

variable "secrets_mountpoint" {
  description = "Mountpoint of Secret path"
  type        = string
}

variable "bu" {
  description = "Business Unit"
  type        = string
}

variable "env" {
  description = "Env"
  type        = string
}

================
File: pr/vault_policies_and_roles/versions.tf
================
terraform {
  required_version = ">= 1.8"
  backend "s3" {}
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3"
    }
  }
}

provider "vault" {
  address = var.VAULT_ADDR
}

================
File: pr/vpc/.terraform-version
================
latest:^1.7

================
File: pr/vpc/data.tf
================
data "aws_default_tags" "aws_default_tags" {}

================
File: pr/vpc/dev.backend.tfvars
================
key            = "040927785588/dev/vpc/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"

================
File: pr/vpc/dev.tfvars
================
tag_name                             = "pr-vpc-dev"
tag_stack                            = "dev"
cidr_block                           = "10.24.80.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "nonprod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: pr/vpc/main.tf
================
module "pr-vpc-east" {
  source = "git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git?ref=v2.11.1"

  aws_region                           = "us-east-1"
  tag_name                             = var.tag_name
  tag_environment                      = data.aws_default_tags.aws_default_tags.tags.Environment
  vpc_cidr_block                       = var.cidr_block
  enable_cgnat_subnet                  = var.enable_cgnat_subnet
  cloud_wan_core_network_id            = var.cloud_wan_core_network_id
  tag_cloud_wan_segment                = var.tag_cloud_wan_segment
  enable_cloud_wan_vpc_attachment      = var.enable_cloud_wan_vpc_attachment
  enable_local_managed_prefix_lists    = true
  ecr_endpoint_type                    = var.ecr_endpoint_type
  cloudwatch_logs_endpoint_type        = var.cloudwatch_logs_endpoint_type
  enable_centralized_endpoints_profile = var.enable_centralized_endpoints_profile
  enable_ue1_az3                       = var.enable_ue1_az3
}

================
File: pr/vpc/prod.backend.tfvars
================
#bucket         = "di-pr-prod-terraform"
key            = "330682006453/prod/vpc/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"

================
File: pr/vpc/prod.tfvars
================
tag_name                             = "pr-vpc-prod"
tag_stack                            = "prod"
cidr_block                           = "10.24.88.0/21"
enable_cgnat_subnet                  = true
cloud_wan_core_network_id            = "core-network-0974bc461dd2eb751"
tag_cloud_wan_segment                = "prod"
enable_cloud_wan_vpc_attachment      = true
ecr_endpoint_type                    = false
cloudwatch_logs_endpoint_type        = false
enable_centralized_endpoints_profile = true
enable_ue1_az3                       = true

================
File: pr/vpc/variables.tf
================
variable "tag_name" {
  description = "tag_name"
  type        = string
}

variable "tag_stack" {
  description = "tag_stack"
  type        = string
}

variable "cidr_block" {
  description = "vpc_cidr_block"
  type        = string
}

variable "assume_role_arn" {
  description = "The arn of the role to assume. specific to the account being deployed to"
  type        = string
}

variable "bu" {
  description = "business unit"
  type        = string
}

variable "env" {
  description = "Prod/Dev/preprod environment"
  type        = string
}

variable "enable_cgnat_subnet" {
  description = "Enable use of Carrier Grade subnets"
  type        = bool
}

variable "cloud_wan_core_network_id" {
  description = "The id of the core network to attach to"
  type        = string
}

variable "tag_cloud_wan_segment" {
  description = "The segment of the AWS CloudWAN network to attach to"
  type        = string
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Enable vpc attachment to Cloud-WAN core network."
  type        = bool
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC in the Route 53 profile.
variable "ecr_endpoint_type" {
  description = "Boolean value to determine if decentralized ECR endpoint should be created."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine if decentralized CloudWatch Logs endpoint should be created."
  type        = bool
  default     = false
}

# If you have resources in AZ3 currently, enable this variable to use us-east-1-az3. Otherwise the subnet and its resources will be destroyed.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: pr/vpc/versions.tf
================
terraform {
  required_version = ">= 1.7"
  backend "s3" {}
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.37.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
  assume_role {
    role_arn = var.assume_role_arn
  }
  default_tags {
    tags = {
      BusinessUnit     = var.bu
      Component        = "vpc"
      Team             = "sre@enverus.com"
      SourceCode       = "https://github.com/enverus-cts/sre.pr.terraform/tree/main/vpc"
      TerraformCreated = "true"
      Environment      = var.env
    }
  }
}

================
File: pr/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_lb_listener.consul_listener": [
      "aws_lb.consul_lb",
      "aws_lb_target_group.consul_tg"
    ],
    "aws_autoscaling_attachment.asg_attachment_bar": [
      "aws_lb_target_group.consul_tg"
    ],
    "aws_route53_record.consul_ui": [
      "aws_lb.consul_lb"
    ],
    "aws_acm_certificate_validation.cert_validation": [
      "aws_acm_certificate.pr"
    ],
    "aws_iam_access_key.iam_access_key": [
      "aws_iam_user.iam_user"
    ],
    "aws_iam_user_policy_attachment.iam_user_policy_attachment": [
      "aws_iam_policy.iam_policy",
      "aws_iam_user.iam_user"
    ],
    "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment": [
      "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy",
      "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role"
    ],
    "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment": [
      "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role",
      "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy"
    ]
  },
  "dependents": {
    "aws_lb.consul_lb": [
      "aws_lb_listener.consul_listener",
      "aws_route53_record.consul_ui"
    ],
    "aws_lb_target_group.consul_tg": [
      "aws_lb_listener.consul_listener",
      "aws_autoscaling_attachment.asg_attachment_bar"
    ],
    "aws_acm_certificate.pr": [
      "aws_acm_certificate_validation.cert_validation"
    ],
    "aws_iam_user.iam_user": [
      "aws_iam_access_key.iam_access_key",
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.iam_policy": [
      "aws_iam_user_policy_attachment.iam_user_policy_attachment"
    ],
    "aws_iam_policy.kms-cmk-not-scheduled-for-deletion-remediation-document-policy": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.kms-cmk-not-scheduled-for-deletion-remediation-document-role": [
      "aws_iam_role_policy_attachment.kms-cmk-not-scheduled-for-deletion-remediation-document-policy-attachment"
    ],
    "aws_iam_role.ec2-ebs-encryption-by-default-remediation-role": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ],
    "aws_iam_policy.ec2-ebs-encryption-by-default-remediation-policy": [
      "aws_iam_role_policy_attachment.ec2-ebs-encryption-by-default-remediation-policy-attachment"
    ]
  },
  "cross_repo_references": [
    "external.cidr_block",
    "external.bucket_hook_environment",
    "external.os",
    "external.ecr_endpoint_type",
    "external.aws_subnets.inside",
    "external.bu",
    "external.consul_token",
    "external.aws_caller_identity.current",
    "external.vpc_name_tag",
    "external.vault_generic_secret.Azure_Service_Principal_Atlantis",
    "external.allowed_redirect_uris_prefix",
    "external.VAULT_ADDR",
    "external.enable_ue1_az3",
    "external.aws_ec2_managed_prefix_list.vpn_prefix_list",
    "external.aws_security_group.inside_sg",
    "external.vault_identity_group_alias_sre",
    "external.keypair",
    "external.secrets_mountpoint",
    "external.business_unit",
    "external.abv",
    "external.region",
    "external.environment",
    "external.vault_path_azure_service_principal_atlantis",
    "external.cloudwatch_logs_endpoint_type",
    "external.aws_default_tags.aws_default_tags",
    "external.tag_name",
    "external.cloud_wan_core_network_id",
    "external.multi",
    "external.enable_cloud_wan_vpc_attachment",
    "external.tag_cloud_wan_segment",
    "external.vault_identity_group_alias_dev",
    "external.enable_cgnat_subnet",
    "external.aws_route53_zone.main",
    "external.encryption_key",
    "external.resource_type_exclusion_list",
    "external.user_provided_ansible_pull_playbook_list",
    "external.image",
    "external.elb",
    "external.configBackend",
    "external.oidc_client_id",
    "external.dns",
    "external.oidc_discovery_url",
    "external.vo_routing_key",
    "external.name",
    "external.instance_type",
    "external.kms_exclusion_list",
    "external.inside_subnet_filter",
    "external.template_file.policy",
    "external.aws_route53_zone.selected",
    "external.datacenter",
    "external.aws_vpc.vpc",
    "external.env",
    "external.list_vault_policies",
    "external.assume_role_arn",
    "external.enable",
    "external.enable_centralized_endpoints_profile",
    "external.asg",
    "external.aws_config_sns",
    "external.aws_route53_zone.pr",
    "external.vault_generic_secret.grafana_api",
    "external.aws_default_tags.current",
    "external.recursors",
    "external.chef",
    "external.ec2",
    "external.vault_path_oidc_client_secret",
    "external.tagComponent",
    "external.consul_servers_aws"
  ],
  "outputs": [
    "vault_azuread_sso",
    "vault_policies_and_roles"
  ],
  "metadata": {
    "total_resources": 17,
    "resources_with_dependencies": 8,
    "resources_that_are_dependencies": 9,
    "cross_repo_refs_count": 67,
    "outputs_count": 2,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: pr/.gitattributes
================
* text=auto

================
File: pr/.gitignore
================
# Local .terraform directories
**/.terraform/*

# .tfstate files
*.tfstate
*.tfstate.*

# Crash log files
crash.log

# Ignore any .tfvars files that are generated automatically for each Terraform run. Most
# .tfvars files are managed as part of configuration and so should be included in
# version control.
#
# example.tfvars

# Ignore override files as they are usually used to override resources locally and so
# are not checked in
override.tf
override.tf.json
*_override.tf
*_override.tf.json

# Include override files you do wish to add to version control using negated pattern
#
# !example_override.tf

# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan
# example: *tfplan*

.terraform
terraform.tfsta*
.terraform.lock.hcl
*/.terraform.lock.hcl
.idea/
.DS_Store

================
File: pr/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.88.4
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"

================
File: pr/atlantis.yaml
================
version: 3
automerge: false
projects:
  ############ pr vpc #################
  - name: vpc-dev
    dir: vpc
    workflow: dev
    autoplan:
      when_modified: ["*.tf*"]
  - name: vpc-prod
    dir: vpc
    workflow: prod
    autoplan:
      when_modified: ["*.tf*"]
    ############ route 53 ###############
  - name: route53-dev
    dir: route-53
    workflow: dev
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: route53-prod
    dir: route-53
    workflow: prod
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
    ############ consul ###############
    ## temp workflows till pr vault is deployed
  - name: consul-dev
    dir: consul
    workflow: dev-vault
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: consul-prod
    dir: consul
    workflow: prod-vault
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
    ############ s3-buckets ###############
  - name: s3-buckets-dev
    dir: s3-buckets
    workflow: dev
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: s3-buckets-prod
    dir: s3-buckets
    workflow: prod
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-dev
    dir: vault
    workflow: dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault-prod
    dir: vault
    workflow: prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: acm-dev
    dir: acm
    workflow: dev
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
  - name: acm-prod
    dir: acm
    workflow: prod
    terraform_version: v1.7.5
    autoplan:
      when_modified: ["*.tf*"]
    ############ vault policies dev ###############
  - name: vault_policies_and_roles-dev
    dir: vault_policies_and_roles
    workflow: pr-dev-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault_azuread_sso-dev
    dir: vault_azuread_sso
    workflow: pr-dev-vault
    autoplan:
      when_modified: ["*.tf*"]
    ############ vault policies prod ###############
  - name: vault_policies_and_roles-prod
    dir: vault_policies_and_roles
    workflow: pr-prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  - name: vault_azuread_sso-prod
    dir: vault_azuread_sso
    workflow: pr-prod-vault
    autoplan:
      when_modified: ["*.tf*"]
  ##### aws config #######
  - name: aws-config-dev
    dir: config
    workflow: dev
  - name: aws-config-prod
    dir: config
    workflow: prod
  ##### grafana #######
  - name: grafana-datasources-dev
    dir: grafana/datasources
    workflow: pr-dev-vault
    terraform_version: v1.7.5
  - name: grafana-datasources-prod
    dir: grafana/datasources
    workflow: pr-prod-vault
    terraform_version: v1.7.5

================
File: pr/global-dev-backend.tfvars
================
shared_credentials_file = "/secrets/vault_atlantis_pr_dev.env"
#bucket                  = "di-pr-dev-terraform"
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::040927785588:role/terraform" }

================
File: pr/global-dev.tfvars
================
bu                  = "pr"
env                 = "dev"
VAULT_ADDR          = "https://vault.dev.pr.enverus.com"
assume_role_arn     = "arn:aws:iam::040927785588:role/terraform"
vo_routing_key      = "key-DevUptime"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_pr_dev"

================
File: pr/global-prod-backend.tfvars
================
shared_credentials_file = "/secrets/vault_atlantis_pr_prod.env"
#bucket                  = "di-pr-prod-terraform"
bucket         = "enverus-centralized-terraform-state"
region         = "us-east-1"
dynamodb_table = "terraform-state-locking"
assume_role    = { role_arn = "arn:aws:iam::330682006453:role/terraform" }

================
File: pr/global-prod.tfvars
================
bu                  = "pr"
env                 = "prod"
VAULT_ADDR          = "https://vault.prod.pr.enverus.com"
vault_path_aws_keys = "di-secrets/terraform/aws_api_keys/terraform_keys_pr_prod"
assume_role_arn     = "arn:aws:iam::330682006453:role/terraform"
vo_routing_key      = "key-ProdUptime"

================
File: pr/README.md
================
# pr-terraform
Repository for the PR accounts.

================
File: vpc/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: vpc/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: vpc/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: vpc/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: vpc/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: vpc/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: vpc/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: vpc/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: vpc/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: vpc/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: vpc/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: vpc/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: vpc/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: vpc/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: vpc/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406125 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc.git

================
File: vpc/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406125 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc.git

================
File: vpc/.git/logs/HEAD
================
0000000000000000000000000000000000000000 2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8 Abdullah Sheikh <abdullah.sheikh@enverus.com> 1755406125 -0600	clone: from github.com:enverus-cts/sre.tf-modules.aws-vpc.git

================
File: vpc/.git/refs/heads/main
================
2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8

================
File: vpc/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: vpc/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:enverus-cts/sre.tf-modules.aws-vpc.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: vpc/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: vpc/.git/HEAD
================
ref: refs/heads/main

================
File: vpc/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
ce02d1f79fa213c3aefbcd7081e64a636821ac3c refs/remotes/origin/DI-240
cc744564a64a1e43d50044a3347de107a0b75a0c refs/remotes/origin/feat/sre-11618-name-tag-assoc
2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8 refs/remotes/origin/main
8c33acc762575338a291fa53fa5e6b9384f25f2b refs/remotes/origin/remove-az3
e693a71482a7539f3620b61bbf7d82b6427a7c06 refs/remotes/origin/sre-11530-cloudwan-test-vpc-create-fernando
c57f5df928d7a2bcd4fb185161e4bf2c51b71409 refs/remotes/origin/sre-15165
e4204e489e7d1836816cd917b39531d91dede6f5 refs/remotes/origin/sre-8549
a14f07731703baa3e63b37513c130cbcd0df8728 refs/tags/v0.0.1
^00c190dc02ec99d2f40d226f21ceb90849e81c51
8b418a2d9ea61868482bfbd84f515d8d6f4ce99b refs/tags/v0.0.2
8f621e3b0daf55f74155d3ffcb7469e197424b6f refs/tags/v0.0.3
89c1ed9baf72f194f13c49df82a8245534be09ac refs/tags/v0.0.4
40e8bca8d2f62d3a1354a3d4a038df0c361e3bce refs/tags/v0.14.0
218de0bb76d0a01c49f33d0e5def6de3fe651de9 refs/tags/v0.15.0
06438e18e55cc783affdccd6ddcb19071cea5cdc refs/tags/v0.16.0
0ac874ea8ab2b09aadd04994a2fe6dced72944d1 refs/tags/v1.0.0
b95db31a5b4a765aae99d0a795e51ae8b427b9ca refs/tags/v1.1.0
^95cc0ad248c1d0ccc866cad7be9b19b3d2975098
364f5f3fd2693095101c471f863e90eb3ff8639e refs/tags/v2.0.0
9f1fc8adf826f969cfdb30c0ea03b2268d004eab refs/tags/v2.1.0
^2af728cf312b12ffa0fc8a23b865c7cf6859f022
70edf63e563ac6dc6827758508452a6d654a919a refs/tags/v2.10.0
5b602993e060d38a98904f840f381b58e8c577b8 refs/tags/v2.10.1
1b9d93638edde0005efe8f524521d81b71ec34e3 refs/tags/v2.10.2
710087f5a464e2eb2b9a60b6cd56f92ac13a01df refs/tags/v2.11.0
2c81e94c91d30ee0d70ebaf92a7474f6c58ad7f8 refs/tags/v2.11.1
3f976015f65d6e588e112a0b41cf6c853726dd78 refs/tags/v2.2.0
8b3d8e821eb324a5d475483da8474522e979e3df refs/tags/v2.3.0
3cc7595eb14bfcba638faf5520f1eb38decb718e refs/tags/v2.4.0
e1c9b9b2f2a4746be9acab608f29548a9a68d3d0 refs/tags/v2.4.1
bd9560ec79dfc198cbb7aee4c5c33a3af140214f refs/tags/v2.4.2
3654ff50528abdb4af08ab15bb600f0208eb2719 refs/tags/v2.4.3
c87c464ead836ee2772120c36e6888d824a86444 refs/tags/v2.5.0
a2b05340e94848bf519fc9636ad371313094c4bc refs/tags/v2.6.0
afbc6425c744f9d7431ba779444041730c01d466 refs/tags/v2.6.1
0c17b5ae12340358581cdfc12aff57ed340f20de refs/tags/v2.7.0
8098bd8dfd9099d51d55e85c42d7288bcd9f8b14 refs/tags/v2.7.1
47bd7cee7c9d83fba5ab8be9e7d934638430a4b6 refs/tags/v2.7.2
b8f28186d9f7a471c23a5919ffd5f67a09806cc0 refs/tags/v2.7.3
f2c3cc2b7001841f6da0a2075a8f1c3350b58cd4 refs/tags/v2.8.0
41dc3ce6f259b70657907a170d3ec8816362e431 refs/tags/v2.9.0

================
File: vpc/.github/workflows/ci-release.yaml
================
name: Release

on:
  push:
    branches:
      - main
    paths-ignore:
      - "docs/**"
      - "examples/**"
      - ".tests/**"
      - ".github/**"

jobs:
  terraform:
    name: Release Terraform Module
    runs-on: enverus-ubuntu
    steps:

    - name: Checkout
      uses: actions/checkout@v3.5.3

    - name: Get changed files
      id: changed-files
      uses: tj-actions/changed-files@v36
      with:
        files: |
          *.tf
          modules/**/*.tf
          charts/**/Chart.yaml
          charts/**/values.yaml
          charts/**/templates/**
          !.github/**
          !examples/**
          !.tests/**
          !docs/**

    - uses: enverus-cts/sre.actions.terraform-release@v0.2.0
      with:
        repoName: ${{ github.event.repository.name }}
        releaserGithubAppId: ${{ secrets.RELEASER_APP_ID }}
        releaserGithubAppPrivateKey: ${{ secrets.RELEASER_APP_PRIVATE_KEY_BASE64 }}

================
File: vpc/.github/workflows/ci-terraform.yaml
================
---
name: feature-branch
on:
  workflow_dispatch:
  pull_request:
    branches:
      - main
      - release/**
    types: [opened, synchronize, reopened, labeled, unlabeled]
jobs:
  format:
    runs-on: enverus-ubuntu
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Terraform format
        uses: dflook/terraform-fmt@v1

      - name: Reviewdog suggester
        # if: ${{ inputs.suggestions }}
        uses: reviewdog/action-suggester@v1
        with:
          tool_name: "terraform fmt -recursive"
          cleanup: false
          filter_mode: diff_context

      - name: Status check
        shell: bash
        run: git diff --exit-code

  lint-find-dirs:
    runs-on: enverus-ubuntu
    steps:
      - uses: actions/checkout@v3

      - id: set-matrix
        run: |
          matrix=$(find ./ -name '*.tf' \
            -not -path '*/.terraform/*' \
            -exec dirname {} \; \
            | sort \
            | uniq \
            | jq --raw-input --slurp 'split("\n")| map(select(. != ""))')
          echo "matrix=$(echo $matrix)" >> $GITHUB_OUTPUT
    outputs:
      tfdirs_matrix: ${{ steps.set-matrix.outputs.matrix }}

  lint:
    runs-on: enverus-ubuntu
    needs: lint-find-dirs
    strategy:
      fail-fast: false
      matrix:
        tfdir: ${{ fromJson(needs.lint-find-dirs.outputs.tfdirs_matrix) }}
    env:
      TFLINT_PLUGIN_DIR: ${{ github.workspace }}/.tflint.d/plugins
      TFLINT_PLUGINS: aws
      TFLINT_CACHE_VER: 1 # Increment this to force a cache refresh
    steps:
      - uses: actions/checkout@v3

      - name: Get token
        uses: npalm/action-app-token@v1.0.0
        id: app-token
        with:
          appId: ${{ secrets.RELEASER_APP_ID }}
          appPrivateKeyBase64: ${{ secrets.RELEASER_APP_PRIVATE_KEY_BASE64 }}
          appInstallationType: repo
          appInstallationValue: ${{ github.repository }}

      - name: git insteadOf
        run: |
          git config --global url."https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/".insteadOf ssh://git@github.com/
          git config --global user.name "Enverus CI"
          git config --global user.email 'ci@enverus.com'
          git clone https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/enverus-cts/sre.tf-modules.eks
        shell: bash

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"

      - uses: hashicorp/setup-terraform@v2

      - run: terraform init
        working-directory: ${{ matrix.tfdir }}

      - name: cache tflint plugins
        id: cache-plugins
        uses: actions/cache@v3
        with:
          path: ${{ env.TFLINT_PLUGIN_DIR }}
          key: tflint-plugins-${{ env.TFLINT_CACHE_VER }}

      - name: tflint
        uses: reviewdog/action-tflint@v1.18.0
        with:
          reporter: ${{ 'github-pr-review' || 'local' }}
          fail_on_error: true # Set to true when all tflint issues are fixed in all tf repo release branches
          tflint_rulesets: ${{ env.TFLINT_PLUGINS }}
          tflint_init: true
          tflint_version: "v0.49.0"
          working_directory: ${{ matrix.tfdir }}
          filter_mode: diff_context

  validate:
    runs-on: enverus-ubuntu
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          repository: ${{ github.event.pull_request.head.repo.full_name }}

      - name: Generate readme
        shell: bash
        run: |
          make gen

      - name: Check readme
        id: readme_diff
        shell: bash
        run: git diff --exit-code
        continue-on-error: true

      - name: Auto-update README.md for bot pull requests
        id: auto_commit
        if: |
          steps.readme_diff.outcome == 'failure'
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'gihub-actions[bot]@users.noreply.github.com'
          git commit -a -m "chore: auto-update README.md [skip-ci]"
          git push

================
File: vpc/.github/workflows/pr-labeler.yaml
================
name: PR Labeler

on:
  pull_request:
    types: [opened]

jobs:
  pr-labeler:
    runs-on: enverus-ubuntu
    steps:
      - name: Appling automatically labels to the PRs
        uses: TimonVS/pr-labeler-action@v3.1.0
        with:
          configuration-path: .github/pr-labeler.yml
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

================
File: vpc/.github/workflows/pr-lint.yaml
================
name: PR Lint

on:
  pull_request_target:
    types:
      - opened
      - edited
      - synchronize

jobs:
  main:
    name: Validate PR title
    runs-on: enverus-ubuntu
    steps:
      - uses: enverus-cts/sre.actions.pr-lint@v1.0.0
        with:
          githubToken: ${{ secrets.GITHUB_TOKEN }}

================
File: vpc/.github/dependabot.yaml
================
version: 2
updates:
  - package-ecosystem: "terraform"
    directory: "/"
    schedule:
      interval: "daily"
    commit-message:
      prefix: "fix"
      prefix-development: "build"
      include: "scope"
    allow:
      - dependency-type: "production"
    reviewers:
      - "@enverus-cts/sre"

================
File: vpc/.github/pr-labeler.yaml
================
feature: ['feature/*', 'feat/*']
fix: 'fix/*'
bug: 'fix/*'
release: 'bc/*'

================
File: vpc/examples/vpc/main.tf
================
# The values for `customer_gateway_bgp_asn`, `vpc_cidr_block` are completely made up for this example.

module "test-vpc" {
  aws_region                           = "us-east-1"
  source                               = "../../"
  tag_name                             = "vpc-test"
  vpc_cidr_block                       = "172.19.16.0/21"
  enable_cloud_wan_vpc_attachment      = true
  cloud_wan_core_network_id            = "core-network-00000000000000000"
  tag_cloud_wan_segment                = "dev"
  ecr_endpoint_type                    = false
  tag_environment                      = "dev"
  cloudwatch_logs_endpoint_type        = true
  enable_ue1_az3                       = true
  enable_centralized_endpoints_profile = true
}

================
File: vpc/jenkins/aws-vpc.yaml
================
# yaml to define Jenkins builds for this repo
- project:
    name: aws-vpc
    repo: aws-vpc
    organization: TF-Modules
    type: terraform-module
    terraform-version: "0.12"
    jobs:
      - "{name}-terraform-release"
      - "{name}-terraform-module-pull-request"
      - "{name}-terraform-fmt-pull-request"
      - "{name}-jjb"

================
File: vpc/_dependency_graph.json
================
{
  "repo_name": "",
  "dependencies": {
    "aws_internet_gateway.internet_gateway": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint.s3_endpoint": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association": [
      "aws_route_table.private",
      "aws_vpc_endpoint.s3_endpoint"
    ],
    "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association": [
      "aws_route_table.public",
      "aws_vpc_endpoint.s3_endpoint"
    ],
    "aws_vpc_endpoint.dynamodb_endpoint": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association": [
      "aws_route_table.private",
      "aws_vpc_endpoint.dynamodb_endpoint"
    ],
    "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association": [
      "aws_vpc_endpoint.dynamodb_endpoint",
      "aws_route_table.public"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc.vpc",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks": [
      "aws_vpc.vpc",
      "aws_servicequotas_service_quota.vpc"
    ],
    "aws_route.private_nat_gateway": [
      "aws_route_table.private",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_route.private_cloudWAN": [
      "aws_route_table.private"
    ],
    "aws_route.public_internet_gateway": [
      "aws_route_table.public",
      "aws_internet_gateway.internet_gateway"
    ],
    "aws_route.rfc-1918-public": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_route_table.public",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_route.rfc-1918-private": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_route_table.private",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_route_table_association.private": [
      "aws_route_table.private",
      "aws_subnet.private"
    ],
    "aws_route_table_association.public": [
      "aws_subnet.public",
      "aws_route_table.public"
    ],
    "aws_route_table_association.ecs": [
      "aws_route_table.private",
      "aws_subnet.ecs"
    ],
    "aws_network_interface.network_interface": [
      "aws_subnet.public"
    ],
    "aws_route53profiles_association.centralized-endpoints-profile-association": [
      "aws_vpc.vpc"
    ],
    "aws_network_acl.network_acl": [
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr"
    ],
    "aws_network_acl_rule.Allow_10_egress_acl_rule": [
      "aws_vpc.vpc",
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_20_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_30_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_40_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_50_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_60_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_10_ingress_acl_rule": [
      "aws_vpc.vpc",
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_20_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_30_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_40_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_50_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_60_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_subnet.public",
      "aws_eip.eip",
      "aws_internet_gateway.internet_gateway"
    ],
    "aws_security_group_rule.inside_ingress_grafana_cloud_agent": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_ne": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.dmz_egress_default": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_http": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_https": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_icmp": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_egress_default": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_http": [
      "aws_security_group.dmz",
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_https": [
      "aws_security_group.dmz",
      "aws_ec2_managed_prefix_list.vpn",
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_snmp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_openstack": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_ssh": [
      "aws_security_group.inside",
      "aws_ec2_managed_prefix_list.vpn",
      "aws_ec2_managed_prefix_list.eks_extended_subnets"
    ],
    "aws_security_group_rule.inside_ingress_serf_tcp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_serf_udp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_icmp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.vpn_egress": [
      "aws_security_group.vpn"
    ],
    "aws_security_group_rule.vpn_ingress": [
      "aws_security_group.vpn"
    ],
    "aws_security_group_rule.vpn_ingress_icmp": [
      "aws_security_group.vpn"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_dhcp_options_association.dhcp_options_association": [
      "aws_vpc.vpc",
      "aws_vpc_dhcp_options.dhcp_options"
    ],
    "aws_flow_log.vpc_flow_log": [
      "aws_vpc.vpc"
    ]
  },
  "dependents": {
    "aws_vpc.vpc": [
      "aws_internet_gateway.internet_gateway",
      "aws_vpc_endpoint.s3_endpoint",
      "aws_vpc_endpoint.dynamodb_endpoint",
      "aws_security_group.endpoint-sg",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks",
      "aws_route53profiles_association.centralized-endpoints-profile-association",
      "aws_network_acl_rule.Allow_10_egress_acl_rule",
      "aws_network_acl_rule.Allow_10_ingress_acl_rule",
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr",
      "aws_vpc_dhcp_options_association.dhcp_options_association",
      "aws_flow_log.vpc_flow_log"
    ],
    "aws_route_table.private": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association",
      "aws_route.private_nat_gateway",
      "aws_route.private_cloudWAN",
      "aws_route.rfc-1918-private",
      "aws_route_table_association.private",
      "aws_route_table_association.ecs"
    ],
    "aws_vpc_endpoint.s3_endpoint": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association"
    ],
    "aws_route_table.public": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association",
      "aws_route.public_internet_gateway",
      "aws_route.rfc-1918-public",
      "aws_route_table_association.public"
    ],
    "aws_vpc_endpoint.dynamodb_endpoint": [
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association"
    ],
    "aws_ec2_managed_prefix_list.rfc-1918": [
      "aws_security_group.endpoint-sg",
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_subnet.private": [
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_route_table_association.private"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint"
    ],
    "aws_servicequotas_service_quota.vpc": [
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_route.private_nat_gateway"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_route.public_internet_gateway",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_networkmanager_vpc_attachment.vpc_attachment": [
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_subnet.public": [
      "aws_route_table_association.public",
      "aws_network_interface.network_interface",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_subnet.ecs": [
      "aws_route_table_association.ecs"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl.network_acl": [
      "aws_network_acl_rule.Allow_10_egress_acl_rule",
      "aws_network_acl_rule.Allow_20_egress_acl_rule",
      "aws_network_acl_rule.Deny_30_egress_acl_rule",
      "aws_network_acl_rule.Deny_40_egress_acl_rule",
      "aws_network_acl_rule.Deny_50_egress_acl_rule",
      "aws_network_acl_rule.Allow_60_egress_acl_rule",
      "aws_network_acl_rule.Allow_10_ingress_acl_rule",
      "aws_network_acl_rule.Allow_20_ingress_acl_rule",
      "aws_network_acl_rule.Deny_30_ingress_acl_rule",
      "aws_network_acl_rule.Deny_40_ingress_acl_rule",
      "aws_network_acl_rule.Deny_50_ingress_acl_rule",
      "aws_network_acl_rule.Allow_60_ingress_acl_rule"
    ],
    "aws_eip.eip": [
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_security_group.inside": [
      "aws_security_group_rule.inside_ingress_grafana_cloud_agent",
      "aws_security_group_rule.inside_ingress_ne",
      "aws_security_group_rule.inside_egress_default",
      "aws_security_group_rule.inside_ingress_http",
      "aws_security_group_rule.inside_ingress_https",
      "aws_security_group_rule.inside_ingress_snmp",
      "aws_security_group_rule.inside_ingress_openstack",
      "aws_security_group_rule.inside_ingress_ssh",
      "aws_security_group_rule.inside_ingress_serf_tcp",
      "aws_security_group_rule.inside_ingress_serf_udp",
      "aws_security_group_rule.inside_ingress_icmp"
    ],
    "aws_security_group.dmz": [
      "aws_security_group_rule.dmz_egress_default",
      "aws_security_group_rule.dmz_ingress_http",
      "aws_security_group_rule.dmz_ingress_https",
      "aws_security_group_rule.dmz_ingress_icmp",
      "aws_security_group_rule.inside_ingress_http",
      "aws_security_group_rule.inside_ingress_https"
    ],
    "aws_ec2_managed_prefix_list.vpn": [
      "aws_security_group_rule.inside_ingress_https",
      "aws_security_group_rule.inside_ingress_ssh"
    ],
    "aws_ec2_managed_prefix_list.eks_extended_subnets": [
      "aws_security_group_rule.inside_ingress_ssh"
    ],
    "aws_security_group.vpn": [
      "aws_security_group_rule.vpn_egress",
      "aws_security_group_rule.vpn_ingress",
      "aws_security_group_rule.vpn_ingress_icmp"
    ],
    "aws_vpc_dhcp_options.dhcp_options": [
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ]
  },
  "cross_repo_references": [
    "external.security_group_rule_vpn_cidr_blocks",
    "external.dhcp_options_domain_name",
    "external.cloud_wan_core_network_id",
    "external.enable_ue1_az3",
    "external.security_group_rule_inside_cidr_blocks",
    "external.aws_availability_zones.good_zone_ids",
    "external.vpc_cidr_block",
    "external.eip_timeout_read",
    "external.enable_ecs_subnet",
    "external.cloudwatch_logs_endpoint_type",
    "external.endpoint_timeout_create",
    "external.availability_zone_count",
    "external.tag_name",
    "external.aws_region",
    "external.eip_timeout_update",
    "external.tag_cloud_wan_segment",
    "external.tag_environment",
    "external.aws_availability_zones.availability_zones",
    "external.aws_ec2_managed_prefix_list.eks_extended_subnets",
    "external.enable_cloud_wan_vpc_attachment",
    "external.enable_cgnat_subnet",
    "external.enable_centralized_endpoints_profile",
    "external.aws_ec2_managed_prefix_list.vpn",
    "external.aws_caller_identity.current",
    "external.ecr_endpoint_type",
    "external.eip_timeout_delete",
    "external.endpoint_timeout_delete",
    "external.dhcp_options_domain_name_servers",
    "external.endpoint_timeout_update",
    "external.enable_local_managed_prefix_lists"
  ],
  "outputs": [
    "aws_vpc_dhcp_options",
    "aws_vpc_dhcp_options_association",
    "aws_eip",
    "aws_vpc_endpoint",
    "aws_vpc_endpoint_route_table_association",
    "aws_internet_gateway",
    "aws_nat_gateway",
    "aws_network_interface",
    "aws_security_group_dmz",
    "aws_security_group_rule_dmz_egress_default",
    "aws_security_group_rule_dmz_ingress_http",
    "aws_security_group_rule_dmz_ingress_https",
    "aws_security_group_rule_dmz_ingress_icmp",
    "aws_security_group_inside",
    "aws_security_group_rule_inside_egress_default",
    "aws_security_group_rule_inside_ingress_http",
    "aws_security_group_rule_inside_ingress_https",
    "aws_security_group_rule_inside_ingress_snmp",
    "aws_security_group_rule_inside_ingress_openstack",
    "aws_security_group_rule_inside_ingress_ssh",
    "aws_security_group_rule_inside_ingress_serf_tcp",
    "aws_security_group_rule_inside_ingress_serf_udp",
    "aws_security_group_rule_inside_ingress_icmp",
    "aws_security_group_rule_inside_ingress_grafana_cloud_agent",
    "aws_security_group_rule_inside_ingress_ne",
    "aws_security_group_vpn",
    "aws_security_group_rule_vpn_egress",
    "aws_security_group_rule_vpn_ingress",
    "aws_security_group_rule_vpn_ingress_icmp",
    "aws_subnet_private",
    "aws_subnet_public",
    "aws_subnetecs",
    "aws_vpc",
    "vpc_id",
    "cidrsubnets",
    "local_secondary_eks_cidr",
    "local_networks",
    "aws_vpc_ipv4_cidr_block_association_secondary_cidr_eks",
    "aws_servicequotas_service_quota_vpc",
    "aws_subnet_eks",
    "good_zone_ids",
    "aws_ec2_managed_prefix_list_vpn",
    "aws_ec2_managed_prefix_list_eks_extended_subnets",
    "aws_networkmanager_vpc_attachment"
  ],
  "metadata": {
    "total_resources": 72,
    "resources_with_dependencies": 56,
    "resources_that_are_dependencies": 23,
    "cross_repo_refs_count": 30,
    "outputs_count": 44,
    "generated_from": ".",
    "repo_name": ""
  }
}

================
File: vpc/.gitignore
================
.terraform*
!.terraform-version
crash.log
terraform.tfstate*
node_modules/
typescript

================
File: vpc/.pre-commit-config.yaml
================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: trailing-whitespace
        args: ["--markdown-linebreak-ext=md"]
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: detect-private-key
      - id: detect-aws-credentials
        args: ["--allow-missing-credentials"]
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.99.0
    hooks:
      - id: terraform_fmt
      - id: terraform_docs
        args:
          - "--args=--lockfile=false"
      - id: terraform_validate
        exclude: deploy
      - id: terraform_tflint
        args:
          - "--args=--only=terraform_deprecated_interpolation"
          - "--args=--only=terraform_deprecated_index"
          - "--args=--only=terraform_unused_declarations"
          - "--args=--only=terraform_comment_syntax"
          # - "--args=--only=terraform_typed_variables"
          - "--args=--only=terraform_module_pinned_source"
          - "--args=--only=terraform_unused_required_providers"

================
File: vpc/.releaserc
================
{
  "branches": [
    "main"
  ],
  "plugins": [
    "@semantic-release/commit-analyzer",
    [
      "semantic-release-jira-notes",
      {
        "jiraHost": "drillinginfo.atlassian.net",
        "ticketPrefixes": [
          "SRE",
          "NEXUS"
        ],
        "preset": "conventionalcommits",
        "presetConfig": {
          "types": [
            {
              "type": "feat",
              "section": "Features"
            },
            {
              "type": "fix",
              "section": "Bug Fixes"
            },
            {
              "type": "revert",
              "section": "Reverts"
            },
            {
              "type": "chore",
              "section": "Miscellaneous Chores"
            }
          ]
        }
      }
    ],
    [
      "@semantic-release/github"
    ],
    [
      "@semantic-release/changelog",
      {
        "changelogFile": "CHANGELOG.md"
      }
    ],
    [
      "@semantic-release/git",
      {
        "assets": [
          "CHANGELOG.md"
        ]
      }
    ],
    [
      "semantic-release-ms-teams",
      {
        "webhookUrl": "https://drillinginfo.webhook.office.com/webhookb2/4a035bb2-7aab-4668-879e-6d7add60a35c@61f90f11-8d76-4b05-9b09-90af7d07328a/IncomingWebhook/6b77492907c740cb862c5f5af3d72eab/bdd3e6a1-7ee8-4ae1-a516-ceccd765cc86",
        "title": "A new version of sre.tf-modules.aws-vpc has been released",
        "imageUrl": "https://blogs.vmware.com/cloudprovider/files/2019/04/og-image-8b3e4f7d-blog-aspect-ratio.png",
        "showContributors": true,
        "notifyInDryRun": false
      }
    ]
  ]
}

================
File: vpc/.semver-output
================
[7:50:42 PM] [semantic-release]    Published release 2.11.1 on default channel

================
File: vpc/.terraform-version
================
latest:^1.5

================
File: vpc/CHANGELOG.md
================
## [2.11.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.11.0...v2.11.1) (2025-07-29)


### Bug Fixes

* **[SRE-15416](https://drillinginfo.atlassian.net/browse/SRE-15416):** Updated to remove unnecessary provider dependancy. ([#75](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/75)) ([624715e](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/624715e9738ada56788230fd29eae0fe1cce7474))


### Miscellaneous Chores

* update  to 2.11.1 [skip ci] ([f8ac771](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/f8ac771d064fdcb75153022c479cc3568f6ecf4c))

## [2.11.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.10.2...v2.11.0) (2025-07-28)


### Features

* **[SRE-15386](https://drillinginfo.atlassian.net/browse/SRE-15386):** Updated VPC module to work with Route 53 Profiles for centralized endpoint access. ([#73](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/73)) ([fa38508](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/fa38508ba3a5bd65c40270ebc37911891c06eccc))


### Miscellaneous Chores

* update  to 2.11.0 [skip ci] ([3e568aa](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/3e568aa2e8419fe2c946320d17ed8b97ba3fb8e6))

## [2.10.2](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.10.1...v2.10.2) (2025-07-22)


### Bug Fixes

* **[SRE-15378](https://drillinginfo.atlassian.net/browse/SRE-15378):** Associate public route tables and add tags for S3 and DynamoDB gateway endpoints. ([#72](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/72)) ([0b5590d](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/0b5590d231542fa3d85f6e3aa9cee2b33403c701))


### Miscellaneous Chores

* update  to 2.10.2 [skip ci] ([09f1202](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/09f120252eaaf66ca8b11c7b5a0dcc354dc19511))

## [2.10.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.10.0...v2.10.1) (2025-07-17)


### Bug Fixes

* **[SRE-15165](https://drillinginfo.atlassian.net/browse/SRE-15165):** added enable_ue1_az3 flag to determine which availability zones to use for subnets. ([#71](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/71)) ([99fe4b9](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/99fe4b9f6d5289fe5ecfe5325aa4a3f4fd588402))


### Miscellaneous Chores

* update  to 2.10.1 [skip ci] ([aebd0ec](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/aebd0ec688e4b9a5d583f96c006146db26028499))

## [2.10.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.9.0...v2.10.0) (2025-07-15)


### Features

* **[SRE-15167](https://drillinginfo.atlassian.net/browse/SRE-15167):** Adding Private Hosted Zone association and endpoint creation logic. ([#70](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/70)) ([16b2be8](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/16b2be8ebdf9f919b5e1fd84366e91c36d670c88))


### Miscellaneous Chores

* update  to 2.10.0 [skip ci] ([e755069](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/e755069f9a09bfbe2e12c8cae90c8bd4211a1d55))

## [2.9.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.8.0...v2.9.0) (2024-07-24)


### Features

* **[SRE-13395](https://drillinginfo.atlassian.net/browse/SRE-13395):** update to allow keeping local mpl ([#69](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/69)) ([d21173f](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/d21173f43348cb2248e590539081a48379d894bf))


### Miscellaneous Chores

* update  to 2.9.0 [skip ci] ([ccd2518](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/ccd2518554236cde1569301e8bcc0783a229f5dc))

## [2.8.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.7.3...v2.8.0) (2024-07-18)


### Features

* **[SRE-13395](https://drillinginfo.atlassian.net/browse/SRE-13395):** use shared mananged prefix lists ([#68](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/68)) ([81a39c6](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/81a39c6762e04239cb64d1464c0e323af7b49627))


### Miscellaneous Chores

* update  to 2.8.0 [skip ci] ([1bf6216](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/1bf6216cbac9d679dbc5273494fed9d070f7fc47))

## [2.7.3](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.7.2...v2.7.3) (2024-04-05)


### Bug Fixes

* **[SRE-12766](https://drillinginfo.atlassian.net/browse/SRE-12766)-2:** update number of prefix lists entries ([#67](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/67)) ([3d73b04](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/3d73b04fc87abf1766093f0fc32b9ef782a015cf))


### Miscellaneous Chores

* update  to 2.7.3 [skip ci] ([9f8a5bc](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/9f8a5bcfcf4efcff689787b8a7e55d5d75ab83b1))

## [2.7.2](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.7.1...v2.7.2) (2024-04-05)


### Bug Fixes

* **[SRE-12766](https://drillinginfo.atlassian.net/browse/SRE-12766):** Fix prefix list to add in 100.64 CIDR blocks.  Update Public Route tables to put prefix list down cloudwan connection ([#66](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/66)) ([caaa45f](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/caaa45f065cab8cfbf0440e4662560c1db041065))


### Miscellaneous Chores

* update  to 2.7.2 [skip ci] ([994fe43](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/994fe43eee98a94220c89510174812ba4604ed73))

## [2.7.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.7.0...v2.7.1) (2024-02-21)


### Bug Fixes

* **[SRE-12681](https://drillinginfo.atlassian.net/browse/SRE-12681):** Allow CloudWAN CoreNetworkID to be a null value ([#63](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/63)) ([fc18a4b](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/fc18a4b080f39a4a7473d2a1322fd65dfdd55c79))
* **[SRE-12681](https://drillinginfo.atlassian.net/browse/SRE-12681):** update minimum terraform versions ([#65](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/65)) ([e3bb042](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/e3bb042b1f6a668e17e4e4371de8caa6414955ad))


### Miscellaneous Chores

* update  to 2.7.1 [skip ci] ([3b5c67a](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/3b5c67a7732974b386f0883bb010fee88382520b))

## [2.7.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.6.1...v2.7.0) (2024-02-15)


### Features

* **[SRE-12632](https://drillinginfo.atlassian.net/browse/SRE-12632):** Update VPN names and remove pulse entry ([#62](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/62)) ([f566b70](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/f566b702e34e048385c1300370b0375e2351d8f2))


### Reverts

* Revert "chore(release): 2.6.1 [skip ci]" ([84746ea](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/84746ea9ee04f7aa362313bf450ae87624f2f684))


### Miscellaneous Chores

* **[SRE-12632](https://drillinginfo.atlassian.net/browse/SRE-12632):** Update VPN names to reflect site ([3b0d9aa](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/3b0d9aab1146a498a5cf7e39f2b6704bf8b148eb))
* update  to 2.7.0 [skip ci] ([41de451](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/41de451748d18622644ca7a4dab66cb47ecc7347))

## [2.6.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.5.0...v2.6.0) (2024-02-09)


### Features

* **[SRE-12632](https://drillinginfo.atlassian.net/browse/SRE-12632):** Apply new vpc-module to allow access from NewVPN ([#59](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/59)) ([d4c5f72](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/d4c5f7231c5f3358065db32ac505ead7ed4a52d5))


### Miscellaneous Chores

* update  to 2.6.0 [skip ci] ([16cc41c](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/16cc41c85bce80719e867db20d6f53308be06330))

## [2.5.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.4.3...v2.5.0) (2024-02-09)


### Features

* **[SRE-12632](https://drillinginfo.atlassian.net/browse/SRE-12632):** Add NewVPN to prefixlist to allow ([#58](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/58)) ([28c5fa0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/28c5fa0c12f24c0be45c240c42e7749ff766878d))


### Miscellaneous Chores

* **[SRE-12367](https://drillinginfo.atlassian.net/browse/SRE-12367):** add dependabot ([#55](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/55)) ([0facd7b](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/0facd7ba3f114d5dab1a9c5a40941b79aa4ffbb3))
* **[SRE-12522](https://drillinginfo.atlassian.net/browse/SRE-12522):** Updated Semantic Release add Jira ([#56](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/56)) ([4e16765](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/4e16765b24da9fad449d812f81f9c8e5696bcb22))
* **[SRE-12541](https://drillinginfo.atlassian.net/browse/SRE-12541):** Add ci action and pr label action ([#57](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/57)) ([0d816f1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/0d816f1c74d02d9cd86dd71d57ad7af683242fe3))
* update  to 2.5.0 [skip ci] ([250f282](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/250f2820c4418a8e188f9d908f98cce9c648b988))

## [2.4.1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.4.0...v2.4.1) (2023-09-26)


### Bug Fixes

* **SRE-12121:** fix variable reference ([#52](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/52)) ([9fec195](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/9fec1952fed3675b58e1bbd817f506ac3118ede1))

# [2.4.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.3.0...v2.4.0) (2023-09-14)


### Features

* add in flowlogs to central bucket ([#51](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/51)) ([d6a830d](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/d6a830d8a6110f8eb86c2b819ee45ae633194d13))

# [2.3.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.2.0...v2.3.0) (2023-09-13)


### Features

* **SRE-11976:** add in cloudwan Routing ([#50](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/50)) ([db068f8](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/db068f8eaf03e33e89ae4d0707435f87ffc2e6ae))

# [2.2.0](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/compare/v2.1.0...v2.2.0) (2023-07-31)


### Bug Fixes

* **SRE-11428:** Updated CIDR range for Avanti ([#38](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/38)) ([a8c2c92](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/a8c2c924684a86496b375ea625698d0fad89ed3d))
* **SRE-11530:** cloudwan get  private subnet from vpc create ([#42](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/42)) ([40e8bca](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/40e8bca8d2f62d3a1354a3d4a038df0c361e3bce))
* **SRE-11530:** default null for cloud-wan vars ([#41](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/41)) ([acc9938](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/acc9938a6e7ecd3bea78550755568a41f1a99633))


### Features

* **SRE-11530:** Added flag to turn on VPC attachment to cloud-wan. ([#39](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/39)) ([0ef1765](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/0ef1765f41a6e493cbbc8ad2b016142c59a1f573))
* **SRE-11650:** Add `Vpc` tag to prefix lists ([#48](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/issues/48)) ([06438e1](https://github.com/enverus-cts/sre.tf-modules.aws-vpc/commit/06438e18e55cc783affdccd6ddcb19071cea5cdc))

## Unreleased

* Enable DNS Hostnames

## 1.1.0 (2019-06-10)

* Remove Customer Gateway and VPW resources


## 1.0.0 (2019-06-05)

* Remove Transit Gateway resources (Created with Aviatrix)


## 0.0.4 (2019-06-04)

* Use dynamic routing for VPN connections
* Set default BGP ASN for Customer Gateways


## 0.0.3 (2019-04-25)

* Use boolean comparison where applicable
* Separate examples for vpc with(out) attaching to a transit gateway
* Remove provider block from module


## 0.0.2 (2019-04-09)

* Add VPN security group
* Add missing `aws_security_group_rule` resources for the INSIDE security group
* Add variables for CIDR blocks used in security group rule resources
* Remove variables for the description argument of the `aws_security_group` resource
* Add variables `customer_gateway_bgp_asn` and `customer_gateway_ip_address`
* Add data source `aws_ec2_transit_gateway` conditionally for variable `attach_transit_gateway`
* Add a route, conditionally, on each private route table for the transit gateway
* Add transit gateway attachment (conditionally)
* Update the example to test transit gateway attachment


## 0.0.1 (2019-03-28)

* Initial Release

================
File: vpc/clould-wan.tf
================
# Core Network policy attachment

resource "aws_networkmanager_vpc_attachment" "vpc_attachment" {
  count           = var.cloud_wan_core_network_id == null ? 0 : 1
  subnet_arns     = aws_subnet.private[*].arn
  core_network_id = var.cloud_wan_core_network_id
  vpc_arn         = aws_vpc.vpc.arn

  tags = {
    cloud-wan = var.tag_cloud_wan_segment
    Name      = "${var.tag_environment}-${data.aws_caller_identity.current.id}-${var.tag_name}"
  }
  depends_on = [aws_vpc.vpc]
}

output "aws_networkmanager_vpc_attachment" { value = aws_networkmanager_vpc_attachment.vpc_attachment }

================
File: vpc/data_sources.tf
================
data "aws_availability_zones" "availability_zones" {}

data "aws_availability_zones" "good_zone_ids" {
  exclude_zone_ids = [
    # There are no modern instance types in use1-az3; AWS has left
    # that zone behind for the most part.  See, for example, here:
    # https://www.reddit.com/r/aws/comments/g5lh7h/t3m5r5_instance_types_in_use1az3/
    "use1-az3",
  ]
  state = "available"
}
# output "good_zone_ids" { value = data.aws_availability_zones.good_zone_ids }

data "aws_caller_identity" "current" {}

data "aws_ec2_managed_prefix_list" "rfc-1918" {
  name = "All RFC-1918 CIDR-s - shared"
}

data "aws_route53profiles_profiles" "centralized-endpoints-profile" {}

================
File: vpc/dhcp_options.tf
================
resource "aws_vpc_dhcp_options" "dhcp_options" {
  domain_name         = var.dhcp_options_domain_name
  domain_name_servers = var.dhcp_options_domain_name_servers

  tags = {
    Component = "dhcp-options"
    Name      = var.tag_name
  }
}

resource "aws_vpc_dhcp_options_association" "dhcp_options_association" {
  dhcp_options_id = aws_vpc_dhcp_options.dhcp_options.id
  vpc_id          = aws_vpc.vpc.id
}

================
File: vpc/eks_cgnat.tf
================
locals {
  ## Splits a Carrier Grade NAT range into /19 (3 bits of /16). Excludes the first /18 (100.64.0.0-100.64.32.255) due to clash with pre-existing vpc-peers
  cidrsubnets = cidrsubnets("100.64.0.0/16", 2, 3, 3, 3, 3, 3, 3)

  ## Excludes the first /18 (100.64.0.0-100.64.32.255) due to clash with pre-existing vpc-peers
  length_availability_zones = length(data.aws_availability_zones.good_zone_ids.zone_ids)
  secondary_eks_cidr        = toset(slice(local.cidrsubnets, 1, "${local.length_availability_zones}" + 1))
  networks = { for key, cidr in keys(aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks) :
    cidr => {
      key        = key
      cidr_block = aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks[cidr].cidr_block
      id         = aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks[cidr].id
      vpc_id     = aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks[cidr].vpc_id

      zone_id   = data.aws_availability_zones.good_zone_ids.zone_ids[key]
      zone_name = data.aws_availability_zones.good_zone_ids.names[key]
    }
  }

}
# output "cidrsubnets" { value = local.cidrsubnets }
output "local_secondary_eks_cidr" { value = local.secondary_eks_cidr }
output "local_networks" { value = local.networks }

resource "aws_vpc_ipv4_cidr_block_association" "secondary_cidr_eks" {
  for_each = var.enable_cgnat_subnet == true ? local.secondary_eks_cidr : toset([])

  vpc_id     = aws_vpc.vpc.id
  cidr_block = each.key

  depends_on = [
    aws_servicequotas_service_quota.vpc,
  ]
}
output "aws_vpc_ipv4_cidr_block_association_secondary_cidr_eks" { value = aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks }

resource "aws_servicequotas_service_quota" "vpc" {
  count = var.enable_cgnat_subnet ? 1 : 0

  quota_code   = "L-83CA0A9D"
  service_code = "vpc"
  value        = 10
}
output "aws_servicequotas_service_quota_vpc" { value = aws_servicequotas_service_quota.vpc }

resource "aws_subnet" "eks" {
  for_each = local.networks

  availability_zone_id                = each.value.zone_id
  cidr_block                          = each.value.cidr_block
  vpc_id                              = each.value.vpc_id
  private_dns_hostname_type_on_launch = "resource-name"

  tags = {
    Name                                     = "${var.tag_name} | ${each.value.zone_name} | INSIDE-POD-SECONDARY | EKS Subnet"
    Component                                = "subnet"
    "failure-domain.beta.kubernetes.io/zone" = each.value.zone_name
  }
}
output "aws_subnet_eks" { value = aws_subnet.eks }

================
File: vpc/elastic_ips.tf
================
resource "aws_eip" "eip" {
  # Disabled to retain the existing EIP's in case they are needed.  This can be enabled after 180 days of CloudWAN
  #count  = enable_cloud_wan_vpc_attachment == false ? local.az_count : 0
  count  = local.az_count
  domain = "vpc"

  tags = {
    Component = "elastic-ip"
    Name      = var.tag_name
  }

  timeouts {
    delete = var.eip_timeout_delete
    read   = var.eip_timeout_read
    update = var.eip_timeout_update
  }
}

================
File: vpc/endpoints.tf
================
resource "aws_vpc_endpoint" "s3_endpoint" {
  service_name = "com.amazonaws.${var.aws_region}.s3"
  vpc_id       = aws_vpc.vpc.id

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }

  tags = {
    Name      = "S3 Endpoint"
    Component = "vpc-endpoint"
  }
}

resource "aws_vpc_endpoint_route_table_association" "s3_endpoint_route_table_association" {
  count           = local.az_count
  route_table_id  = element(aws_route_table.private.*.id, count.index)
  vpc_endpoint_id = aws_vpc_endpoint.s3_endpoint.id
}

resource "aws_vpc_endpoint_route_table_association" "s3_endpoint_public_route_table_association" {
  route_table_id  = aws_route_table.public.id
  vpc_endpoint_id = aws_vpc_endpoint.s3_endpoint.id
}

resource "aws_vpc_endpoint" "dynamodb_endpoint" {
  service_name = "com.amazonaws.${var.aws_region}.dynamodb"
  vpc_id       = aws_vpc.vpc.id

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }

  tags = {
    Name      = "DynamoDB Endpoint"
    Component = "vpc-endpoint"
  }
}

resource "aws_vpc_endpoint_route_table_association" "dynamodb_endpoint_route_table_association" {
  count           = local.az_count
  route_table_id  = element(aws_route_table.private.*.id, count.index)
  vpc_endpoint_id = aws_vpc_endpoint.dynamodb_endpoint.id
}

resource "aws_vpc_endpoint_route_table_association" "dynamodb_endpoint_public_route_table_association" {
  route_table_id  = aws_route_table.public.id
  vpc_endpoint_id = aws_vpc_endpoint.dynamodb_endpoint.id
}

# Security group to allow endpoint access
resource "aws_security_group" "endpoint-sg" {
  name        = "EndpointSecurityGroup"
  description = "Security group for VPC endpoints access"
  vpc_id      = aws_vpc.vpc.id

  ingress {
    description     = "Allow all inbound traffic from prefix list"
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    prefix_list_ids = [data.aws_ec2_managed_prefix_list.rfc-1918.id]
  }

  egress {
    description = "Allow all outbound traffic"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

}

# ECR Docker Registry Endpoint
resource "aws_vpc_endpoint" "ecr_dkr_endpoint" {
  count               = var.ecr_endpoint_type ? 1 : 0
  service_name        = "com.amazonaws.${var.aws_region}.ecr.dkr"
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = true
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = "ECR DKR Endpoint"
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

# CloudWatch Logs Endpoint
resource "aws_vpc_endpoint" "cloudwatch_logs_endpoint" {
  count               = var.cloudwatch_logs_endpoint_type ? 1 : 0
  service_name        = "com.amazonaws.${var.aws_region}.logs"
  vpc_id              = aws_vpc.vpc.id
  vpc_endpoint_type   = "Interface"
  private_dns_enabled = true
  subnet_ids          = aws_subnet.private[*].id

  security_group_ids = [
    aws_security_group.endpoint-sg.id
  ]

  tags = {
    Name      = "CloudWatch Logs Endpoint"
    Component = "vpc-endpoint"
  }

  timeouts {
    create = var.endpoint_timeout_create
    delete = var.endpoint_timeout_delete
    update = var.endpoint_timeout_update
  }
}

================
File: vpc/flowlogs.tf
================
resource "aws_flow_log" "vpc_flow_log" {
  log_destination      = "arn:aws:s3:::enverus-central-logs"
  log_destination_type = "s3"
  traffic_type         = "ALL"
  vpc_id               = resource.aws_vpc.vpc.id
  destination_options {
    per_hour_partition = true
    file_format        = "parquet"
  }
  tags = {
    Name = "VPC Flow Log to central"
  }
}

================
File: vpc/internet_gateways.tf
================
resource "aws_internet_gateway" "internet_gateway" {
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "internet-gateway"
    Name      = var.tag_name
  }
}

================
File: vpc/locals.tf
================
locals {
  az_count                 = var.availability_zone_count != null ? var.availability_zone_count : length(var.enable_ue1_az3 ? data.aws_availability_zones.availability_zones.zone_ids : data.aws_availability_zones.good_zone_ids.zone_ids)
  new_bits                 = local.az_count == 1 ? 0 : local.az_count == 2 ? 1 : local.az_count <= 4 ? 2 : 3
  even_private_supernet    = local.az_count == 1 || local.az_count == 2 || local.az_count == 4 || local.az_count == 8 ? cidrsubnet(aws_vpc.vpc.cidr_block, 1, 0) : ""
  odd_private_supernet     = local.az_count == 3 || local.az_count == 5 || local.az_count == 6 || local.az_count == 7 ? aws_vpc.vpc.cidr_block : ""
  even_public_supernet     = local.az_count == 1 || local.az_count == 2 || local.az_count == 4 || local.az_count == 8 ? cidrsubnet(aws_vpc.vpc.cidr_block, 1, 1) : ""
  three_public_supernet    = local.az_count == 3 ? cidrsubnet(aws_vpc.vpc.cidr_block, 2, 3) : ""
  five_six_public_supernet = local.az_count == 5 || local.az_count == 6 ? cidrsubnet(cidrsubnet(aws_vpc.vpc.cidr_block, 3, 6), -1, 0) : ""
  seven_public_supernet    = local.az_count == 7 ? cidrsubnet(aws_vpc.vpc.cidr_block, 3, 7) : ""
  private_supernet         = coalesce(local.even_private_supernet, local.odd_private_supernet)
  public_supernet = coalesce(
    local.even_public_supernet,
    local.three_public_supernet,
    local.five_six_public_supernet,
    local.seven_public_supernet,
  )
  # This is used to determine which availability zones to use based on the enable_ue1_az3 flag.
  aws_availability_zones = var.enable_ue1_az3 ? data.aws_availability_zones.availability_zones.zone_ids : data.aws_availability_zones.good_zone_ids.zone_ids

  centralized_endpoints_profile = [
    for profile in data.aws_route53profiles_profiles.centralized-endpoints-profile.profiles :
    profile if profile.name == "centralized-endpoints-profile"
  ][0]
}

================
File: vpc/Makefile
================
.PHONY: gen _gen-main _gen-examples _gen-modules

CURRENT_DIR     = $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
TF_EXAMPLES     = $(sort $(dir $(wildcard $(CURRENT_DIR)examples/*/)))
TF_MODULES      = $(sort $(dir $(wildcard $(CURRENT_DIR)modules/*/)))
TF_DOCS_VERSION = 0.16.0

# Updated to match your README.md delimiters
DELIM_START = <!-- BEGIN_TF_DOCS -->
DELIM_CLOSE = <!-- END_TF_DOCS -->

gen:
	@echo "################################################################################"
	@echo "# Terraform-docs generate"
	@echo "################################################################################"
	@$(MAKE) _gen-main

_gen-main:
	@echo "------------------------------------------------------------"
	@echo "# Main module"
	@echo "------------------------------------------------------------"
	@if docker run --rm \
		-v $(CURRENT_DIR):/data \
		-e DELIM_START='$(DELIM_START)' \
		-e DELIM_CLOSE='$(DELIM_CLOSE)' \
		cytopia/terraform-docs:${TF_DOCS_VERSION} \
		terraform-docs-replace-012 md README.md; then \
		echo "OK"; \
	else \
		echo "Failed"; \
		exit 1; \
	fi

================
File: vpc/nacl.tf
================
#NACLS#
locals {
  nacls = 1
}
resource "aws_network_acl" "network_acl" {
  count  = var.enable_ecs_subnet == true ? 1 : 0
  vpc_id = aws_vpc_ipv4_cidr_block_association.secondary_cidr[count.index].vpc_id
  tags = {
    Component = "nacl"
    Name      = var.tag_name
  }
}

#Deny all outbound to private IP's
#Deny all inbound from private IP's
#Allow all outbound to internet
#Allow all inbound from VPC CIDR

resource "aws_network_acl_rule" "Allow_10_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 10
  egress         = true
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = aws_vpc.vpc.cidr_block
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Allow_20_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 20
  egress         = true
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = local.ecs_subnet
  depends_on     = [aws_network_acl.network_acl[0]]

}
resource "aws_network_acl_rule" "Deny_30_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 30
  egress         = true
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "10.0.0.0/8"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Deny_40_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 40
  egress         = true
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "172.16.0.0/12"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Deny_50_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 50
  egress         = true
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "192.168.0.0/16"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Allow_60_egress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 60
  egress         = true
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = "0.0.0.0/0"
  depends_on     = [aws_network_acl.network_acl[0]]
}

#Ingress
resource "aws_network_acl_rule" "Allow_10_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 10
  egress         = false
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = aws_vpc.vpc.cidr_block
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Allow_20_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 20
  egress         = false
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = local.ecs_subnet
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Deny_30_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 30
  egress         = false
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "10.0.0.0/8"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Deny_40_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 40
  egress         = false
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "172.16.0.0/12"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Deny_50_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 50
  egress         = false
  protocol       = "-1"
  rule_action    = "deny"
  cidr_block     = "192.168.0.0/16"
  depends_on     = [aws_network_acl.network_acl[0]]
}

resource "aws_network_acl_rule" "Allow_60_ingress_acl_rule" {
  count          = var.enable_ecs_subnet == true ? 1 : 0
  network_acl_id = aws_network_acl.network_acl[0].id
  rule_number    = 60
  egress         = false
  protocol       = "-1"
  rule_action    = "allow"
  cidr_block     = "0.0.0.0/0"
  depends_on     = [aws_network_acl.network_acl[0]]
}

================
File: vpc/nat_gateways.tf
================
resource "aws_nat_gateway" "nat_gateway" {
  depends_on = [aws_internet_gateway.internet_gateway]

  allocation_id = element(aws_eip.eip.*.id, count.index)
  count         = var.enable_cloud_wan_vpc_attachment == false ? local.az_count : 0
  subnet_id     = element(aws_subnet.public.*.id, count.index)

  tags = {
    Component = "nat-gateway"
    Name      = var.tag_name
  }
}

================
File: vpc/network_interfaces.tf
================
resource "aws_network_interface" "network_interface" {
  count       = local.az_count
  description = "Interface for NAT Gateway ${count.index}"
  subnet_id   = element(aws_subnet.public.*.id, count.index)

  tags = {
    Component = "network-interface"
    Name      = var.tag_name
  }
}

================
File: vpc/outputs.tf
================
# DHCP
output "aws_vpc_dhcp_options" {
  description = "VPC DHCP options"
  value       = aws_vpc_dhcp_options.dhcp_options
}

output "aws_vpc_dhcp_options_association" {
  description = "VPC DHCP Options association"
  value       = aws_vpc_dhcp_options_association.dhcp_options_association
}

# EIP
output "aws_eip" {
  description = "Elastic IP's used"
  value       = aws_eip.eip
}

# ENDPOINTS
output "aws_vpc_endpoint" {
  description = "S3 Endpoints"
  value       = aws_vpc_endpoint.s3_endpoint
}

output "aws_vpc_endpoint_route_table_association" {
  description = "Route Table used for S3 endpoint"
  value       = aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association
}

# GATEWAYS
output "aws_internet_gateway" {
  description = "VPC Internet Gateway"
  value       = aws_internet_gateway.internet_gateway
}

output "aws_nat_gateway" {
  description = "VPC NAT Gateway"
  value       = aws_nat_gateway.nat_gateway
}

# NETWORK INTERFACE
output "aws_network_interface" {
  description = "VPC Network Interfaces"
  value       = aws_network_interface.network_interface
}

# SECURITY GROUPS
output "aws_security_group_dmz" {
  description = "DMZ Security Group"
  value       = aws_security_group.dmz
}

output "aws_security_group_rule_dmz_egress_default" {
  description = "DMZ egress default rule"
  value       = aws_security_group_rule.dmz_egress_default
}

output "aws_security_group_rule_dmz_ingress_http" {
  description = "Allow ingress HTTP from inside CIDR."
  value       = aws_security_group_rule.dmz_ingress_http
}

output "aws_security_group_rule_dmz_ingress_https" {
  description = "Allow ingress HTTPS from inside CIDR."
  value       = aws_security_group_rule.dmz_ingress_https
}

output "aws_security_group_rule_dmz_ingress_icmp" {
  description = "Allow ingress ICMP from inside CIDR."
  value       = aws_security_group_rule.dmz_ingress_icmp
}

output "aws_security_group_inside" {
  description = "Inside Security Group"
  value       = aws_security_group.inside
}

output "aws_security_group_rule_inside_egress_default" {
  description = "Allow all egress traffic."
  value       = aws_security_group_rule.inside_egress_default
}

output "aws_security_group_rule_inside_ingress_http" {
  description = "Allow HTTP ingress from inside CIDR."
  value       = aws_security_group_rule.inside_ingress_http
}

output "aws_security_group_rule_inside_ingress_https" {
  description = "Allow HTTPS ingres from inside CIDR."
  value       = aws_security_group_rule.inside_ingress_https
}

output "aws_security_group_rule_inside_ingress_snmp" {
  description = "Allow SNMP ingress from inside CIDR."
  value       = aws_security_group_rule.inside_ingress_snmp
}

output "aws_security_group_rule_inside_ingress_openstack" {
  description = "Allow Openstack inbound from inside CIDR."
  value       = aws_security_group_rule.inside_ingress_openstack
}

output "aws_security_group_rule_inside_ingress_ssh" {
  description = "Allow SSH from inside"
  value       = aws_security_group_rule.inside_ingress_ssh
}

output "aws_security_group_rule_inside_ingress_serf_tcp" {
  description = "Allow inbound tcp Serf traffic. This is the gossip protocol used by Consul."
  value       = aws_security_group_rule.inside_ingress_serf_tcp
}

output "aws_security_group_rule_inside_ingress_serf_udp" {
  description = "Allow inbound udp Serf traffic. This is the gossip protocol used by Consul."
  value       = aws_security_group_rule.inside_ingress_serf_udp
}

output "aws_security_group_rule_inside_ingress_icmp" {
  description = "Allow inbound icmp Serf traffic. This is the gossip protocol used by Consul."
  value       = aws_security_group_rule.inside_ingress_icmp
}

output "aws_security_group_rule_inside_ingress_grafana_cloud_agent" {
  description = "Internal Grafana Agent Security Group"
  value       = aws_security_group_rule.inside_ingress_grafana_cloud_agent
}

output "aws_security_group_rule_inside_ingress_ne" {
  description = "Internal Node Exporter Security Group"
  value       = aws_security_group_rule.inside_ingress_ne
}

output "aws_security_group_vpn" {
  description = "VPN Security Group"
  value       = aws_security_group.vpn
}

output "aws_security_group_rule_vpn_egress" {
  description = "VPN Egress Allow ALL"
  value       = aws_security_group_rule.vpn_egress
}

output "aws_security_group_rule_vpn_ingress" {
  description = "VPN Ingress Allow ALL"
  value       = aws_security_group_rule.vpn_ingress
}

output "aws_security_group_rule_vpn_ingress_icmp" {
  description = "VPN Ingress ICMP"
  value       = aws_security_group_rule.vpn_ingress_icmp
}

# SUBNETS

output "aws_subnet_private" {
  description = "Private subnets"
  value       = aws_subnet.private
}

output "aws_subnet_public" {
  description = "Public Subnets"
  value       = aws_subnet.public
}

output "aws_subnetecs" {
  description = "ECS Subnets"
  value       = aws_subnet.ecs
}

# VPC

output "aws_vpc" {
  description = "Created VPC"
  value       = aws_vpc.vpc
}

output "vpc_id" {
  description = "ID of created VPC."
  value       = aws_vpc.vpc.id
}

================
File: vpc/package.json
================
{
  "devDependencies": {
    "@semantic-release/changelog": "^6.0.3",
    "@semantic-release/commit-analyzer": "^9.0.2",
    "@semantic-release/git": "^10.0.1",
    "@semantic-release/github": "^8.0.7",
    "conventional-changelog-conventionalcommits": "^7.0.2",
    "semantic-release": "^19.0.5",
    "semantic-release-jira-notes": "^3.0.0",
    "semantic-release-ms-teams": "^2.1.0"
  }
}

================
File: vpc/prefix_list.tf
================
resource "aws_ec2_managed_prefix_list" "vpn" {
  count          = var.enable_local_managed_prefix_lists == true ? 1 : 0
  name           = "VPN/Office CIDRs"
  address_family = "IPv4"
  max_entries    = 10

  entry {
    cidr        = "10.8.0.0/16"
    description = "Met2 - Old"
  }

  entry {
    cidr        = "10.150.0.0/16"
    description = "Met2"
  }

  entry {
    cidr        = "10.52.0.0/14"
    description = "DC2"
  }

  entry {
    cidr        = "172.16.0.0/12"
    description = "Branch Offices"
  }

  entry {
    cidr        = "10.54.248.0/21"
    description = "PaloAltoVPN_Virginia"
  }

  entry {
    cidr        = "10.50.248.0/21"
    description = "PaloAltoVPN_Chicago"
  }

  tags = {
    Component = "prefix-list"
    Vpc       = var.tag_name
  }
}
output "aws_ec2_managed_prefix_list_vpn" {
  value = var.enable_local_managed_prefix_lists == true ? aws_ec2_managed_prefix_list.vpn[0] : null
}


resource "aws_ec2_managed_prefix_list" "eks_extended_subnets" {
  count          = var.enable_local_managed_prefix_lists == true ? 1 : 0
  name           = "EKS extended 100.64 Subnets"
  address_family = "IPv4"
  max_entries    = local.length_availability_zones

  dynamic "entry" {
    for_each = local.networks
    content {
      cidr        = entry.value.cidr_block
      description = entry.value.cidr_block
    }
  }

  tags = {
    Component = "prefix-list"
    Vpc       = var.tag_name
  }
}
output "aws_ec2_managed_prefix_list_eks_extended_subnets" {
  value = var.enable_local_managed_prefix_lists == true ? aws_ec2_managed_prefix_list.eks_extended_subnets[0] : null
}

resource "aws_ec2_managed_prefix_list" "rfc-1918" {
  count          = var.enable_local_managed_prefix_lists == true ? 1 : 0
  name           = "All RFC-1918 CIDR-s"
  address_family = "IPv4"
  max_entries    = 10

  entry {
    cidr        = "10.0.0.0/8"
    description = "Primary"
  }

  entry {
    cidr        = "172.16.0.0/12"
    description = "Secondary"
  }
  entry {
    cidr        = "192.168.0.0/16"
    description = "Tertiary"
  }
  entry {
    cidr        = "100.64.0.0/27"
    description = "Overlapping CIDR"
  }
  entry {
    cidr        = "100.64.0.32/27"
    description = "Overlapping CIDR"
  }
}

================
File: vpc/README.md
================
# AWS VPC Terraform Module
## Overview
This module creates the base VPC's used by Enverus, and sets the standards used throughout the AWS environment.  
<!-- BEGIN_TF_DOCS -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.5 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | >= 5.0 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_aws"></a> [aws](#provider\_aws) | >= 5.0 |

## Modules

No modules.

## Resources

| Name | Type |
|------|------|
| [aws_ec2_managed_prefix_list.eks_extended_subnets](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_managed_prefix_list) | resource |
| [aws_ec2_managed_prefix_list.rfc-1918](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_managed_prefix_list) | resource |
| [aws_ec2_managed_prefix_list.vpn](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_managed_prefix_list) | resource |
| [aws_eip.eip](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eip) | resource |
| [aws_flow_log.vpc_flow_log](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/flow_log) | resource |
| [aws_internet_gateway.internet_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway) | resource |
| [aws_nat_gateway.nat_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/nat_gateway) | resource |
| [aws_network_acl.network_acl](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl) | resource |
| [aws_network_acl_rule.Allow_10_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Allow_10_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Allow_20_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Allow_20_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Allow_60_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Allow_60_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_30_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_30_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_40_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_40_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_50_egress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_acl_rule.Deny_50_ingress_acl_rule](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_acl_rule) | resource |
| [aws_network_interface.network_interface](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/network_interface) | resource |
| [aws_networkmanager_vpc_attachment.vpc_attachment](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/networkmanager_vpc_attachment) | resource |
| [aws_route.private_cloudWAN](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.private_nat_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.public_internet_gateway](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.rfc-1918-private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route.rfc-1918-public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route) | resource |
| [aws_route53profiles_association.centralized-endpoints-profile-association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53profiles_association) | resource |
| [aws_route_table.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table) | resource |
| [aws_route_table.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table) | resource |
| [aws_route_table_association.ecs](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association) | resource |
| [aws_route_table_association.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association) | resource |
| [aws_route_table_association.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association) | resource |
| [aws_security_group.dmz](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group) | resource |
| [aws_security_group.endpoint-sg](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group) | resource |
| [aws_security_group.inside](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group) | resource |
| [aws_security_group.vpn](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group) | resource |
| [aws_security_group_rule.dmz_egress_default](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.dmz_ingress_http](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.dmz_ingress_https](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.dmz_ingress_icmp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_egress_default](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_grafana_cloud_agent](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_http](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_https](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_icmp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_ne](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_openstack](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_serf_tcp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_serf_udp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_snmp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.inside_ingress_ssh](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.vpn_egress](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.vpn_ingress](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_security_group_rule.vpn_ingress_icmp](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule) | resource |
| [aws_servicequotas_service_quota.vpc](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/servicequotas_service_quota) | resource |
| [aws_subnet.ecs](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_subnet.eks](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_subnet.private](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_subnet.public](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet) | resource |
| [aws_vpc.vpc](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc) | resource |
| [aws_vpc_dhcp_options.dhcp_options](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_dhcp_options) | resource |
| [aws_vpc_dhcp_options_association.dhcp_options_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_dhcp_options_association) | resource |
| [aws_vpc_endpoint.cloudwatch_logs_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.dynamodb_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.ecr_dkr_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint.s3_endpoint](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint) | resource |
| [aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint_route_table_association) | resource |
| [aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint_route_table_association) | resource |
| [aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint_route_table_association) | resource |
| [aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint_route_table_association) | resource |
| [aws_vpc_ipv4_cidr_block_association.secondary_cidr](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_ipv4_cidr_block_association) | resource |
| [aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_ipv4_cidr_block_association) | resource |
| [aws_availability_zones.availability_zones](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/availability_zones) | data source |
| [aws_availability_zones.good_zone_ids](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/availability_zones) | data source |
| [aws_caller_identity.current](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/caller_identity) | data source |
| [aws_ec2_managed_prefix_list.eks_extended_subnets](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_managed_prefix_list) | data source |
| [aws_ec2_managed_prefix_list.rfc-1918](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_managed_prefix_list) | data source |
| [aws_ec2_managed_prefix_list.vpn](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_managed_prefix_list) | data source |
| [aws_route53profiles_profiles.centralized-endpoints-profile](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/route53profiles_profiles) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_availability_zone_count"></a> [availability\_zone\_count](#input\_availability\_zone\_count) | The number of AZs that should be broken out into subnets. This applies to both private and public subnets. | `number` | `null` | no |
| <a name="input_aws_region"></a> [aws\_region](#input\_aws\_region) | The AWS region where the VPC will be created. | `string` | n/a | yes |
| <a name="input_cloud_wan_core_network_id"></a> [cloud\_wan\_core\_network\_id](#input\_cloud\_wan\_core\_network\_id) | Id of Cloud-WAN core network to attach to. | `string` | `null` | no |
| <a name="input_cloudwatch_logs_endpoint_type"></a> [cloudwatch\_logs\_endpoint\_type](#input\_cloudwatch\_logs\_endpoint\_type) | Boolean value to determine CloudWatch Logs endpoint type. | `bool` | `false` | no |
| <a name="input_dhcp_options_domain_name"></a> [dhcp\_options\_domain\_name](#input\_dhcp\_options\_domain\_name) | The suffix domain name to use by default when resolving non Fully Qualified Domain Names. In other words, this is what ends up being the search value in the /etc/resolv.conf file. | `string` | `"compute.internal"` | no |
| <a name="input_dhcp_options_domain_name_servers"></a> [dhcp\_options\_domain\_name\_servers](#input\_dhcp\_options\_domain\_name\_servers) | List of name servers to configure in /etc/resolv.conf. | `list(string)` | <pre>[<br>  "AmazonProvidedDNS"<br>]</pre> | no |
| <a name="input_ecr_endpoint_type"></a> [ecr\_endpoint\_type](#input\_ecr\_endpoint\_type) | Value to determine ECR endpoint type. | `bool` | `false` | no |
| <a name="input_eip_timeout_delete"></a> [eip\_timeout\_delete](#input\_eip\_timeout\_delete) | How long to wait for an EIP to be deleted. | `string` | `"3m"` | no |
| <a name="input_eip_timeout_read"></a> [eip\_timeout\_read](#input\_eip\_timeout\_read) | How long to wait querying for information about EIPs. | `string` | `"15m"` | no |
| <a name="input_eip_timeout_update"></a> [eip\_timeout\_update](#input\_eip\_timeout\_update) | How long to wait for an EIP to be updated. | `string` | `"5m"` | no |
| <a name="input_enable_centralized_endpoints_profile"></a> [enable\_centralized\_endpoints\_profile](#input\_enable\_centralized\_endpoints\_profile) | Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled. | `bool` | `false` | no |
| <a name="input_enable_cgnat_subnet"></a> [enable\_cgnat\_subnet](#input\_enable\_cgnat\_subnet) | Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default | `bool` | `false` | no |
| <a name="input_enable_cloud_wan_vpc_attachment"></a> [enable\_cloud\_wan\_vpc\_attachment](#input\_enable\_cloud\_wan\_vpc\_attachment) | Enable vpc attachment to Cloud-WAN core network. | `bool` | `false` | no |
| <a name="input_enable_ecs_subnet"></a> [enable\_ecs\_subnet](#input\_enable\_ecs\_subnet) | Boolean to enable the ECS/K8's /20 subnet.  Disabled by default | `bool` | `false` | no |
| <a name="input_enable_local_managed_prefix_lists"></a> [enable\_local\_managed\_prefix\_lists](#input\_enable\_local\_managed\_prefix\_lists) | set to true to create local managed prefix lists | `bool` | `false` | no |
| <a name="input_enable_ue1_az3"></a> [enable\_ue1\_az3](#input\_enable\_ue1\_az3) | Boolean to enable the use of us-east-1-az3.  Disabled by default. | `bool` | `false` | no |
| <a name="input_endpoint_timeout_create"></a> [endpoint\_timeout\_create](#input\_endpoint\_timeout\_create) | Used for creating a VPC endpoint. | `string` | `"10m"` | no |
| <a name="input_endpoint_timeout_delete"></a> [endpoint\_timeout\_delete](#input\_endpoint\_timeout\_delete) | Used for destroying VPC endpoints. | `string` | `"10m"` | no |
| <a name="input_endpoint_timeout_update"></a> [endpoint\_timeout\_update](#input\_endpoint\_timeout\_update) | Used for VPC endpoint modifications. | `string` | `"10m"` | no |
| <a name="input_security_group_rule_inside_cidr_blocks"></a> [security\_group\_rule\_inside\_cidr\_blocks](#input\_security\_group\_rule\_inside\_cidr\_blocks) | The list of CIDR blocks used for ingress rules for the INSIDE security group. | `list(string)` | <pre>[<br>  "10.0.0.0/8",<br>  "172.0.0.0/8",<br>  "192.168.0.0/16"<br>]</pre> | no |
| <a name="input_security_group_rule_vpn_cidr_blocks"></a> [security\_group\_rule\_vpn\_cidr\_blocks](#input\_security\_group\_rule\_vpn\_cidr\_blocks) | The list of CIDR blocks used for ingress and egress rules for the VPN security group. | `list(string)` | <pre>[<br>  "10.0.0.0/8",<br>  "172.0.0.0/8",<br>  "192.168.0.0/16"<br>]</pre> | no |
| <a name="input_tag_cloud_wan_segment"></a> [tag\_cloud\_wan\_segment](#input\_tag\_cloud\_wan\_segment) | Set which cloud-wan segment the VPC attachement will join. | `string` | `null` | no |
| <a name="input_tag_environment"></a> [tag\_environment](#input\_tag\_environment) | Set the 'Environment' tag on all VPC components that support tagging. | `string` | n/a | yes |
| <a name="input_tag_name"></a> [tag\_name](#input\_tag\_name) | The name of the VPC. Set the 'Name' tag for the VPC, and is used in all other VPC components that support tagging. | `string` | n/a | yes |
| <a name="input_vpc_cidr_block"></a> [vpc\_cidr\_block](#input\_vpc\_cidr\_block) | The CIDR block for the VPC. | `string` | n/a | yes |

## Outputs

| Name | Description |
|------|-------------|
| <a name="output_aws_ec2_managed_prefix_list_eks_extended_subnets"></a> [aws\_ec2\_managed\_prefix\_list\_eks\_extended\_subnets](#output\_aws\_ec2\_managed\_prefix\_list\_eks\_extended\_subnets) | n/a |
| <a name="output_aws_ec2_managed_prefix_list_vpn"></a> [aws\_ec2\_managed\_prefix\_list\_vpn](#output\_aws\_ec2\_managed\_prefix\_list\_vpn) | n/a |
| <a name="output_aws_eip"></a> [aws\_eip](#output\_aws\_eip) | Elastic IP's used |
| <a name="output_aws_internet_gateway"></a> [aws\_internet\_gateway](#output\_aws\_internet\_gateway) | VPC Internet Gateway |
| <a name="output_aws_nat_gateway"></a> [aws\_nat\_gateway](#output\_aws\_nat\_gateway) | VPC NAT Gateway |
| <a name="output_aws_network_interface"></a> [aws\_network\_interface](#output\_aws\_network\_interface) | VPC Network Interfaces |
| <a name="output_aws_networkmanager_vpc_attachment"></a> [aws\_networkmanager\_vpc\_attachment](#output\_aws\_networkmanager\_vpc\_attachment) | n/a |
| <a name="output_aws_security_group_dmz"></a> [aws\_security\_group\_dmz](#output\_aws\_security\_group\_dmz) | DMZ Security Group |
| <a name="output_aws_security_group_inside"></a> [aws\_security\_group\_inside](#output\_aws\_security\_group\_inside) | Inside Security Group |
| <a name="output_aws_security_group_rule_dmz_egress_default"></a> [aws\_security\_group\_rule\_dmz\_egress\_default](#output\_aws\_security\_group\_rule\_dmz\_egress\_default) | DMZ egress default rule |
| <a name="output_aws_security_group_rule_dmz_ingress_http"></a> [aws\_security\_group\_rule\_dmz\_ingress\_http](#output\_aws\_security\_group\_rule\_dmz\_ingress\_http) | Allow ingress HTTP from inside CIDR. |
| <a name="output_aws_security_group_rule_dmz_ingress_https"></a> [aws\_security\_group\_rule\_dmz\_ingress\_https](#output\_aws\_security\_group\_rule\_dmz\_ingress\_https) | Allow ingress HTTPS from inside CIDR. |
| <a name="output_aws_security_group_rule_dmz_ingress_icmp"></a> [aws\_security\_group\_rule\_dmz\_ingress\_icmp](#output\_aws\_security\_group\_rule\_dmz\_ingress\_icmp) | Allow ingress ICMP from inside CIDR. |
| <a name="output_aws_security_group_rule_inside_egress_default"></a> [aws\_security\_group\_rule\_inside\_egress\_default](#output\_aws\_security\_group\_rule\_inside\_egress\_default) | Allow all egress traffic. |
| <a name="output_aws_security_group_rule_inside_ingress_grafana_cloud_agent"></a> [aws\_security\_group\_rule\_inside\_ingress\_grafana\_cloud\_agent](#output\_aws\_security\_group\_rule\_inside\_ingress\_grafana\_cloud\_agent) | Internal Grafana Agent Security Group |
| <a name="output_aws_security_group_rule_inside_ingress_http"></a> [aws\_security\_group\_rule\_inside\_ingress\_http](#output\_aws\_security\_group\_rule\_inside\_ingress\_http) | Allow HTTP ingress from inside CIDR. |
| <a name="output_aws_security_group_rule_inside_ingress_https"></a> [aws\_security\_group\_rule\_inside\_ingress\_https](#output\_aws\_security\_group\_rule\_inside\_ingress\_https) | Allow HTTPS ingres from inside CIDR. |
| <a name="output_aws_security_group_rule_inside_ingress_icmp"></a> [aws\_security\_group\_rule\_inside\_ingress\_icmp](#output\_aws\_security\_group\_rule\_inside\_ingress\_icmp) | Allow inbound icmp Serf traffic. This is the gossip protocol used by Consul. |
| <a name="output_aws_security_group_rule_inside_ingress_ne"></a> [aws\_security\_group\_rule\_inside\_ingress\_ne](#output\_aws\_security\_group\_rule\_inside\_ingress\_ne) | Internal Node Exporter Security Group |
| <a name="output_aws_security_group_rule_inside_ingress_openstack"></a> [aws\_security\_group\_rule\_inside\_ingress\_openstack](#output\_aws\_security\_group\_rule\_inside\_ingress\_openstack) | Allow Openstack inbound from inside CIDR. |
| <a name="output_aws_security_group_rule_inside_ingress_serf_tcp"></a> [aws\_security\_group\_rule\_inside\_ingress\_serf\_tcp](#output\_aws\_security\_group\_rule\_inside\_ingress\_serf\_tcp) | Allow inbound tcp Serf traffic. This is the gossip protocol used by Consul. |
| <a name="output_aws_security_group_rule_inside_ingress_serf_udp"></a> [aws\_security\_group\_rule\_inside\_ingress\_serf\_udp](#output\_aws\_security\_group\_rule\_inside\_ingress\_serf\_udp) | Allow inbound udp Serf traffic. This is the gossip protocol used by Consul. |
| <a name="output_aws_security_group_rule_inside_ingress_snmp"></a> [aws\_security\_group\_rule\_inside\_ingress\_snmp](#output\_aws\_security\_group\_rule\_inside\_ingress\_snmp) | Allow SNMP ingress from inside CIDR. |
| <a name="output_aws_security_group_rule_inside_ingress_ssh"></a> [aws\_security\_group\_rule\_inside\_ingress\_ssh](#output\_aws\_security\_group\_rule\_inside\_ingress\_ssh) | Allow SSH from inside |
| <a name="output_aws_security_group_rule_vpn_egress"></a> [aws\_security\_group\_rule\_vpn\_egress](#output\_aws\_security\_group\_rule\_vpn\_egress) | VPN Egress Allow ALL |
| <a name="output_aws_security_group_rule_vpn_ingress"></a> [aws\_security\_group\_rule\_vpn\_ingress](#output\_aws\_security\_group\_rule\_vpn\_ingress) | VPN Ingress Allow ALL |
| <a name="output_aws_security_group_rule_vpn_ingress_icmp"></a> [aws\_security\_group\_rule\_vpn\_ingress\_icmp](#output\_aws\_security\_group\_rule\_vpn\_ingress\_icmp) | VPN Ingress ICMP |
| <a name="output_aws_security_group_vpn"></a> [aws\_security\_group\_vpn](#output\_aws\_security\_group\_vpn) | VPN Security Group |
| <a name="output_aws_servicequotas_service_quota_vpc"></a> [aws\_servicequotas\_service\_quota\_vpc](#output\_aws\_servicequotas\_service\_quota\_vpc) | n/a |
| <a name="output_aws_subnet_eks"></a> [aws\_subnet\_eks](#output\_aws\_subnet\_eks) | n/a |
| <a name="output_aws_subnet_private"></a> [aws\_subnet\_private](#output\_aws\_subnet\_private) | Private subnets |
| <a name="output_aws_subnet_public"></a> [aws\_subnet\_public](#output\_aws\_subnet\_public) | Public Subnets |
| <a name="output_aws_subnetecs"></a> [aws\_subnetecs](#output\_aws\_subnetecs) | ECS Subnets |
| <a name="output_aws_vpc"></a> [aws\_vpc](#output\_aws\_vpc) | Created VPC |
| <a name="output_aws_vpc_dhcp_options"></a> [aws\_vpc\_dhcp\_options](#output\_aws\_vpc\_dhcp\_options) | VPC DHCP options |
| <a name="output_aws_vpc_dhcp_options_association"></a> [aws\_vpc\_dhcp\_options\_association](#output\_aws\_vpc\_dhcp\_options\_association) | VPC DHCP Options association |
| <a name="output_aws_vpc_endpoint"></a> [aws\_vpc\_endpoint](#output\_aws\_vpc\_endpoint) | S3 Endpoints |
| <a name="output_aws_vpc_endpoint_route_table_association"></a> [aws\_vpc\_endpoint\_route\_table\_association](#output\_aws\_vpc\_endpoint\_route\_table\_association) | Route Table used for S3 endpoint |
| <a name="output_aws_vpc_ipv4_cidr_block_association_secondary_cidr_eks"></a> [aws\_vpc\_ipv4\_cidr\_block\_association\_secondary\_cidr\_eks](#output\_aws\_vpc\_ipv4\_cidr\_block\_association\_secondary\_cidr\_eks) | n/a |
| <a name="output_local_networks"></a> [local\_networks](#output\_local\_networks) | n/a |
| <a name="output_local_secondary_eks_cidr"></a> [local\_secondary\_eks\_cidr](#output\_local\_secondary\_eks\_cidr) | output "cidrsubnets" { value = local.cidrsubnets } |
| <a name="output_vpc_id"></a> [vpc\_id](#output\_vpc\_id) | ID of created VPC. |

<!-- END_TF_DOCS -->

================
File: vpc/route_tables.tf
================
#Route tables
resource "aws_route_table" "private" {
  count  = local.az_count
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "route-table"
    Name      = "${var.tag_name} - AZ${count.index + 1} - Private Table"
  }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.vpc.id

  tags = {
    Component = "route-table"
    Name      = "${var.tag_name} - AZ ALL - Public Table"
  }
}

#Routes
resource "aws_route" "private_nat_gateway" {
  count                  = var.enable_cloud_wan_vpc_attachment == false ? local.az_count : 0
  destination_cidr_block = "0.0.0.0/0"
  nat_gateway_id         = element(aws_nat_gateway.nat_gateway.*.id, count.index)
  route_table_id         = element(aws_route_table.private.*.id, count.index)
}

resource "aws_route" "private_cloudWAN" {
  count                  = var.enable_cloud_wan_vpc_attachment == true ? local.az_count : 0
  destination_cidr_block = "0.0.0.0/0"
  core_network_arn       = "arn:aws:networkmanager::449228620267:core-network/${var.cloud_wan_core_network_id}"
  route_table_id         = element(aws_route_table.private.*.id, count.index)
}

resource "aws_route" "public_internet_gateway" {
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.internet_gateway.id
  route_table_id         = aws_route_table.public.id
}

resource "aws_route" "rfc-1918-public" {
  count                      = var.enable_cloud_wan_vpc_attachment == true ? local.az_count : 0
  destination_prefix_list_id = var.enable_local_managed_prefix_lists == true ? aws_ec2_managed_prefix_list.rfc-1918[0].id : data.aws_ec2_managed_prefix_list.rfc-1918.id
  core_network_arn           = "arn:aws:networkmanager::449228620267:core-network/${var.cloud_wan_core_network_id}"
  route_table_id             = element(aws_route_table.public.*.id, count.index)
  depends_on                 = [aws_networkmanager_vpc_attachment.vpc_attachment]
}

resource "aws_route" "rfc-1918-private" {
  count                      = var.enable_cloud_wan_vpc_attachment == true ? local.az_count : 0
  destination_prefix_list_id = var.enable_local_managed_prefix_lists == true ? aws_ec2_managed_prefix_list.rfc-1918[0].id : data.aws_ec2_managed_prefix_list.rfc-1918.id
  route_table_id             = element(aws_route_table.private.*.id, count.index)
  core_network_arn           = "arn:aws:networkmanager::449228620267:core-network/${var.cloud_wan_core_network_id}"
  depends_on                 = [aws_networkmanager_vpc_attachment.vpc_attachment]
}

#Route table associations
resource "aws_route_table_association" "private" {
  count          = local.az_count
  route_table_id = element(aws_route_table.private.*.id, count.index)
  subnet_id      = element(aws_subnet.private.*.id, count.index)
}

resource "aws_route_table_association" "public" {
  count          = local.az_count
  route_table_id = aws_route_table.public.id
  subnet_id      = element(aws_subnet.public.*.id, count.index)
}

resource "aws_route_table_association" "ecs" {
  count          = var.enable_ecs_subnet == true ? local.az_count : 0
  route_table_id = element(aws_route_table.private.*.id, count.index)
  subnet_id      = element(aws_subnet.ecs.*.id, count.index)
}

================
File: vpc/route53_profile_associations.tf
================
resource "aws_route53profiles_association" "centralized-endpoints-profile-association" {
  count       = var.enable_centralized_endpoints_profile ? 1 : 0
  name        = "centralized-endpoints-profile"
  profile_id  = local.centralized_endpoints_profile.id
  resource_id = aws_vpc.vpc.id
}

================
File: vpc/security_groups.tf
================
data "aws_ec2_managed_prefix_list" "vpn" {
  name = "VPN/Office CIDRs - shared"
}

data "aws_ec2_managed_prefix_list" "eks_extended_subnets" {
  name = "EKS extended 100.64 Subnets - shared"
}

resource "aws_security_group" "dmz" {
  description = "${var.tag_name} DMZ - Public - Internet Exposed - Security Group"
  name_prefix = "${var.tag_name}-sg-dmz-"
  vpc_id      = aws_vpc.vpc.id

  tags = {
    Component = "security-group"
    Name      = "${var.tag_name}-dmz-sg"
  }
}

resource "aws_security_group" "inside" {
  description = "${var.tag_name} INSIDE - Private Subnet - Security Group"
  name_prefix = "${var.tag_name}-sg-inside-"
  vpc_id      = aws_vpc.vpc.id

  tags = {
    Component = "security-group"
    Name      = "${var.tag_name}-inside-sg"
  }
}

resource "aws_security_group" "vpn" {
  description = "${var.tag_name} VPN Security Group"
  name_prefix = "${var.tag_name}-sg-vpn-"
  vpc_id      = aws_vpc.vpc.id

  tags = {
    Component = "security-group"
    Name      = "${var.tag_name}-vpn-sg"
  }
}

resource "aws_security_group_rule" "inside_ingress_grafana_cloud_agent" {
  description       = "Allow inbound grafana_cloud_agent traffic."
  from_port         = 53000
  protocol          = "tcp"
  to_port           = 53000
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "inside_ingress_ne" {
  description       = "Allow inbound node_exporter traffic."
  from_port         = 9100
  protocol          = "tcp"
  to_port           = 9100
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "dmz_egress_default" {
  cidr_blocks = [
    "0.0.0.0/0",
  ]

  description       = "Allow all outbound traffic."
  from_port         = 0
  protocol          = "-1"
  to_port           = 0
  type              = "egress"
  security_group_id = aws_security_group.dmz.id
}

resource "aws_security_group_rule" "dmz_ingress_http" {
  cidr_blocks = [
    "0.0.0.0/0",
  ]

  description       = "Allow inbound HTTP traffic from everywhere."
  from_port         = 80
  protocol          = "tcp"
  to_port           = 80
  type              = "ingress"
  security_group_id = aws_security_group.dmz.id
}

resource "aws_security_group_rule" "dmz_ingress_https" {
  description       = "Allow inbound HTTPS traffic from everywhere."
  from_port         = 443
  protocol          = "tcp"
  to_port           = 443
  type              = "ingress"
  security_group_id = aws_security_group.dmz.id
  cidr_blocks = [
    "0.0.0.0/0",
  ]
}

resource "aws_security_group_rule" "dmz_ingress_icmp" {
  description       = "Allow inbound ICMP traffic."
  from_port         = -1
  protocol          = "icmp"
  to_port           = -1
  type              = "ingress"
  security_group_id = aws_security_group.dmz.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "inside_egress_default" {
  description       = "Allow all outbound traffic."
  from_port         = 0
  protocol          = "-1"
  to_port           = 0
  type              = "egress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks = [
    "0.0.0.0/0",
  ]
}

resource "aws_security_group_rule" "inside_ingress_http" {
  description              = "Allow inbound HTTP traffic from the DMZ security group."
  from_port                = 80
  protocol                 = "tcp"
  to_port                  = 80
  type                     = "ingress"
  security_group_id        = aws_security_group.inside.id
  source_security_group_id = aws_security_group.dmz.id
}

resource "aws_security_group_rule" "inside_ingress_https" {
  description              = "Allow inbound HTTPS traffic from the DMZ security group."
  from_port                = 443
  protocol                 = "tcp"
  to_port                  = 443
  type                     = "ingress"
  security_group_id        = aws_security_group.inside.id
  source_security_group_id = aws_security_group.dmz.id
  prefix_list_ids          = var.enable_local_managed_prefix_lists == true ? [aws_ec2_managed_prefix_list.vpn[0].id] : [data.aws_ec2_managed_prefix_list.vpn.id]
}

resource "aws_security_group_rule" "inside_ingress_snmp" {
  description       = "Allow inbound HTTP traffic."
  from_port         = 161
  protocol          = "udp"
  to_port           = 161
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "inside_ingress_openstack" {
  cidr_blocks = [
    "169.254.255.16/30",
  ]

  description       = "Allow all inbound traffic from OpenStack (potential legacy)."
  from_port         = -1
  protocol          = "-1"
  security_group_id = aws_security_group.inside.id
  to_port           = -1
  type              = "ingress"
}

resource "aws_security_group_rule" "inside_ingress_ssh" {
  description       = "Allow inbound SSH traffic."
  from_port         = 22
  protocol          = "tcp"
  to_port           = 22
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
  prefix_list_ids = var.enable_local_managed_prefix_lists == true ? [
    aws_ec2_managed_prefix_list.vpn[0].id,
    aws_ec2_managed_prefix_list.eks_extended_subnets[0].id,
    ] : [
    data.aws_ec2_managed_prefix_list.vpn.id,
    data.aws_ec2_managed_prefix_list.eks_extended_subnets.id,
  ]
}

resource "aws_security_group_rule" "inside_ingress_serf_tcp" {
  description       = "Allow inbound Serf traffic. This is the gossip protocol used by Consul."
  from_port         = 8301
  protocol          = "tcp"
  to_port           = 8301
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "inside_ingress_serf_udp" {
  description       = "Allow inbound Serf traffic. This is the gossip protocol used by Consul."
  from_port         = 8301
  protocol          = "udp"
  to_port           = 8301
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "inside_ingress_icmp" {
  description       = "Allow inbound Serf traffic. This is the gossip protocol used by Consul."
  from_port         = -1
  protocol          = "icmp"
  to_port           = -1
  type              = "ingress"
  security_group_id = aws_security_group.inside.id
  cidr_blocks       = var.security_group_rule_inside_cidr_blocks
}

resource "aws_security_group_rule" "vpn_egress" {
  description       = "Allow all outbound traffic."
  from_port         = -1
  protocol          = "-1"
  to_port           = -1
  type              = "egress"
  security_group_id = aws_security_group.vpn.id
  cidr_blocks       = var.security_group_rule_vpn_cidr_blocks
}

resource "aws_security_group_rule" "vpn_ingress" {
  description       = "Allow all inbound traffic."
  from_port         = -1
  protocol          = "-1"
  to_port           = -1
  type              = "ingress"
  security_group_id = aws_security_group.vpn.id
  cidr_blocks = concat(
    var.security_group_rule_vpn_cidr_blocks,
    ["198.58.75.132/32"]
  )
}

resource "aws_security_group_rule" "vpn_ingress_icmp" {
  cidr_blocks = [
    "168.215.170.130/32",
  ]

  description       = "Allow all ICMP traffic."
  from_port         = -1
  protocol          = "icmp"
  security_group_id = aws_security_group.vpn.id
  to_port           = -1
  type              = "ingress"
}

================
File: vpc/subnets.tf
================
resource "aws_subnet" "private" {
  availability_zone_id = element(
    local.aws_availability_zones,
    count.index,
  )
  cidr_block                          = cidrsubnet(local.private_supernet, local.new_bits, count.index)
  count                               = local.az_count
  vpc_id                              = aws_vpc.vpc.id
  private_dns_hostname_type_on_launch = "resource-name"

  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ${count.index + 1} | INSIDE | Private Subnet"
  }
}

resource "aws_subnet" "public" {
  availability_zone_id = element(
    local.aws_availability_zones,
    count.index,
  )
  cidr_block                          = cidrsubnet(local.public_supernet, local.new_bits, count.index)
  count                               = local.az_count
  vpc_id                              = aws_vpc.vpc.id
  private_dns_hostname_type_on_launch = "resource-name"

  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ${count.index + 1} | DMZ | Public Subnet"
  }
}

locals {
  ecs_subnet = "10.26.0.0/20"
}

resource "aws_subnet" "ecs" {
  count = var.enable_ecs_subnet == true ? local.az_count : 0

  availability_zone_id = element(
    local.aws_availability_zones,
    count.index,
  )
  cidr_block                          = cidrsubnet(local.ecs_subnet, local.new_bits, count.index)
  vpc_id                              = aws_vpc_ipv4_cidr_block_association.secondary_cidr[0].vpc_id
  private_dns_hostname_type_on_launch = "resource-name"

  depends_on = [
    aws_vpc_ipv4_cidr_block_association.secondary_cidr[0]
  ]

  tags = {
    Component = "subnet"
    Name      = "${var.tag_name} | AZ${count.index + 1} | INSIDE | ECS Subnet"
  }
}

resource "aws_vpc_ipv4_cidr_block_association" "secondary_cidr" {
  count      = var.enable_ecs_subnet == true ? 1 : 0
  vpc_id     = aws_vpc.vpc.id
  cidr_block = local.ecs_subnet
}

================
File: vpc/variables.tf
================
### DHCP Options ###

variable "dhcp_options_domain_name" {
  description = "The suffix domain name to use by default when resolving non Fully Qualified Domain Names. In other words, this is what ends up being the search value in the /etc/resolv.conf file."
  type        = string
  default     = "compute.internal"
  nullable    = false
}

variable "dhcp_options_domain_name_servers" {
  description = "List of name servers to configure in /etc/resolv.conf."
  type        = list(string)
  default = [
    "AmazonProvidedDNS",
  ]
  nullable = false
}

### Elastic IP ###

variable "eip_timeout_delete" {
  description = "How long to wait for an EIP to be deleted."
  type        = string
  default     = "3m"
  nullable    = false
}

variable "eip_timeout_read" {
  description = "How long to wait querying for information about EIPs."
  type        = string
  default     = "15m"
  nullable    = false
}

variable "eip_timeout_update" {
  default     = "5m"
  description = "How long to wait for an EIP to be updated."
  type        = string
}

### Endpoint ###

variable "aws_region" {
  description = "The AWS region where the VPC will be created."
  type        = string
}

variable "endpoint_timeout_create" {
  description = "Used for creating a VPC endpoint."
  type        = string
  default     = "10m"
  nullable    = false
}

variable "endpoint_timeout_delete" {
  description = "Used for destroying VPC endpoints."
  type        = string
  default     = "10m"
  nullable    = false
}

variable "endpoint_timeout_update" {
  description = "Used for VPC endpoint modifications."
  type        = string
  default     = "10m"
  nullable    = false
}

### Security Group ###

variable "security_group_rule_inside_cidr_blocks" {
  description = "The list of CIDR blocks used for ingress rules for the INSIDE security group."
  type        = list(string)
  default = [
    "10.0.0.0/8",
    "172.0.0.0/8",
    "192.168.0.0/16",
  ]
  nullable = false
}

variable "security_group_rule_vpn_cidr_blocks" {
  description = "The list of CIDR blocks used for ingress and egress rules for the VPN security group."
  type        = list(string)
  default = [
    "10.0.0.0/8",
    "172.0.0.0/8",
    "192.168.0.0/16",
  ]
  nullable = false
}

### Tags ###

variable "tag_name" {
  description = "The name of the VPC. Set the 'Name' tag for the VPC, and is used in all other VPC components that support tagging."
  type        = string
}

variable "tag_environment" {
  description = "Set the 'Environment' tag on all VPC components that support tagging."
  type        = string
}

### VPC ###

variable "vpc_cidr_block" {
  description = "The CIDR block for the VPC."
  type        = string
}

## Subnets ##

variable "availability_zone_count" {
  description = "The number of AZs that should be broken out into subnets. This applies to both private and public subnets."
  type        = number
  default     = null
}

# If you have resources in AZ3 currently, you can enable this variable to use us-east-1-az3.
variable "enable_ue1_az3" {
  description = "Boolean to enable the use of us-east-1-az3.  Disabled by default."
  type        = bool
  default     = false
  nullable    = false
}

variable "enable_ecs_subnet" {
  description = "Boolean to enable the ECS/K8's /20 subnet.  Disabled by default"
  type        = bool
  default     = false
  nullable    = false
}

variable "enable_cgnat_subnet" {
  description = "Boolean to enable the CarrierGradeNAT IP ranges for EKS/k8s.  Disabled by default"
  type        = bool
  default     = false
  nullable    = false
}

variable "enable_cloud_wan_vpc_attachment" {
  description = "Enable vpc attachment to Cloud-WAN core network."
  type        = bool
  default     = false
}

variable "cloud_wan_core_network_id" {
  description = "Id of Cloud-WAN core network to attach to."
  type        = string
  default     = null
}

variable "tag_cloud_wan_segment" {
  description = "Set which cloud-wan segment the VPC attachement will join."
  type        = string
  default     = null
}

variable "enable_local_managed_prefix_lists" {
  description = "set to true to create local managed prefix lists"
  type        = bool
  default     = false
}

# Flag to determine which endpoint to create
# IMPORTANT: In the case of centralized endpoints, the appropriate Private Hosted Zone (PHZ) and the record must already exist at the Egress VPC
variable "ecr_endpoint_type" {
  description = "Value to determine ECR endpoint type."
  type        = bool
  default     = false
}

variable "cloudwatch_logs_endpoint_type" {
  description = "Boolean value to determine CloudWatch Logs endpoint type."
  type        = bool
  default     = false
}

# Only enable this if you are on CloudWAN and the profile is created and shared out.
variable "enable_centralized_endpoints_profile" {
  description = "Boolean value to determine if the centralized endpoints profile should be associated with the VPC. true = enabled, false = disabled."
  type        = bool
  default     = false
}

================
File: vpc/versions.tf
================
terraform {
  required_version = ">= 1.5"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}

================
File: vpc/vpc_dependency_graph.json
================
{
  "repo_name": "vpc",
  "dependencies": {
    "aws_internet_gateway.internet_gateway": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint.s3_endpoint": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association": [
      "aws_vpc_endpoint.s3_endpoint",
      "aws_route_table.private"
    ],
    "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association": [
      "aws_vpc_endpoint.s3_endpoint",
      "aws_route_table.public"
    ],
    "aws_vpc_endpoint.dynamodb_endpoint": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association": [
      "aws_vpc_endpoint.dynamodb_endpoint",
      "aws_route_table.private"
    ],
    "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association": [
      "aws_route_table.public",
      "aws_vpc_endpoint.dynamodb_endpoint"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc.vpc",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_vpc_endpoint.ecr_dkr_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_endpoint.cloudwatch_logs_endpoint": [
      "aws_vpc.vpc",
      "aws_subnet.private",
      "aws_security_group.endpoint-sg"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks": [
      "aws_vpc.vpc",
      "aws_servicequotas_service_quota.vpc"
    ],
    "aws_route.private_nat_gateway": [
      "aws_nat_gateway.nat_gateway",
      "aws_route_table.private"
    ],
    "aws_route.private_cloudWAN": [
      "aws_route_table.private"
    ],
    "aws_route.public_internet_gateway": [
      "aws_route_table.public",
      "aws_internet_gateway.internet_gateway"
    ],
    "aws_route.rfc-1918-public": [
      "aws_route_table.public",
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_ec2_managed_prefix_list.rfc-1918"
    ],
    "aws_route.rfc-1918-private": [
      "aws_networkmanager_vpc_attachment.vpc_attachment",
      "aws_ec2_managed_prefix_list.rfc-1918",
      "aws_route_table.private"
    ],
    "aws_route_table_association.private": [
      "aws_subnet.private",
      "aws_route_table.private"
    ],
    "aws_route_table_association.public": [
      "aws_route_table.public",
      "aws_subnet.public"
    ],
    "aws_route_table_association.ecs": [
      "aws_subnet.ecs",
      "aws_route_table.private"
    ],
    "aws_network_interface.network_interface": [
      "aws_subnet.public"
    ],
    "aws_route53profiles_association.centralized-endpoints-profile-association": [
      "aws_vpc.vpc"
    ],
    "aws_network_acl.network_acl": [
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr"
    ],
    "aws_network_acl_rule.Allow_10_egress_acl_rule": [
      "aws_vpc.vpc",
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_20_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_30_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_40_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_50_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_60_egress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_10_ingress_acl_rule": [
      "aws_vpc.vpc",
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_20_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_30_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_40_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Deny_50_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl_rule.Allow_60_ingress_acl_rule": [
      "aws_network_acl.network_acl"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_subnet.public",
      "aws_internet_gateway.internet_gateway",
      "aws_eip.eip"
    ],
    "aws_security_group_rule.inside_ingress_grafana_cloud_agent": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_ne": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.dmz_egress_default": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_http": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_https": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.dmz_ingress_icmp": [
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_egress_default": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_http": [
      "aws_security_group.inside",
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_ingress_https": [
      "aws_security_group.inside",
      "aws_ec2_managed_prefix_list.vpn",
      "aws_security_group.dmz"
    ],
    "aws_security_group_rule.inside_ingress_snmp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_openstack": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_ssh": [
      "aws_security_group.inside",
      "aws_ec2_managed_prefix_list.vpn",
      "aws_ec2_managed_prefix_list.eks_extended_subnets"
    ],
    "aws_security_group_rule.inside_ingress_serf_tcp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_serf_udp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.inside_ingress_icmp": [
      "aws_security_group.inside"
    ],
    "aws_security_group_rule.vpn_egress": [
      "aws_security_group.vpn"
    ],
    "aws_security_group_rule.vpn_ingress": [
      "aws_security_group.vpn"
    ],
    "aws_security_group_rule.vpn_ingress_icmp": [
      "aws_security_group.vpn"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr": [
      "aws_vpc.vpc"
    ],
    "aws_vpc_dhcp_options_association.dhcp_options_association": [
      "aws_vpc.vpc",
      "aws_vpc_dhcp_options.dhcp_options"
    ],
    "aws_flow_log.vpc_flow_log": [
      "aws_vpc.vpc"
    ]
  },
  "dependents": {
    "aws_vpc.vpc": [
      "aws_internet_gateway.internet_gateway",
      "aws_vpc_endpoint.s3_endpoint",
      "aws_vpc_endpoint.dynamodb_endpoint",
      "aws_security_group.endpoint-sg",
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks",
      "aws_route53profiles_association.centralized-endpoints-profile-association",
      "aws_network_acl_rule.Allow_10_egress_acl_rule",
      "aws_network_acl_rule.Allow_10_ingress_acl_rule",
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr",
      "aws_vpc_dhcp_options_association.dhcp_options_association",
      "aws_flow_log.vpc_flow_log"
    ],
    "aws_vpc_endpoint.s3_endpoint": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association"
    ],
    "aws_route_table.private": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association",
      "aws_route.private_nat_gateway",
      "aws_route.private_cloudWAN",
      "aws_route.rfc-1918-private",
      "aws_route_table_association.private",
      "aws_route_table_association.ecs"
    ],
    "aws_route_table.public": [
      "aws_vpc_endpoint_route_table_association.s3_endpoint_public_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association",
      "aws_route.public_internet_gateway",
      "aws_route.rfc-1918-public",
      "aws_route_table_association.public"
    ],
    "aws_vpc_endpoint.dynamodb_endpoint": [
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_route_table_association",
      "aws_vpc_endpoint_route_table_association.dynamodb_endpoint_public_route_table_association"
    ],
    "aws_ec2_managed_prefix_list.rfc-1918": [
      "aws_security_group.endpoint-sg",
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_subnet.private": [
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint",
      "aws_route_table_association.private"
    ],
    "aws_security_group.endpoint-sg": [
      "aws_vpc_endpoint.ecr_dkr_endpoint",
      "aws_vpc_endpoint.cloudwatch_logs_endpoint"
    ],
    "aws_servicequotas_service_quota.vpc": [
      "aws_vpc_ipv4_cidr_block_association.secondary_cidr_eks"
    ],
    "aws_nat_gateway.nat_gateway": [
      "aws_route.private_nat_gateway"
    ],
    "aws_internet_gateway.internet_gateway": [
      "aws_route.public_internet_gateway",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_networkmanager_vpc_attachment.vpc_attachment": [
      "aws_route.rfc-1918-public",
      "aws_route.rfc-1918-private"
    ],
    "aws_subnet.public": [
      "aws_route_table_association.public",
      "aws_network_interface.network_interface",
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_subnet.ecs": [
      "aws_route_table_association.ecs"
    ],
    "aws_vpc_ipv4_cidr_block_association.secondary_cidr": [
      "aws_network_acl.network_acl"
    ],
    "aws_network_acl.network_acl": [
      "aws_network_acl_rule.Allow_10_egress_acl_rule",
      "aws_network_acl_rule.Allow_20_egress_acl_rule",
      "aws_network_acl_rule.Deny_30_egress_acl_rule",
      "aws_network_acl_rule.Deny_40_egress_acl_rule",
      "aws_network_acl_rule.Deny_50_egress_acl_rule",
      "aws_network_acl_rule.Allow_60_egress_acl_rule",
      "aws_network_acl_rule.Allow_10_ingress_acl_rule",
      "aws_network_acl_rule.Allow_20_ingress_acl_rule",
      "aws_network_acl_rule.Deny_30_ingress_acl_rule",
      "aws_network_acl_rule.Deny_40_ingress_acl_rule",
      "aws_network_acl_rule.Deny_50_ingress_acl_rule",
      "aws_network_acl_rule.Allow_60_ingress_acl_rule"
    ],
    "aws_eip.eip": [
      "aws_nat_gateway.nat_gateway"
    ],
    "aws_security_group.inside": [
      "aws_security_group_rule.inside_ingress_grafana_cloud_agent",
      "aws_security_group_rule.inside_ingress_ne",
      "aws_security_group_rule.inside_egress_default",
      "aws_security_group_rule.inside_ingress_http",
      "aws_security_group_rule.inside_ingress_https",
      "aws_security_group_rule.inside_ingress_snmp",
      "aws_security_group_rule.inside_ingress_openstack",
      "aws_security_group_rule.inside_ingress_ssh",
      "aws_security_group_rule.inside_ingress_serf_tcp",
      "aws_security_group_rule.inside_ingress_serf_udp",
      "aws_security_group_rule.inside_ingress_icmp"
    ],
    "aws_security_group.dmz": [
      "aws_security_group_rule.dmz_egress_default",
      "aws_security_group_rule.dmz_ingress_http",
      "aws_security_group_rule.dmz_ingress_https",
      "aws_security_group_rule.dmz_ingress_icmp",
      "aws_security_group_rule.inside_ingress_http",
      "aws_security_group_rule.inside_ingress_https"
    ],
    "aws_ec2_managed_prefix_list.vpn": [
      "aws_security_group_rule.inside_ingress_https",
      "aws_security_group_rule.inside_ingress_ssh"
    ],
    "aws_ec2_managed_prefix_list.eks_extended_subnets": [
      "aws_security_group_rule.inside_ingress_ssh"
    ],
    "aws_security_group.vpn": [
      "aws_security_group_rule.vpn_egress",
      "aws_security_group_rule.vpn_ingress",
      "aws_security_group_rule.vpn_ingress_icmp"
    ],
    "aws_vpc_dhcp_options.dhcp_options": [
      "aws_vpc_dhcp_options_association.dhcp_options_association"
    ]
  },
  "cross_repo_references": [
    "external.enable_cloud_wan_vpc_attachment",
    "external.aws_availability_zones.good_zone_ids",
    "external.aws_ec2_managed_prefix_list.eks_extended_subnets",
    "external.security_group_rule_vpn_cidr_blocks",
    "external.dhcp_options_domain_name",
    "external.aws_region",
    "external.enable_ecs_subnet",
    "external.endpoint_timeout_delete",
    "external.enable_ue1_az3",
    "external.eip_timeout_read",
    "external.dhcp_options_domain_name_servers",
    "external.ecr_endpoint_type",
    "external.availability_zone_count",
    "external.aws_caller_identity.current",
    "external.aws_ec2_managed_prefix_list.vpn",
    "external.aws_availability_zones.availability_zones",
    "external.enable_cgnat_subnet",
    "external.cloudwatch_logs_endpoint_type",
    "external.cloud_wan_core_network_id",
    "external.security_group_rule_inside_cidr_blocks",
    "external.enable_centralized_endpoints_profile",
    "external.eip_timeout_update",
    "external.tag_environment",
    "external.endpoint_timeout_create",
    "external.enable_local_managed_prefix_lists",
    "external.tag_cloud_wan_segment",
    "external.vpc_cidr_block",
    "external.endpoint_timeout_update",
    "external.eip_timeout_delete",
    "external.tag_name"
  ],
  "outputs": [
    "aws_vpc_dhcp_options",
    "aws_vpc_dhcp_options_association",
    "aws_eip",
    "aws_vpc_endpoint",
    "aws_vpc_endpoint_route_table_association",
    "aws_internet_gateway",
    "aws_nat_gateway",
    "aws_network_interface",
    "aws_security_group_dmz",
    "aws_security_group_rule_dmz_egress_default",
    "aws_security_group_rule_dmz_ingress_http",
    "aws_security_group_rule_dmz_ingress_https",
    "aws_security_group_rule_dmz_ingress_icmp",
    "aws_security_group_inside",
    "aws_security_group_rule_inside_egress_default",
    "aws_security_group_rule_inside_ingress_http",
    "aws_security_group_rule_inside_ingress_https",
    "aws_security_group_rule_inside_ingress_snmp",
    "aws_security_group_rule_inside_ingress_openstack",
    "aws_security_group_rule_inside_ingress_ssh",
    "aws_security_group_rule_inside_ingress_serf_tcp",
    "aws_security_group_rule_inside_ingress_serf_udp",
    "aws_security_group_rule_inside_ingress_icmp",
    "aws_security_group_rule_inside_ingress_grafana_cloud_agent",
    "aws_security_group_rule_inside_ingress_ne",
    "aws_security_group_vpn",
    "aws_security_group_rule_vpn_egress",
    "aws_security_group_rule_vpn_ingress",
    "aws_security_group_rule_vpn_ingress_icmp",
    "aws_subnet_private",
    "aws_subnet_public",
    "aws_subnetecs",
    "aws_vpc",
    "vpc_id",
    "cidrsubnets",
    "local_secondary_eks_cidr",
    "local_networks",
    "aws_vpc_ipv4_cidr_block_association_secondary_cidr_eks",
    "aws_servicequotas_service_quota_vpc",
    "aws_subnet_eks",
    "good_zone_ids",
    "aws_ec2_managed_prefix_list_vpn",
    "aws_ec2_managed_prefix_list_eks_extended_subnets",
    "aws_networkmanager_vpc_attachment"
  ],
  "metadata": {
    "total_resources": 72,
    "resources_with_dependencies": 56,
    "resources_that_are_dependencies": 23,
    "cross_repo_refs_count": 30,
    "outputs_count": 44,
    "generated_from": ".",
    "repo_name": "vpc"
  }
}

================
File: vpc/vpc.tf
================
resource "aws_vpc" "vpc" {
  cidr_block           = var.vpc_cidr_block
  enable_dns_hostnames = true

  tags = {
    Name = var.tag_name
  }
}




================================================================
End of Codebase
================================================================
